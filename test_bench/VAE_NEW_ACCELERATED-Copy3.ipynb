{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pma/.local/lib/python3.6/site-packages/numba/core/decorators.py:255: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, prange, njit\n",
    "from blimpy import Waterfall\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from synthetic_real import create_true, create_full_cadence, create_false, create_true_single_shot, create_true_faster\n",
    "from scipy import spatial\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.insert(1, '../ML_Training')\n",
    "sys.path.insert(2, '../GBT_pipeline')\n",
    "from preprocess import get_data\n",
    "from single_search import search_model_eval, combine\n",
    "\n",
    "# tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6, 16, 256)\n",
      "(60000, 16, 256, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You must add noise in the image to specify SNR!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7cfb4e2b818f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrue_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_full_cadence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_SAMPLES\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mtrue_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_ED\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt_home/pma/peterma-ml/BL-Reservoir/development_env/F-Engine_Search/test_bench/synthetic_real.py\u001b[0m in \u001b[0;36mcreate_full_cadence\u001b[0;34m(function, samples, plate, snr_base, snr_range, factor)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m#     print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msnr_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msnr_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt_home/pma/peterma-ml/BL-Reservoir/development_env/F-Engine_Search/test_bench/synthetic_real.py\u001b[0m in \u001b[0;36mcreate_true\u001b[0;34m(plate, snr_base, snr_range, factor)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0msnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msnr_range\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msnr_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mcadence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnew_cadence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0minjection_plate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mnew_cadence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt_home/pma/peterma-ml/BL-Reservoir/development_env/F-Engine_Search/test_bench/synthetic_real.py\u001b[0m in \u001b[0;36mnew_cadence\u001b[0;34m(data, snr)\u001b[0m\n\u001b[1;32m     57\u001b[0m     signal = frame.add_signal(stg.constant_path(f_start=frame.get_frequency(index=start),\n\u001b[1;32m     58\u001b[0m                                               drift_rate=drift*u.Hz/u.s),\n\u001b[0;32m---> 59\u001b[0;31m                             \u001b[0mstg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_t_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                             \u001b[0mstg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_f_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwitdh\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                             stg.constant_bp_profile(level=1))\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/setigen/frame.py\u001b[0m in \u001b[0;36mget_intensity\u001b[0;34m(self, snr)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \"\"\"\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_std\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You must add noise in the image to specify SNR!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msnr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_std\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtchans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You must add noise in the image to specify SNR!"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "NUM_SAMPLES = 10000\n",
    "plate = np.load('../../real_filtered.npy')\n",
    "\n",
    "@jit(nopython=True)\n",
    "def pre_proc(data):\n",
    "    data = np.log(data)\n",
    "    data= data - data.min()\n",
    "    data = data/data.max()\n",
    "    return data\n",
    "\n",
    "@jit(parallel=True)\n",
    "def load_data_ED(data):\n",
    "    print(data.shape)\n",
    "    data_transform =  np.zeros((data.shape[0],6, 16,256,1))\n",
    "    for i in prange(data.shape[0]):\n",
    "        data_transform[i,:,:,:,0]  = pre_proc(data[i,:,:,:] )\n",
    "    return data_transform\n",
    "\n",
    "def combine(data):\n",
    "    new_data = np.zeros((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],data.shape[4]))\n",
    "    for i in prange(data.shape[0]):\n",
    "        new_data[i*data.shape[1] : (i+1)*data.shape[1],:,:,:] = data[i,:,:,:,:]\n",
    "    return new_data\n",
    "\n",
    "data = abs(create_full_cadence(create_true, plate = plate, samples =  NUM_SAMPLES, snr_base=300, snr_range=20,factor=1))\n",
    "data = combine(load_data_ED(data))\n",
    "print(data.shape)\n",
    "\n",
    "true_data = abs(create_full_cadence(create_true, plate = plate, samples = NUM_SAMPLES*6, snr_base=300, snr_range=20, factor=1))\n",
    "true_data = load_data_ED(true_data)\n",
    "\n",
    "cadence_set = ['../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_58929_GJ380_fine.h5',\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_59291_HIP48887_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_59650_GJ380_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_60004_HIP48924_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_60354_GJ380_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_60706_HIP48954_fine.h5\"\n",
    "                ]\n",
    "\n",
    "false_data_1 = get_data(cadence_set, 1543, 1678)\n",
    "false_data_0 = abs(create_full_cadence(create_false, plate = plate, samples = NUM_SAMPLES*6, snr_base=300, snr_range=20))\n",
    "false_data_0 = load_data_ED(false_data_0)\n",
    "\n",
    "false_data = np.concatenate((false_data_1[:50000],false_data_0[:10000]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1000, 6, 16, 256)\n",
      "(6000, 16, 256, 1)\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "(6000, 6, 16, 256)\n",
      "Getting Data\n",
      "reshaping Data\n",
      "Combining Cadence\n",
      "Data Load Execution Time: 4.423967361450195\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "(6000, 6, 16, 256)\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES_TEST=1000\n",
    "data_test = abs(create_full_cadence(create_true, plate = plate, samples =  NUM_SAMPLES_TEST, snr_base=300, snr_range=20,factor=1))\n",
    "start = time.time()\n",
    "data_test = combine(load_data_ED(data_test))\n",
    "print(data_test.shape)\n",
    "\n",
    "true_data_test = abs(create_full_cadence(create_true, plate = plate, samples = NUM_SAMPLES_TEST*6, snr_base=300, snr_range=20, factor=1))\n",
    "start = time.time()\n",
    "true_data_test = load_data_ED(true_data_test)\n",
    "\n",
    "cadence_set = ['../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_58929_GJ380_fine.h5',\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_59291_HIP48887_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_59650_GJ380_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_60004_HIP48924_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_60354_GJ380_fine.h5\",\n",
    "                \"../../../../../../../mnt_blpd7/datax2/dl/GBT_57636_60706_HIP48954_fine.h5\"\n",
    "                ]\n",
    "false_data_test_1 = get_data(cadence_set, 1260, 1276)\n",
    "\n",
    "false_data_test_0 = abs(create_full_cadence(create_false, plate = plate, samples = NUM_SAMPLES_TEST*6, snr_base=300, snr_range=20))\n",
    "start = time.time()\n",
    "false_data_test_0 = load_data_ED(false_data_test_0)\n",
    "\n",
    "false_data_test = np.concatenate((false_data_test_1[:5000],false_data_test_0[:1000]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder,  **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.true_loss_tracker = keras.metrics.Mean(name=\"true_loss\")\n",
    "        self.false_loss_tracker = keras.metrics.Mean(name=\"false_loss\")\n",
    "        \n",
    "        self.total_loss_tracker_validation = keras.metrics.Mean(name=\"val_total_loss\")\n",
    "        self.reconstruction_loss_tracker_validation = keras.metrics.Mean(\n",
    "            name=\"val_reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker_validation = keras.metrics.Mean(name=\"val_kl_loss\")\n",
    "        self.false_loss_tracker_validation = keras.metrics.Mean(name=\"val_false_loss\")\n",
    "        self.true_loss_tracker_validation = keras.metrics.Mean(name=\"val_true_loss\")\n",
    "        \n",
    "        alpha=100\n",
    "        beta=1\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.count=1\n",
    "\n",
    "    @tf.function\n",
    "    def loss_diff(self, a,b):\n",
    "        return 1/ self.loss_same(a,b)\n",
    "   \n",
    "    @tf.function\n",
    "    def loss_same(self, a,b):\n",
    "        return tf.math.reduce_mean(tf.math.reduce_euclidean_norm(a-b, axis=1))\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def true_clustering(self, true_data,training=True):\n",
    "        similarity = 0\n",
    "        difference = 0\n",
    "        same = 0\n",
    "        a1 = self.encoder(true_data[:,0,:,:,:], training)[2]\n",
    "        b = self.encoder(true_data[:,1,:,:,:], training)[2]\n",
    "        a2 = self.encoder(true_data[:,2,:,:,:],training)[2]\n",
    "        c = self.encoder(true_data[:,3,:,:,:], training)[2]\n",
    "        a3 = self.encoder(true_data[:,4,:,:,:], training)[2]\n",
    "        d = self.encoder(true_data[:,5,:,:,:], training)[2]\n",
    "\n",
    "        difference += self.loss_diff(a1,b)\n",
    "        difference += self.loss_diff(a1,c)\n",
    "        difference += self.loss_diff(a1,d)\n",
    "\n",
    "        difference += self.loss_diff(a2,b)\n",
    "        difference += self.loss_diff(a2,c)\n",
    "        difference += self.loss_diff(a2,d)\n",
    "\n",
    "        difference += self.loss_diff(a3,b)\n",
    "        difference += self.loss_diff(a3,c)\n",
    "        difference += self.loss_diff(a3,d)\n",
    "\n",
    "        same += self.loss_same(a1,a2)\n",
    "        same += self.loss_same(a1,a3)\n",
    "        same += self.loss_same(a2,a3)\n",
    "        \n",
    "        same += self.loss_same(b,c)\n",
    "        same += self.loss_same(c,d)\n",
    "        same += self.loss_same(b,d)\n",
    "        \n",
    "\n",
    "        similarity += 1.5*same+difference\n",
    "        return similarity\n",
    "    \n",
    "    @tf.function\n",
    "    def false_clustering(self, false_data, training=True):\n",
    "#         print(false_data.shape)\n",
    "        similarity = 0\n",
    "        difference = 0\n",
    "        same = 0\n",
    "        a1 = self.encoder(false_data[:,0,:,:,:], training)[2]\n",
    "        b = self.encoder(false_data[:,1,:,:,:], training)[2]\n",
    "        a2 = self.encoder(false_data[:,2,:,:,:],training)[2]\n",
    "        c = self.encoder(false_data[:,3,:,:,:], training)[2]\n",
    "        a3 = self.encoder(false_data[:,4,:,:,:], training)[2]\n",
    "        d = self.encoder(false_data[:,5,:,:,:], training)[2]\n",
    "\n",
    "        difference += self.loss_same(a1,b)\n",
    "        difference += self.loss_same(a1,c)\n",
    "        difference += self.loss_same(a1,d)\n",
    "\n",
    "        difference += self.loss_same(a2,b)\n",
    "        difference += self.loss_same(a2,c)\n",
    "        difference += self.loss_same(a2,d)\n",
    "\n",
    "        difference += self.loss_same(a3,b)\n",
    "        difference += self.loss_same(a3,c)\n",
    "        difference += self.loss_same(a3,d)\n",
    "\n",
    "        same += self.loss_same(a1,a2)\n",
    "        same += self.loss_same(a1,a3)\n",
    "        same += self.loss_same(a2,a3)\n",
    "        \n",
    "        same += self.loss_same(b,c)\n",
    "        same += self.loss_same(c,d)\n",
    "        same += self.loss_same(b,d)\n",
    "        \n",
    "        similarity += 1.5*same+difference\n",
    "        return similarity\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        self.count+=1\n",
    "        cluster_loss =0\n",
    "        x, y = data\n",
    "        true_data = x[1]\n",
    "        false_data = x[2]\n",
    "        x= x[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(y, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "            false_loss = self.false_clustering(false_data)\n",
    "            true_loss = self.true_clustering(true_data)\n",
    "            total_loss = reconstruction_loss + self.beta*kl_loss +self.alpha*(3*true_loss+false_loss)\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.false_loss_tracker.update_state(false_loss)\n",
    "        self.true_loss_tracker.update_state(true_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"false_loss\": self.false_loss_tracker.result(),\n",
    "            \"true_loss\": self.true_loss_tracker.result()\n",
    "        }\n",
    "    \n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        true_data = x[1]\n",
    "        false_data = x[2]\n",
    "        x= x[0]\n",
    "        z_mean, z_log_var, z = self.encoder(x, training=False)\n",
    "        reconstruction = self.decoder(z, training=False)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(y, reconstruction), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        false_loss = self.false_clustering(false_data, False)\n",
    "        true_loss = self.true_clustering(true_data, False)\n",
    "        total_loss = reconstruction_loss + self.beta*kl_loss +self.alpha*(true_loss+3*false_loss)\n",
    "        \n",
    "        \n",
    "        self.total_loss_tracker_validation.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker_validation.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker_validation.update_state(kl_loss)\n",
    "        self.false_loss_tracker_validation.update_state(false_loss)\n",
    "        self.true_loss_tracker_validation.update_state(true_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker_validation.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker_validation.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker_validation.result(),\n",
    "            \"false_loss\": self.false_loss_tracker_validation.result(),\n",
    "            \"true_loss\": self.true_loss_tracker_validation.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_creation(inputs):\n",
    "    z_mean = inputs[0]\n",
    "    z_log_var = inputs[1]\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "tensorflow      INFO     Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 16, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 128, 16)   160         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 128, 16)   2320        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 64, 32)    4640        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 64, 32)    9248        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 64, 32)    9248        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 2, 32, 64)    18496       conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 2, 32, 64)    36928       conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 2, 32, 64)    36928       conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 1, 16, 64)    36928       conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1024)         0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          524800      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 8)            4104        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 8)            4104        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_5 (Sampling)           (None, 8)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 687,904\n",
      "Trainable params: 687,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               4608      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 1, 16, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_50 (Conv2DT (None, 2, 32, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_51 (Conv2DT (None, 4, 64, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_52 (Conv2DT (None, 4, 64, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_53 (Conv2DT (None, 4, 64, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_54 (Conv2DT (None, 4, 64, 32)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_55 (Conv2DT (None, 4, 64, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_56 (Conv2DT (None, 8, 128, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_57 (Conv2DT (None, 8, 128, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_58 (Conv2DT (None, 16, 256, 16)       2320      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_59 (Conv2DT (None, 16, 256, 1)        145       \n",
      "=================================================================\n",
      "Total params: 721,681\n",
      "Trainable params: 721,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    latent_dim = 8\n",
    "    dens_lay = 512\n",
    "    kernel = (3,3)\n",
    "    encoder_inputs = keras.Input(shape=(16, 256, 1))\n",
    "    x = layers.Conv2D(16, kernel, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "    x = layers.Conv2D(16, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, kernel, activation=\"relu\", strides=2,padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(dens_lay, activation=\"relu\")(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    encoder.summary()\n",
    "    \n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(dens_lay, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Dense(1* 16 * 64, activation=\"relu\")(x)\n",
    "    x = layers.Reshape((1,16, 64))(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel, activation=\"relu\", strides=2,padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(32, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1, kernel, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    decoder.summary()\n",
    "\n",
    "    vae = VAE(encoder, decoder)\n",
    "    vae.compile(optimizer=keras.optimizers.Adam(lr=0.0005))\n",
    "    return vae\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2700\n",
      "12/12 [==============================] - 21s 2s/step - loss: 2256.5258 - reconstruction_loss: 1893.4193 - kl_loss: 97.7841 - false_loss: 0.1052 - true_loss: 1.2206 - val_loss: 6768.1431 - val_reconstruction_loss: 1897.6704 - val_kl_loss: 98.6703 - val_false_loss: 15.4840 - val_true_loss: 1.2662\n",
      "Epoch 2/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.8291 - reconstruction_loss: 1893.5651 - kl_loss: 97.3764 - false_loss: 0.1052 - true_loss: 1.2206 - val_loss: 6767.4814 - val_reconstruction_loss: 1897.6694 - val_kl_loss: 98.6713 - val_false_loss: 15.4818 - val_true_loss: 1.2661\n",
      "Epoch 3/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.1651 - reconstruction_loss: 1893.1276 - kl_loss: 97.7497 - false_loss: 0.1052 - true_loss: 1.2205 - val_loss: 6766.8164 - val_reconstruction_loss: 1897.6683 - val_kl_loss: 98.6718 - val_false_loss: 15.4796 - val_true_loss: 1.2661\n",
      "Epoch 4/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.0102 - reconstruction_loss: 1893.2274 - kl_loss: 98.2253 - false_loss: 0.1052 - true_loss: 1.2204 - val_loss: 6766.1479 - val_reconstruction_loss: 1897.6676 - val_kl_loss: 98.6724 - val_false_loss: 15.4774 - val_true_loss: 1.2660\n",
      "Epoch 5/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.9196 - reconstruction_loss: 1893.4774 - kl_loss: 98.0546 - false_loss: 0.1052 - true_loss: 1.2204 - val_loss: 6765.4814 - val_reconstruction_loss: 1897.6664 - val_kl_loss: 98.6744 - val_false_loss: 15.4752 - val_true_loss: 1.2660\n",
      "Epoch 6/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.1548 - reconstruction_loss: 1893.4716 - kl_loss: 99.4031 - false_loss: 0.1052 - true_loss: 1.2203 - val_loss: 6764.8184 - val_reconstruction_loss: 1897.6654 - val_kl_loss: 98.6749 - val_false_loss: 15.4730 - val_true_loss: 1.2659\n",
      "Epoch 7/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.2759 - reconstruction_loss: 1893.4321 - kl_loss: 98.6958 - false_loss: 0.1052 - true_loss: 1.2202 - val_loss: 6764.1553 - val_reconstruction_loss: 1897.6646 - val_kl_loss: 98.6756 - val_false_loss: 15.4708 - val_true_loss: 1.2658\n",
      "Epoch 8/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0836 - reconstruction_loss: 1893.9287 - kl_loss: 99.4594 - false_loss: 0.1051 - true_loss: 1.2202 - val_loss: 6763.4946 - val_reconstruction_loss: 1897.6635 - val_kl_loss: 98.6772 - val_false_loss: 15.4686 - val_true_loss: 1.2658\n",
      "Epoch 9/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2255.5343 - reconstruction_loss: 1893.5537 - kl_loss: 98.4287 - false_loss: 0.1051 - true_loss: 1.2201 - val_loss: 6762.8311 - val_reconstruction_loss: 1897.6624 - val_kl_loss: 98.6789 - val_false_loss: 15.4664 - val_true_loss: 1.2657\n",
      "Epoch 10/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.2354 - reconstruction_loss: 1893.4027 - kl_loss: 98.6735 - false_loss: 0.1051 - true_loss: 1.2200 - val_loss: 6762.1870 - val_reconstruction_loss: 1897.6617 - val_kl_loss: 98.6796 - val_false_loss: 15.4643 - val_true_loss: 1.2656\n",
      "Epoch 11/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2255.9588 - reconstruction_loss: 1893.6195 - kl_loss: 97.9051 - false_loss: 0.1051 - true_loss: 1.2200 - val_loss: 6761.5371 - val_reconstruction_loss: 1897.6606 - val_kl_loss: 98.6815 - val_false_loss: 15.4621 - val_true_loss: 1.2656\n",
      "Epoch 12/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2261.5224 - reconstruction_loss: 1893.3160 - kl_loss: 99.2068 - false_loss: 0.1051 - true_loss: 1.2199 - val_loss: 6760.8721 - val_reconstruction_loss: 1897.6598 - val_kl_loss: 98.6833 - val_false_loss: 15.4599 - val_true_loss: 1.2655\n",
      "Epoch 13/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.0772 - reconstruction_loss: 1893.4974 - kl_loss: 99.4354 - false_loss: 0.1051 - true_loss: 1.2198 - val_loss: 6760.2100 - val_reconstruction_loss: 1897.6588 - val_kl_loss: 98.6844 - val_false_loss: 15.4578 - val_true_loss: 1.2655\n",
      "Epoch 14/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.7450 - reconstruction_loss: 1893.5189 - kl_loss: 98.4974 - false_loss: 0.1051 - true_loss: 1.2198 - val_loss: 6759.5562 - val_reconstruction_loss: 1897.6576 - val_kl_loss: 98.6859 - val_false_loss: 15.4556 - val_true_loss: 1.2654\n",
      "Epoch 15/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2254.5604 - reconstruction_loss: 1893.3551 - kl_loss: 98.3409 - false_loss: 0.1051 - true_loss: 1.2197 - val_loss: 6758.9082 - val_reconstruction_loss: 1897.6567 - val_kl_loss: 98.6877 - val_false_loss: 15.4535 - val_true_loss: 1.2653\n",
      "Epoch 16/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2262.5402 - reconstruction_loss: 1894.1353 - kl_loss: 99.2990 - false_loss: 0.1051 - true_loss: 1.2196 - val_loss: 6758.2451 - val_reconstruction_loss: 1897.6556 - val_kl_loss: 98.6875 - val_false_loss: 15.4513 - val_true_loss: 1.2653\n",
      "Epoch 17/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2256.9682 - reconstruction_loss: 1893.7816 - kl_loss: 99.0067 - false_loss: 0.1050 - true_loss: 1.2196 - val_loss: 6757.5771 - val_reconstruction_loss: 1897.6548 - val_kl_loss: 98.6871 - val_false_loss: 15.4491 - val_true_loss: 1.2652\n",
      "Epoch 18/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.5054 - reconstruction_loss: 1893.4310 - kl_loss: 98.6068 - false_loss: 0.1050 - true_loss: 1.2195 - val_loss: 6756.9258 - val_reconstruction_loss: 1897.6539 - val_kl_loss: 98.6872 - val_false_loss: 15.4469 - val_true_loss: 1.2652\n",
      "Epoch 19/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.8348 - reconstruction_loss: 1892.9288 - kl_loss: 97.6234 - false_loss: 0.1050 - true_loss: 1.2194 - val_loss: 6756.2695 - val_reconstruction_loss: 1897.6527 - val_kl_loss: 98.6879 - val_false_loss: 15.4447 - val_true_loss: 1.2651\n",
      "Epoch 20/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.9683 - reconstruction_loss: 1893.6124 - kl_loss: 97.8542 - false_loss: 0.1050 - true_loss: 1.2194 - val_loss: 6755.6143 - val_reconstruction_loss: 1897.6516 - val_kl_loss: 98.6883 - val_false_loss: 15.4426 - val_true_loss: 1.2650\n",
      "Epoch 21/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.1670 - reconstruction_loss: 1893.4261 - kl_loss: 98.1295 - false_loss: 0.1050 - true_loss: 1.2193 - val_loss: 6754.9897 - val_reconstruction_loss: 1897.6508 - val_kl_loss: 98.6890 - val_false_loss: 15.4405 - val_true_loss: 1.2650\n",
      "Epoch 22/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.6285 - reconstruction_loss: 1893.8805 - kl_loss: 98.5301 - false_loss: 0.1050 - true_loss: 1.2192 - val_loss: 6754.3491 - val_reconstruction_loss: 1897.6499 - val_kl_loss: 98.6904 - val_false_loss: 15.4384 - val_true_loss: 1.2649\n",
      "Epoch 23/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.8252 - reconstruction_loss: 1893.2325 - kl_loss: 99.4560 - false_loss: 0.1050 - true_loss: 1.2191 - val_loss: 6753.7007 - val_reconstruction_loss: 1897.6490 - val_kl_loss: 98.6913 - val_false_loss: 15.4363 - val_true_loss: 1.2648\n",
      "Epoch 24/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.9628 - reconstruction_loss: 1894.1445 - kl_loss: 98.3750 - false_loss: 0.1050 - true_loss: 1.2191 - val_loss: 6753.0444 - val_reconstruction_loss: 1897.6481 - val_kl_loss: 98.6928 - val_false_loss: 15.4341 - val_true_loss: 1.2648\n",
      "Epoch 25/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.4844 - reconstruction_loss: 1893.6676 - kl_loss: 96.8249 - false_loss: 0.1050 - true_loss: 1.2190 - val_loss: 6752.3862 - val_reconstruction_loss: 1897.6472 - val_kl_loss: 98.6941 - val_false_loss: 15.4319 - val_true_loss: 1.2647\n",
      "Epoch 26/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2261.2038 - reconstruction_loss: 1893.1625 - kl_loss: 97.0658 - false_loss: 0.1049 - true_loss: 1.2190 - val_loss: 6751.7256 - val_reconstruction_loss: 1897.6461 - val_kl_loss: 98.6940 - val_false_loss: 15.4297 - val_true_loss: 1.2647\n",
      "Epoch 27/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2259.2009 - reconstruction_loss: 1893.6598 - kl_loss: 97.8285 - false_loss: 0.1049 - true_loss: 1.2189 - val_loss: 6751.0708 - val_reconstruction_loss: 1897.6453 - val_kl_loss: 98.6940 - val_false_loss: 15.4276 - val_true_loss: 1.2646\n",
      "Epoch 28/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.5118 - reconstruction_loss: 1893.1305 - kl_loss: 97.8671 - false_loss: 0.1049 - true_loss: 1.2188 - val_loss: 6750.4209 - val_reconstruction_loss: 1897.6440 - val_kl_loss: 98.6941 - val_false_loss: 15.4254 - val_true_loss: 1.2645\n",
      "Epoch 29/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2260.3241 - reconstruction_loss: 1893.1085 - kl_loss: 99.7268 - false_loss: 0.1049 - true_loss: 1.2188 - val_loss: 6749.7749 - val_reconstruction_loss: 1897.6431 - val_kl_loss: 98.6924 - val_false_loss: 15.4233 - val_true_loss: 1.2645\n",
      "Epoch 30/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2284.2859 - reconstruction_loss: 1893.3135 - kl_loss: 98.1390 - false_loss: 0.1049 - true_loss: 1.2187 - val_loss: 6749.1265 - val_reconstruction_loss: 1897.6422 - val_kl_loss: 98.6935 - val_false_loss: 15.4212 - val_true_loss: 1.2645\n",
      "Epoch 31/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2279.9265 - reconstruction_loss: 1893.4369 - kl_loss: 97.5559 - false_loss: 0.1049 - true_loss: 1.2187 - val_loss: 6748.4766 - val_reconstruction_loss: 1897.6415 - val_kl_loss: 98.6919 - val_false_loss: 15.4190 - val_true_loss: 1.2644\n",
      "Epoch 32/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2266.5731 - reconstruction_loss: 1893.8363 - kl_loss: 97.1587 - false_loss: 0.1049 - true_loss: 1.2186 - val_loss: 6747.8188 - val_reconstruction_loss: 1897.6403 - val_kl_loss: 98.6926 - val_false_loss: 15.4168 - val_true_loss: 1.2644\n",
      "Epoch 33/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.7828 - reconstruction_loss: 1893.1260 - kl_loss: 96.7404 - false_loss: 0.1049 - true_loss: 1.2185 - val_loss: 6747.1577 - val_reconstruction_loss: 1897.6394 - val_kl_loss: 98.6938 - val_false_loss: 15.4147 - val_true_loss: 1.2643\n",
      "Epoch 34/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.0824 - reconstruction_loss: 1893.1602 - kl_loss: 97.4428 - false_loss: 0.1049 - true_loss: 1.2185 - val_loss: 6746.5029 - val_reconstruction_loss: 1897.6384 - val_kl_loss: 98.6938 - val_false_loss: 15.4125 - val_true_loss: 1.2643\n",
      "Epoch 35/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.6857 - reconstruction_loss: 1893.3405 - kl_loss: 97.2761 - false_loss: 0.1048 - true_loss: 1.2184 - val_loss: 6745.8613 - val_reconstruction_loss: 1897.6373 - val_kl_loss: 98.6935 - val_false_loss: 15.4104 - val_true_loss: 1.2642\n",
      "Epoch 36/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.4915 - reconstruction_loss: 1893.4757 - kl_loss: 98.5956 - false_loss: 0.1048 - true_loss: 1.2183 - val_loss: 6745.2090 - val_reconstruction_loss: 1897.6364 - val_kl_loss: 98.6943 - val_false_loss: 15.4082 - val_true_loss: 1.2641\n",
      "Epoch 37/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.3030 - reconstruction_loss: 1893.4751 - kl_loss: 97.9100 - false_loss: 0.1048 - true_loss: 1.2183 - val_loss: 6744.5620 - val_reconstruction_loss: 1897.6353 - val_kl_loss: 98.6955 - val_false_loss: 15.4061 - val_true_loss: 1.2641\n",
      "Epoch 38/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.3225 - reconstruction_loss: 1893.1074 - kl_loss: 98.8723 - false_loss: 0.1048 - true_loss: 1.2182 - val_loss: 6743.9102 - val_reconstruction_loss: 1897.6344 - val_kl_loss: 98.6953 - val_false_loss: 15.4039 - val_true_loss: 1.2640\n",
      "Epoch 39/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.1674 - reconstruction_loss: 1893.3229 - kl_loss: 99.4642 - false_loss: 0.1048 - true_loss: 1.2181 - val_loss: 6743.2632 - val_reconstruction_loss: 1897.6335 - val_kl_loss: 98.6953 - val_false_loss: 15.4018 - val_true_loss: 1.2639\n",
      "Epoch 40/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.0316 - reconstruction_loss: 1893.3480 - kl_loss: 98.0228 - false_loss: 0.1048 - true_loss: 1.2181 - val_loss: 6742.6177 - val_reconstruction_loss: 1897.6326 - val_kl_loss: 98.6952 - val_false_loss: 15.3997 - val_true_loss: 1.2639\n",
      "Epoch 41/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.0610 - reconstruction_loss: 1893.7417 - kl_loss: 98.0784 - false_loss: 0.1048 - true_loss: 1.2180 - val_loss: 6741.9634 - val_reconstruction_loss: 1897.6317 - val_kl_loss: 98.6968 - val_false_loss: 15.3975 - val_true_loss: 1.2638\n",
      "Epoch 42/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.4148 - reconstruction_loss: 1893.4360 - kl_loss: 99.6195 - false_loss: 0.1048 - true_loss: 1.2179 - val_loss: 6741.3081 - val_reconstruction_loss: 1897.6305 - val_kl_loss: 98.6980 - val_false_loss: 15.3954 - val_true_loss: 1.2638\n",
      "Epoch 43/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.9664 - reconstruction_loss: 1893.8389 - kl_loss: 99.4416 - false_loss: 0.1048 - true_loss: 1.2178 - val_loss: 6740.6694 - val_reconstruction_loss: 1897.6294 - val_kl_loss: 98.6978 - val_false_loss: 15.3933 - val_true_loss: 1.2637\n",
      "Epoch 44/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.3811 - reconstruction_loss: 1893.4355 - kl_loss: 98.4478 - false_loss: 0.1047 - true_loss: 1.2178 - val_loss: 6740.0249 - val_reconstruction_loss: 1897.6284 - val_kl_loss: 98.6973 - val_false_loss: 15.3911 - val_true_loss: 1.2636\n",
      "Epoch 45/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.5188 - reconstruction_loss: 1892.8145 - kl_loss: 99.2744 - false_loss: 0.1047 - true_loss: 1.2177 - val_loss: 6739.3823 - val_reconstruction_loss: 1897.6276 - val_kl_loss: 98.6969 - val_false_loss: 15.3890 - val_true_loss: 1.2636\n",
      "Epoch 46/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.3281 - reconstruction_loss: 1893.5072 - kl_loss: 98.7014 - false_loss: 0.1047 - true_loss: 1.2176 - val_loss: 6738.7368 - val_reconstruction_loss: 1897.6263 - val_kl_loss: 98.6965 - val_false_loss: 15.3869 - val_true_loss: 1.2635\n",
      "Epoch 47/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.8093 - reconstruction_loss: 1893.1469 - kl_loss: 97.7392 - false_loss: 0.1047 - true_loss: 1.2176 - val_loss: 6738.0825 - val_reconstruction_loss: 1897.6252 - val_kl_loss: 98.6964 - val_false_loss: 15.3847 - val_true_loss: 1.2635\n",
      "Epoch 48/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2258.2793 - reconstruction_loss: 1893.2710 - kl_loss: 96.6140 - false_loss: 0.1047 - true_loss: 1.2175 - val_loss: 6737.4331 - val_reconstruction_loss: 1897.6243 - val_kl_loss: 98.6959 - val_false_loss: 15.3826 - val_true_loss: 1.2634\n",
      "Epoch 49/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.3447 - reconstruction_loss: 1893.0078 - kl_loss: 97.7726 - false_loss: 0.1047 - true_loss: 1.2174 - val_loss: 6736.7773 - val_reconstruction_loss: 1897.6234 - val_kl_loss: 98.6965 - val_false_loss: 15.3804 - val_true_loss: 1.2634\n",
      "Epoch 50/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.2008 - reconstruction_loss: 1893.4725 - kl_loss: 98.5212 - false_loss: 0.1047 - true_loss: 1.2174 - val_loss: 6736.1338 - val_reconstruction_loss: 1897.6224 - val_kl_loss: 98.6972 - val_false_loss: 15.3783 - val_true_loss: 1.2633\n",
      "Epoch 51/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.1998 - reconstruction_loss: 1893.4219 - kl_loss: 99.4876 - false_loss: 0.1047 - true_loss: 1.2173 - val_loss: 6735.4795 - val_reconstruction_loss: 1897.6213 - val_kl_loss: 98.6971 - val_false_loss: 15.3761 - val_true_loss: 1.2632\n",
      "Epoch 52/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.5498 - reconstruction_loss: 1893.3467 - kl_loss: 99.0511 - false_loss: 0.1047 - true_loss: 1.2172 - val_loss: 6734.8335 - val_reconstruction_loss: 1897.6204 - val_kl_loss: 98.6973 - val_false_loss: 15.3740 - val_true_loss: 1.2632\n",
      "Epoch 53/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2245.8593 - reconstruction_loss: 1892.9869 - kl_loss: 98.6571 - false_loss: 0.1046 - true_loss: 1.2172 - val_loss: 6734.1802 - val_reconstruction_loss: 1897.6193 - val_kl_loss: 98.6986 - val_false_loss: 15.3719 - val_true_loss: 1.2631\n",
      "Epoch 54/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.9403 - reconstruction_loss: 1893.4380 - kl_loss: 98.7121 - false_loss: 0.1046 - true_loss: 1.2171 - val_loss: 6733.5327 - val_reconstruction_loss: 1897.6183 - val_kl_loss: 98.6996 - val_false_loss: 15.3697 - val_true_loss: 1.2630\n",
      "Epoch 55/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.2932 - reconstruction_loss: 1892.9053 - kl_loss: 98.6382 - false_loss: 0.1046 - true_loss: 1.2170 - val_loss: 6732.8779 - val_reconstruction_loss: 1897.6172 - val_kl_loss: 98.7003 - val_false_loss: 15.3676 - val_true_loss: 1.2630\n",
      "Epoch 56/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.8431 - reconstruction_loss: 1893.8097 - kl_loss: 98.1911 - false_loss: 0.1046 - true_loss: 1.2170 - val_loss: 6732.2295 - val_reconstruction_loss: 1897.6163 - val_kl_loss: 98.7022 - val_false_loss: 15.3654 - val_true_loss: 1.2629\n",
      "Epoch 57/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.3974 - reconstruction_loss: 1893.6449 - kl_loss: 100.3333 - false_loss: 0.1046 - true_loss: 1.2169 - val_loss: 6731.5718 - val_reconstruction_loss: 1897.6154 - val_kl_loss: 98.7034 - val_false_loss: 15.3632 - val_true_loss: 1.2629\n",
      "Epoch 58/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.4632 - reconstruction_loss: 1893.5503 - kl_loss: 99.1148 - false_loss: 0.1046 - true_loss: 1.2168 - val_loss: 6730.9170 - val_reconstruction_loss: 1897.6145 - val_kl_loss: 98.7033 - val_false_loss: 15.3611 - val_true_loss: 1.2628\n",
      "Epoch 59/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.8565 - reconstruction_loss: 1892.9391 - kl_loss: 98.5863 - false_loss: 0.1046 - true_loss: 1.2168 - val_loss: 6730.2627 - val_reconstruction_loss: 1897.6135 - val_kl_loss: 98.7046 - val_false_loss: 15.3589 - val_true_loss: 1.2627\n",
      "Epoch 60/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.3976 - reconstruction_loss: 1893.4867 - kl_loss: 99.6861 - false_loss: 0.1046 - true_loss: 1.2167 - val_loss: 6729.6182 - val_reconstruction_loss: 1897.6127 - val_kl_loss: 98.7043 - val_false_loss: 15.3568 - val_true_loss: 1.2627\n",
      "Epoch 61/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.8294 - reconstruction_loss: 1892.9305 - kl_loss: 98.3111 - false_loss: 0.1046 - true_loss: 1.2166 - val_loss: 6728.9722 - val_reconstruction_loss: 1897.6118 - val_kl_loss: 98.7051 - val_false_loss: 15.3547 - val_true_loss: 1.2626\n",
      "Epoch 62/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.2061 - reconstruction_loss: 1893.9313 - kl_loss: 99.5885 - false_loss: 0.1046 - true_loss: 1.2166 - val_loss: 6728.3252 - val_reconstruction_loss: 1897.6110 - val_kl_loss: 98.7051 - val_false_loss: 15.3525 - val_true_loss: 1.2626\n",
      "Epoch 63/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.9975 - reconstruction_loss: 1893.5424 - kl_loss: 99.4174 - false_loss: 0.1045 - true_loss: 1.2165 - val_loss: 6727.6758 - val_reconstruction_loss: 1897.6099 - val_kl_loss: 98.7060 - val_false_loss: 15.3504 - val_true_loss: 1.2625\n",
      "Epoch 64/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.6644 - reconstruction_loss: 1893.2350 - kl_loss: 98.9333 - false_loss: 0.1045 - true_loss: 1.2164 - val_loss: 6727.0249 - val_reconstruction_loss: 1897.6088 - val_kl_loss: 98.7070 - val_false_loss: 15.3482 - val_true_loss: 1.2624\n",
      "Epoch 65/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.3211 - reconstruction_loss: 1893.4967 - kl_loss: 98.6651 - false_loss: 0.1045 - true_loss: 1.2163 - val_loss: 6726.3789 - val_reconstruction_loss: 1897.6079 - val_kl_loss: 98.7075 - val_false_loss: 15.3461 - val_true_loss: 1.2624\n",
      "Epoch 66/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.4231 - reconstruction_loss: 1893.7133 - kl_loss: 98.5217 - false_loss: 0.1045 - true_loss: 1.2163 - val_loss: 6725.7285 - val_reconstruction_loss: 1897.6068 - val_kl_loss: 98.7090 - val_false_loss: 15.3440 - val_true_loss: 1.2623\n",
      "Epoch 67/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.2533 - reconstruction_loss: 1893.3173 - kl_loss: 98.8900 - false_loss: 0.1045 - true_loss: 1.2162 - val_loss: 6725.0850 - val_reconstruction_loss: 1897.6058 - val_kl_loss: 98.7120 - val_false_loss: 15.3418 - val_true_loss: 1.2622\n",
      "Epoch 68/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.2655 - reconstruction_loss: 1892.9087 - kl_loss: 100.2056 - false_loss: 0.1045 - true_loss: 1.2162 - val_loss: 6724.4448 - val_reconstruction_loss: 1897.6046 - val_kl_loss: 98.7128 - val_false_loss: 15.3397 - val_true_loss: 1.2622\n",
      "Epoch 69/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.6879 - reconstruction_loss: 1893.0541 - kl_loss: 99.3601 - false_loss: 0.1045 - true_loss: 1.2161 - val_loss: 6723.8027 - val_reconstruction_loss: 1897.6038 - val_kl_loss: 98.7131 - val_false_loss: 15.3376 - val_true_loss: 1.2621\n",
      "Epoch 70/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.8615 - reconstruction_loss: 1892.7832 - kl_loss: 98.7627 - false_loss: 0.1045 - true_loss: 1.2160 - val_loss: 6723.1567 - val_reconstruction_loss: 1897.6028 - val_kl_loss: 98.7142 - val_false_loss: 15.3355 - val_true_loss: 1.2620\n",
      "Epoch 71/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.9768 - reconstruction_loss: 1893.3658 - kl_loss: 99.2815 - false_loss: 0.1045 - true_loss: 1.2159 - val_loss: 6722.5137 - val_reconstruction_loss: 1897.6017 - val_kl_loss: 98.7142 - val_false_loss: 15.3333 - val_true_loss: 1.2620\n",
      "Epoch 72/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.6400 - reconstruction_loss: 1893.3042 - kl_loss: 99.7225 - false_loss: 0.1044 - true_loss: 1.2159 - val_loss: 6721.8691 - val_reconstruction_loss: 1897.6008 - val_kl_loss: 98.7139 - val_false_loss: 15.3312 - val_true_loss: 1.2619\n",
      "Epoch 73/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.2747 - reconstruction_loss: 1892.9688 - kl_loss: 98.3546 - false_loss: 0.1044 - true_loss: 1.2158 - val_loss: 6721.2271 - val_reconstruction_loss: 1897.5999 - val_kl_loss: 98.7146 - val_false_loss: 15.3291 - val_true_loss: 1.2619\n",
      "Epoch 74/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.0110 - reconstruction_loss: 1893.5693 - kl_loss: 99.1314 - false_loss: 0.1044 - true_loss: 1.2157 - val_loss: 6720.5884 - val_reconstruction_loss: 1897.5990 - val_kl_loss: 98.7155 - val_false_loss: 15.3270 - val_true_loss: 1.2618\n",
      "Epoch 75/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.3502 - reconstruction_loss: 1893.1274 - kl_loss: 99.9799 - false_loss: 0.1044 - true_loss: 1.2157 - val_loss: 6719.9424 - val_reconstruction_loss: 1897.5978 - val_kl_loss: 98.7166 - val_false_loss: 15.3249 - val_true_loss: 1.2617\n",
      "Epoch 76/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.4856 - reconstruction_loss: 1892.8799 - kl_loss: 99.6300 - false_loss: 0.1044 - true_loss: 1.2156 - val_loss: 6719.3008 - val_reconstruction_loss: 1897.5969 - val_kl_loss: 98.7171 - val_false_loss: 15.3227 - val_true_loss: 1.2617\n",
      "Epoch 77/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.7443 - reconstruction_loss: 1893.5312 - kl_loss: 99.1962 - false_loss: 0.1044 - true_loss: 1.2155 - val_loss: 6718.6685 - val_reconstruction_loss: 1897.5959 - val_kl_loss: 98.7170 - val_false_loss: 15.3207 - val_true_loss: 1.2616\n",
      "Epoch 78/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.9268 - reconstruction_loss: 1893.2079 - kl_loss: 98.4998 - false_loss: 0.1044 - true_loss: 1.2155 - val_loss: 6718.0239 - val_reconstruction_loss: 1897.5951 - val_kl_loss: 98.7163 - val_false_loss: 15.3185 - val_true_loss: 1.2616\n",
      "Epoch 79/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.4371 - reconstruction_loss: 1893.6635 - kl_loss: 100.7226 - false_loss: 0.1044 - true_loss: 1.2154 - val_loss: 6717.3843 - val_reconstruction_loss: 1897.5942 - val_kl_loss: 98.7152 - val_false_loss: 15.3164 - val_true_loss: 1.2615\n",
      "Epoch 80/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.5246 - reconstruction_loss: 1893.7267 - kl_loss: 100.3852 - false_loss: 0.1044 - true_loss: 1.2153 - val_loss: 6716.7417 - val_reconstruction_loss: 1897.5934 - val_kl_loss: 98.7137 - val_false_loss: 15.3143 - val_true_loss: 1.2615\n",
      "Epoch 81/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2261.5080 - reconstruction_loss: 1893.2653 - kl_loss: 100.0315 - false_loss: 0.1043 - true_loss: 1.2153 - val_loss: 6716.1060 - val_reconstruction_loss: 1897.5924 - val_kl_loss: 98.7150 - val_false_loss: 15.3122 - val_true_loss: 1.2614\n",
      "Epoch 82/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2254.3146 - reconstruction_loss: 1892.8955 - kl_loss: 98.8484 - false_loss: 0.1043 - true_loss: 1.2152 - val_loss: 6715.4702 - val_reconstruction_loss: 1897.5916 - val_kl_loss: 98.7161 - val_false_loss: 15.3101 - val_true_loss: 1.2613\n",
      "Epoch 83/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.3365 - reconstruction_loss: 1893.1943 - kl_loss: 98.1542 - false_loss: 0.1043 - true_loss: 1.2151 - val_loss: 6714.8306 - val_reconstruction_loss: 1897.5906 - val_kl_loss: 98.7175 - val_false_loss: 15.3080 - val_true_loss: 1.2613\n",
      "Epoch 84/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.1903 - reconstruction_loss: 1893.1886 - kl_loss: 98.8534 - false_loss: 0.1043 - true_loss: 1.2151 - val_loss: 6714.1934 - val_reconstruction_loss: 1897.5897 - val_kl_loss: 98.7198 - val_false_loss: 15.3059 - val_true_loss: 1.2612\n",
      "Epoch 85/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.7668 - reconstruction_loss: 1893.3939 - kl_loss: 98.8713 - false_loss: 0.1043 - true_loss: 1.2150 - val_loss: 6713.5542 - val_reconstruction_loss: 1897.5889 - val_kl_loss: 98.7209 - val_false_loss: 15.3038 - val_true_loss: 1.2611\n",
      "Epoch 86/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.7951 - reconstruction_loss: 1892.9985 - kl_loss: 98.3410 - false_loss: 0.1043 - true_loss: 1.2149 - val_loss: 6712.9175 - val_reconstruction_loss: 1897.5879 - val_kl_loss: 98.7214 - val_false_loss: 15.3017 - val_true_loss: 1.2611\n",
      "Epoch 87/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.8953 - reconstruction_loss: 1892.9471 - kl_loss: 99.4050 - false_loss: 0.1043 - true_loss: 1.2149 - val_loss: 6712.2710 - val_reconstruction_loss: 1897.5870 - val_kl_loss: 98.7218 - val_false_loss: 15.2995 - val_true_loss: 1.2610\n",
      "Epoch 88/2700\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2251.5513 - reconstruction_loss: 1893.0194 - kl_loss: 97.9154 - false_loss: 0.1043 - true_loss: 1.2148 - val_loss: 6711.6431 - val_reconstruction_loss: 1897.5861 - val_kl_loss: 98.7236 - val_false_loss: 15.2975 - val_true_loss: 1.2610\n",
      "Epoch 89/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.1887 - reconstruction_loss: 1893.2196 - kl_loss: 99.1417 - false_loss: 0.1043 - true_loss: 1.2147 - val_loss: 6711.0010 - val_reconstruction_loss: 1897.5850 - val_kl_loss: 98.7248 - val_false_loss: 15.2953 - val_true_loss: 1.2609\n",
      "Epoch 90/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.8880 - reconstruction_loss: 1892.7181 - kl_loss: 98.3200 - false_loss: 0.1042 - true_loss: 1.2147 - val_loss: 6710.3643 - val_reconstruction_loss: 1897.5840 - val_kl_loss: 98.7254 - val_false_loss: 15.2932 - val_true_loss: 1.2608\n",
      "Epoch 91/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2255.3010 - reconstruction_loss: 1893.2062 - kl_loss: 97.7283 - false_loss: 0.1042 - true_loss: 1.2146 - val_loss: 6709.7256 - val_reconstruction_loss: 1897.5830 - val_kl_loss: 98.7270 - val_false_loss: 15.2911 - val_true_loss: 1.2608\n",
      "Epoch 92/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2263.9165 - reconstruction_loss: 1893.5590 - kl_loss: 99.0384 - false_loss: 0.1042 - true_loss: 1.2145 - val_loss: 6709.0947 - val_reconstruction_loss: 1897.5819 - val_kl_loss: 98.7295 - val_false_loss: 15.2890 - val_true_loss: 1.2607\n",
      "Epoch 93/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2261.6934 - reconstruction_loss: 1893.4388 - kl_loss: 99.0237 - false_loss: 0.1042 - true_loss: 1.2145 - val_loss: 6708.4502 - val_reconstruction_loss: 1897.5809 - val_kl_loss: 98.7300 - val_false_loss: 15.2869 - val_true_loss: 1.2607\n",
      "Epoch 94/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.1618 - reconstruction_loss: 1893.2012 - kl_loss: 100.2673 - false_loss: 0.1042 - true_loss: 1.2144 - val_loss: 6707.8115 - val_reconstruction_loss: 1897.5800 - val_kl_loss: 98.7294 - val_false_loss: 15.2848 - val_true_loss: 1.2606\n",
      "Epoch 95/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.0054 - reconstruction_loss: 1892.8154 - kl_loss: 99.0058 - false_loss: 0.1042 - true_loss: 1.2143 - val_loss: 6707.1714 - val_reconstruction_loss: 1897.5791 - val_kl_loss: 98.7293 - val_false_loss: 15.2827 - val_true_loss: 1.2606\n",
      "Epoch 96/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.7690 - reconstruction_loss: 1892.9293 - kl_loss: 98.6132 - false_loss: 0.1042 - true_loss: 1.2143 - val_loss: 6706.5381 - val_reconstruction_loss: 1897.5779 - val_kl_loss: 98.7302 - val_false_loss: 15.2806 - val_true_loss: 1.2605\n",
      "Epoch 97/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.3398 - reconstruction_loss: 1893.1699 - kl_loss: 99.0204 - false_loss: 0.1042 - true_loss: 1.2142 - val_loss: 6705.9077 - val_reconstruction_loss: 1897.5770 - val_kl_loss: 98.7314 - val_false_loss: 15.2785 - val_true_loss: 1.2604\n",
      "Epoch 98/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.5401 - reconstruction_loss: 1893.2773 - kl_loss: 99.7485 - false_loss: 0.1042 - true_loss: 1.2141 - val_loss: 6705.2739 - val_reconstruction_loss: 1897.5762 - val_kl_loss: 98.7324 - val_false_loss: 15.2764 - val_true_loss: 1.2604\n",
      "Epoch 99/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.4493 - reconstruction_loss: 1893.0385 - kl_loss: 99.2132 - false_loss: 0.1041 - true_loss: 1.2141 - val_loss: 6704.6416 - val_reconstruction_loss: 1897.5752 - val_kl_loss: 98.7326 - val_false_loss: 15.2744 - val_true_loss: 1.2603\n",
      "Epoch 100/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.4460 - reconstruction_loss: 1893.4362 - kl_loss: 98.7671 - false_loss: 0.1041 - true_loss: 1.2140 - val_loss: 6704.0107 - val_reconstruction_loss: 1897.5743 - val_kl_loss: 98.7336 - val_false_loss: 15.2723 - val_true_loss: 1.2602\n",
      "Epoch 101/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.4734 - reconstruction_loss: 1893.2909 - kl_loss: 99.1028 - false_loss: 0.1041 - true_loss: 1.2139 - val_loss: 6703.3740 - val_reconstruction_loss: 1897.5735 - val_kl_loss: 98.7340 - val_false_loss: 15.2702 - val_true_loss: 1.2602\n",
      "Epoch 102/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.2810 - reconstruction_loss: 1892.8434 - kl_loss: 99.1655 - false_loss: 0.1041 - true_loss: 1.2139 - val_loss: 6702.7344 - val_reconstruction_loss: 1897.5725 - val_kl_loss: 98.7346 - val_false_loss: 15.2681 - val_true_loss: 1.2601\n",
      "Epoch 103/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2259.2991 - reconstruction_loss: 1892.7313 - kl_loss: 97.7992 - false_loss: 0.1041 - true_loss: 1.2138 - val_loss: 6702.0991 - val_reconstruction_loss: 1897.5713 - val_kl_loss: 98.7343 - val_false_loss: 15.2660 - val_true_loss: 1.2601\n",
      "Epoch 104/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.4203 - reconstruction_loss: 1892.9780 - kl_loss: 98.4770 - false_loss: 0.1041 - true_loss: 1.2137 - val_loss: 6701.4580 - val_reconstruction_loss: 1897.5707 - val_kl_loss: 98.7336 - val_false_loss: 15.2639 - val_true_loss: 1.2600\n",
      "Epoch 105/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2253.2393 - reconstruction_loss: 1893.0848 - kl_loss: 99.9211 - false_loss: 0.1041 - true_loss: 1.2137 - val_loss: 6700.8252 - val_reconstruction_loss: 1897.5698 - val_kl_loss: 98.7323 - val_false_loss: 15.2618 - val_true_loss: 1.2600\n",
      "Epoch 106/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.0287 - reconstruction_loss: 1892.9972 - kl_loss: 98.3108 - false_loss: 0.1041 - true_loss: 1.2136 - val_loss: 6700.1978 - val_reconstruction_loss: 1897.5688 - val_kl_loss: 98.7322 - val_false_loss: 15.2597 - val_true_loss: 1.2599\n",
      "Epoch 107/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.3397 - reconstruction_loss: 1892.6342 - kl_loss: 99.2317 - false_loss: 0.1041 - true_loss: 1.2135 - val_loss: 6699.5605 - val_reconstruction_loss: 1897.5679 - val_kl_loss: 98.7314 - val_false_loss: 15.2576 - val_true_loss: 1.2599\n",
      "Epoch 108/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.7780 - reconstruction_loss: 1893.0209 - kl_loss: 98.9195 - false_loss: 0.1040 - true_loss: 1.2135 - val_loss: 6698.9316 - val_reconstruction_loss: 1897.5668 - val_kl_loss: 98.7304 - val_false_loss: 15.2555 - val_true_loss: 1.2598\n",
      "Epoch 109/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.6732 - reconstruction_loss: 1892.9706 - kl_loss: 99.4612 - false_loss: 0.1040 - true_loss: 1.2134 - val_loss: 6698.2974 - val_reconstruction_loss: 1897.5658 - val_kl_loss: 98.7305 - val_false_loss: 15.2534 - val_true_loss: 1.2598\n",
      "Epoch 110/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.4768 - reconstruction_loss: 1893.1754 - kl_loss: 99.1301 - false_loss: 0.1040 - true_loss: 1.2133 - val_loss: 6697.6602 - val_reconstruction_loss: 1897.5649 - val_kl_loss: 98.7316 - val_false_loss: 15.2513 - val_true_loss: 1.2597\n",
      "Epoch 111/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.7146 - reconstruction_loss: 1893.2266 - kl_loss: 100.1820 - false_loss: 0.1040 - true_loss: 1.2133 - val_loss: 6697.0381 - val_reconstruction_loss: 1897.5641 - val_kl_loss: 98.7333 - val_false_loss: 15.2493 - val_true_loss: 1.2596\n",
      "Epoch 112/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0812 - reconstruction_loss: 1893.2437 - kl_loss: 98.8129 - false_loss: 0.1040 - true_loss: 1.2132 - val_loss: 6696.4072 - val_reconstruction_loss: 1897.5631 - val_kl_loss: 98.7344 - val_false_loss: 15.2472 - val_true_loss: 1.2596\n",
      "Epoch 113/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.6401 - reconstruction_loss: 1893.5150 - kl_loss: 99.4557 - false_loss: 0.1040 - true_loss: 1.2131 - val_loss: 6695.7744 - val_reconstruction_loss: 1897.5621 - val_kl_loss: 98.7353 - val_false_loss: 15.2451 - val_true_loss: 1.2595\n",
      "Epoch 114/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.6297 - reconstruction_loss: 1892.6855 - kl_loss: 99.0059 - false_loss: 0.1040 - true_loss: 1.2131 - val_loss: 6695.1460 - val_reconstruction_loss: 1897.5612 - val_kl_loss: 98.7360 - val_false_loss: 15.2430 - val_true_loss: 1.2595\n",
      "Epoch 115/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.3421 - reconstruction_loss: 1893.2264 - kl_loss: 99.1452 - false_loss: 0.1040 - true_loss: 1.2130 - val_loss: 6694.5195 - val_reconstruction_loss: 1897.5603 - val_kl_loss: 98.7369 - val_false_loss: 15.2410 - val_true_loss: 1.2594\n",
      "Epoch 116/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.0951 - reconstruction_loss: 1893.3529 - kl_loss: 99.4972 - false_loss: 0.1040 - true_loss: 1.2129 - val_loss: 6693.8818 - val_reconstruction_loss: 1897.5593 - val_kl_loss: 98.7375 - val_false_loss: 15.2389 - val_true_loss: 1.2593\n",
      "Epoch 117/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.2399 - reconstruction_loss: 1893.2037 - kl_loss: 98.9402 - false_loss: 0.1039 - true_loss: 1.2129 - val_loss: 6693.2490 - val_reconstruction_loss: 1897.5585 - val_kl_loss: 98.7390 - val_false_loss: 15.2368 - val_true_loss: 1.2593\n",
      "Epoch 118/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.7205 - reconstruction_loss: 1892.8617 - kl_loss: 99.6421 - false_loss: 0.1039 - true_loss: 1.2128 - val_loss: 6692.6191 - val_reconstruction_loss: 1897.5573 - val_kl_loss: 98.7404 - val_false_loss: 15.2347 - val_true_loss: 1.2592\n",
      "Epoch 119/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.4421 - reconstruction_loss: 1892.9498 - kl_loss: 99.3680 - false_loss: 0.1039 - true_loss: 1.2127 - val_loss: 6691.9824 - val_reconstruction_loss: 1897.5563 - val_kl_loss: 98.7415 - val_false_loss: 15.2326 - val_true_loss: 1.2591\n",
      "Epoch 120/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.7184 - reconstruction_loss: 1892.9113 - kl_loss: 99.1941 - false_loss: 0.1039 - true_loss: 1.2127 - val_loss: 6691.3535 - val_reconstruction_loss: 1897.5554 - val_kl_loss: 98.7415 - val_false_loss: 15.2305 - val_true_loss: 1.2591\n",
      "Epoch 121/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.8134 - reconstruction_loss: 1892.7217 - kl_loss: 99.5015 - false_loss: 0.1039 - true_loss: 1.2126 - val_loss: 6690.7178 - val_reconstruction_loss: 1897.5544 - val_kl_loss: 98.7415 - val_false_loss: 15.2284 - val_true_loss: 1.2590\n",
      "Epoch 122/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.9605 - reconstruction_loss: 1893.4349 - kl_loss: 98.4287 - false_loss: 0.1039 - true_loss: 1.2125 - val_loss: 6690.0986 - val_reconstruction_loss: 1897.5536 - val_kl_loss: 98.7416 - val_false_loss: 15.2264 - val_true_loss: 1.2590\n",
      "Epoch 123/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2259.1382 - reconstruction_loss: 1893.0586 - kl_loss: 98.9807 - false_loss: 0.1039 - true_loss: 1.2125 - val_loss: 6689.4624 - val_reconstruction_loss: 1897.5526 - val_kl_loss: 98.7416 - val_false_loss: 15.2243 - val_true_loss: 1.2589\n",
      "Epoch 124/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.0511 - reconstruction_loss: 1893.1058 - kl_loss: 98.8980 - false_loss: 0.1039 - true_loss: 1.2124 - val_loss: 6688.8325 - val_reconstruction_loss: 1897.5518 - val_kl_loss: 98.7424 - val_false_loss: 15.2222 - val_true_loss: 1.2589\n",
      "Epoch 125/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.3819 - reconstruction_loss: 1894.2012 - kl_loss: 98.3921 - false_loss: 0.1039 - true_loss: 1.2123 - val_loss: 6688.2085 - val_reconstruction_loss: 1897.5508 - val_kl_loss: 98.7430 - val_false_loss: 15.2201 - val_true_loss: 1.2588\n",
      "Epoch 126/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.8127 - reconstruction_loss: 1893.1871 - kl_loss: 99.8029 - false_loss: 0.1039 - true_loss: 1.2123 - val_loss: 6687.5786 - val_reconstruction_loss: 1897.5498 - val_kl_loss: 98.7442 - val_false_loss: 15.2181 - val_true_loss: 1.2587\n",
      "Epoch 127/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.4834 - reconstruction_loss: 1893.0773 - kl_loss: 99.2655 - false_loss: 0.1038 - true_loss: 1.2122 - val_loss: 6686.9453 - val_reconstruction_loss: 1897.5487 - val_kl_loss: 98.7449 - val_false_loss: 15.2160 - val_true_loss: 1.2587\n",
      "Epoch 128/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2259.1015 - reconstruction_loss: 1892.8857 - kl_loss: 98.3492 - false_loss: 0.1038 - true_loss: 1.2121 - val_loss: 6686.3203 - val_reconstruction_loss: 1897.5477 - val_kl_loss: 98.7464 - val_false_loss: 15.2139 - val_true_loss: 1.2586\n",
      "Epoch 129/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.0358 - reconstruction_loss: 1893.0389 - kl_loss: 98.6547 - false_loss: 0.1038 - true_loss: 1.2121 - val_loss: 6685.6855 - val_reconstruction_loss: 1897.5468 - val_kl_loss: 98.7465 - val_false_loss: 15.2118 - val_true_loss: 1.2586\n",
      "Epoch 130/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.3431 - reconstruction_loss: 1892.6842 - kl_loss: 97.6627 - false_loss: 0.1038 - true_loss: 1.2120 - val_loss: 6685.0596 - val_reconstruction_loss: 1897.5459 - val_kl_loss: 98.7466 - val_false_loss: 15.2097 - val_true_loss: 1.2585\n",
      "Epoch 131/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.1751 - reconstruction_loss: 1893.0096 - kl_loss: 98.0413 - false_loss: 0.1038 - true_loss: 1.2119 - val_loss: 6684.4214 - val_reconstruction_loss: 1897.5449 - val_kl_loss: 98.7473 - val_false_loss: 15.2076 - val_true_loss: 1.2584\n",
      "Epoch 132/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.2299 - reconstruction_loss: 1892.6803 - kl_loss: 97.2632 - false_loss: 0.1038 - true_loss: 1.2119 - val_loss: 6683.7983 - val_reconstruction_loss: 1897.5441 - val_kl_loss: 98.7485 - val_false_loss: 15.2056 - val_true_loss: 1.2584\n",
      "Epoch 133/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.5098 - reconstruction_loss: 1892.8970 - kl_loss: 98.1942 - false_loss: 0.1038 - true_loss: 1.2118 - val_loss: 6683.1709 - val_reconstruction_loss: 1897.5431 - val_kl_loss: 98.7498 - val_false_loss: 15.2035 - val_true_loss: 1.2583\n",
      "Epoch 134/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.3674 - reconstruction_loss: 1893.5688 - kl_loss: 99.3375 - false_loss: 0.1038 - true_loss: 1.2118 - val_loss: 6682.5581 - val_reconstruction_loss: 1897.5422 - val_kl_loss: 98.7506 - val_false_loss: 15.2015 - val_true_loss: 1.2583\n",
      "Epoch 135/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.0938 - reconstruction_loss: 1893.3461 - kl_loss: 99.3440 - false_loss: 0.1038 - true_loss: 1.2117 - val_loss: 6681.9346 - val_reconstruction_loss: 1897.5413 - val_kl_loss: 98.7504 - val_false_loss: 15.1994 - val_true_loss: 1.2582\n",
      "Epoch 136/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.6867 - reconstruction_loss: 1892.6216 - kl_loss: 98.6056 - false_loss: 0.1037 - true_loss: 1.2116 - val_loss: 6681.3071 - val_reconstruction_loss: 1897.5404 - val_kl_loss: 98.7509 - val_false_loss: 15.1974 - val_true_loss: 1.2582\n",
      "Epoch 137/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.8203 - reconstruction_loss: 1893.3424 - kl_loss: 99.0305 - false_loss: 0.1037 - true_loss: 1.2116 - val_loss: 6680.6777 - val_reconstruction_loss: 1897.5394 - val_kl_loss: 98.7514 - val_false_loss: 15.1953 - val_true_loss: 1.2581\n",
      "Epoch 138/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.1159 - reconstruction_loss: 1892.8896 - kl_loss: 98.4537 - false_loss: 0.1037 - true_loss: 1.2115 - val_loss: 6680.0513 - val_reconstruction_loss: 1897.5383 - val_kl_loss: 98.7524 - val_false_loss: 15.1932 - val_true_loss: 1.2580\n",
      "Epoch 139/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.8496 - reconstruction_loss: 1892.9032 - kl_loss: 98.9845 - false_loss: 0.1037 - true_loss: 1.2114 - val_loss: 6679.4224 - val_reconstruction_loss: 1897.5375 - val_kl_loss: 98.7543 - val_false_loss: 15.1911 - val_true_loss: 1.2580\n",
      "Epoch 140/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.8964 - reconstruction_loss: 1893.4072 - kl_loss: 99.0843 - false_loss: 0.1037 - true_loss: 1.2114 - val_loss: 6678.7915 - val_reconstruction_loss: 1897.5365 - val_kl_loss: 98.7554 - val_false_loss: 15.1890 - val_true_loss: 1.2579\n",
      "Epoch 141/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.3405 - reconstruction_loss: 1893.7550 - kl_loss: 97.5625 - false_loss: 0.1037 - true_loss: 1.2113 - val_loss: 6678.1611 - val_reconstruction_loss: 1897.5355 - val_kl_loss: 98.7562 - val_false_loss: 15.1870 - val_true_loss: 1.2579\n",
      "Epoch 142/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.4517 - reconstruction_loss: 1893.5278 - kl_loss: 97.2730 - false_loss: 0.1037 - true_loss: 1.2112 - val_loss: 6677.5366 - val_reconstruction_loss: 1897.5344 - val_kl_loss: 98.7567 - val_false_loss: 15.1849 - val_true_loss: 1.2578\n",
      "Epoch 143/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.6216 - reconstruction_loss: 1893.1320 - kl_loss: 99.1398 - false_loss: 0.1037 - true_loss: 1.2112 - val_loss: 6676.9102 - val_reconstruction_loss: 1897.5337 - val_kl_loss: 98.7575 - val_false_loss: 15.1828 - val_true_loss: 1.2577\n",
      "Epoch 144/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.5650 - reconstruction_loss: 1892.7738 - kl_loss: 98.8957 - false_loss: 0.1037 - true_loss: 1.2111 - val_loss: 6676.2852 - val_reconstruction_loss: 1897.5326 - val_kl_loss: 98.7575 - val_false_loss: 15.1808 - val_true_loss: 1.2577\n",
      "Epoch 145/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.4064 - reconstruction_loss: 1893.3336 - kl_loss: 99.1770 - false_loss: 0.1037 - true_loss: 1.2110 - val_loss: 6675.6631 - val_reconstruction_loss: 1897.5319 - val_kl_loss: 98.7576 - val_false_loss: 15.1787 - val_true_loss: 1.2576\n",
      "Epoch 146/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.9772 - reconstruction_loss: 1892.8472 - kl_loss: 99.4281 - false_loss: 0.1036 - true_loss: 1.2110 - val_loss: 6675.0557 - val_reconstruction_loss: 1897.5309 - val_kl_loss: 98.7568 - val_false_loss: 15.1767 - val_true_loss: 1.2576\n",
      "Epoch 147/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.9878 - reconstruction_loss: 1892.7286 - kl_loss: 97.8206 - false_loss: 0.1036 - true_loss: 1.2109 - val_loss: 6674.4331 - val_reconstruction_loss: 1897.5297 - val_kl_loss: 98.7574 - val_false_loss: 15.1747 - val_true_loss: 1.2575\n",
      "Epoch 148/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.3715 - reconstruction_loss: 1892.9366 - kl_loss: 99.5481 - false_loss: 0.1036 - true_loss: 1.2108 - val_loss: 6673.8125 - val_reconstruction_loss: 1897.5291 - val_kl_loss: 98.7596 - val_false_loss: 15.1726 - val_true_loss: 1.2574\n",
      "Epoch 149/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.0233 - reconstruction_loss: 1893.7330 - kl_loss: 99.8029 - false_loss: 0.1036 - true_loss: 1.2108 - val_loss: 6673.1821 - val_reconstruction_loss: 1897.5281 - val_kl_loss: 98.7613 - val_false_loss: 15.1705 - val_true_loss: 1.2574\n",
      "Epoch 150/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.9486 - reconstruction_loss: 1893.2086 - kl_loss: 99.3329 - false_loss: 0.1036 - true_loss: 1.2107 - val_loss: 6672.5586 - val_reconstruction_loss: 1897.5270 - val_kl_loss: 98.7610 - val_false_loss: 15.1685 - val_true_loss: 1.2573\n",
      "Epoch 151/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.2891 - reconstruction_loss: 1892.5449 - kl_loss: 98.6425 - false_loss: 0.1036 - true_loss: 1.2106 - val_loss: 6671.9346 - val_reconstruction_loss: 1897.5260 - val_kl_loss: 98.7599 - val_false_loss: 15.1664 - val_true_loss: 1.2573\n",
      "Epoch 152/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2258.7357 - reconstruction_loss: 1892.7939 - kl_loss: 100.2552 - false_loss: 0.1036 - true_loss: 1.2106 - val_loss: 6671.3120 - val_reconstruction_loss: 1897.5250 - val_kl_loss: 98.7597 - val_false_loss: 15.1644 - val_true_loss: 1.2572\n",
      "Epoch 153/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2258.8610 - reconstruction_loss: 1892.9205 - kl_loss: 97.8117 - false_loss: 0.1036 - true_loss: 1.2105 - val_loss: 6670.6938 - val_reconstruction_loss: 1897.5245 - val_kl_loss: 98.7609 - val_false_loss: 15.1623 - val_true_loss: 1.2572\n",
      "Epoch 154/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.3219 - reconstruction_loss: 1893.2155 - kl_loss: 98.0628 - false_loss: 0.1036 - true_loss: 1.2104 - val_loss: 6670.0684 - val_reconstruction_loss: 1897.5236 - val_kl_loss: 98.7626 - val_false_loss: 15.1603 - val_true_loss: 1.2571\n",
      "Epoch 155/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.2066 - reconstruction_loss: 1893.1396 - kl_loss: 98.2600 - false_loss: 0.1035 - true_loss: 1.2104 - val_loss: 6669.4497 - val_reconstruction_loss: 1897.5226 - val_kl_loss: 98.7636 - val_false_loss: 15.1582 - val_true_loss: 1.2571\n",
      "Epoch 156/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.2281 - reconstruction_loss: 1892.8517 - kl_loss: 99.1310 - false_loss: 0.1035 - true_loss: 1.2103 - val_loss: 6668.8271 - val_reconstruction_loss: 1897.5216 - val_kl_loss: 98.7644 - val_false_loss: 15.1562 - val_true_loss: 1.2570\n",
      "Epoch 157/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2245.7395 - reconstruction_loss: 1892.9052 - kl_loss: 99.5101 - false_loss: 0.1035 - true_loss: 1.2102 - val_loss: 6668.2124 - val_reconstruction_loss: 1897.5208 - val_kl_loss: 98.7642 - val_false_loss: 15.1541 - val_true_loss: 1.2569\n",
      "Epoch 158/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.1509 - reconstruction_loss: 1892.6766 - kl_loss: 98.5824 - false_loss: 0.1035 - true_loss: 1.2102 - val_loss: 6667.5840 - val_reconstruction_loss: 1897.5198 - val_kl_loss: 98.7635 - val_false_loss: 15.1521 - val_true_loss: 1.2569\n",
      "Epoch 159/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.8690 - reconstruction_loss: 1892.5439 - kl_loss: 99.3308 - false_loss: 0.1035 - true_loss: 1.2101 - val_loss: 6666.9629 - val_reconstruction_loss: 1897.5189 - val_kl_loss: 98.7631 - val_false_loss: 15.1500 - val_true_loss: 1.2568\n",
      "Epoch 160/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0287 - reconstruction_loss: 1892.6422 - kl_loss: 98.3370 - false_loss: 0.1035 - true_loss: 1.2100 - val_loss: 6666.3452 - val_reconstruction_loss: 1897.5179 - val_kl_loss: 98.7628 - val_false_loss: 15.1480 - val_true_loss: 1.2568\n",
      "Epoch 161/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.1360 - reconstruction_loss: 1892.7975 - kl_loss: 100.1414 - false_loss: 0.1035 - true_loss: 1.2100 - val_loss: 6665.7178 - val_reconstruction_loss: 1897.5170 - val_kl_loss: 98.7618 - val_false_loss: 15.1459 - val_true_loss: 1.2567\n",
      "Epoch 162/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.3610 - reconstruction_loss: 1893.1288 - kl_loss: 99.2728 - false_loss: 0.1035 - true_loss: 1.2099 - val_loss: 6665.0977 - val_reconstruction_loss: 1897.5160 - val_kl_loss: 98.7614 - val_false_loss: 15.1439 - val_true_loss: 1.2567\n",
      "Epoch 163/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.1426 - reconstruction_loss: 1892.8854 - kl_loss: 99.0491 - false_loss: 0.1035 - true_loss: 1.2098 - val_loss: 6664.4839 - val_reconstruction_loss: 1897.5150 - val_kl_loss: 98.7616 - val_false_loss: 15.1418 - val_true_loss: 1.2566\n",
      "Epoch 164/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.2321 - reconstruction_loss: 1892.9741 - kl_loss: 100.0198 - false_loss: 0.1034 - true_loss: 1.2098 - val_loss: 6663.8677 - val_reconstruction_loss: 1897.5142 - val_kl_loss: 98.7616 - val_false_loss: 15.1398 - val_true_loss: 1.2565\n",
      "Epoch 165/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.3165 - reconstruction_loss: 1892.7588 - kl_loss: 98.8191 - false_loss: 0.1034 - true_loss: 1.2097 - val_loss: 6663.2490 - val_reconstruction_loss: 1897.5131 - val_kl_loss: 98.7619 - val_false_loss: 15.1378 - val_true_loss: 1.2565\n",
      "Epoch 166/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.8526 - reconstruction_loss: 1893.0054 - kl_loss: 99.7921 - false_loss: 0.1034 - true_loss: 1.2096 - val_loss: 6662.6304 - val_reconstruction_loss: 1897.5121 - val_kl_loss: 98.7624 - val_false_loss: 15.1357 - val_true_loss: 1.2564\n",
      "Epoch 167/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.8695 - reconstruction_loss: 1893.0576 - kl_loss: 99.8023 - false_loss: 0.1034 - true_loss: 1.2096 - val_loss: 6662.0132 - val_reconstruction_loss: 1897.5110 - val_kl_loss: 98.7643 - val_false_loss: 15.1337 - val_true_loss: 1.2564\n",
      "Epoch 168/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.5302 - reconstruction_loss: 1892.5778 - kl_loss: 99.4021 - false_loss: 0.1034 - true_loss: 1.2095 - val_loss: 6661.3975 - val_reconstruction_loss: 1897.5103 - val_kl_loss: 98.7651 - val_false_loss: 15.1317 - val_true_loss: 1.2563\n",
      "Epoch 169/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.4918 - reconstruction_loss: 1892.9503 - kl_loss: 99.7426 - false_loss: 0.1034 - true_loss: 1.2094 - val_loss: 6660.7788 - val_reconstruction_loss: 1897.5093 - val_kl_loss: 98.7659 - val_false_loss: 15.1296 - val_true_loss: 1.2562\n",
      "Epoch 170/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.1909 - reconstruction_loss: 1893.5714 - kl_loss: 100.9483 - false_loss: 0.1034 - true_loss: 1.2094 - val_loss: 6660.1660 - val_reconstruction_loss: 1897.5081 - val_kl_loss: 98.7683 - val_false_loss: 15.1276 - val_true_loss: 1.2562\n",
      "Epoch 171/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.0979 - reconstruction_loss: 1893.5179 - kl_loss: 99.5180 - false_loss: 0.1034 - true_loss: 1.2093 - val_loss: 6659.5464 - val_reconstruction_loss: 1897.5073 - val_kl_loss: 98.7698 - val_false_loss: 15.1255 - val_true_loss: 1.2561\n",
      "Epoch 172/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.0672 - reconstruction_loss: 1893.1064 - kl_loss: 99.0966 - false_loss: 0.1034 - true_loss: 1.2092 - val_loss: 6658.9268 - val_reconstruction_loss: 1897.5062 - val_kl_loss: 98.7708 - val_false_loss: 15.1235 - val_true_loss: 1.2561\n",
      "Epoch 173/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.7232 - reconstruction_loss: 1893.4108 - kl_loss: 98.9766 - false_loss: 0.1034 - true_loss: 1.2092 - val_loss: 6658.3110 - val_reconstruction_loss: 1897.5055 - val_kl_loss: 98.7713 - val_false_loss: 15.1215 - val_true_loss: 1.2560\n",
      "Epoch 174/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.4006 - reconstruction_loss: 1892.6793 - kl_loss: 99.4704 - false_loss: 0.1033 - true_loss: 1.2091 - val_loss: 6657.6885 - val_reconstruction_loss: 1897.5045 - val_kl_loss: 98.7726 - val_false_loss: 15.1194 - val_true_loss: 1.2559\n",
      "Epoch 175/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.8607 - reconstruction_loss: 1892.6759 - kl_loss: 99.8982 - false_loss: 0.1033 - true_loss: 1.2090 - val_loss: 6657.0806 - val_reconstruction_loss: 1897.5037 - val_kl_loss: 98.7720 - val_false_loss: 15.1174 - val_true_loss: 1.2559\n",
      "Epoch 176/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.3343 - reconstruction_loss: 1892.5648 - kl_loss: 99.8859 - false_loss: 0.1033 - true_loss: 1.2090 - val_loss: 6656.4644 - val_reconstruction_loss: 1897.5027 - val_kl_loss: 98.7709 - val_false_loss: 15.1154 - val_true_loss: 1.2558\n",
      "Epoch 177/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.9913 - reconstruction_loss: 1893.1451 - kl_loss: 99.9363 - false_loss: 0.1033 - true_loss: 1.2089 - val_loss: 6655.8467 - val_reconstruction_loss: 1897.5018 - val_kl_loss: 98.7699 - val_false_loss: 15.1133 - val_true_loss: 1.2558\n",
      "Epoch 178/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.4617 - reconstruction_loss: 1893.0826 - kl_loss: 98.5646 - false_loss: 0.1033 - true_loss: 1.2088 - val_loss: 6655.2290 - val_reconstruction_loss: 1897.5009 - val_kl_loss: 98.7699 - val_false_loss: 15.1113 - val_true_loss: 1.2557\n",
      "Epoch 179/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.9384 - reconstruction_loss: 1892.9253 - kl_loss: 99.7047 - false_loss: 0.1033 - true_loss: 1.2088 - val_loss: 6654.6089 - val_reconstruction_loss: 1897.4999 - val_kl_loss: 98.7695 - val_false_loss: 15.1093 - val_true_loss: 1.2557\n",
      "Epoch 180/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.2542 - reconstruction_loss: 1892.6522 - kl_loss: 99.7943 - false_loss: 0.1033 - true_loss: 1.2087 - val_loss: 6653.9971 - val_reconstruction_loss: 1897.4989 - val_kl_loss: 98.7688 - val_false_loss: 15.1072 - val_true_loss: 1.2556\n",
      "Epoch 181/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.7085 - reconstruction_loss: 1892.5830 - kl_loss: 99.2862 - false_loss: 0.1033 - true_loss: 1.2086 - val_loss: 6653.3804 - val_reconstruction_loss: 1897.4979 - val_kl_loss: 98.7682 - val_false_loss: 15.1052 - val_true_loss: 1.2556\n",
      "Epoch 182/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.7590 - reconstruction_loss: 1892.5996 - kl_loss: 98.9763 - false_loss: 0.1033 - true_loss: 1.2086 - val_loss: 6652.7573 - val_reconstruction_loss: 1897.4969 - val_kl_loss: 98.7687 - val_false_loss: 15.1032 - val_true_loss: 1.2555\n",
      "Epoch 183/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.4517 - reconstruction_loss: 1892.3434 - kl_loss: 99.5836 - false_loss: 0.1032 - true_loss: 1.2085 - val_loss: 6652.1470 - val_reconstruction_loss: 1897.4960 - val_kl_loss: 98.7688 - val_false_loss: 15.1011 - val_true_loss: 1.2554\n",
      "Epoch 184/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.5148 - reconstruction_loss: 1892.9830 - kl_loss: 99.3889 - false_loss: 0.1032 - true_loss: 1.2084 - val_loss: 6651.5371 - val_reconstruction_loss: 1897.4950 - val_kl_loss: 98.7691 - val_false_loss: 15.0991 - val_true_loss: 1.2554\n",
      "Epoch 185/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.1099 - reconstruction_loss: 1892.8688 - kl_loss: 99.4927 - false_loss: 0.1032 - true_loss: 1.2084 - val_loss: 6650.9209 - val_reconstruction_loss: 1897.4941 - val_kl_loss: 98.7693 - val_false_loss: 15.0971 - val_true_loss: 1.2553\n",
      "Epoch 186/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0270 - reconstruction_loss: 1893.1421 - kl_loss: 99.9039 - false_loss: 0.1032 - true_loss: 1.2083 - val_loss: 6650.3115 - val_reconstruction_loss: 1897.4934 - val_kl_loss: 98.7693 - val_false_loss: 15.0951 - val_true_loss: 1.2553\n",
      "Epoch 187/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.0578 - reconstruction_loss: 1892.7988 - kl_loss: 100.2410 - false_loss: 0.1032 - true_loss: 1.2082 - val_loss: 6649.7012 - val_reconstruction_loss: 1897.4924 - val_kl_loss: 98.7691 - val_false_loss: 15.0931 - val_true_loss: 1.2552\n",
      "Epoch 188/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6260 - reconstruction_loss: 1892.6039 - kl_loss: 98.6136 - false_loss: 0.1032 - true_loss: 1.2082 - val_loss: 6649.0952 - val_reconstruction_loss: 1897.4916 - val_kl_loss: 98.7707 - val_false_loss: 15.0911 - val_true_loss: 1.2551\n",
      "Epoch 189/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.0192 - reconstruction_loss: 1892.4884 - kl_loss: 99.8010 - false_loss: 0.1032 - true_loss: 1.2081 - val_loss: 6648.4824 - val_reconstruction_loss: 1897.4906 - val_kl_loss: 98.7719 - val_false_loss: 15.0891 - val_true_loss: 1.2551\n",
      "Epoch 190/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.5056 - reconstruction_loss: 1892.7358 - kl_loss: 98.9135 - false_loss: 0.1032 - true_loss: 1.2080 - val_loss: 6647.8633 - val_reconstruction_loss: 1897.4897 - val_kl_loss: 98.7729 - val_false_loss: 15.0870 - val_true_loss: 1.2550\n",
      "Epoch 191/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.0994 - reconstruction_loss: 1893.0146 - kl_loss: 98.6465 - false_loss: 0.1032 - true_loss: 1.2080 - val_loss: 6647.2476 - val_reconstruction_loss: 1897.4888 - val_kl_loss: 98.7730 - val_false_loss: 15.0850 - val_true_loss: 1.2550\n",
      "Epoch 192/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.3363 - reconstruction_loss: 1892.8754 - kl_loss: 99.1298 - false_loss: 0.1031 - true_loss: 1.2079 - val_loss: 6646.6396 - val_reconstruction_loss: 1897.4878 - val_kl_loss: 98.7735 - val_false_loss: 15.0830 - val_true_loss: 1.2549\n",
      "Epoch 193/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.7745 - reconstruction_loss: 1892.9022 - kl_loss: 99.8700 - false_loss: 0.1031 - true_loss: 1.2078 - val_loss: 6646.0239 - val_reconstruction_loss: 1897.4868 - val_kl_loss: 98.7742 - val_false_loss: 15.0809 - val_true_loss: 1.2548\n",
      "Epoch 194/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.4202 - reconstruction_loss: 1892.9004 - kl_loss: 99.7077 - false_loss: 0.1031 - true_loss: 1.2078 - val_loss: 6645.4136 - val_reconstruction_loss: 1897.4861 - val_kl_loss: 98.7736 - val_false_loss: 15.0789 - val_true_loss: 1.2548\n",
      "Epoch 195/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.0593 - reconstruction_loss: 1893.1185 - kl_loss: 100.9999 - false_loss: 0.1031 - true_loss: 1.2077 - val_loss: 6644.8013 - val_reconstruction_loss: 1897.4852 - val_kl_loss: 98.7729 - val_false_loss: 15.0769 - val_true_loss: 1.2547\n",
      "Epoch 196/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.6993 - reconstruction_loss: 1892.6793 - kl_loss: 99.4573 - false_loss: 0.1031 - true_loss: 1.2076 - val_loss: 6644.1953 - val_reconstruction_loss: 1897.4845 - val_kl_loss: 98.7740 - val_false_loss: 15.0749 - val_true_loss: 1.2547\n",
      "Epoch 197/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.7581 - reconstruction_loss: 1892.9625 - kl_loss: 98.9374 - false_loss: 0.1031 - true_loss: 1.2076 - val_loss: 6643.5933 - val_reconstruction_loss: 1897.4835 - val_kl_loss: 98.7749 - val_false_loss: 15.0729 - val_true_loss: 1.2546\n",
      "Epoch 198/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.5714 - reconstruction_loss: 1892.5062 - kl_loss: 99.1125 - false_loss: 0.1031 - true_loss: 1.2075 - val_loss: 6642.9824 - val_reconstruction_loss: 1897.4825 - val_kl_loss: 98.7747 - val_false_loss: 15.0709 - val_true_loss: 1.2545\n",
      "Epoch 199/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.8966 - reconstruction_loss: 1892.5807 - kl_loss: 99.6704 - false_loss: 0.1031 - true_loss: 1.2074 - val_loss: 6642.3740 - val_reconstruction_loss: 1897.4813 - val_kl_loss: 98.7741 - val_false_loss: 15.0689 - val_true_loss: 1.2545\n",
      "Epoch 200/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.1753 - reconstruction_loss: 1892.9717 - kl_loss: 97.8219 - false_loss: 0.1031 - true_loss: 1.2074 - val_loss: 6641.7690 - val_reconstruction_loss: 1897.4803 - val_kl_loss: 98.7734 - val_false_loss: 15.0669 - val_true_loss: 1.2544\n",
      "Epoch 201/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.3073 - reconstruction_loss: 1892.4556 - kl_loss: 98.7632 - false_loss: 0.1031 - true_loss: 1.2073 - val_loss: 6641.1597 - val_reconstruction_loss: 1897.4796 - val_kl_loss: 98.7726 - val_false_loss: 15.0649 - val_true_loss: 1.2544\n",
      "Epoch 202/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2253.7657 - reconstruction_loss: 1892.7394 - kl_loss: 98.9910 - false_loss: 0.1030 - true_loss: 1.2072 - val_loss: 6640.5562 - val_reconstruction_loss: 1897.4786 - val_kl_loss: 98.7717 - val_false_loss: 15.0629 - val_true_loss: 1.2544\n",
      "Epoch 203/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2261.1626 - reconstruction_loss: 1892.7417 - kl_loss: 99.5883 - false_loss: 0.1030 - true_loss: 1.2072 - val_loss: 6639.9458 - val_reconstruction_loss: 1897.4778 - val_kl_loss: 98.7711 - val_false_loss: 15.0609 - val_true_loss: 1.2543\n",
      "Epoch 204/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.0626 - reconstruction_loss: 1892.4971 - kl_loss: 99.3033 - false_loss: 0.1030 - true_loss: 1.2071 - val_loss: 6639.3325 - val_reconstruction_loss: 1897.4768 - val_kl_loss: 98.7711 - val_false_loss: 15.0589 - val_true_loss: 1.2542\n",
      "Epoch 205/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.5722 - reconstruction_loss: 1892.8256 - kl_loss: 99.9257 - false_loss: 0.1030 - true_loss: 1.2070 - val_loss: 6638.7202 - val_reconstruction_loss: 1897.4758 - val_kl_loss: 98.7706 - val_false_loss: 15.0569 - val_true_loss: 1.2542\n",
      "Epoch 206/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.9067 - reconstruction_loss: 1892.9506 - kl_loss: 99.4213 - false_loss: 0.1030 - true_loss: 1.2070 - val_loss: 6638.1133 - val_reconstruction_loss: 1897.4752 - val_kl_loss: 98.7694 - val_false_loss: 15.0549 - val_true_loss: 1.2541\n",
      "Epoch 207/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2261.7131 - reconstruction_loss: 1892.5795 - kl_loss: 100.8967 - false_loss: 0.1030 - true_loss: 1.2069 - val_loss: 6637.5039 - val_reconstruction_loss: 1897.4742 - val_kl_loss: 98.7698 - val_false_loss: 15.0529 - val_true_loss: 1.2541\n",
      "Epoch 208/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.4350 - reconstruction_loss: 1892.8082 - kl_loss: 100.0446 - false_loss: 0.1030 - true_loss: 1.2069 - val_loss: 6636.8921 - val_reconstruction_loss: 1897.4734 - val_kl_loss: 98.7710 - val_false_loss: 15.0508 - val_true_loss: 1.2540\n",
      "Epoch 209/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2246.6426 - reconstruction_loss: 1893.2374 - kl_loss: 97.9790 - false_loss: 0.1030 - true_loss: 1.2068 - val_loss: 6636.2783 - val_reconstruction_loss: 1897.4724 - val_kl_loss: 98.7717 - val_false_loss: 15.0488 - val_true_loss: 1.2539\n",
      "Epoch 210/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.0404 - reconstruction_loss: 1892.5812 - kl_loss: 99.7700 - false_loss: 0.1030 - true_loss: 1.2067 - val_loss: 6635.6748 - val_reconstruction_loss: 1897.4717 - val_kl_loss: 98.7719 - val_false_loss: 15.0468 - val_true_loss: 1.2539\n",
      "Epoch 211/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.6767 - reconstruction_loss: 1892.7626 - kl_loss: 99.0549 - false_loss: 0.1029 - true_loss: 1.2067 - val_loss: 6635.0610 - val_reconstruction_loss: 1897.4705 - val_kl_loss: 98.7721 - val_false_loss: 15.0448 - val_true_loss: 1.2538\n",
      "Epoch 212/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.6654 - reconstruction_loss: 1892.6108 - kl_loss: 99.5192 - false_loss: 0.1029 - true_loss: 1.2066 - val_loss: 6634.4546 - val_reconstruction_loss: 1897.4694 - val_kl_loss: 98.7726 - val_false_loss: 15.0428 - val_true_loss: 1.2538\n",
      "Epoch 213/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.4761 - reconstruction_loss: 1892.7975 - kl_loss: 99.8177 - false_loss: 0.1029 - true_loss: 1.2065 - val_loss: 6633.8491 - val_reconstruction_loss: 1897.4688 - val_kl_loss: 98.7740 - val_false_loss: 15.0408 - val_true_loss: 1.2537\n",
      "Epoch 214/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.7091 - reconstruction_loss: 1893.1270 - kl_loss: 99.1597 - false_loss: 0.1029 - true_loss: 1.2065 - val_loss: 6633.2397 - val_reconstruction_loss: 1897.4675 - val_kl_loss: 98.7747 - val_false_loss: 15.0388 - val_true_loss: 1.2537\n",
      "Epoch 215/2700\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2245.4528 - reconstruction_loss: 1892.6729 - kl_loss: 98.9474 - false_loss: 0.1029 - true_loss: 1.2064 - val_loss: 6632.6289 - val_reconstruction_loss: 1897.4666 - val_kl_loss: 98.7756 - val_false_loss: 15.0368 - val_true_loss: 1.2536\n",
      "Epoch 216/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.5733 - reconstruction_loss: 1893.0460 - kl_loss: 99.5659 - false_loss: 0.1029 - true_loss: 1.2063 - val_loss: 6632.0112 - val_reconstruction_loss: 1897.4658 - val_kl_loss: 98.7760 - val_false_loss: 15.0347 - val_true_loss: 1.2535\n",
      "Epoch 217/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.8552 - reconstruction_loss: 1892.6730 - kl_loss: 99.8133 - false_loss: 0.1029 - true_loss: 1.2063 - val_loss: 6631.4077 - val_reconstruction_loss: 1897.4650 - val_kl_loss: 98.7764 - val_false_loss: 15.0328 - val_true_loss: 1.2535\n",
      "Epoch 218/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.7717 - reconstruction_loss: 1892.3219 - kl_loss: 99.4384 - false_loss: 0.1029 - true_loss: 1.2062 - val_loss: 6630.7983 - val_reconstruction_loss: 1897.4640 - val_kl_loss: 98.7765 - val_false_loss: 15.0307 - val_true_loss: 1.2534\n",
      "Epoch 219/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.8333 - reconstruction_loss: 1892.6627 - kl_loss: 99.0842 - false_loss: 0.1029 - true_loss: 1.2061 - val_loss: 6630.1885 - val_reconstruction_loss: 1897.4630 - val_kl_loss: 98.7773 - val_false_loss: 15.0287 - val_true_loss: 1.2533\n",
      "Epoch 220/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.9693 - reconstruction_loss: 1892.4186 - kl_loss: 99.5704 - false_loss: 0.1029 - true_loss: 1.2061 - val_loss: 6629.5786 - val_reconstruction_loss: 1897.4623 - val_kl_loss: 98.7788 - val_false_loss: 15.0267 - val_true_loss: 1.2533\n",
      "Epoch 221/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.3190 - reconstruction_loss: 1893.2858 - kl_loss: 99.9808 - false_loss: 0.1028 - true_loss: 1.2060 - val_loss: 6628.9736 - val_reconstruction_loss: 1897.4613 - val_kl_loss: 98.7799 - val_false_loss: 15.0247 - val_true_loss: 1.2532\n",
      "Epoch 222/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.8536 - reconstruction_loss: 1892.8717 - kl_loss: 99.7777 - false_loss: 0.1028 - true_loss: 1.2059 - val_loss: 6628.3643 - val_reconstruction_loss: 1897.4603 - val_kl_loss: 98.7810 - val_false_loss: 15.0227 - val_true_loss: 1.2532\n",
      "Epoch 223/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.1661 - reconstruction_loss: 1892.7455 - kl_loss: 99.2884 - false_loss: 0.1028 - true_loss: 1.2058 - val_loss: 6627.7603 - val_reconstruction_loss: 1897.4596 - val_kl_loss: 98.7825 - val_false_loss: 15.0207 - val_true_loss: 1.2531\n",
      "Epoch 224/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.3490 - reconstruction_loss: 1892.9639 - kl_loss: 99.1694 - false_loss: 0.1028 - true_loss: 1.2058 - val_loss: 6627.1538 - val_reconstruction_loss: 1897.4584 - val_kl_loss: 98.7844 - val_false_loss: 15.0187 - val_true_loss: 1.2530\n",
      "Epoch 225/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2253.1907 - reconstruction_loss: 1892.6417 - kl_loss: 98.8031 - false_loss: 0.1028 - true_loss: 1.2057 - val_loss: 6626.5479 - val_reconstruction_loss: 1897.4574 - val_kl_loss: 98.7849 - val_false_loss: 15.0167 - val_true_loss: 1.2530\n",
      "Epoch 226/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.3176 - reconstruction_loss: 1892.3854 - kl_loss: 99.5894 - false_loss: 0.1028 - true_loss: 1.2057 - val_loss: 6625.9360 - val_reconstruction_loss: 1897.4564 - val_kl_loss: 98.7848 - val_false_loss: 15.0147 - val_true_loss: 1.2529\n",
      "Epoch 227/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.4820 - reconstruction_loss: 1892.6030 - kl_loss: 99.5290 - false_loss: 0.1028 - true_loss: 1.2056 - val_loss: 6625.3281 - val_reconstruction_loss: 1897.4554 - val_kl_loss: 98.7846 - val_false_loss: 15.0127 - val_true_loss: 1.2529\n",
      "Epoch 228/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.7079 - reconstruction_loss: 1892.8812 - kl_loss: 99.5357 - false_loss: 0.1028 - true_loss: 1.2055 - val_loss: 6624.7212 - val_reconstruction_loss: 1897.4547 - val_kl_loss: 98.7848 - val_false_loss: 15.0107 - val_true_loss: 1.2528\n",
      "Epoch 229/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.3001 - reconstruction_loss: 1893.3286 - kl_loss: 99.7682 - false_loss: 0.1028 - true_loss: 1.2055 - val_loss: 6624.1182 - val_reconstruction_loss: 1897.4535 - val_kl_loss: 98.7841 - val_false_loss: 15.0087 - val_true_loss: 1.2528\n",
      "Epoch 230/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.4836 - reconstruction_loss: 1893.2665 - kl_loss: 99.1988 - false_loss: 0.1027 - true_loss: 1.2054 - val_loss: 6623.5112 - val_reconstruction_loss: 1897.4525 - val_kl_loss: 98.7835 - val_false_loss: 15.0067 - val_true_loss: 1.2527\n",
      "Epoch 231/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.8844 - reconstruction_loss: 1892.8145 - kl_loss: 99.8001 - false_loss: 0.1027 - true_loss: 1.2053 - val_loss: 6622.9087 - val_reconstruction_loss: 1897.4517 - val_kl_loss: 98.7834 - val_false_loss: 15.0047 - val_true_loss: 1.2526\n",
      "Epoch 232/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.1750 - reconstruction_loss: 1892.8013 - kl_loss: 98.6405 - false_loss: 0.1027 - true_loss: 1.2053 - val_loss: 6622.3062 - val_reconstruction_loss: 1897.4508 - val_kl_loss: 98.7835 - val_false_loss: 15.0027 - val_true_loss: 1.2526\n",
      "Epoch 233/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.6205 - reconstruction_loss: 1892.9062 - kl_loss: 98.8343 - false_loss: 0.1027 - true_loss: 1.2052 - val_loss: 6621.7080 - val_reconstruction_loss: 1897.4497 - val_kl_loss: 98.7848 - val_false_loss: 15.0008 - val_true_loss: 1.2525\n",
      "Epoch 234/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.8824 - reconstruction_loss: 1892.6852 - kl_loss: 100.0352 - false_loss: 0.1027 - true_loss: 1.2051 - val_loss: 6621.1025 - val_reconstruction_loss: 1897.4487 - val_kl_loss: 98.7851 - val_false_loss: 14.9988 - val_true_loss: 1.2525\n",
      "Epoch 235/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.7667 - reconstruction_loss: 1892.2550 - kl_loss: 98.9473 - false_loss: 0.1027 - true_loss: 1.2051 - val_loss: 6620.5039 - val_reconstruction_loss: 1897.4478 - val_kl_loss: 98.7853 - val_false_loss: 14.9968 - val_true_loss: 1.2524\n",
      "Epoch 236/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.7439 - reconstruction_loss: 1892.6879 - kl_loss: 99.6457 - false_loss: 0.1027 - true_loss: 1.2050 - val_loss: 6619.9014 - val_reconstruction_loss: 1897.4469 - val_kl_loss: 98.7850 - val_false_loss: 14.9948 - val_true_loss: 1.2523\n",
      "Epoch 237/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.7540 - reconstruction_loss: 1892.6436 - kl_loss: 99.1940 - false_loss: 0.1027 - true_loss: 1.2049 - val_loss: 6619.2954 - val_reconstruction_loss: 1897.4459 - val_kl_loss: 98.7852 - val_false_loss: 14.9928 - val_true_loss: 1.2523\n",
      "Epoch 238/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5630 - reconstruction_loss: 1892.4904 - kl_loss: 99.5346 - false_loss: 0.1027 - true_loss: 1.2049 - val_loss: 6618.6895 - val_reconstruction_loss: 1897.4452 - val_kl_loss: 98.7857 - val_false_loss: 14.9908 - val_true_loss: 1.2522\n",
      "Epoch 239/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.3601 - reconstruction_loss: 1892.8212 - kl_loss: 100.1081 - false_loss: 0.1027 - true_loss: 1.2048 - val_loss: 6618.0854 - val_reconstruction_loss: 1897.4441 - val_kl_loss: 98.7858 - val_false_loss: 14.9888 - val_true_loss: 1.2522\n",
      "Epoch 240/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.2332 - reconstruction_loss: 1892.2582 - kl_loss: 99.6278 - false_loss: 0.1026 - true_loss: 1.2047 - val_loss: 6617.4858 - val_reconstruction_loss: 1897.4431 - val_kl_loss: 98.7856 - val_false_loss: 14.9868 - val_true_loss: 1.2521\n",
      "Epoch 241/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.7340 - reconstruction_loss: 1892.8519 - kl_loss: 99.1778 - false_loss: 0.1026 - true_loss: 1.2047 - val_loss: 6616.8813 - val_reconstruction_loss: 1897.4423 - val_kl_loss: 98.7849 - val_false_loss: 14.9848 - val_true_loss: 1.2521\n",
      "Epoch 242/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2260.2954 - reconstruction_loss: 1892.9424 - kl_loss: 99.8086 - false_loss: 0.1026 - true_loss: 1.2046 - val_loss: 6616.2788 - val_reconstruction_loss: 1897.4417 - val_kl_loss: 98.7842 - val_false_loss: 14.9829 - val_true_loss: 1.2520\n",
      "Epoch 243/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.5409 - reconstruction_loss: 1892.6343 - kl_loss: 99.4902 - false_loss: 0.1026 - true_loss: 1.2045 - val_loss: 6615.6738 - val_reconstruction_loss: 1897.4407 - val_kl_loss: 98.7836 - val_false_loss: 14.9809 - val_true_loss: 1.2520\n",
      "Epoch 244/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.6715 - reconstruction_loss: 1893.4088 - kl_loss: 98.8634 - false_loss: 0.1026 - true_loss: 1.2045 - val_loss: 6615.0815 - val_reconstruction_loss: 1897.4398 - val_kl_loss: 98.7835 - val_false_loss: 14.9789 - val_true_loss: 1.2519\n",
      "Epoch 245/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.6147 - reconstruction_loss: 1892.6835 - kl_loss: 99.2331 - false_loss: 0.1026 - true_loss: 1.2044 - val_loss: 6614.4702 - val_reconstruction_loss: 1897.4390 - val_kl_loss: 98.7825 - val_false_loss: 14.9769 - val_true_loss: 1.2518\n",
      "Epoch 246/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2252.8854 - reconstruction_loss: 1892.6436 - kl_loss: 99.0294 - false_loss: 0.1026 - true_loss: 1.2043 - val_loss: 6613.8726 - val_reconstruction_loss: 1897.4382 - val_kl_loss: 98.7826 - val_false_loss: 14.9749 - val_true_loss: 1.2518\n",
      "Epoch 247/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.7645 - reconstruction_loss: 1892.4508 - kl_loss: 98.0486 - false_loss: 0.1026 - true_loss: 1.2043 - val_loss: 6613.2700 - val_reconstruction_loss: 1897.4373 - val_kl_loss: 98.7842 - val_false_loss: 14.9729 - val_true_loss: 1.2517\n",
      "Epoch 248/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.0643 - reconstruction_loss: 1892.7059 - kl_loss: 98.6041 - false_loss: 0.1026 - true_loss: 1.2042 - val_loss: 6612.6655 - val_reconstruction_loss: 1897.4363 - val_kl_loss: 98.7853 - val_false_loss: 14.9709 - val_true_loss: 1.2517\n",
      "Epoch 249/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.9348 - reconstruction_loss: 1892.2509 - kl_loss: 98.4130 - false_loss: 0.1025 - true_loss: 1.2042 - val_loss: 6612.0615 - val_reconstruction_loss: 1897.4353 - val_kl_loss: 98.7860 - val_false_loss: 14.9690 - val_true_loss: 1.2516\n",
      "Epoch 250/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.6913 - reconstruction_loss: 1892.3984 - kl_loss: 99.0722 - false_loss: 0.1025 - true_loss: 1.2041 - val_loss: 6611.4556 - val_reconstruction_loss: 1897.4346 - val_kl_loss: 98.7872 - val_false_loss: 14.9669 - val_true_loss: 1.2515\n",
      "Epoch 251/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.1522 - reconstruction_loss: 1892.9795 - kl_loss: 99.3941 - false_loss: 0.1025 - true_loss: 1.2040 - val_loss: 6610.8555 - val_reconstruction_loss: 1897.4336 - val_kl_loss: 98.7870 - val_false_loss: 14.9650 - val_true_loss: 1.2515\n",
      "Epoch 252/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.4308 - reconstruction_loss: 1892.7432 - kl_loss: 98.6946 - false_loss: 0.1025 - true_loss: 1.2040 - val_loss: 6610.2505 - val_reconstruction_loss: 1897.4327 - val_kl_loss: 98.7872 - val_false_loss: 14.9630 - val_true_loss: 1.2514\n",
      "Epoch 253/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.8009 - reconstruction_loss: 1892.6405 - kl_loss: 99.8397 - false_loss: 0.1025 - true_loss: 1.2039 - val_loss: 6609.6416 - val_reconstruction_loss: 1897.4316 - val_kl_loss: 98.7868 - val_false_loss: 14.9610 - val_true_loss: 1.2514\n",
      "Epoch 254/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.8165 - reconstruction_loss: 1892.6244 - kl_loss: 99.5789 - false_loss: 0.1025 - true_loss: 1.2038 - val_loss: 6609.0381 - val_reconstruction_loss: 1897.4308 - val_kl_loss: 98.7864 - val_false_loss: 14.9590 - val_true_loss: 1.2513\n",
      "Epoch 255/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.2340 - reconstruction_loss: 1892.4852 - kl_loss: 99.9277 - false_loss: 0.1025 - true_loss: 1.2038 - val_loss: 6608.4365 - val_reconstruction_loss: 1897.4299 - val_kl_loss: 98.7859 - val_false_loss: 14.9570 - val_true_loss: 1.2513\n",
      "Epoch 256/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.6874 - reconstruction_loss: 1893.1561 - kl_loss: 98.3983 - false_loss: 0.1025 - true_loss: 1.2037 - val_loss: 6607.8364 - val_reconstruction_loss: 1897.4290 - val_kl_loss: 98.7860 - val_false_loss: 14.9550 - val_true_loss: 1.2512\n",
      "Epoch 257/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.8270 - reconstruction_loss: 1892.4613 - kl_loss: 99.4995 - false_loss: 0.1025 - true_loss: 1.2036 - val_loss: 6607.2295 - val_reconstruction_loss: 1897.4280 - val_kl_loss: 98.7862 - val_false_loss: 14.9530 - val_true_loss: 1.2512\n",
      "Epoch 258/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.7092 - reconstruction_loss: 1892.6133 - kl_loss: 99.2589 - false_loss: 0.1025 - true_loss: 1.2036 - val_loss: 6606.6284 - val_reconstruction_loss: 1897.4271 - val_kl_loss: 98.7873 - val_false_loss: 14.9510 - val_true_loss: 1.2511\n",
      "Epoch 259/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.1639 - reconstruction_loss: 1892.5195 - kl_loss: 100.0053 - false_loss: 0.1024 - true_loss: 1.2035 - val_loss: 6606.0293 - val_reconstruction_loss: 1897.4263 - val_kl_loss: 98.7878 - val_false_loss: 14.9491 - val_true_loss: 1.2510\n",
      "Epoch 260/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.6208 - reconstruction_loss: 1892.4225 - kl_loss: 100.3271 - false_loss: 0.1024 - true_loss: 1.2034 - val_loss: 6605.4277 - val_reconstruction_loss: 1897.4253 - val_kl_loss: 98.7880 - val_false_loss: 14.9471 - val_true_loss: 1.2510\n",
      "Epoch 261/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 17s 1s/step - loss: 2238.3562 - reconstruction_loss: 1892.5709 - kl_loss: 100.1722 - false_loss: 0.1024 - true_loss: 1.2034 - val_loss: 6604.8359 - val_reconstruction_loss: 1897.4244 - val_kl_loss: 98.7879 - val_false_loss: 14.9451 - val_true_loss: 1.2509\n",
      "Epoch 262/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.1326 - reconstruction_loss: 1892.4517 - kl_loss: 99.7232 - false_loss: 0.1024 - true_loss: 1.2033 - val_loss: 6604.2275 - val_reconstruction_loss: 1897.4236 - val_kl_loss: 98.7876 - val_false_loss: 14.9431 - val_true_loss: 1.2509\n",
      "Epoch 263/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.2039 - reconstruction_loss: 1892.5060 - kl_loss: 100.7355 - false_loss: 0.1024 - true_loss: 1.2032 - val_loss: 6603.6235 - val_reconstruction_loss: 1897.4224 - val_kl_loss: 98.7868 - val_false_loss: 14.9411 - val_true_loss: 1.2508\n",
      "Epoch 264/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.6779 - reconstruction_loss: 1892.4106 - kl_loss: 99.9816 - false_loss: 0.1024 - true_loss: 1.2032 - val_loss: 6603.0273 - val_reconstruction_loss: 1897.4216 - val_kl_loss: 98.7860 - val_false_loss: 14.9392 - val_true_loss: 1.2508\n",
      "Epoch 265/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.4227 - reconstruction_loss: 1892.6805 - kl_loss: 99.7828 - false_loss: 0.1024 - true_loss: 1.2031 - val_loss: 6602.4297 - val_reconstruction_loss: 1897.4207 - val_kl_loss: 98.7859 - val_false_loss: 14.9372 - val_true_loss: 1.2507\n",
      "Epoch 266/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.6485 - reconstruction_loss: 1892.3934 - kl_loss: 100.2372 - false_loss: 0.1024 - true_loss: 1.2030 - val_loss: 6601.8369 - val_reconstruction_loss: 1897.4197 - val_kl_loss: 98.7857 - val_false_loss: 14.9352 - val_true_loss: 1.2506\n",
      "Epoch 267/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.7799 - reconstruction_loss: 1892.1964 - kl_loss: 99.9753 - false_loss: 0.1024 - true_loss: 1.2030 - val_loss: 6601.2402 - val_reconstruction_loss: 1897.4187 - val_kl_loss: 98.7857 - val_false_loss: 14.9333 - val_true_loss: 1.2506\n",
      "Epoch 268/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.5392 - reconstruction_loss: 1892.8073 - kl_loss: 99.2748 - false_loss: 0.1023 - true_loss: 1.2029 - val_loss: 6600.6450 - val_reconstruction_loss: 1897.4180 - val_kl_loss: 98.7861 - val_false_loss: 14.9313 - val_true_loss: 1.2505\n",
      "Epoch 269/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.2421 - reconstruction_loss: 1892.5695 - kl_loss: 99.2719 - false_loss: 0.1023 - true_loss: 1.2028 - val_loss: 6600.0479 - val_reconstruction_loss: 1897.4172 - val_kl_loss: 98.7863 - val_false_loss: 14.9293 - val_true_loss: 1.2505\n",
      "Epoch 270/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5742 - reconstruction_loss: 1893.4510 - kl_loss: 100.2019 - false_loss: 0.1023 - true_loss: 1.2028 - val_loss: 6599.4468 - val_reconstruction_loss: 1897.4164 - val_kl_loss: 98.7870 - val_false_loss: 14.9274 - val_true_loss: 1.2504\n",
      "Epoch 271/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2253.6091 - reconstruction_loss: 1893.2882 - kl_loss: 100.1404 - false_loss: 0.1023 - true_loss: 1.2027 - val_loss: 6598.8452 - val_reconstruction_loss: 1897.4154 - val_kl_loss: 98.7889 - val_false_loss: 14.9254 - val_true_loss: 1.2504\n",
      "Epoch 272/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.9626 - reconstruction_loss: 1892.4307 - kl_loss: 99.1186 - false_loss: 0.1023 - true_loss: 1.2026 - val_loss: 6598.2476 - val_reconstruction_loss: 1897.4146 - val_kl_loss: 98.7890 - val_false_loss: 14.9234 - val_true_loss: 1.2503\n",
      "Epoch 273/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.9659 - reconstruction_loss: 1892.5107 - kl_loss: 98.6408 - false_loss: 0.1023 - true_loss: 1.2026 - val_loss: 6597.6548 - val_reconstruction_loss: 1897.4136 - val_kl_loss: 98.7904 - val_false_loss: 14.9214 - val_true_loss: 1.2502\n",
      "Epoch 274/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.8878 - reconstruction_loss: 1892.3475 - kl_loss: 99.9691 - false_loss: 0.1023 - true_loss: 1.2025 - val_loss: 6597.0596 - val_reconstruction_loss: 1897.4126 - val_kl_loss: 98.7899 - val_false_loss: 14.9195 - val_true_loss: 1.2502\n",
      "Epoch 275/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.8346 - reconstruction_loss: 1892.9821 - kl_loss: 99.9042 - false_loss: 0.1023 - true_loss: 1.2025 - val_loss: 6596.4722 - val_reconstruction_loss: 1897.4119 - val_kl_loss: 98.7896 - val_false_loss: 14.9175 - val_true_loss: 1.2501\n",
      "Epoch 276/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.9223 - reconstruction_loss: 1892.9186 - kl_loss: 99.1493 - false_loss: 0.1023 - true_loss: 1.2024 - val_loss: 6595.8740 - val_reconstruction_loss: 1897.4106 - val_kl_loss: 98.7902 - val_false_loss: 14.9156 - val_true_loss: 1.2501\n",
      "Epoch 277/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.2341 - reconstruction_loss: 1892.6295 - kl_loss: 99.9013 - false_loss: 0.1023 - true_loss: 1.2023 - val_loss: 6595.2783 - val_reconstruction_loss: 1897.4099 - val_kl_loss: 98.7907 - val_false_loss: 14.9136 - val_true_loss: 1.2500\n",
      "Epoch 278/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.0342 - reconstruction_loss: 1892.4113 - kl_loss: 98.9987 - false_loss: 0.1022 - true_loss: 1.2022 - val_loss: 6594.6768 - val_reconstruction_loss: 1897.4089 - val_kl_loss: 98.7917 - val_false_loss: 14.9116 - val_true_loss: 1.2500\n",
      "Epoch 279/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.5398 - reconstruction_loss: 1892.5792 - kl_loss: 100.7772 - false_loss: 0.1022 - true_loss: 1.2022 - val_loss: 6594.0776 - val_reconstruction_loss: 1897.4080 - val_kl_loss: 98.7922 - val_false_loss: 14.9096 - val_true_loss: 1.2499\n",
      "Epoch 280/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.3359 - reconstruction_loss: 1892.2866 - kl_loss: 100.1060 - false_loss: 0.1022 - true_loss: 1.2021 - val_loss: 6593.4780 - val_reconstruction_loss: 1897.4069 - val_kl_loss: 98.7921 - val_false_loss: 14.9077 - val_true_loss: 1.2499\n",
      "Epoch 281/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.8434 - reconstruction_loss: 1892.8771 - kl_loss: 99.8074 - false_loss: 0.1022 - true_loss: 1.2020 - val_loss: 6592.8813 - val_reconstruction_loss: 1897.4061 - val_kl_loss: 98.7918 - val_false_loss: 14.9057 - val_true_loss: 1.2498\n",
      "Epoch 282/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.7935 - reconstruction_loss: 1892.4899 - kl_loss: 100.1439 - false_loss: 0.1022 - true_loss: 1.2020 - val_loss: 6592.2866 - val_reconstruction_loss: 1897.4052 - val_kl_loss: 98.7911 - val_false_loss: 14.9037 - val_true_loss: 1.2497\n",
      "Epoch 283/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.6884 - reconstruction_loss: 1892.3754 - kl_loss: 98.9277 - false_loss: 0.1022 - true_loss: 1.2019 - val_loss: 6591.6890 - val_reconstruction_loss: 1897.4042 - val_kl_loss: 98.7906 - val_false_loss: 14.9018 - val_true_loss: 1.2497\n",
      "Epoch 284/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.8724 - reconstruction_loss: 1892.5282 - kl_loss: 99.9324 - false_loss: 0.1022 - true_loss: 1.2018 - val_loss: 6591.0962 - val_reconstruction_loss: 1897.4032 - val_kl_loss: 98.7898 - val_false_loss: 14.8998 - val_true_loss: 1.2496\n",
      "Epoch 285/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5704 - reconstruction_loss: 1893.0547 - kl_loss: 100.5023 - false_loss: 0.1022 - true_loss: 1.2018 - val_loss: 6590.4976 - val_reconstruction_loss: 1897.4023 - val_kl_loss: 98.7892 - val_false_loss: 14.8978 - val_true_loss: 1.2496\n",
      "Epoch 286/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.0220 - reconstruction_loss: 1892.4340 - kl_loss: 99.5740 - false_loss: 0.1022 - true_loss: 1.2017 - val_loss: 6589.8999 - val_reconstruction_loss: 1897.4014 - val_kl_loss: 98.7889 - val_false_loss: 14.8959 - val_true_loss: 1.2495\n",
      "Epoch 287/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.4495 - reconstruction_loss: 1892.2266 - kl_loss: 99.4304 - false_loss: 0.1022 - true_loss: 1.2016 - val_loss: 6589.3013 - val_reconstruction_loss: 1897.4004 - val_kl_loss: 98.7890 - val_false_loss: 14.8939 - val_true_loss: 1.2495\n",
      "Epoch 288/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.0603 - reconstruction_loss: 1892.5062 - kl_loss: 100.1829 - false_loss: 0.1021 - true_loss: 1.2016 - val_loss: 6588.7065 - val_reconstruction_loss: 1897.3997 - val_kl_loss: 98.7881 - val_false_loss: 14.8919 - val_true_loss: 1.2494\n",
      "Epoch 289/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.9581 - reconstruction_loss: 1892.8063 - kl_loss: 99.6286 - false_loss: 0.1021 - true_loss: 1.2015 - val_loss: 6588.1196 - val_reconstruction_loss: 1897.3984 - val_kl_loss: 98.7885 - val_false_loss: 14.8900 - val_true_loss: 1.2494\n",
      "Epoch 290/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7040 - reconstruction_loss: 1892.3154 - kl_loss: 99.3111 - false_loss: 0.1021 - true_loss: 1.2015 - val_loss: 6587.5234 - val_reconstruction_loss: 1897.3979 - val_kl_loss: 98.7898 - val_false_loss: 14.8880 - val_true_loss: 1.2493\n",
      "Epoch 291/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.3619 - reconstruction_loss: 1892.7256 - kl_loss: 99.8748 - false_loss: 0.1021 - true_loss: 1.2014 - val_loss: 6586.9380 - val_reconstruction_loss: 1897.3967 - val_kl_loss: 98.7918 - val_false_loss: 14.8861 - val_true_loss: 1.2492\n",
      "Epoch 292/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.6054 - reconstruction_loss: 1892.7194 - kl_loss: 99.5484 - false_loss: 0.1021 - true_loss: 1.2013 - val_loss: 6586.3442 - val_reconstruction_loss: 1897.3960 - val_kl_loss: 98.7921 - val_false_loss: 14.8841 - val_true_loss: 1.2492\n",
      "Epoch 293/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.0958 - reconstruction_loss: 1892.8448 - kl_loss: 98.8499 - false_loss: 0.1021 - true_loss: 1.2013 - val_loss: 6585.7510 - val_reconstruction_loss: 1897.3949 - val_kl_loss: 98.7919 - val_false_loss: 14.8822 - val_true_loss: 1.2491\n",
      "Epoch 294/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.5873 - reconstruction_loss: 1892.4775 - kl_loss: 98.9500 - false_loss: 0.1021 - true_loss: 1.2012 - val_loss: 6585.1592 - val_reconstruction_loss: 1897.3940 - val_kl_loss: 98.7921 - val_false_loss: 14.8802 - val_true_loss: 1.2491\n",
      "Epoch 295/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.1200 - reconstruction_loss: 1892.1660 - kl_loss: 99.7454 - false_loss: 0.1021 - true_loss: 1.2011 - val_loss: 6584.5591 - val_reconstruction_loss: 1897.3932 - val_kl_loss: 98.7916 - val_false_loss: 14.8783 - val_true_loss: 1.2490\n",
      "Epoch 296/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.7685 - reconstruction_loss: 1892.4985 - kl_loss: 99.7398 - false_loss: 0.1021 - true_loss: 1.2011 - val_loss: 6583.9600 - val_reconstruction_loss: 1897.3922 - val_kl_loss: 98.7914 - val_false_loss: 14.8763 - val_true_loss: 1.2490\n",
      "Epoch 297/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2253.3263 - reconstruction_loss: 1892.1714 - kl_loss: 99.6281 - false_loss: 0.1020 - true_loss: 1.2010 - val_loss: 6583.3711 - val_reconstruction_loss: 1897.3915 - val_kl_loss: 98.7922 - val_false_loss: 14.8743 - val_true_loss: 1.2489\n",
      "Epoch 298/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2271.7361 - reconstruction_loss: 1892.7584 - kl_loss: 98.6977 - false_loss: 0.1020 - true_loss: 1.2009 - val_loss: 6582.7808 - val_reconstruction_loss: 1897.3905 - val_kl_loss: 98.7915 - val_false_loss: 14.8724 - val_true_loss: 1.2489\n",
      "Epoch 299/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2271.4205 - reconstruction_loss: 1892.6906 - kl_loss: 98.1641 - false_loss: 0.1020 - true_loss: 1.2009 - val_loss: 6582.1890 - val_reconstruction_loss: 1897.3895 - val_kl_loss: 98.7909 - val_false_loss: 14.8704 - val_true_loss: 1.2488\n",
      "Epoch 300/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2262.0381 - reconstruction_loss: 1892.3617 - kl_loss: 96.7438 - false_loss: 0.1020 - true_loss: 1.2008 - val_loss: 6581.5957 - val_reconstruction_loss: 1897.3884 - val_kl_loss: 98.7903 - val_false_loss: 14.8685 - val_true_loss: 1.2488\n",
      "Epoch 301/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2263.2817 - reconstruction_loss: 1892.6110 - kl_loss: 95.8312 - false_loss: 0.1020 - true_loss: 1.2008 - val_loss: 6581.0005 - val_reconstruction_loss: 1897.3877 - val_kl_loss: 98.7911 - val_false_loss: 14.8665 - val_true_loss: 1.2487\n",
      "Epoch 302/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2267.5925 - reconstruction_loss: 1892.4498 - kl_loss: 98.2927 - false_loss: 0.1020 - true_loss: 1.2007 - val_loss: 6580.4097 - val_reconstruction_loss: 1897.3868 - val_kl_loss: 98.7898 - val_false_loss: 14.8646 - val_true_loss: 1.2487\n",
      "Epoch 303/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2260.6204 - reconstruction_loss: 1892.6595 - kl_loss: 97.7000 - false_loss: 0.1020 - true_loss: 1.2007 - val_loss: 6579.8228 - val_reconstruction_loss: 1897.3861 - val_kl_loss: 98.7917 - val_false_loss: 14.8626 - val_true_loss: 1.2486\n",
      "Epoch 304/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.0109 - reconstruction_loss: 1892.5656 - kl_loss: 98.0691 - false_loss: 0.1020 - true_loss: 1.2006 - val_loss: 6579.2231 - val_reconstruction_loss: 1897.3851 - val_kl_loss: 98.7916 - val_false_loss: 14.8606 - val_true_loss: 1.2486\n",
      "Epoch 305/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.9141 - reconstruction_loss: 1892.1967 - kl_loss: 98.7325 - false_loss: 0.1020 - true_loss: 1.2006 - val_loss: 6578.6343 - val_reconstruction_loss: 1897.3843 - val_kl_loss: 98.7910 - val_false_loss: 14.8587 - val_true_loss: 1.2485\n",
      "Epoch 306/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.4616 - reconstruction_loss: 1892.5221 - kl_loss: 97.5966 - false_loss: 0.1020 - true_loss: 1.2005 - val_loss: 6578.0317 - val_reconstruction_loss: 1897.3834 - val_kl_loss: 98.7906 - val_false_loss: 14.8567 - val_true_loss: 1.2485\n",
      "Epoch 307/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.4245 - reconstruction_loss: 1892.9243 - kl_loss: 98.4635 - false_loss: 0.1019 - true_loss: 1.2004 - val_loss: 6577.4341 - val_reconstruction_loss: 1897.3826 - val_kl_loss: 98.7898 - val_false_loss: 14.8547 - val_true_loss: 1.2484\n",
      "Epoch 308/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.4433 - reconstruction_loss: 1892.2465 - kl_loss: 97.7490 - false_loss: 0.1019 - true_loss: 1.2004 - val_loss: 6576.8418 - val_reconstruction_loss: 1897.3816 - val_kl_loss: 98.7899 - val_false_loss: 14.8528 - val_true_loss: 1.2483\n",
      "Epoch 309/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.1390 - reconstruction_loss: 1892.7426 - kl_loss: 97.8947 - false_loss: 0.1019 - true_loss: 1.2003 - val_loss: 6576.2534 - val_reconstruction_loss: 1897.3806 - val_kl_loss: 98.7908 - val_false_loss: 14.8509 - val_true_loss: 1.2483\n",
      "Epoch 310/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.8325 - reconstruction_loss: 1892.4493 - kl_loss: 98.8699 - false_loss: 0.1019 - true_loss: 1.2002 - val_loss: 6575.6665 - val_reconstruction_loss: 1897.3796 - val_kl_loss: 98.7924 - val_false_loss: 14.8489 - val_true_loss: 1.2482\n",
      "Epoch 311/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.5292 - reconstruction_loss: 1892.0830 - kl_loss: 99.3890 - false_loss: 0.1019 - true_loss: 1.2002 - val_loss: 6575.0811 - val_reconstruction_loss: 1897.3788 - val_kl_loss: 98.7929 - val_false_loss: 14.8470 - val_true_loss: 1.2482\n",
      "Epoch 312/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.3548 - reconstruction_loss: 1892.4365 - kl_loss: 99.1552 - false_loss: 0.1019 - true_loss: 1.2001 - val_loss: 6574.4888 - val_reconstruction_loss: 1897.3778 - val_kl_loss: 98.7947 - val_false_loss: 14.8450 - val_true_loss: 1.2481\n",
      "Epoch 313/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2245.6708 - reconstruction_loss: 1892.6056 - kl_loss: 99.1101 - false_loss: 0.1019 - true_loss: 1.2000 - val_loss: 6573.8979 - val_reconstruction_loss: 1897.3768 - val_kl_loss: 98.7953 - val_false_loss: 14.8431 - val_true_loss: 1.2480\n",
      "Epoch 314/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.1080 - reconstruction_loss: 1892.1115 - kl_loss: 99.6437 - false_loss: 0.1019 - true_loss: 1.2000 - val_loss: 6573.3086 - val_reconstruction_loss: 1897.3760 - val_kl_loss: 98.7956 - val_false_loss: 14.8411 - val_true_loss: 1.2480\n",
      "Epoch 315/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.7198 - reconstruction_loss: 1892.5155 - kl_loss: 99.9977 - false_loss: 0.1019 - true_loss: 1.1999 - val_loss: 6572.7139 - val_reconstruction_loss: 1897.3750 - val_kl_loss: 98.7952 - val_false_loss: 14.8392 - val_true_loss: 1.2479\n",
      "Epoch 316/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.7088 - reconstruction_loss: 1892.4688 - kl_loss: 99.5343 - false_loss: 0.1019 - true_loss: 1.1998 - val_loss: 6572.1206 - val_reconstruction_loss: 1897.3743 - val_kl_loss: 98.7947 - val_false_loss: 14.8372 - val_true_loss: 1.2479\n",
      "Epoch 317/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.1512 - reconstruction_loss: 1892.4093 - kl_loss: 98.8839 - false_loss: 0.1018 - true_loss: 1.1998 - val_loss: 6571.5249 - val_reconstruction_loss: 1897.3734 - val_kl_loss: 98.7938 - val_false_loss: 14.8353 - val_true_loss: 1.2478\n",
      "Epoch 318/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.4163 - reconstruction_loss: 1892.4115 - kl_loss: 98.2413 - false_loss: 0.1018 - true_loss: 1.1997 - val_loss: 6570.9316 - val_reconstruction_loss: 1897.3727 - val_kl_loss: 98.7938 - val_false_loss: 14.8333 - val_true_loss: 1.2478\n",
      "Epoch 319/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.0439 - reconstruction_loss: 1892.5817 - kl_loss: 99.0295 - false_loss: 0.1018 - true_loss: 1.1997 - val_loss: 6570.3408 - val_reconstruction_loss: 1897.3717 - val_kl_loss: 98.7940 - val_false_loss: 14.8314 - val_true_loss: 1.2477\n",
      "Epoch 320/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6006 - reconstruction_loss: 1892.4535 - kl_loss: 99.3782 - false_loss: 0.1018 - true_loss: 1.1996 - val_loss: 6569.7573 - val_reconstruction_loss: 1897.3710 - val_kl_loss: 98.7943 - val_false_loss: 14.8294 - val_true_loss: 1.2477\n",
      "Epoch 321/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.9730 - reconstruction_loss: 1893.4098 - kl_loss: 98.0925 - false_loss: 0.1018 - true_loss: 1.1995 - val_loss: 6569.1660 - val_reconstruction_loss: 1897.3700 - val_kl_loss: 98.7952 - val_false_loss: 14.8275 - val_true_loss: 1.2476\n",
      "Epoch 322/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.4469 - reconstruction_loss: 1894.6053 - kl_loss: 98.7913 - false_loss: 0.1018 - true_loss: 1.1995 - val_loss: 6568.5781 - val_reconstruction_loss: 1897.3693 - val_kl_loss: 98.7950 - val_false_loss: 14.8255 - val_true_loss: 1.2475\n",
      "Epoch 323/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.6830 - reconstruction_loss: 1893.3287 - kl_loss: 99.6890 - false_loss: 0.1018 - true_loss: 1.1994 - val_loss: 6567.9883 - val_reconstruction_loss: 1897.3683 - val_kl_loss: 98.7945 - val_false_loss: 14.8236 - val_true_loss: 1.2475\n",
      "Epoch 324/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.1170 - reconstruction_loss: 1892.3544 - kl_loss: 99.3612 - false_loss: 0.1018 - true_loss: 1.1993 - val_loss: 6567.4023 - val_reconstruction_loss: 1897.3674 - val_kl_loss: 98.7938 - val_false_loss: 14.8217 - val_true_loss: 1.2474\n",
      "Epoch 325/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.0873 - reconstruction_loss: 1892.2372 - kl_loss: 100.3997 - false_loss: 0.1018 - true_loss: 1.1993 - val_loss: 6566.8135 - val_reconstruction_loss: 1897.3666 - val_kl_loss: 98.7934 - val_false_loss: 14.8197 - val_true_loss: 1.2474\n",
      "Epoch 326/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.3480 - reconstruction_loss: 1892.1500 - kl_loss: 98.5170 - false_loss: 0.1018 - true_loss: 1.1992 - val_loss: 6566.2354 - val_reconstruction_loss: 1897.3657 - val_kl_loss: 98.7935 - val_false_loss: 14.8178 - val_true_loss: 1.2473\n",
      "Epoch 327/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.4558 - reconstruction_loss: 1892.2267 - kl_loss: 99.1290 - false_loss: 0.1017 - true_loss: 1.1991 - val_loss: 6565.6504 - val_reconstruction_loss: 1897.3647 - val_kl_loss: 98.7937 - val_false_loss: 14.8159 - val_true_loss: 1.2473\n",
      "Epoch 328/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.9111 - reconstruction_loss: 1891.9248 - kl_loss: 100.5340 - false_loss: 0.1017 - true_loss: 1.1991 - val_loss: 6565.0630 - val_reconstruction_loss: 1897.3638 - val_kl_loss: 98.7925 - val_false_loss: 14.8140 - val_true_loss: 1.2472\n",
      "Epoch 329/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.0550 - reconstruction_loss: 1892.6537 - kl_loss: 99.3251 - false_loss: 0.1017 - true_loss: 1.1990 - val_loss: 6564.4746 - val_reconstruction_loss: 1897.3633 - val_kl_loss: 98.7928 - val_false_loss: 14.8120 - val_true_loss: 1.2472\n",
      "Epoch 330/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.7692 - reconstruction_loss: 1893.2598 - kl_loss: 98.8250 - false_loss: 0.1017 - true_loss: 1.1989 - val_loss: 6563.8882 - val_reconstruction_loss: 1897.3622 - val_kl_loss: 98.7929 - val_false_loss: 14.8101 - val_true_loss: 1.2471\n",
      "Epoch 331/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6890 - reconstruction_loss: 1892.9126 - kl_loss: 99.4707 - false_loss: 0.1017 - true_loss: 1.1989 - val_loss: 6563.3042 - val_reconstruction_loss: 1897.3613 - val_kl_loss: 98.7930 - val_false_loss: 14.8082 - val_true_loss: 1.2470\n",
      "Epoch 332/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.2113 - reconstruction_loss: 1892.2103 - kl_loss: 100.5738 - false_loss: 0.1017 - true_loss: 1.1988 - val_loss: 6562.7217 - val_reconstruction_loss: 1897.3605 - val_kl_loss: 98.7924 - val_false_loss: 14.8062 - val_true_loss: 1.2470\n",
      "Epoch 333/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.3738 - reconstruction_loss: 1892.5908 - kl_loss: 99.3243 - false_loss: 0.1017 - true_loss: 1.1988 - val_loss: 6562.1289 - val_reconstruction_loss: 1897.3596 - val_kl_loss: 98.7927 - val_false_loss: 14.8043 - val_true_loss: 1.2469\n",
      "Epoch 334/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.5025 - reconstruction_loss: 1892.5104 - kl_loss: 99.2183 - false_loss: 0.1017 - true_loss: 1.1987 - val_loss: 6561.5410 - val_reconstruction_loss: 1897.3588 - val_kl_loss: 98.7931 - val_false_loss: 14.8024 - val_true_loss: 1.2469\n",
      "Epoch 335/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.5239 - reconstruction_loss: 1892.1495 - kl_loss: 99.1122 - false_loss: 0.1017 - true_loss: 1.1986 - val_loss: 6560.9551 - val_reconstruction_loss: 1897.3580 - val_kl_loss: 98.7952 - val_false_loss: 14.8004 - val_true_loss: 1.2468\n",
      "Epoch 336/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.4561 - reconstruction_loss: 1892.3470 - kl_loss: 100.4584 - false_loss: 0.1016 - true_loss: 1.1986 - val_loss: 6560.3682 - val_reconstruction_loss: 1897.3571 - val_kl_loss: 98.7955 - val_false_loss: 14.7985 - val_true_loss: 1.2467\n",
      "Epoch 337/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.3918 - reconstruction_loss: 1892.3580 - kl_loss: 99.4751 - false_loss: 0.1016 - true_loss: 1.1985 - val_loss: 6559.7920 - val_reconstruction_loss: 1897.3563 - val_kl_loss: 98.7973 - val_false_loss: 14.7966 - val_true_loss: 1.2467\n",
      "Epoch 338/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.5413 - reconstruction_loss: 1892.5521 - kl_loss: 99.2842 - false_loss: 0.1016 - true_loss: 1.1984 - val_loss: 6559.2129 - val_reconstruction_loss: 1897.3553 - val_kl_loss: 98.7983 - val_false_loss: 14.7947 - val_true_loss: 1.2466\n",
      "Epoch 339/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.3029 - reconstruction_loss: 1892.1527 - kl_loss: 98.9551 - false_loss: 0.1016 - true_loss: 1.1984 - val_loss: 6558.6289 - val_reconstruction_loss: 1897.3546 - val_kl_loss: 98.7988 - val_false_loss: 14.7927 - val_true_loss: 1.2466\n",
      "Epoch 340/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.3033 - reconstruction_loss: 1892.1508 - kl_loss: 99.3594 - false_loss: 0.1016 - true_loss: 1.1983 - val_loss: 6558.0356 - val_reconstruction_loss: 1897.3536 - val_kl_loss: 98.7993 - val_false_loss: 14.7908 - val_true_loss: 1.2465\n",
      "Epoch 341/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.2188 - reconstruction_loss: 1892.1771 - kl_loss: 99.5530 - false_loss: 0.1016 - true_loss: 1.1982 - val_loss: 6557.4478 - val_reconstruction_loss: 1897.3525 - val_kl_loss: 98.7989 - val_false_loss: 14.7888 - val_true_loss: 1.2465\n",
      "Epoch 342/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.3085 - reconstruction_loss: 1892.2067 - kl_loss: 100.0447 - false_loss: 0.1016 - true_loss: 1.1982 - val_loss: 6556.8584 - val_reconstruction_loss: 1897.3518 - val_kl_loss: 98.7984 - val_false_loss: 14.7869 - val_true_loss: 1.2464\n",
      "Epoch 343/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.9190 - reconstruction_loss: 1892.1949 - kl_loss: 99.7081 - false_loss: 0.1016 - true_loss: 1.1981 - val_loss: 6556.2778 - val_reconstruction_loss: 1897.3508 - val_kl_loss: 98.7980 - val_false_loss: 14.7850 - val_true_loss: 1.2464\n",
      "Epoch 344/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.4810 - reconstruction_loss: 1892.2148 - kl_loss: 99.1042 - false_loss: 0.1016 - true_loss: 1.1980 - val_loss: 6555.6914 - val_reconstruction_loss: 1897.3500 - val_kl_loss: 98.7987 - val_false_loss: 14.7830 - val_true_loss: 1.2463\n",
      "Epoch 345/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.2061 - reconstruction_loss: 1892.5182 - kl_loss: 99.9694 - false_loss: 0.1016 - true_loss: 1.1980 - val_loss: 6555.1011 - val_reconstruction_loss: 1897.3490 - val_kl_loss: 98.7991 - val_false_loss: 14.7811 - val_true_loss: 1.2463\n",
      "Epoch 346/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.3042 - reconstruction_loss: 1892.4873 - kl_loss: 100.1824 - false_loss: 0.1015 - true_loss: 1.1979 - val_loss: 6554.5146 - val_reconstruction_loss: 1897.3480 - val_kl_loss: 98.7992 - val_false_loss: 14.7792 - val_true_loss: 1.2462\n",
      "Epoch 347/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.4818 - reconstruction_loss: 1892.6259 - kl_loss: 99.2845 - false_loss: 0.1015 - true_loss: 1.1978 - val_loss: 6553.9292 - val_reconstruction_loss: 1897.3475 - val_kl_loss: 98.7997 - val_false_loss: 14.7772 - val_true_loss: 1.2461\n",
      "Epoch 348/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.7445 - reconstruction_loss: 1892.0387 - kl_loss: 98.8292 - false_loss: 0.1015 - true_loss: 1.1978 - val_loss: 6553.3418 - val_reconstruction_loss: 1897.3464 - val_kl_loss: 98.8002 - val_false_loss: 14.7753 - val_true_loss: 1.2461\n",
      "Epoch 349/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.9912 - reconstruction_loss: 1892.0537 - kl_loss: 100.3838 - false_loss: 0.1015 - true_loss: 1.1977 - val_loss: 6552.7612 - val_reconstruction_loss: 1897.3455 - val_kl_loss: 98.8003 - val_false_loss: 14.7734 - val_true_loss: 1.2460\n",
      "Epoch 350/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.9694 - reconstruction_loss: 1891.9208 - kl_loss: 99.7749 - false_loss: 0.1015 - true_loss: 1.1976 - val_loss: 6552.1816 - val_reconstruction_loss: 1897.3447 - val_kl_loss: 98.8005 - val_false_loss: 14.7715 - val_true_loss: 1.2460\n",
      "Epoch 351/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.2724 - reconstruction_loss: 1892.0055 - kl_loss: 99.7766 - false_loss: 0.1015 - true_loss: 1.1976 - val_loss: 6551.6079 - val_reconstruction_loss: 1897.3440 - val_kl_loss: 98.8017 - val_false_loss: 14.7696 - val_true_loss: 1.2459\n",
      "Epoch 352/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.2346 - reconstruction_loss: 1892.7426 - kl_loss: 98.9072 - false_loss: 0.1015 - true_loss: 1.1975 - val_loss: 6551.0195 - val_reconstruction_loss: 1897.3429 - val_kl_loss: 98.8026 - val_false_loss: 14.7676 - val_true_loss: 1.2458\n",
      "Epoch 353/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.3597 - reconstruction_loss: 1891.9833 - kl_loss: 98.5906 - false_loss: 0.1015 - true_loss: 1.1975 - val_loss: 6550.4355 - val_reconstruction_loss: 1897.3420 - val_kl_loss: 98.8034 - val_false_loss: 14.7657 - val_true_loss: 1.2458\n",
      "Epoch 354/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.4415 - reconstruction_loss: 1892.7289 - kl_loss: 98.9145 - false_loss: 0.1015 - true_loss: 1.1974 - val_loss: 6549.8472 - val_reconstruction_loss: 1897.3409 - val_kl_loss: 98.8038 - val_false_loss: 14.7638 - val_true_loss: 1.2457\n",
      "Epoch 355/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.7531 - reconstruction_loss: 1892.2490 - kl_loss: 99.2923 - false_loss: 0.1015 - true_loss: 1.1973 - val_loss: 6549.2759 - val_reconstruction_loss: 1897.3402 - val_kl_loss: 98.8045 - val_false_loss: 14.7619 - val_true_loss: 1.2457\n",
      "Epoch 356/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.6141 - reconstruction_loss: 1892.3329 - kl_loss: 99.1621 - false_loss: 0.1014 - true_loss: 1.1973 - val_loss: 6548.6958 - val_reconstruction_loss: 1897.3395 - val_kl_loss: 98.8048 - val_false_loss: 14.7600 - val_true_loss: 1.2456\n",
      "Epoch 357/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.4455 - reconstruction_loss: 1892.5209 - kl_loss: 100.4650 - false_loss: 0.1014 - true_loss: 1.1972 - val_loss: 6548.1167 - val_reconstruction_loss: 1897.3385 - val_kl_loss: 98.8047 - val_false_loss: 14.7581 - val_true_loss: 1.2456\n",
      "Epoch 358/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.8693 - reconstruction_loss: 1892.5771 - kl_loss: 99.4375 - false_loss: 0.1014 - true_loss: 1.1971 - val_loss: 6547.5317 - val_reconstruction_loss: 1897.3376 - val_kl_loss: 98.8050 - val_false_loss: 14.7561 - val_true_loss: 1.2455\n",
      "Epoch 359/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.7801 - reconstruction_loss: 1892.3638 - kl_loss: 99.7278 - false_loss: 0.1014 - true_loss: 1.1971 - val_loss: 6546.9556 - val_reconstruction_loss: 1897.3367 - val_kl_loss: 98.8049 - val_false_loss: 14.7542 - val_true_loss: 1.2454\n",
      "Epoch 360/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.8407 - reconstruction_loss: 1892.0834 - kl_loss: 99.7262 - false_loss: 0.1014 - true_loss: 1.1970 - val_loss: 6546.3765 - val_reconstruction_loss: 1897.3358 - val_kl_loss: 98.8042 - val_false_loss: 14.7523 - val_true_loss: 1.2454\n",
      "Epoch 361/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.6830 - reconstruction_loss: 1892.3727 - kl_loss: 98.1718 - false_loss: 0.1014 - true_loss: 1.1969 - val_loss: 6545.7891 - val_reconstruction_loss: 1897.3348 - val_kl_loss: 98.8043 - val_false_loss: 14.7504 - val_true_loss: 1.2453\n",
      "Epoch 362/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2272.5971 - reconstruction_loss: 1892.3068 - kl_loss: 97.0310 - false_loss: 0.1014 - true_loss: 1.1969 - val_loss: 6545.2070 - val_reconstruction_loss: 1897.3339 - val_kl_loss: 98.8038 - val_false_loss: 14.7485 - val_true_loss: 1.2453\n",
      "Epoch 363/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2268.9749 - reconstruction_loss: 1892.4498 - kl_loss: 96.1700 - false_loss: 0.1014 - true_loss: 1.1969 - val_loss: 6544.6318 - val_reconstruction_loss: 1897.3330 - val_kl_loss: 98.8039 - val_false_loss: 14.7466 - val_true_loss: 1.2453\n",
      "Epoch 364/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2268.6404 - reconstruction_loss: 1892.8778 - kl_loss: 97.3024 - false_loss: 0.1014 - true_loss: 1.1968 - val_loss: 6544.0483 - val_reconstruction_loss: 1897.3323 - val_kl_loss: 98.8028 - val_false_loss: 14.7446 - val_true_loss: 1.2452\n",
      "Epoch 365/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2264.4937 - reconstruction_loss: 1892.5958 - kl_loss: 96.4148 - false_loss: 0.1014 - true_loss: 1.1967 - val_loss: 6543.4663 - val_reconstruction_loss: 1897.3313 - val_kl_loss: 98.8033 - val_false_loss: 14.7427 - val_true_loss: 1.2452\n",
      "Epoch 366/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2260.0125 - reconstruction_loss: 1892.1250 - kl_loss: 96.6805 - false_loss: 0.1013 - true_loss: 1.1967 - val_loss: 6542.8838 - val_reconstruction_loss: 1897.3306 - val_kl_loss: 98.8039 - val_false_loss: 14.7408 - val_true_loss: 1.2451\n",
      "Epoch 367/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2259.6432 - reconstruction_loss: 1892.3145 - kl_loss: 96.6707 - false_loss: 0.1013 - true_loss: 1.1966 - val_loss: 6542.3062 - val_reconstruction_loss: 1897.3295 - val_kl_loss: 98.8024 - val_false_loss: 14.7389 - val_true_loss: 1.2451\n",
      "Epoch 368/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2264.8948 - reconstruction_loss: 1892.5111 - kl_loss: 96.6673 - false_loss: 0.1013 - true_loss: 1.1966 - val_loss: 6541.7310 - val_reconstruction_loss: 1897.3289 - val_kl_loss: 98.8034 - val_false_loss: 14.7370 - val_true_loss: 1.2451\n",
      "Epoch 369/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2263.0936 - reconstruction_loss: 1892.5890 - kl_loss: 96.9273 - false_loss: 0.1013 - true_loss: 1.1965 - val_loss: 6541.1504 - val_reconstruction_loss: 1897.3278 - val_kl_loss: 98.8021 - val_false_loss: 14.7351 - val_true_loss: 1.2450\n",
      "Epoch 370/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2262.4382 - reconstruction_loss: 1892.3148 - kl_loss: 97.1130 - false_loss: 0.1013 - true_loss: 1.1965 - val_loss: 6540.5664 - val_reconstruction_loss: 1897.3269 - val_kl_loss: 98.8033 - val_false_loss: 14.7331 - val_true_loss: 1.2450\n",
      "Epoch 371/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2257.7782 - reconstruction_loss: 1892.1738 - kl_loss: 96.9090 - false_loss: 0.1013 - true_loss: 1.1964 - val_loss: 6539.9868 - val_reconstruction_loss: 1897.3259 - val_kl_loss: 98.8034 - val_false_loss: 14.7312 - val_true_loss: 1.2449\n",
      "Epoch 372/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.1987 - reconstruction_loss: 1892.1849 - kl_loss: 99.7942 - false_loss: 0.1013 - true_loss: 1.1964 - val_loss: 6539.4067 - val_reconstruction_loss: 1897.3251 - val_kl_loss: 98.8025 - val_false_loss: 14.7293 - val_true_loss: 1.2449\n",
      "Epoch 373/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.3375 - reconstruction_loss: 1891.9438 - kl_loss: 97.3090 - false_loss: 0.1013 - true_loss: 1.1963 - val_loss: 6538.8198 - val_reconstruction_loss: 1897.3242 - val_kl_loss: 98.8017 - val_false_loss: 14.7274 - val_true_loss: 1.2448\n",
      "Epoch 374/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.2526 - reconstruction_loss: 1891.9696 - kl_loss: 97.6037 - false_loss: 0.1013 - true_loss: 1.1962 - val_loss: 6538.2397 - val_reconstruction_loss: 1897.3234 - val_kl_loss: 98.8015 - val_false_loss: 14.7255 - val_true_loss: 1.2448\n",
      "Epoch 375/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.1734 - reconstruction_loss: 1891.9818 - kl_loss: 98.4144 - false_loss: 0.1013 - true_loss: 1.1962 - val_loss: 6537.6538 - val_reconstruction_loss: 1897.3226 - val_kl_loss: 98.8016 - val_false_loss: 14.7235 - val_true_loss: 1.2447\n",
      "Epoch 376/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6435 - reconstruction_loss: 1892.6224 - kl_loss: 98.4048 - false_loss: 0.1012 - true_loss: 1.1961 - val_loss: 6537.0728 - val_reconstruction_loss: 1897.3217 - val_kl_loss: 98.8023 - val_false_loss: 14.7216 - val_true_loss: 1.2447\n",
      "Epoch 377/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.9772 - reconstruction_loss: 1891.9254 - kl_loss: 97.6635 - false_loss: 0.1012 - true_loss: 1.1960 - val_loss: 6536.4937 - val_reconstruction_loss: 1897.3208 - val_kl_loss: 98.8031 - val_false_loss: 14.7197 - val_true_loss: 1.2446\n",
      "Epoch 378/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.2041 - reconstruction_loss: 1892.1815 - kl_loss: 99.5569 - false_loss: 0.1012 - true_loss: 1.1960 - val_loss: 6535.9126 - val_reconstruction_loss: 1897.3198 - val_kl_loss: 98.8046 - val_false_loss: 14.7178 - val_true_loss: 1.2445\n",
      "Epoch 379/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.1041 - reconstruction_loss: 1892.0560 - kl_loss: 99.0152 - false_loss: 0.1012 - true_loss: 1.1959 - val_loss: 6535.3369 - val_reconstruction_loss: 1897.3191 - val_kl_loss: 98.8059 - val_false_loss: 14.7159 - val_true_loss: 1.2445\n",
      "Epoch 380/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.4312 - reconstruction_loss: 1892.0680 - kl_loss: 99.4973 - false_loss: 0.1012 - true_loss: 1.1959 - val_loss: 6534.7573 - val_reconstruction_loss: 1897.3181 - val_kl_loss: 98.8070 - val_false_loss: 14.7140 - val_true_loss: 1.2444\n",
      "Epoch 381/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.3907 - reconstruction_loss: 1892.7333 - kl_loss: 99.7337 - false_loss: 0.1012 - true_loss: 1.1958 - val_loss: 6534.1816 - val_reconstruction_loss: 1897.3173 - val_kl_loss: 98.8085 - val_false_loss: 14.7121 - val_true_loss: 1.2444\n",
      "Epoch 382/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.8155 - reconstruction_loss: 1892.7412 - kl_loss: 100.2053 - false_loss: 0.1012 - true_loss: 1.1957 - val_loss: 6533.5986 - val_reconstruction_loss: 1897.3163 - val_kl_loss: 98.8086 - val_false_loss: 14.7101 - val_true_loss: 1.2443\n",
      "Epoch 383/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.9444 - reconstruction_loss: 1892.4312 - kl_loss: 99.0528 - false_loss: 0.1012 - true_loss: 1.1957 - val_loss: 6533.0259 - val_reconstruction_loss: 1897.3154 - val_kl_loss: 98.8086 - val_false_loss: 14.7083 - val_true_loss: 1.2443\n",
      "Epoch 384/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.7668 - reconstruction_loss: 1891.9396 - kl_loss: 99.1458 - false_loss: 0.1012 - true_loss: 1.1956 - val_loss: 6532.4497 - val_reconstruction_loss: 1897.3147 - val_kl_loss: 98.8092 - val_false_loss: 14.7064 - val_true_loss: 1.2442\n",
      "Epoch 385/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.6766 - reconstruction_loss: 1892.3140 - kl_loss: 99.6683 - false_loss: 0.1012 - true_loss: 1.1955 - val_loss: 6531.8804 - val_reconstruction_loss: 1897.3137 - val_kl_loss: 98.8095 - val_false_loss: 14.7045 - val_true_loss: 1.2441\n",
      "Epoch 386/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.5267 - reconstruction_loss: 1892.3265 - kl_loss: 99.5424 - false_loss: 0.1011 - true_loss: 1.1955 - val_loss: 6531.3066 - val_reconstruction_loss: 1897.3129 - val_kl_loss: 98.8110 - val_false_loss: 14.7026 - val_true_loss: 1.2441\n",
      "Epoch 387/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.8894 - reconstruction_loss: 1892.1840 - kl_loss: 99.8926 - false_loss: 0.1011 - true_loss: 1.1954 - val_loss: 6530.7275 - val_reconstruction_loss: 1897.3119 - val_kl_loss: 98.8123 - val_false_loss: 14.7007 - val_true_loss: 1.2440\n",
      "Epoch 388/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.9488 - reconstruction_loss: 1891.9518 - kl_loss: 99.4067 - false_loss: 0.1011 - true_loss: 1.1953 - val_loss: 6530.1450 - val_reconstruction_loss: 1897.3110 - val_kl_loss: 98.8122 - val_false_loss: 14.6988 - val_true_loss: 1.2440\n",
      "Epoch 389/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7973 - reconstruction_loss: 1892.3016 - kl_loss: 99.5886 - false_loss: 0.1011 - true_loss: 1.1953 - val_loss: 6529.5645 - val_reconstruction_loss: 1897.3103 - val_kl_loss: 98.8121 - val_false_loss: 14.6968 - val_true_loss: 1.2439\n",
      "Epoch 390/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.4487 - reconstruction_loss: 1892.2972 - kl_loss: 99.5878 - false_loss: 0.1011 - true_loss: 1.1952 - val_loss: 6528.9946 - val_reconstruction_loss: 1897.3093 - val_kl_loss: 98.8124 - val_false_loss: 14.6950 - val_true_loss: 1.2439\n",
      "Epoch 391/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.1699 - reconstruction_loss: 1892.2445 - kl_loss: 100.3711 - false_loss: 0.1011 - true_loss: 1.1951 - val_loss: 6528.4150 - val_reconstruction_loss: 1897.3086 - val_kl_loss: 98.8119 - val_false_loss: 14.6931 - val_true_loss: 1.2438\n",
      "Epoch 392/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.5882 - reconstruction_loss: 1892.3281 - kl_loss: 99.9020 - false_loss: 0.1011 - true_loss: 1.1951 - val_loss: 6527.8438 - val_reconstruction_loss: 1897.3075 - val_kl_loss: 98.8118 - val_false_loss: 14.6912 - val_true_loss: 1.2438\n",
      "Epoch 393/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.6994 - reconstruction_loss: 1892.4000 - kl_loss: 99.7840 - false_loss: 0.1011 - true_loss: 1.1950 - val_loss: 6527.2603 - val_reconstruction_loss: 1897.3065 - val_kl_loss: 98.8115 - val_false_loss: 14.6893 - val_true_loss: 1.2437\n",
      "Epoch 394/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.0954 - reconstruction_loss: 1892.2223 - kl_loss: 100.1725 - false_loss: 0.1011 - true_loss: 1.1950 - val_loss: 6526.6821 - val_reconstruction_loss: 1897.3058 - val_kl_loss: 98.8102 - val_false_loss: 14.6873 - val_true_loss: 1.2437\n",
      "Epoch 395/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.6202 - reconstruction_loss: 1892.3571 - kl_loss: 100.1350 - false_loss: 0.1011 - true_loss: 1.1949 - val_loss: 6526.1113 - val_reconstruction_loss: 1897.3049 - val_kl_loss: 98.8110 - val_false_loss: 14.6855 - val_true_loss: 1.2436\n",
      "Epoch 396/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.4065 - reconstruction_loss: 1891.9913 - kl_loss: 98.1968 - false_loss: 0.1010 - true_loss: 1.1948 - val_loss: 6525.5288 - val_reconstruction_loss: 1897.3040 - val_kl_loss: 98.8118 - val_false_loss: 14.6835 - val_true_loss: 1.2435\n",
      "Epoch 397/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5664 - reconstruction_loss: 1891.7677 - kl_loss: 99.1093 - false_loss: 0.1010 - true_loss: 1.1948 - val_loss: 6524.9600 - val_reconstruction_loss: 1897.3031 - val_kl_loss: 98.8116 - val_false_loss: 14.6817 - val_true_loss: 1.2435\n",
      "Epoch 398/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.8251 - reconstruction_loss: 1892.3756 - kl_loss: 99.1318 - false_loss: 0.1010 - true_loss: 1.1947 - val_loss: 6524.3848 - val_reconstruction_loss: 1897.3021 - val_kl_loss: 98.8117 - val_false_loss: 14.6798 - val_true_loss: 1.2434\n",
      "Epoch 399/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.3203 - reconstruction_loss: 1891.8531 - kl_loss: 99.0942 - false_loss: 0.1010 - true_loss: 1.1946 - val_loss: 6523.8057 - val_reconstruction_loss: 1897.3014 - val_kl_loss: 98.8118 - val_false_loss: 14.6779 - val_true_loss: 1.2434\n",
      "Epoch 400/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.4468 - reconstruction_loss: 1892.0171 - kl_loss: 99.5328 - false_loss: 0.1010 - true_loss: 1.1946 - val_loss: 6523.2290 - val_reconstruction_loss: 1897.3003 - val_kl_loss: 98.8119 - val_false_loss: 14.6760 - val_true_loss: 1.2433\n",
      "Epoch 401/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.4315 - reconstruction_loss: 1891.8086 - kl_loss: 99.5693 - false_loss: 0.1010 - true_loss: 1.1945 - val_loss: 6522.6499 - val_reconstruction_loss: 1897.2994 - val_kl_loss: 98.8125 - val_false_loss: 14.6740 - val_true_loss: 1.2433\n",
      "Epoch 402/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.3237 - reconstruction_loss: 1892.1508 - kl_loss: 100.4231 - false_loss: 0.1010 - true_loss: 1.1944 - val_loss: 6522.0737 - val_reconstruction_loss: 1897.2985 - val_kl_loss: 98.8120 - val_false_loss: 14.6721 - val_true_loss: 1.2432\n",
      "Epoch 403/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.2971 - reconstruction_loss: 1891.7515 - kl_loss: 99.5599 - false_loss: 0.1010 - true_loss: 1.1944 - val_loss: 6521.4956 - val_reconstruction_loss: 1897.2977 - val_kl_loss: 98.8129 - val_false_loss: 14.6702 - val_true_loss: 1.2432\n",
      "Epoch 404/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5537 - reconstruction_loss: 1892.6390 - kl_loss: 100.5433 - false_loss: 0.1010 - true_loss: 1.1943 - val_loss: 6520.9165 - val_reconstruction_loss: 1897.2969 - val_kl_loss: 98.8128 - val_false_loss: 14.6683 - val_true_loss: 1.2431\n",
      "Epoch 405/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.8336 - reconstruction_loss: 1892.5605 - kl_loss: 99.4856 - false_loss: 0.1010 - true_loss: 1.1943 - val_loss: 6520.3472 - val_reconstruction_loss: 1897.2961 - val_kl_loss: 98.8118 - val_false_loss: 14.6665 - val_true_loss: 1.2430\n",
      "Epoch 406/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.3417 - reconstruction_loss: 1892.6166 - kl_loss: 100.7084 - false_loss: 0.1009 - true_loss: 1.1942 - val_loss: 6519.7720 - val_reconstruction_loss: 1897.2952 - val_kl_loss: 98.8120 - val_false_loss: 14.6646 - val_true_loss: 1.2430\n",
      "Epoch 407/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.1244 - reconstruction_loss: 1892.1488 - kl_loss: 99.2964 - false_loss: 0.1009 - true_loss: 1.1941 - val_loss: 6519.1914 - val_reconstruction_loss: 1897.2947 - val_kl_loss: 98.8124 - val_false_loss: 14.6626 - val_true_loss: 1.2429\n",
      "Epoch 408/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.5370 - reconstruction_loss: 1892.6191 - kl_loss: 99.2887 - false_loss: 0.1009 - true_loss: 1.1941 - val_loss: 6518.6152 - val_reconstruction_loss: 1897.2937 - val_kl_loss: 98.8124 - val_false_loss: 14.6608 - val_true_loss: 1.2429\n",
      "Epoch 409/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8422 - reconstruction_loss: 1892.1083 - kl_loss: 100.7052 - false_loss: 0.1009 - true_loss: 1.1940 - val_loss: 6518.0366 - val_reconstruction_loss: 1897.2928 - val_kl_loss: 98.8120 - val_false_loss: 14.6588 - val_true_loss: 1.2428\n",
      "Epoch 410/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.4968 - reconstruction_loss: 1891.6664 - kl_loss: 99.6662 - false_loss: 0.1009 - true_loss: 1.1939 - val_loss: 6517.4663 - val_reconstruction_loss: 1897.2919 - val_kl_loss: 98.8122 - val_false_loss: 14.6570 - val_true_loss: 1.2428\n",
      "Epoch 411/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2254.2593 - reconstruction_loss: 1892.5259 - kl_loss: 100.5754 - false_loss: 0.1009 - true_loss: 1.1939 - val_loss: 6516.8882 - val_reconstruction_loss: 1897.2911 - val_kl_loss: 98.8113 - val_false_loss: 14.6551 - val_true_loss: 1.2427\n",
      "Epoch 412/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.6606 - reconstruction_loss: 1892.6078 - kl_loss: 100.0797 - false_loss: 0.1009 - true_loss: 1.1938 - val_loss: 6516.3159 - val_reconstruction_loss: 1897.2904 - val_kl_loss: 98.8109 - val_false_loss: 14.6532 - val_true_loss: 1.2427\n",
      "Epoch 413/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.2434 - reconstruction_loss: 1892.3932 - kl_loss: 100.1453 - false_loss: 0.1009 - true_loss: 1.1937 - val_loss: 6515.7383 - val_reconstruction_loss: 1897.2896 - val_kl_loss: 98.8103 - val_false_loss: 14.6513 - val_true_loss: 1.2426\n",
      "Epoch 414/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.5161 - reconstruction_loss: 1892.3275 - kl_loss: 99.7099 - false_loss: 0.1009 - true_loss: 1.1937 - val_loss: 6515.1870 - val_reconstruction_loss: 1897.2886 - val_kl_loss: 98.8122 - val_false_loss: 14.6494 - val_true_loss: 1.2425\n",
      "Epoch 415/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.7365 - reconstruction_loss: 1892.1688 - kl_loss: 100.0251 - false_loss: 0.1009 - true_loss: 1.1936 - val_loss: 6514.6147 - val_reconstruction_loss: 1897.2877 - val_kl_loss: 98.8132 - val_false_loss: 14.6476 - val_true_loss: 1.2425\n",
      "Epoch 416/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.1159 - reconstruction_loss: 1892.0131 - kl_loss: 99.7739 - false_loss: 0.1008 - true_loss: 1.1936 - val_loss: 6514.0454 - val_reconstruction_loss: 1897.2871 - val_kl_loss: 98.8138 - val_false_loss: 14.6457 - val_true_loss: 1.2424\n",
      "Epoch 417/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2239.8646 - reconstruction_loss: 1892.3846 - kl_loss: 99.9467 - false_loss: 0.1008 - true_loss: 1.1935 - val_loss: 6513.4785 - val_reconstruction_loss: 1897.2863 - val_kl_loss: 98.8146 - val_false_loss: 14.6438 - val_true_loss: 1.2424\n",
      "Epoch 418/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.1310 - reconstruction_loss: 1892.0602 - kl_loss: 99.7857 - false_loss: 0.1008 - true_loss: 1.1934 - val_loss: 6512.8965 - val_reconstruction_loss: 1897.2853 - val_kl_loss: 98.8148 - val_false_loss: 14.6419 - val_true_loss: 1.2423\n",
      "Epoch 419/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.4313 - reconstruction_loss: 1892.3828 - kl_loss: 99.6703 - false_loss: 0.1008 - true_loss: 1.1934 - val_loss: 6512.3223 - val_reconstruction_loss: 1897.2844 - val_kl_loss: 98.8149 - val_false_loss: 14.6400 - val_true_loss: 1.2423\n",
      "Epoch 420/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.9171 - reconstruction_loss: 1892.0541 - kl_loss: 99.8896 - false_loss: 0.1008 - true_loss: 1.1933 - val_loss: 6511.7476 - val_reconstruction_loss: 1897.2837 - val_kl_loss: 98.8142 - val_false_loss: 14.6381 - val_true_loss: 1.2422\n",
      "Epoch 421/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.5394 - reconstruction_loss: 1892.1957 - kl_loss: 100.2273 - false_loss: 0.1008 - true_loss: 1.1932 - val_loss: 6511.1719 - val_reconstruction_loss: 1897.2826 - val_kl_loss: 98.8140 - val_false_loss: 14.6362 - val_true_loss: 1.2422\n",
      "Epoch 422/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.2427 - reconstruction_loss: 1891.7404 - kl_loss: 99.5963 - false_loss: 0.1008 - true_loss: 1.1932 - val_loss: 6510.5952 - val_reconstruction_loss: 1897.2817 - val_kl_loss: 98.8149 - val_false_loss: 14.6343 - val_true_loss: 1.2421\n",
      "Epoch 423/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.3303 - reconstruction_loss: 1891.8207 - kl_loss: 100.0766 - false_loss: 0.1008 - true_loss: 1.1931 - val_loss: 6510.0146 - val_reconstruction_loss: 1897.2810 - val_kl_loss: 98.8155 - val_false_loss: 14.6324 - val_true_loss: 1.2420\n",
      "Epoch 424/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.4471 - reconstruction_loss: 1892.3789 - kl_loss: 99.8933 - false_loss: 0.1008 - true_loss: 1.1930 - val_loss: 6509.4375 - val_reconstruction_loss: 1897.2803 - val_kl_loss: 98.8162 - val_false_loss: 14.6305 - val_true_loss: 1.2420\n",
      "Epoch 425/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.8181 - reconstruction_loss: 1892.4052 - kl_loss: 100.2077 - false_loss: 0.1008 - true_loss: 1.1930 - val_loss: 6508.8589 - val_reconstruction_loss: 1897.2795 - val_kl_loss: 98.8170 - val_false_loss: 14.6286 - val_true_loss: 1.2419\n",
      "Epoch 426/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.1764 - reconstruction_loss: 1891.7676 - kl_loss: 99.9566 - false_loss: 0.1007 - true_loss: 1.1929 - val_loss: 6508.2852 - val_reconstruction_loss: 1897.2788 - val_kl_loss: 98.8172 - val_false_loss: 14.6267 - val_true_loss: 1.2419\n",
      "Epoch 427/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.0700 - reconstruction_loss: 1892.3594 - kl_loss: 99.6914 - false_loss: 0.1007 - true_loss: 1.1928 - val_loss: 6507.7212 - val_reconstruction_loss: 1897.2778 - val_kl_loss: 98.8171 - val_false_loss: 14.6248 - val_true_loss: 1.2418\n",
      "Epoch 428/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.2625 - reconstruction_loss: 1892.2422 - kl_loss: 99.9730 - false_loss: 0.1007 - true_loss: 1.1928 - val_loss: 6507.1553 - val_reconstruction_loss: 1897.2771 - val_kl_loss: 98.8172 - val_false_loss: 14.6230 - val_true_loss: 1.2418\n",
      "Epoch 429/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.4106 - reconstruction_loss: 1892.4396 - kl_loss: 99.5405 - false_loss: 0.1007 - true_loss: 1.1927 - val_loss: 6506.5845 - val_reconstruction_loss: 1897.2762 - val_kl_loss: 98.8177 - val_false_loss: 14.6211 - val_true_loss: 1.2417\n",
      "Epoch 430/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.6214 - reconstruction_loss: 1891.7311 - kl_loss: 100.4933 - false_loss: 0.1007 - true_loss: 1.1926 - val_loss: 6506.0122 - val_reconstruction_loss: 1897.2755 - val_kl_loss: 98.8182 - val_false_loss: 14.6192 - val_true_loss: 1.2416\n",
      "Epoch 431/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.2330 - reconstruction_loss: 1892.1979 - kl_loss: 99.6741 - false_loss: 0.1007 - true_loss: 1.1926 - val_loss: 6505.4419 - val_reconstruction_loss: 1897.2748 - val_kl_loss: 98.8202 - val_false_loss: 14.6173 - val_true_loss: 1.2416\n",
      "Epoch 432/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.0245 - reconstruction_loss: 1892.6505 - kl_loss: 99.9062 - false_loss: 0.1007 - true_loss: 1.1925 - val_loss: 6504.8633 - val_reconstruction_loss: 1897.2738 - val_kl_loss: 98.8212 - val_false_loss: 14.6154 - val_true_loss: 1.2415\n",
      "Epoch 433/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.2581 - reconstruction_loss: 1891.9766 - kl_loss: 99.5881 - false_loss: 0.1007 - true_loss: 1.1925 - val_loss: 6504.2935 - val_reconstruction_loss: 1897.2731 - val_kl_loss: 98.8224 - val_false_loss: 14.6135 - val_true_loss: 1.2415\n",
      "Epoch 434/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.8729 - reconstruction_loss: 1891.9170 - kl_loss: 100.5074 - false_loss: 0.1007 - true_loss: 1.1924 - val_loss: 6503.7217 - val_reconstruction_loss: 1897.2720 - val_kl_loss: 98.8231 - val_false_loss: 14.6116 - val_true_loss: 1.2414\n",
      "Epoch 435/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.1991 - reconstruction_loss: 1892.1221 - kl_loss: 99.7330 - false_loss: 0.1007 - true_loss: 1.1923 - val_loss: 6503.1470 - val_reconstruction_loss: 1897.2712 - val_kl_loss: 98.8235 - val_false_loss: 14.6097 - val_true_loss: 1.2413\n",
      "Epoch 436/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.3855 - reconstruction_loss: 1892.2084 - kl_loss: 99.7680 - false_loss: 0.1006 - true_loss: 1.1923 - val_loss: 6502.5820 - val_reconstruction_loss: 1897.2704 - val_kl_loss: 98.8237 - val_false_loss: 14.6079 - val_true_loss: 1.2413\n",
      "Epoch 437/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.8976 - reconstruction_loss: 1892.2299 - kl_loss: 100.4625 - false_loss: 0.1006 - true_loss: 1.1922 - val_loss: 6502.0093 - val_reconstruction_loss: 1897.2695 - val_kl_loss: 98.8249 - val_false_loss: 14.6060 - val_true_loss: 1.2412\n",
      "Epoch 438/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.2920 - reconstruction_loss: 1892.9108 - kl_loss: 98.6118 - false_loss: 0.1006 - true_loss: 1.1921 - val_loss: 6501.4307 - val_reconstruction_loss: 1897.2688 - val_kl_loss: 98.8257 - val_false_loss: 14.6041 - val_true_loss: 1.2412\n",
      "Epoch 439/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.6131 - reconstruction_loss: 1892.9784 - kl_loss: 100.2025 - false_loss: 0.1006 - true_loss: 1.1921 - val_loss: 6500.8638 - val_reconstruction_loss: 1897.2678 - val_kl_loss: 98.8259 - val_false_loss: 14.6022 - val_true_loss: 1.2411\n",
      "Epoch 440/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.3507 - reconstruction_loss: 1892.9459 - kl_loss: 99.8448 - false_loss: 0.1006 - true_loss: 1.1920 - val_loss: 6500.2944 - val_reconstruction_loss: 1897.2671 - val_kl_loss: 98.8259 - val_false_loss: 14.6003 - val_true_loss: 1.2411\n",
      "Epoch 441/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.6432 - reconstruction_loss: 1892.0890 - kl_loss: 99.6799 - false_loss: 0.1006 - true_loss: 1.1919 - val_loss: 6499.7275 - val_reconstruction_loss: 1897.2662 - val_kl_loss: 98.8256 - val_false_loss: 14.5985 - val_true_loss: 1.2410\n",
      "Epoch 442/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6213 - reconstruction_loss: 1892.5751 - kl_loss: 99.4947 - false_loss: 0.1006 - true_loss: 1.1919 - val_loss: 6499.1558 - val_reconstruction_loss: 1897.2654 - val_kl_loss: 98.8258 - val_false_loss: 14.5966 - val_true_loss: 1.2409\n",
      "Epoch 443/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.2428 - reconstruction_loss: 1891.7545 - kl_loss: 99.1620 - false_loss: 0.1006 - true_loss: 1.1918 - val_loss: 6498.5903 - val_reconstruction_loss: 1897.2644 - val_kl_loss: 98.8267 - val_false_loss: 14.5947 - val_true_loss: 1.2409\n",
      "Epoch 444/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6177 - reconstruction_loss: 1891.9471 - kl_loss: 100.1612 - false_loss: 0.1006 - true_loss: 1.1918 - val_loss: 6498.0176 - val_reconstruction_loss: 1897.2635 - val_kl_loss: 98.8272 - val_false_loss: 14.5928 - val_true_loss: 1.2408\n",
      "Epoch 445/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.9673 - reconstruction_loss: 1892.3314 - kl_loss: 100.0844 - false_loss: 0.1006 - true_loss: 1.1917 - val_loss: 6497.4419 - val_reconstruction_loss: 1897.2626 - val_kl_loss: 98.8265 - val_false_loss: 14.5909 - val_true_loss: 1.2408\n",
      "Epoch 446/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.7405 - reconstruction_loss: 1892.0677 - kl_loss: 99.1298 - false_loss: 0.1005 - true_loss: 1.1916 - val_loss: 6496.8726 - val_reconstruction_loss: 1897.2617 - val_kl_loss: 98.8258 - val_false_loss: 14.5890 - val_true_loss: 1.2407\n",
      "Epoch 447/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.7001 - reconstruction_loss: 1892.2109 - kl_loss: 99.7283 - false_loss: 0.1005 - true_loss: 1.1916 - val_loss: 6496.3066 - val_reconstruction_loss: 1897.2610 - val_kl_loss: 98.8275 - val_false_loss: 14.5872 - val_true_loss: 1.2407\n",
      "Epoch 448/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2269.5215 - reconstruction_loss: 1892.3334 - kl_loss: 100.3132 - false_loss: 0.1005 - true_loss: 1.1915 - val_loss: 6495.7334 - val_reconstruction_loss: 1897.2601 - val_kl_loss: 98.8269 - val_false_loss: 14.5853 - val_true_loss: 1.2406\n",
      "Epoch 449/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.6754 - reconstruction_loss: 1892.3984 - kl_loss: 98.3643 - false_loss: 0.1005 - true_loss: 1.1915 - val_loss: 6495.1636 - val_reconstruction_loss: 1897.2594 - val_kl_loss: 98.8269 - val_false_loss: 14.5834 - val_true_loss: 1.2406\n",
      "Epoch 450/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.8014 - reconstruction_loss: 1892.0811 - kl_loss: 98.8466 - false_loss: 0.1005 - true_loss: 1.1914 - val_loss: 6494.5928 - val_reconstruction_loss: 1897.2584 - val_kl_loss: 98.8270 - val_false_loss: 14.5815 - val_true_loss: 1.2405\n",
      "Epoch 451/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0360 - reconstruction_loss: 1891.9596 - kl_loss: 98.8522 - false_loss: 0.1005 - true_loss: 1.1913 - val_loss: 6494.0259 - val_reconstruction_loss: 1897.2574 - val_kl_loss: 98.8284 - val_false_loss: 14.5797 - val_true_loss: 1.2405\n",
      "Epoch 452/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.6423 - reconstruction_loss: 1891.9711 - kl_loss: 100.1437 - false_loss: 0.1005 - true_loss: 1.1913 - val_loss: 6493.4526 - val_reconstruction_loss: 1897.2567 - val_kl_loss: 98.8284 - val_false_loss: 14.5778 - val_true_loss: 1.2404\n",
      "Epoch 453/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.4430 - reconstruction_loss: 1892.5162 - kl_loss: 99.7871 - false_loss: 0.1005 - true_loss: 1.1912 - val_loss: 6492.8784 - val_reconstruction_loss: 1897.2557 - val_kl_loss: 98.8286 - val_false_loss: 14.5759 - val_true_loss: 1.2404\n",
      "Epoch 454/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.5511 - reconstruction_loss: 1892.2113 - kl_loss: 100.3024 - false_loss: 0.1005 - true_loss: 1.1911 - val_loss: 6492.3115 - val_reconstruction_loss: 1897.2550 - val_kl_loss: 98.8284 - val_false_loss: 14.5740 - val_true_loss: 1.2403\n",
      "Epoch 455/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.8451 - reconstruction_loss: 1891.8483 - kl_loss: 100.4020 - false_loss: 0.1005 - true_loss: 1.1911 - val_loss: 6491.7471 - val_reconstruction_loss: 1897.2543 - val_kl_loss: 98.8281 - val_false_loss: 14.5721 - val_true_loss: 1.2402\n",
      "Epoch 456/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.4269 - reconstruction_loss: 1892.5905 - kl_loss: 99.9179 - false_loss: 0.1004 - true_loss: 1.1910 - val_loss: 6491.1831 - val_reconstruction_loss: 1897.2535 - val_kl_loss: 98.8273 - val_false_loss: 14.5703 - val_true_loss: 1.2402\n",
      "Epoch 457/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.5969 - reconstruction_loss: 1892.3428 - kl_loss: 99.6280 - false_loss: 0.1004 - true_loss: 1.1909 - val_loss: 6490.6196 - val_reconstruction_loss: 1897.2528 - val_kl_loss: 98.8261 - val_false_loss: 14.5684 - val_true_loss: 1.2402\n",
      "Epoch 458/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.1375 - reconstruction_loss: 1892.3516 - kl_loss: 100.3352 - false_loss: 0.1004 - true_loss: 1.1909 - val_loss: 6490.0479 - val_reconstruction_loss: 1897.2521 - val_kl_loss: 98.8253 - val_false_loss: 14.5665 - val_true_loss: 1.2401\n",
      "Epoch 459/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.2999 - reconstruction_loss: 1891.7208 - kl_loss: 100.4314 - false_loss: 0.1004 - true_loss: 1.1908 - val_loss: 6489.4800 - val_reconstruction_loss: 1897.2512 - val_kl_loss: 98.8256 - val_false_loss: 14.5647 - val_true_loss: 1.2400\n",
      "Epoch 460/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.8061 - reconstruction_loss: 1891.7334 - kl_loss: 99.8962 - false_loss: 0.1004 - true_loss: 1.1908 - val_loss: 6488.9087 - val_reconstruction_loss: 1897.2505 - val_kl_loss: 98.8256 - val_false_loss: 14.5628 - val_true_loss: 1.2400\n",
      "Epoch 461/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.1750 - reconstruction_loss: 1891.8578 - kl_loss: 98.6754 - false_loss: 0.1004 - true_loss: 1.1907 - val_loss: 6488.3364 - val_reconstruction_loss: 1897.2494 - val_kl_loss: 98.8259 - val_false_loss: 14.5609 - val_true_loss: 1.2399\n",
      "Epoch 462/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2256.7372 - reconstruction_loss: 1892.2418 - kl_loss: 99.5049 - false_loss: 0.1004 - true_loss: 1.1906 - val_loss: 6487.7715 - val_reconstruction_loss: 1897.2488 - val_kl_loss: 98.8261 - val_false_loss: 14.5590 - val_true_loss: 1.2399\n",
      "Epoch 463/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2264.8788 - reconstruction_loss: 1892.0834 - kl_loss: 98.9979 - false_loss: 0.1004 - true_loss: 1.1906 - val_loss: 6487.2104 - val_reconstruction_loss: 1897.2482 - val_kl_loss: 98.8256 - val_false_loss: 14.5572 - val_true_loss: 1.2399\n",
      "Epoch 464/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2256.9080 - reconstruction_loss: 1892.6053 - kl_loss: 96.5239 - false_loss: 0.1004 - true_loss: 1.1905 - val_loss: 6486.6489 - val_reconstruction_loss: 1897.2473 - val_kl_loss: 98.8260 - val_false_loss: 14.5553 - val_true_loss: 1.2398\n",
      "Epoch 465/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2271.3911 - reconstruction_loss: 1891.9784 - kl_loss: 97.6540 - false_loss: 0.1004 - true_loss: 1.1905 - val_loss: 6486.0820 - val_reconstruction_loss: 1897.2463 - val_kl_loss: 98.8251 - val_false_loss: 14.5535 - val_true_loss: 1.2398\n",
      "Epoch 466/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.2503 - reconstruction_loss: 1891.6400 - kl_loss: 95.6083 - false_loss: 0.1003 - true_loss: 1.1904 - val_loss: 6485.5166 - val_reconstruction_loss: 1897.2455 - val_kl_loss: 98.8260 - val_false_loss: 14.5516 - val_true_loss: 1.2397\n",
      "Epoch 467/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2272.3304 - reconstruction_loss: 1891.4359 - kl_loss: 96.8907 - false_loss: 0.1003 - true_loss: 1.1904 - val_loss: 6484.9600 - val_reconstruction_loss: 1897.2446 - val_kl_loss: 98.8244 - val_false_loss: 14.5498 - val_true_loss: 1.2397\n",
      "Epoch 468/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2256.4692 - reconstruction_loss: 1892.2035 - kl_loss: 97.4245 - false_loss: 0.1003 - true_loss: 1.1903 - val_loss: 6484.3843 - val_reconstruction_loss: 1897.2437 - val_kl_loss: 98.8251 - val_false_loss: 14.5479 - val_true_loss: 1.2396\n",
      "Epoch 469/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2243.4250 - reconstruction_loss: 1892.0575 - kl_loss: 97.3694 - false_loss: 0.1003 - true_loss: 1.1903 - val_loss: 6483.8140 - val_reconstruction_loss: 1897.2428 - val_kl_loss: 98.8247 - val_false_loss: 14.5460 - val_true_loss: 1.2396\n",
      "Epoch 470/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6058 - reconstruction_loss: 1891.7394 - kl_loss: 98.2792 - false_loss: 0.1003 - true_loss: 1.1902 - val_loss: 6483.2456 - val_reconstruction_loss: 1897.2419 - val_kl_loss: 98.8242 - val_false_loss: 14.5441 - val_true_loss: 1.2395\n",
      "Epoch 471/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.7675 - reconstruction_loss: 1891.8568 - kl_loss: 98.4287 - false_loss: 0.1003 - true_loss: 1.1901 - val_loss: 6482.6768 - val_reconstruction_loss: 1897.2412 - val_kl_loss: 98.8239 - val_false_loss: 14.5422 - val_true_loss: 1.2395\n",
      "Epoch 472/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.9015 - reconstruction_loss: 1892.4176 - kl_loss: 99.0487 - false_loss: 0.1003 - true_loss: 1.1901 - val_loss: 6482.1099 - val_reconstruction_loss: 1897.2401 - val_kl_loss: 98.8236 - val_false_loss: 14.5404 - val_true_loss: 1.2394\n",
      "Epoch 473/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.8374 - reconstruction_loss: 1891.6724 - kl_loss: 99.1863 - false_loss: 0.1003 - true_loss: 1.1900 - val_loss: 6481.5435 - val_reconstruction_loss: 1897.2396 - val_kl_loss: 98.8232 - val_false_loss: 14.5385 - val_true_loss: 1.2394\n",
      "Epoch 474/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.1817 - reconstruction_loss: 1892.0729 - kl_loss: 99.0961 - false_loss: 0.1003 - true_loss: 1.1900 - val_loss: 6480.9756 - val_reconstruction_loss: 1897.2385 - val_kl_loss: 98.8232 - val_false_loss: 14.5366 - val_true_loss: 1.2393\n",
      "Epoch 475/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5856 - reconstruction_loss: 1892.5629 - kl_loss: 99.2919 - false_loss: 0.1003 - true_loss: 1.1899 - val_loss: 6480.4126 - val_reconstruction_loss: 1897.2378 - val_kl_loss: 98.8237 - val_false_loss: 14.5348 - val_true_loss: 1.2393\n",
      "Epoch 476/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0682 - reconstruction_loss: 1892.6014 - kl_loss: 99.4499 - false_loss: 0.1002 - true_loss: 1.1898 - val_loss: 6479.8462 - val_reconstruction_loss: 1897.2369 - val_kl_loss: 98.8232 - val_false_loss: 14.5329 - val_true_loss: 1.2392\n",
      "Epoch 477/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.7320 - reconstruction_loss: 1892.6851 - kl_loss: 99.5306 - false_loss: 0.1002 - true_loss: 1.1898 - val_loss: 6479.2778 - val_reconstruction_loss: 1897.2360 - val_kl_loss: 98.8226 - val_false_loss: 14.5310 - val_true_loss: 1.2392\n",
      "Epoch 478/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.9124 - reconstruction_loss: 1892.3402 - kl_loss: 99.0700 - false_loss: 0.1002 - true_loss: 1.1897 - val_loss: 6478.7222 - val_reconstruction_loss: 1897.2351 - val_kl_loss: 98.8221 - val_false_loss: 14.5292 - val_true_loss: 1.2391\n",
      "Epoch 479/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.8012 - reconstruction_loss: 1891.6162 - kl_loss: 100.2225 - false_loss: 0.1002 - true_loss: 1.1896 - val_loss: 6478.1567 - val_reconstruction_loss: 1897.2344 - val_kl_loss: 98.8217 - val_false_loss: 14.5273 - val_true_loss: 1.2391\n",
      "Epoch 480/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.7992 - reconstruction_loss: 1891.9154 - kl_loss: 100.1067 - false_loss: 0.1002 - true_loss: 1.1896 - val_loss: 6477.5933 - val_reconstruction_loss: 1897.2335 - val_kl_loss: 98.8214 - val_false_loss: 14.5255 - val_true_loss: 1.2390\n",
      "Epoch 481/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.8214 - reconstruction_loss: 1892.2119 - kl_loss: 100.6031 - false_loss: 0.1002 - true_loss: 1.1895 - val_loss: 6477.0327 - val_reconstruction_loss: 1897.2328 - val_kl_loss: 98.8212 - val_false_loss: 14.5236 - val_true_loss: 1.2389\n",
      "Epoch 482/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.1569 - reconstruction_loss: 1892.0737 - kl_loss: 100.6613 - false_loss: 0.1002 - true_loss: 1.1894 - val_loss: 6476.4673 - val_reconstruction_loss: 1897.2321 - val_kl_loss: 98.8210 - val_false_loss: 14.5218 - val_true_loss: 1.2389\n",
      "Epoch 483/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.9824 - reconstruction_loss: 1891.7578 - kl_loss: 99.7958 - false_loss: 0.1002 - true_loss: 1.1894 - val_loss: 6475.8975 - val_reconstruction_loss: 1897.2312 - val_kl_loss: 98.8211 - val_false_loss: 14.5199 - val_true_loss: 1.2388\n",
      "Epoch 484/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.9410 - reconstruction_loss: 1891.7656 - kl_loss: 100.4141 - false_loss: 0.1002 - true_loss: 1.1893 - val_loss: 6475.3315 - val_reconstruction_loss: 1897.2302 - val_kl_loss: 98.8213 - val_false_loss: 14.5180 - val_true_loss: 1.2388\n",
      "Epoch 485/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.1414 - reconstruction_loss: 1891.8862 - kl_loss: 100.2967 - false_loss: 0.1002 - true_loss: 1.1892 - val_loss: 6474.7725 - val_reconstruction_loss: 1897.2296 - val_kl_loss: 98.8217 - val_false_loss: 14.5162 - val_true_loss: 1.2387\n",
      "Epoch 486/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.0268 - reconstruction_loss: 1891.9287 - kl_loss: 100.2274 - false_loss: 0.1001 - true_loss: 1.1892 - val_loss: 6474.2061 - val_reconstruction_loss: 1897.2285 - val_kl_loss: 98.8221 - val_false_loss: 14.5143 - val_true_loss: 1.2387\n",
      "Epoch 487/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.2511 - reconstruction_loss: 1891.9318 - kl_loss: 100.1283 - false_loss: 0.1001 - true_loss: 1.1891 - val_loss: 6473.6401 - val_reconstruction_loss: 1897.2277 - val_kl_loss: 98.8216 - val_false_loss: 14.5124 - val_true_loss: 1.2386\n",
      "Epoch 488/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0291 - reconstruction_loss: 1891.6768 - kl_loss: 99.9747 - false_loss: 0.1001 - true_loss: 1.1890 - val_loss: 6473.0811 - val_reconstruction_loss: 1897.2269 - val_kl_loss: 98.8215 - val_false_loss: 14.5106 - val_true_loss: 1.2386\n",
      "Epoch 489/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.9242 - reconstruction_loss: 1892.0400 - kl_loss: 99.9438 - false_loss: 0.1001 - true_loss: 1.1890 - val_loss: 6472.5146 - val_reconstruction_loss: 1897.2261 - val_kl_loss: 98.8208 - val_false_loss: 14.5087 - val_true_loss: 1.2385\n",
      "Epoch 490/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2255.5556 - reconstruction_loss: 1891.9921 - kl_loss: 100.8575 - false_loss: 0.1001 - true_loss: 1.1889 - val_loss: 6471.9482 - val_reconstruction_loss: 1897.2253 - val_kl_loss: 98.8196 - val_false_loss: 14.5069 - val_true_loss: 1.2385\n",
      "Epoch 491/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.7665 - reconstruction_loss: 1892.8597 - kl_loss: 99.4864 - false_loss: 0.1001 - true_loss: 1.1889 - val_loss: 6471.3882 - val_reconstruction_loss: 1897.2246 - val_kl_loss: 98.8200 - val_false_loss: 14.5050 - val_true_loss: 1.2384\n",
      "Epoch 492/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.4005 - reconstruction_loss: 1893.0519 - kl_loss: 98.9552 - false_loss: 0.1001 - true_loss: 1.1888 - val_loss: 6470.8281 - val_reconstruction_loss: 1897.2239 - val_kl_loss: 98.8211 - val_false_loss: 14.5032 - val_true_loss: 1.2384\n",
      "Epoch 493/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.4247 - reconstruction_loss: 1892.1486 - kl_loss: 99.2680 - false_loss: 0.1001 - true_loss: 1.1888 - val_loss: 6470.2617 - val_reconstruction_loss: 1897.2230 - val_kl_loss: 98.8222 - val_false_loss: 14.5013 - val_true_loss: 1.2383\n",
      "Epoch 494/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.7755 - reconstruction_loss: 1891.5433 - kl_loss: 99.2336 - false_loss: 0.1001 - true_loss: 1.1887 - val_loss: 6469.6958 - val_reconstruction_loss: 1897.2220 - val_kl_loss: 98.8220 - val_false_loss: 14.4994 - val_true_loss: 1.2383\n",
      "Epoch 495/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.5135 - reconstruction_loss: 1891.5941 - kl_loss: 99.2257 - false_loss: 0.1001 - true_loss: 1.1886 - val_loss: 6469.1318 - val_reconstruction_loss: 1897.2212 - val_kl_loss: 98.8218 - val_false_loss: 14.4976 - val_true_loss: 1.2382\n",
      "Epoch 496/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.2896 - reconstruction_loss: 1892.1572 - kl_loss: 99.5237 - false_loss: 0.1000 - true_loss: 1.1886 - val_loss: 6468.5684 - val_reconstruction_loss: 1897.2205 - val_kl_loss: 98.8220 - val_false_loss: 14.4957 - val_true_loss: 1.2381\n",
      "Epoch 497/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.6472 - reconstruction_loss: 1892.1562 - kl_loss: 100.1272 - false_loss: 0.1000 - true_loss: 1.1885 - val_loss: 6468.0054 - val_reconstruction_loss: 1897.2196 - val_kl_loss: 98.8215 - val_false_loss: 14.4939 - val_true_loss: 1.2381\n",
      "Epoch 498/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6453 - reconstruction_loss: 1891.7617 - kl_loss: 99.8550 - false_loss: 0.1000 - true_loss: 1.1884 - val_loss: 6467.4492 - val_reconstruction_loss: 1897.2189 - val_kl_loss: 98.8210 - val_false_loss: 14.4920 - val_true_loss: 1.2380\n",
      "Epoch 499/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.8900 - reconstruction_loss: 1892.1035 - kl_loss: 100.0320 - false_loss: 0.1000 - true_loss: 1.1884 - val_loss: 6466.8926 - val_reconstruction_loss: 1897.2181 - val_kl_loss: 98.8218 - val_false_loss: 14.4902 - val_true_loss: 1.2380\n",
      "Epoch 500/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0910 - reconstruction_loss: 1891.9213 - kl_loss: 99.9309 - false_loss: 0.1000 - true_loss: 1.1883 - val_loss: 6466.3296 - val_reconstruction_loss: 1897.2173 - val_kl_loss: 98.8219 - val_false_loss: 14.4883 - val_true_loss: 1.2379\n",
      "Epoch 501/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.5034 - reconstruction_loss: 1891.7172 - kl_loss: 100.1957 - false_loss: 0.1000 - true_loss: 1.1882 - val_loss: 6465.7612 - val_reconstruction_loss: 1897.2164 - val_kl_loss: 98.8215 - val_false_loss: 14.4865 - val_true_loss: 1.2379\n",
      "Epoch 502/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.5844 - reconstruction_loss: 1891.8862 - kl_loss: 99.9679 - false_loss: 0.1000 - true_loss: 1.1882 - val_loss: 6465.1909 - val_reconstruction_loss: 1897.2156 - val_kl_loss: 98.8217 - val_false_loss: 14.4846 - val_true_loss: 1.2378\n",
      "Epoch 503/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.8775 - reconstruction_loss: 1892.0918 - kl_loss: 100.1828 - false_loss: 0.1000 - true_loss: 1.1881 - val_loss: 6464.6348 - val_reconstruction_loss: 1897.2146 - val_kl_loss: 98.8217 - val_false_loss: 14.4828 - val_true_loss: 1.2378\n",
      "Epoch 504/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.0148 - reconstruction_loss: 1891.7211 - kl_loss: 99.5634 - false_loss: 0.1000 - true_loss: 1.1881 - val_loss: 6464.0723 - val_reconstruction_loss: 1897.2137 - val_kl_loss: 98.8220 - val_false_loss: 14.4809 - val_true_loss: 1.2377\n",
      "Epoch 505/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8184 - reconstruction_loss: 1891.9037 - kl_loss: 100.7118 - false_loss: 0.1000 - true_loss: 1.1880 - val_loss: 6463.5088 - val_reconstruction_loss: 1897.2133 - val_kl_loss: 98.8220 - val_false_loss: 14.4790 - val_true_loss: 1.2376\n",
      "Epoch 506/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.0614 - reconstruction_loss: 1892.0566 - kl_loss: 99.9014 - false_loss: 0.0999 - true_loss: 1.1879 - val_loss: 6462.9497 - val_reconstruction_loss: 1897.2123 - val_kl_loss: 98.8243 - val_false_loss: 14.4772 - val_true_loss: 1.2376\n",
      "Epoch 507/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.3731 - reconstruction_loss: 1891.5267 - kl_loss: 100.4688 - false_loss: 0.0999 - true_loss: 1.1879 - val_loss: 6462.3877 - val_reconstruction_loss: 1897.2117 - val_kl_loss: 98.8253 - val_false_loss: 14.4753 - val_true_loss: 1.2375\n",
      "Epoch 508/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.9776 - reconstruction_loss: 1892.7217 - kl_loss: 100.1489 - false_loss: 0.0999 - true_loss: 1.1878 - val_loss: 6461.8237 - val_reconstruction_loss: 1897.2107 - val_kl_loss: 98.8260 - val_false_loss: 14.4735 - val_true_loss: 1.2375\n",
      "Epoch 509/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0464 - reconstruction_loss: 1893.9618 - kl_loss: 100.1456 - false_loss: 0.0999 - true_loss: 1.1877 - val_loss: 6461.2637 - val_reconstruction_loss: 1897.2098 - val_kl_loss: 98.8261 - val_false_loss: 14.4716 - val_true_loss: 1.2374\n",
      "Epoch 510/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.7444 - reconstruction_loss: 1893.0570 - kl_loss: 99.4067 - false_loss: 0.0999 - true_loss: 1.1877 - val_loss: 6460.7041 - val_reconstruction_loss: 1897.2091 - val_kl_loss: 98.8271 - val_false_loss: 14.4698 - val_true_loss: 1.2374\n",
      "Epoch 511/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.3118 - reconstruction_loss: 1892.0179 - kl_loss: 100.0369 - false_loss: 0.0999 - true_loss: 1.1876 - val_loss: 6460.1475 - val_reconstruction_loss: 1897.2081 - val_kl_loss: 98.8267 - val_false_loss: 14.4680 - val_true_loss: 1.2373\n",
      "Epoch 512/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.1586 - reconstruction_loss: 1891.7335 - kl_loss: 98.9865 - false_loss: 0.0999 - true_loss: 1.1875 - val_loss: 6459.5859 - val_reconstruction_loss: 1897.2074 - val_kl_loss: 98.8268 - val_false_loss: 14.4661 - val_true_loss: 1.2373\n",
      "Epoch 513/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0592 - reconstruction_loss: 1891.6835 - kl_loss: 99.9362 - false_loss: 0.0999 - true_loss: 1.1875 - val_loss: 6459.0298 - val_reconstruction_loss: 1897.2065 - val_kl_loss: 98.8264 - val_false_loss: 14.4643 - val_true_loss: 1.2372\n",
      "Epoch 514/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.8571 - reconstruction_loss: 1891.8304 - kl_loss: 100.2577 - false_loss: 0.0999 - true_loss: 1.1874 - val_loss: 6458.4658 - val_reconstruction_loss: 1897.2058 - val_kl_loss: 98.8260 - val_false_loss: 14.4624 - val_true_loss: 1.2372\n",
      "Epoch 515/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.3962 - reconstruction_loss: 1891.6686 - kl_loss: 99.6037 - false_loss: 0.0999 - true_loss: 1.1874 - val_loss: 6457.9097 - val_reconstruction_loss: 1897.2051 - val_kl_loss: 98.8247 - val_false_loss: 14.4606 - val_true_loss: 1.2371\n",
      "Epoch 516/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2253.7983 - reconstruction_loss: 1891.7148 - kl_loss: 99.8008 - false_loss: 0.0999 - true_loss: 1.1873 - val_loss: 6457.3423 - val_reconstruction_loss: 1897.2043 - val_kl_loss: 98.8249 - val_false_loss: 14.4587 - val_true_loss: 1.2371\n",
      "Epoch 517/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.1067 - reconstruction_loss: 1892.5319 - kl_loss: 99.0774 - false_loss: 0.0998 - true_loss: 1.1872 - val_loss: 6456.7827 - val_reconstruction_loss: 1897.2035 - val_kl_loss: 98.8265 - val_false_loss: 14.4569 - val_true_loss: 1.2370\n",
      "Epoch 518/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.0669 - reconstruction_loss: 1891.8270 - kl_loss: 100.7569 - false_loss: 0.0998 - true_loss: 1.1872 - val_loss: 6456.2212 - val_reconstruction_loss: 1897.2028 - val_kl_loss: 98.8278 - val_false_loss: 14.4550 - val_true_loss: 1.2369\n",
      "Epoch 519/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.5217 - reconstruction_loss: 1891.8008 - kl_loss: 100.5432 - false_loss: 0.0998 - true_loss: 1.1871 - val_loss: 6455.6626 - val_reconstruction_loss: 1897.2019 - val_kl_loss: 98.8287 - val_false_loss: 14.4532 - val_true_loss: 1.2369\n",
      "Epoch 520/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.1516 - reconstruction_loss: 1892.1527 - kl_loss: 100.2639 - false_loss: 0.0998 - true_loss: 1.1871 - val_loss: 6455.1035 - val_reconstruction_loss: 1897.2012 - val_kl_loss: 98.8288 - val_false_loss: 14.4513 - val_true_loss: 1.2368\n",
      "Epoch 521/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2249.0988 - reconstruction_loss: 1892.4188 - kl_loss: 98.8792 - false_loss: 0.0998 - true_loss: 1.1870 - val_loss: 6454.5464 - val_reconstruction_loss: 1897.2004 - val_kl_loss: 98.8295 - val_false_loss: 14.4495 - val_true_loss: 1.2368\n",
      "Epoch 522/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.5675 - reconstruction_loss: 1892.4199 - kl_loss: 99.7376 - false_loss: 0.0998 - true_loss: 1.1869 - val_loss: 6453.9844 - val_reconstruction_loss: 1897.1996 - val_kl_loss: 98.8295 - val_false_loss: 14.4476 - val_true_loss: 1.2367\n",
      "Epoch 523/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.9049 - reconstruction_loss: 1892.0459 - kl_loss: 99.4099 - false_loss: 0.0998 - true_loss: 1.1869 - val_loss: 6453.4238 - val_reconstruction_loss: 1897.1989 - val_kl_loss: 98.8300 - val_false_loss: 14.4458 - val_true_loss: 1.2367\n",
      "Epoch 524/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.5562 - reconstruction_loss: 1891.5621 - kl_loss: 100.4149 - false_loss: 0.0998 - true_loss: 1.1868 - val_loss: 6452.8691 - val_reconstruction_loss: 1897.1980 - val_kl_loss: 98.8306 - val_false_loss: 14.4439 - val_true_loss: 1.2366\n",
      "Epoch 525/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.2539 - reconstruction_loss: 1891.6747 - kl_loss: 100.1575 - false_loss: 0.0998 - true_loss: 1.1867 - val_loss: 6452.3057 - val_reconstruction_loss: 1897.1971 - val_kl_loss: 98.8315 - val_false_loss: 14.4421 - val_true_loss: 1.2366\n",
      "Epoch 526/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.3295 - reconstruction_loss: 1891.6918 - kl_loss: 99.7104 - false_loss: 0.0998 - true_loss: 1.1867 - val_loss: 6451.7495 - val_reconstruction_loss: 1897.1964 - val_kl_loss: 98.8332 - val_false_loss: 14.4402 - val_true_loss: 1.2365\n",
      "Epoch 527/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.3261 - reconstruction_loss: 1891.7516 - kl_loss: 100.2098 - false_loss: 0.0997 - true_loss: 1.1866 - val_loss: 6451.2056 - val_reconstruction_loss: 1897.1954 - val_kl_loss: 98.8341 - val_false_loss: 14.4384 - val_true_loss: 1.2365\n",
      "Epoch 528/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.1161 - reconstruction_loss: 1891.8052 - kl_loss: 99.5382 - false_loss: 0.0997 - true_loss: 1.1865 - val_loss: 6450.6396 - val_reconstruction_loss: 1897.1945 - val_kl_loss: 98.8348 - val_false_loss: 14.4366 - val_true_loss: 1.2364\n",
      "Epoch 529/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.5318 - reconstruction_loss: 1891.8512 - kl_loss: 99.8744 - false_loss: 0.0997 - true_loss: 1.1865 - val_loss: 6450.0874 - val_reconstruction_loss: 1897.1938 - val_kl_loss: 98.8353 - val_false_loss: 14.4348 - val_true_loss: 1.2364\n",
      "Epoch 530/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.6068 - reconstruction_loss: 1892.4869 - kl_loss: 100.4651 - false_loss: 0.0997 - true_loss: 1.1864 - val_loss: 6449.5259 - val_reconstruction_loss: 1897.1931 - val_kl_loss: 98.8357 - val_false_loss: 14.4329 - val_true_loss: 1.2363\n",
      "Epoch 531/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.4552 - reconstruction_loss: 1892.3258 - kl_loss: 100.6118 - false_loss: 0.0997 - true_loss: 1.1864 - val_loss: 6448.9683 - val_reconstruction_loss: 1897.1923 - val_kl_loss: 98.8353 - val_false_loss: 14.4311 - val_true_loss: 1.2362\n",
      "Epoch 532/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.5926 - reconstruction_loss: 1891.8647 - kl_loss: 99.8787 - false_loss: 0.0997 - true_loss: 1.1863 - val_loss: 6448.4126 - val_reconstruction_loss: 1897.1913 - val_kl_loss: 98.8356 - val_false_loss: 14.4292 - val_true_loss: 1.2362\n",
      "Epoch 533/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.8810 - reconstruction_loss: 1892.0082 - kl_loss: 100.6867 - false_loss: 0.0997 - true_loss: 1.1862 - val_loss: 6447.8560 - val_reconstruction_loss: 1897.1907 - val_kl_loss: 98.8364 - val_false_loss: 14.4274 - val_true_loss: 1.2361\n",
      "Epoch 534/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.3092 - reconstruction_loss: 1891.7631 - kl_loss: 100.4224 - false_loss: 0.0997 - true_loss: 1.1862 - val_loss: 6447.3008 - val_reconstruction_loss: 1897.1897 - val_kl_loss: 98.8373 - val_false_loss: 14.4256 - val_true_loss: 1.2361\n",
      "Epoch 535/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8175 - reconstruction_loss: 1891.3722 - kl_loss: 100.4988 - false_loss: 0.0997 - true_loss: 1.1861 - val_loss: 6446.7490 - val_reconstruction_loss: 1897.1887 - val_kl_loss: 98.8385 - val_false_loss: 14.4237 - val_true_loss: 1.2360\n",
      "Epoch 536/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.9427 - reconstruction_loss: 1891.7744 - kl_loss: 101.0511 - false_loss: 0.0997 - true_loss: 1.1860 - val_loss: 6446.1963 - val_reconstruction_loss: 1897.1880 - val_kl_loss: 98.8405 - val_false_loss: 14.4219 - val_true_loss: 1.2360\n",
      "Epoch 537/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.3034 - reconstruction_loss: 1892.3234 - kl_loss: 100.3704 - false_loss: 0.0996 - true_loss: 1.1860 - val_loss: 6445.6421 - val_reconstruction_loss: 1897.1871 - val_kl_loss: 98.8416 - val_false_loss: 14.4201 - val_true_loss: 1.2359\n",
      "Epoch 538/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.4506 - reconstruction_loss: 1891.9224 - kl_loss: 100.3295 - false_loss: 0.0996 - true_loss: 1.1859 - val_loss: 6445.0830 - val_reconstruction_loss: 1897.1863 - val_kl_loss: 98.8422 - val_false_loss: 14.4182 - val_true_loss: 1.2358\n",
      "Epoch 539/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.8508 - reconstruction_loss: 1891.6305 - kl_loss: 100.1413 - false_loss: 0.0996 - true_loss: 1.1858 - val_loss: 6444.5327 - val_reconstruction_loss: 1897.1854 - val_kl_loss: 98.8428 - val_false_loss: 14.4164 - val_true_loss: 1.2358\n",
      "Epoch 540/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.9422 - reconstruction_loss: 1892.3334 - kl_loss: 100.0484 - false_loss: 0.0996 - true_loss: 1.1858 - val_loss: 6443.9751 - val_reconstruction_loss: 1897.1846 - val_kl_loss: 98.8427 - val_false_loss: 14.4146 - val_true_loss: 1.2357\n",
      "Epoch 541/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6663 - reconstruction_loss: 1891.5460 - kl_loss: 100.6761 - false_loss: 0.0996 - true_loss: 1.1857 - val_loss: 6443.4165 - val_reconstruction_loss: 1897.1838 - val_kl_loss: 98.8419 - val_false_loss: 14.4128 - val_true_loss: 1.2357\n",
      "Epoch 542/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.8123 - reconstruction_loss: 1892.2119 - kl_loss: 100.9522 - false_loss: 0.0996 - true_loss: 1.1856 - val_loss: 6442.8672 - val_reconstruction_loss: 1897.1830 - val_kl_loss: 98.8418 - val_false_loss: 14.4109 - val_true_loss: 1.2356\n",
      "Epoch 543/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.7236 - reconstruction_loss: 1892.3193 - kl_loss: 100.1462 - false_loss: 0.0996 - true_loss: 1.1856 - val_loss: 6442.3086 - val_reconstruction_loss: 1897.1824 - val_kl_loss: 98.8419 - val_false_loss: 14.4091 - val_true_loss: 1.2356\n",
      "Epoch 544/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.5768 - reconstruction_loss: 1891.7642 - kl_loss: 100.6393 - false_loss: 0.0996 - true_loss: 1.1855 - val_loss: 6441.7539 - val_reconstruction_loss: 1897.1815 - val_kl_loss: 98.8424 - val_false_loss: 14.4073 - val_true_loss: 1.2355\n",
      "Epoch 545/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.5512 - reconstruction_loss: 1891.9457 - kl_loss: 100.2704 - false_loss: 0.0996 - true_loss: 1.1855 - val_loss: 6441.1948 - val_reconstruction_loss: 1897.1807 - val_kl_loss: 98.8429 - val_false_loss: 14.4054 - val_true_loss: 1.2355\n",
      "Epoch 546/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.5929 - reconstruction_loss: 1891.4161 - kl_loss: 99.0947 - false_loss: 0.0996 - true_loss: 1.1854 - val_loss: 6440.6445 - val_reconstruction_loss: 1897.1799 - val_kl_loss: 98.8435 - val_false_loss: 14.4036 - val_true_loss: 1.2354\n",
      "Epoch 547/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.4130 - reconstruction_loss: 1891.6896 - kl_loss: 100.9113 - false_loss: 0.0995 - true_loss: 1.1853 - val_loss: 6440.0854 - val_reconstruction_loss: 1897.1791 - val_kl_loss: 98.8445 - val_false_loss: 14.4018 - val_true_loss: 1.2353\n",
      "Epoch 548/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.5428 - reconstruction_loss: 1891.9341 - kl_loss: 100.7023 - false_loss: 0.0995 - true_loss: 1.1853 - val_loss: 6439.5278 - val_reconstruction_loss: 1897.1782 - val_kl_loss: 98.8457 - val_false_loss: 14.3999 - val_true_loss: 1.2353\n",
      "Epoch 549/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.1736 - reconstruction_loss: 1892.3877 - kl_loss: 100.7713 - false_loss: 0.0995 - true_loss: 1.1852 - val_loss: 6438.9741 - val_reconstruction_loss: 1897.1774 - val_kl_loss: 98.8467 - val_false_loss: 14.3981 - val_true_loss: 1.2352\n",
      "Epoch 550/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.6289 - reconstruction_loss: 1892.0009 - kl_loss: 100.5467 - false_loss: 0.0995 - true_loss: 1.1851 - val_loss: 6438.4155 - val_reconstruction_loss: 1897.1765 - val_kl_loss: 98.8470 - val_false_loss: 14.3963 - val_true_loss: 1.2352\n",
      "Epoch 551/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.8222 - reconstruction_loss: 1891.9414 - kl_loss: 101.1054 - false_loss: 0.0995 - true_loss: 1.1851 - val_loss: 6437.8584 - val_reconstruction_loss: 1897.1757 - val_kl_loss: 98.8461 - val_false_loss: 14.3944 - val_true_loss: 1.2351\n",
      "Epoch 552/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.1213 - reconstruction_loss: 1891.6830 - kl_loss: 100.8467 - false_loss: 0.0995 - true_loss: 1.1850 - val_loss: 6437.2998 - val_reconstruction_loss: 1897.1750 - val_kl_loss: 98.8463 - val_false_loss: 14.3926 - val_true_loss: 1.2351\n",
      "Epoch 553/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.7994 - reconstruction_loss: 1891.9088 - kl_loss: 98.5947 - false_loss: 0.0995 - true_loss: 1.1850 - val_loss: 6436.7437 - val_reconstruction_loss: 1897.1742 - val_kl_loss: 98.8471 - val_false_loss: 14.3908 - val_true_loss: 1.2350\n",
      "Epoch 554/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.5149 - reconstruction_loss: 1892.2041 - kl_loss: 99.6369 - false_loss: 0.0995 - true_loss: 1.1849 - val_loss: 6436.1846 - val_reconstruction_loss: 1897.1733 - val_kl_loss: 98.8476 - val_false_loss: 14.3889 - val_true_loss: 1.2349\n",
      "Epoch 555/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.5088 - reconstruction_loss: 1891.7582 - kl_loss: 99.8119 - false_loss: 0.0995 - true_loss: 1.1848 - val_loss: 6435.6313 - val_reconstruction_loss: 1897.1722 - val_kl_loss: 98.8480 - val_false_loss: 14.3871 - val_true_loss: 1.2349\n",
      "Epoch 556/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.1190 - reconstruction_loss: 1891.9142 - kl_loss: 98.8570 - false_loss: 0.0995 - true_loss: 1.1848 - val_loss: 6435.0825 - val_reconstruction_loss: 1897.1714 - val_kl_loss: 98.8485 - val_false_loss: 14.3853 - val_true_loss: 1.2348\n",
      "Epoch 557/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.9803 - reconstruction_loss: 1891.7471 - kl_loss: 98.4484 - false_loss: 0.0994 - true_loss: 1.1847 - val_loss: 6434.5215 - val_reconstruction_loss: 1897.1708 - val_kl_loss: 98.8491 - val_false_loss: 14.3834 - val_true_loss: 1.2348\n",
      "Epoch 558/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.3176 - reconstruction_loss: 1891.8363 - kl_loss: 99.5330 - false_loss: 0.0994 - true_loss: 1.1846 - val_loss: 6433.9727 - val_reconstruction_loss: 1897.1700 - val_kl_loss: 98.8504 - val_false_loss: 14.3816 - val_true_loss: 1.2347\n",
      "Epoch 559/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.5125 - reconstruction_loss: 1891.8754 - kl_loss: 99.8159 - false_loss: 0.0994 - true_loss: 1.1846 - val_loss: 6433.4150 - val_reconstruction_loss: 1897.1692 - val_kl_loss: 98.8511 - val_false_loss: 14.3798 - val_true_loss: 1.2347\n",
      "Epoch 560/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.6921 - reconstruction_loss: 1892.2583 - kl_loss: 100.3729 - false_loss: 0.0994 - true_loss: 1.1845 - val_loss: 6432.8564 - val_reconstruction_loss: 1897.1683 - val_kl_loss: 98.8519 - val_false_loss: 14.3779 - val_true_loss: 1.2346\n",
      "Epoch 561/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.4495 - reconstruction_loss: 1891.9242 - kl_loss: 99.2637 - false_loss: 0.0994 - true_loss: 1.1845 - val_loss: 6432.3032 - val_reconstruction_loss: 1897.1676 - val_kl_loss: 98.8533 - val_false_loss: 14.3761 - val_true_loss: 1.2346\n",
      "Epoch 562/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.0611 - reconstruction_loss: 1891.5292 - kl_loss: 100.3541 - false_loss: 0.0994 - true_loss: 1.1844 - val_loss: 6431.7529 - val_reconstruction_loss: 1897.1667 - val_kl_loss: 98.8542 - val_false_loss: 14.3743 - val_true_loss: 1.2345\n",
      "Epoch 563/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6171 - reconstruction_loss: 1891.7094 - kl_loss: 101.1272 - false_loss: 0.0994 - true_loss: 1.1843 - val_loss: 6431.2036 - val_reconstruction_loss: 1897.1659 - val_kl_loss: 98.8537 - val_false_loss: 14.3725 - val_true_loss: 1.2345\n",
      "Epoch 564/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.0601 - reconstruction_loss: 1892.0739 - kl_loss: 100.0770 - false_loss: 0.0994 - true_loss: 1.1843 - val_loss: 6430.6587 - val_reconstruction_loss: 1897.1650 - val_kl_loss: 98.8526 - val_false_loss: 14.3707 - val_true_loss: 1.2344\n",
      "Epoch 565/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.7879 - reconstruction_loss: 1891.7213 - kl_loss: 100.5086 - false_loss: 0.0994 - true_loss: 1.1842 - val_loss: 6430.1074 - val_reconstruction_loss: 1897.1643 - val_kl_loss: 98.8540 - val_false_loss: 14.3689 - val_true_loss: 1.2344\n",
      "Epoch 566/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2267.1340 - reconstruction_loss: 1891.8617 - kl_loss: 99.5745 - false_loss: 0.0994 - true_loss: 1.1842 - val_loss: 6429.5610 - val_reconstruction_loss: 1897.1636 - val_kl_loss: 98.8540 - val_false_loss: 14.3670 - val_true_loss: 1.2343\n",
      "Epoch 567/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2263.9845 - reconstruction_loss: 1891.8944 - kl_loss: 98.4290 - false_loss: 0.0994 - true_loss: 1.1841 - val_loss: 6429.0137 - val_reconstruction_loss: 1897.1627 - val_kl_loss: 98.8561 - val_false_loss: 14.3652 - val_true_loss: 1.2343\n",
      "Epoch 568/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.4961 - reconstruction_loss: 1891.8989 - kl_loss: 98.8453 - false_loss: 0.0993 - true_loss: 1.1841 - val_loss: 6428.4580 - val_reconstruction_loss: 1897.1619 - val_kl_loss: 98.8558 - val_false_loss: 14.3634 - val_true_loss: 1.2342\n",
      "Epoch 569/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.5917 - reconstruction_loss: 1891.6621 - kl_loss: 97.0330 - false_loss: 0.0993 - true_loss: 1.1840 - val_loss: 6427.9023 - val_reconstruction_loss: 1897.1610 - val_kl_loss: 98.8550 - val_false_loss: 14.3616 - val_true_loss: 1.2342\n",
      "Epoch 570/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.3111 - reconstruction_loss: 1891.8105 - kl_loss: 98.5552 - false_loss: 0.0993 - true_loss: 1.1840 - val_loss: 6427.3472 - val_reconstruction_loss: 1897.1605 - val_kl_loss: 98.8553 - val_false_loss: 14.3597 - val_true_loss: 1.2341\n",
      "Epoch 571/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.4874 - reconstruction_loss: 1891.4579 - kl_loss: 99.8093 - false_loss: 0.0993 - true_loss: 1.1839 - val_loss: 6426.7886 - val_reconstruction_loss: 1897.1595 - val_kl_loss: 98.8551 - val_false_loss: 14.3579 - val_true_loss: 1.2341\n",
      "Epoch 572/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0472 - reconstruction_loss: 1892.6079 - kl_loss: 99.3237 - false_loss: 0.0993 - true_loss: 1.1838 - val_loss: 6426.2456 - val_reconstruction_loss: 1897.1587 - val_kl_loss: 98.8556 - val_false_loss: 14.3561 - val_true_loss: 1.2340\n",
      "Epoch 573/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2236.2287 - reconstruction_loss: 1892.2789 - kl_loss: 100.3551 - false_loss: 0.0993 - true_loss: 1.1838 - val_loss: 6425.6890 - val_reconstruction_loss: 1897.1578 - val_kl_loss: 98.8561 - val_false_loss: 14.3543 - val_true_loss: 1.2339\n",
      "Epoch 574/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.9396 - reconstruction_loss: 1892.1429 - kl_loss: 99.3974 - false_loss: 0.0993 - true_loss: 1.1837 - val_loss: 6425.1558 - val_reconstruction_loss: 1897.1573 - val_kl_loss: 98.8572 - val_false_loss: 14.3525 - val_true_loss: 1.2339\n",
      "Epoch 575/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.9480 - reconstruction_loss: 1892.4352 - kl_loss: 98.6949 - false_loss: 0.0993 - true_loss: 1.1836 - val_loss: 6424.6099 - val_reconstruction_loss: 1897.1565 - val_kl_loss: 98.8587 - val_false_loss: 14.3507 - val_true_loss: 1.2338\n",
      "Epoch 576/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.2123 - reconstruction_loss: 1892.0186 - kl_loss: 99.5261 - false_loss: 0.0993 - true_loss: 1.1836 - val_loss: 6424.0542 - val_reconstruction_loss: 1897.1556 - val_kl_loss: 98.8595 - val_false_loss: 14.3489 - val_true_loss: 1.2338\n",
      "Epoch 577/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.1162 - reconstruction_loss: 1891.9171 - kl_loss: 99.9931 - false_loss: 0.0993 - true_loss: 1.1835 - val_loss: 6423.5029 - val_reconstruction_loss: 1897.1549 - val_kl_loss: 98.8598 - val_false_loss: 14.3471 - val_true_loss: 1.2337\n",
      "Epoch 578/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.5366 - reconstruction_loss: 1892.1971 - kl_loss: 99.6706 - false_loss: 0.0992 - true_loss: 1.1835 - val_loss: 6422.9502 - val_reconstruction_loss: 1897.1541 - val_kl_loss: 98.8599 - val_false_loss: 14.3452 - val_true_loss: 1.2337\n",
      "Epoch 579/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1484 - reconstruction_loss: 1891.6185 - kl_loss: 99.9395 - false_loss: 0.0992 - true_loss: 1.1834 - val_loss: 6422.3965 - val_reconstruction_loss: 1897.1532 - val_kl_loss: 98.8596 - val_false_loss: 14.3434 - val_true_loss: 1.2336\n",
      "Epoch 580/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1088 - reconstruction_loss: 1891.7177 - kl_loss: 100.1155 - false_loss: 0.0992 - true_loss: 1.1833 - val_loss: 6421.8442 - val_reconstruction_loss: 1897.1525 - val_kl_loss: 98.8596 - val_false_loss: 14.3416 - val_true_loss: 1.2336\n",
      "Epoch 581/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6162 - reconstruction_loss: 1891.4521 - kl_loss: 99.7137 - false_loss: 0.0992 - true_loss: 1.1833 - val_loss: 6421.2954 - val_reconstruction_loss: 1897.1519 - val_kl_loss: 98.8594 - val_false_loss: 14.3398 - val_true_loss: 1.2335\n",
      "Epoch 582/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.1726 - reconstruction_loss: 1891.7377 - kl_loss: 100.2512 - false_loss: 0.0992 - true_loss: 1.1832 - val_loss: 6420.7534 - val_reconstruction_loss: 1897.1508 - val_kl_loss: 98.8605 - val_false_loss: 14.3380 - val_true_loss: 1.2335\n",
      "Epoch 583/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7930 - reconstruction_loss: 1892.1219 - kl_loss: 100.7241 - false_loss: 0.0992 - true_loss: 1.1831 - val_loss: 6420.2012 - val_reconstruction_loss: 1897.1503 - val_kl_loss: 98.8612 - val_false_loss: 14.3362 - val_true_loss: 1.2334\n",
      "Epoch 584/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1175 - reconstruction_loss: 1891.8241 - kl_loss: 99.3481 - false_loss: 0.0992 - true_loss: 1.1831 - val_loss: 6419.6519 - val_reconstruction_loss: 1897.1494 - val_kl_loss: 98.8628 - val_false_loss: 14.3344 - val_true_loss: 1.2333\n",
      "Epoch 585/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.6865 - reconstruction_loss: 1891.7946 - kl_loss: 100.1574 - false_loss: 0.0992 - true_loss: 1.1830 - val_loss: 6419.1064 - val_reconstruction_loss: 1897.1483 - val_kl_loss: 98.8645 - val_false_loss: 14.3326 - val_true_loss: 1.2333\n",
      "Epoch 586/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.6516 - reconstruction_loss: 1891.4449 - kl_loss: 100.6590 - false_loss: 0.0992 - true_loss: 1.1830 - val_loss: 6418.5532 - val_reconstruction_loss: 1897.1477 - val_kl_loss: 98.8647 - val_false_loss: 14.3307 - val_true_loss: 1.2332\n",
      "Epoch 587/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.7997 - reconstruction_loss: 1891.7450 - kl_loss: 100.2725 - false_loss: 0.0992 - true_loss: 1.1829 - val_loss: 6418.0215 - val_reconstruction_loss: 1897.1469 - val_kl_loss: 98.8646 - val_false_loss: 14.3290 - val_true_loss: 1.2332\n",
      "Epoch 588/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.6274 - reconstruction_loss: 1891.9935 - kl_loss: 99.8602 - false_loss: 0.0991 - true_loss: 1.1828 - val_loss: 6417.4722 - val_reconstruction_loss: 1897.1460 - val_kl_loss: 98.8659 - val_false_loss: 14.3272 - val_true_loss: 1.2331\n",
      "Epoch 589/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.9026 - reconstruction_loss: 1891.8486 - kl_loss: 100.3525 - false_loss: 0.0991 - true_loss: 1.1828 - val_loss: 6416.9204 - val_reconstruction_loss: 1897.1451 - val_kl_loss: 98.8662 - val_false_loss: 14.3253 - val_true_loss: 1.2331\n",
      "Epoch 590/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6503 - reconstruction_loss: 1891.4865 - kl_loss: 99.9159 - false_loss: 0.0991 - true_loss: 1.1827 - val_loss: 6416.3672 - val_reconstruction_loss: 1897.1443 - val_kl_loss: 98.8669 - val_false_loss: 14.3235 - val_true_loss: 1.2330\n",
      "Epoch 591/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6226 - reconstruction_loss: 1891.9248 - kl_loss: 99.8543 - false_loss: 0.0991 - true_loss: 1.1826 - val_loss: 6415.8271 - val_reconstruction_loss: 1897.1436 - val_kl_loss: 98.8674 - val_false_loss: 14.3217 - val_true_loss: 1.2330\n",
      "Epoch 592/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.3454 - reconstruction_loss: 1891.8966 - kl_loss: 99.3475 - false_loss: 0.0991 - true_loss: 1.1826 - val_loss: 6415.2788 - val_reconstruction_loss: 1897.1427 - val_kl_loss: 98.8681 - val_false_loss: 14.3199 - val_true_loss: 1.2329\n",
      "Epoch 593/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.6587 - reconstruction_loss: 1891.4965 - kl_loss: 100.4459 - false_loss: 0.0991 - true_loss: 1.1825 - val_loss: 6414.7319 - val_reconstruction_loss: 1897.1420 - val_kl_loss: 98.8689 - val_false_loss: 14.3181 - val_true_loss: 1.2328\n",
      "Epoch 594/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.4616 - reconstruction_loss: 1892.2079 - kl_loss: 99.6373 - false_loss: 0.0991 - true_loss: 1.1825 - val_loss: 6414.1821 - val_reconstruction_loss: 1897.1410 - val_kl_loss: 98.8699 - val_false_loss: 14.3163 - val_true_loss: 1.2328\n",
      "Epoch 595/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6518 - reconstruction_loss: 1891.4287 - kl_loss: 100.7946 - false_loss: 0.0991 - true_loss: 1.1824 - val_loss: 6413.6313 - val_reconstruction_loss: 1897.1401 - val_kl_loss: 98.8700 - val_false_loss: 14.3145 - val_true_loss: 1.2327\n",
      "Epoch 596/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.7625 - reconstruction_loss: 1892.2150 - kl_loss: 100.1423 - false_loss: 0.0991 - true_loss: 1.1823 - val_loss: 6413.0898 - val_reconstruction_loss: 1897.1394 - val_kl_loss: 98.8702 - val_false_loss: 14.3127 - val_true_loss: 1.2327\n",
      "Epoch 597/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.5182 - reconstruction_loss: 1891.6119 - kl_loss: 99.9811 - false_loss: 0.0991 - true_loss: 1.1823 - val_loss: 6412.5391 - val_reconstruction_loss: 1897.1385 - val_kl_loss: 98.8709 - val_false_loss: 14.3109 - val_true_loss: 1.2326\n",
      "Epoch 598/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4263 - reconstruction_loss: 1891.5133 - kl_loss: 99.7667 - false_loss: 0.0991 - true_loss: 1.1822 - val_loss: 6411.9873 - val_reconstruction_loss: 1897.1379 - val_kl_loss: 98.8724 - val_false_loss: 14.3091 - val_true_loss: 1.2326\n",
      "Epoch 599/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.1369 - reconstruction_loss: 1891.4390 - kl_loss: 101.0745 - false_loss: 0.0990 - true_loss: 1.1821 - val_loss: 6411.4434 - val_reconstruction_loss: 1897.1368 - val_kl_loss: 98.8730 - val_false_loss: 14.3073 - val_true_loss: 1.2325\n",
      "Epoch 600/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0914 - reconstruction_loss: 1891.3350 - kl_loss: 100.0605 - false_loss: 0.0990 - true_loss: 1.1821 - val_loss: 6410.8999 - val_reconstruction_loss: 1897.1360 - val_kl_loss: 98.8738 - val_false_loss: 14.3055 - val_true_loss: 1.2325\n",
      "Epoch 601/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.7549 - reconstruction_loss: 1891.7814 - kl_loss: 100.6131 - false_loss: 0.0990 - true_loss: 1.1820 - val_loss: 6410.3491 - val_reconstruction_loss: 1897.1353 - val_kl_loss: 98.8735 - val_false_loss: 14.3037 - val_true_loss: 1.2324\n",
      "Epoch 602/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7632 - reconstruction_loss: 1891.6178 - kl_loss: 99.5473 - false_loss: 0.0990 - true_loss: 1.1820 - val_loss: 6409.7993 - val_reconstruction_loss: 1897.1344 - val_kl_loss: 98.8726 - val_false_loss: 14.3019 - val_true_loss: 1.2324\n",
      "Epoch 603/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.4001 - reconstruction_loss: 1892.0211 - kl_loss: 100.4951 - false_loss: 0.0990 - true_loss: 1.1819 - val_loss: 6409.2627 - val_reconstruction_loss: 1897.1338 - val_kl_loss: 98.8721 - val_false_loss: 14.3001 - val_true_loss: 1.2323\n",
      "Epoch 604/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7783 - reconstruction_loss: 1891.8252 - kl_loss: 99.9908 - false_loss: 0.0990 - true_loss: 1.1818 - val_loss: 6408.7148 - val_reconstruction_loss: 1897.1331 - val_kl_loss: 98.8725 - val_false_loss: 14.2983 - val_true_loss: 1.2322\n",
      "Epoch 605/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1664 - reconstruction_loss: 1891.3114 - kl_loss: 99.9609 - false_loss: 0.0990 - true_loss: 1.1818 - val_loss: 6408.1665 - val_reconstruction_loss: 1897.1324 - val_kl_loss: 98.8737 - val_false_loss: 14.2965 - val_true_loss: 1.2322\n",
      "Epoch 606/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.4607 - reconstruction_loss: 1892.1869 - kl_loss: 100.6930 - false_loss: 0.0990 - true_loss: 1.1817 - val_loss: 6407.6211 - val_reconstruction_loss: 1897.1316 - val_kl_loss: 98.8739 - val_false_loss: 14.2947 - val_true_loss: 1.2321\n",
      "Epoch 607/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.9373 - reconstruction_loss: 1891.5040 - kl_loss: 101.2905 - false_loss: 0.0990 - true_loss: 1.1816 - val_loss: 6407.0713 - val_reconstruction_loss: 1897.1309 - val_kl_loss: 98.8730 - val_false_loss: 14.2929 - val_true_loss: 1.2321\n",
      "Epoch 608/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.5143 - reconstruction_loss: 1892.0049 - kl_loss: 100.1925 - false_loss: 0.0990 - true_loss: 1.1816 - val_loss: 6406.5220 - val_reconstruction_loss: 1897.1301 - val_kl_loss: 98.8727 - val_false_loss: 14.2911 - val_true_loss: 1.2320\n",
      "Epoch 609/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.6392 - reconstruction_loss: 1892.1534 - kl_loss: 100.4330 - false_loss: 0.0989 - true_loss: 1.1815 - val_loss: 6405.9731 - val_reconstruction_loss: 1897.1295 - val_kl_loss: 98.8722 - val_false_loss: 14.2893 - val_true_loss: 1.2320\n",
      "Epoch 610/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.1028 - reconstruction_loss: 1892.2534 - kl_loss: 98.9683 - false_loss: 0.0989 - true_loss: 1.1815 - val_loss: 6405.4238 - val_reconstruction_loss: 1897.1287 - val_kl_loss: 98.8724 - val_false_loss: 14.2874 - val_true_loss: 1.2319\n",
      "Epoch 611/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.0112 - reconstruction_loss: 1891.7578 - kl_loss: 100.5413 - false_loss: 0.0989 - true_loss: 1.1814 - val_loss: 6404.8809 - val_reconstruction_loss: 1897.1279 - val_kl_loss: 98.8728 - val_false_loss: 14.2857 - val_true_loss: 1.2319\n",
      "Epoch 612/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6647 - reconstruction_loss: 1891.4918 - kl_loss: 99.8991 - false_loss: 0.0989 - true_loss: 1.1813 - val_loss: 6404.3315 - val_reconstruction_loss: 1897.1270 - val_kl_loss: 98.8735 - val_false_loss: 14.2838 - val_true_loss: 1.2318\n",
      "Epoch 613/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.3702 - reconstruction_loss: 1891.4281 - kl_loss: 100.6740 - false_loss: 0.0989 - true_loss: 1.1813 - val_loss: 6403.7886 - val_reconstruction_loss: 1897.1261 - val_kl_loss: 98.8756 - val_false_loss: 14.2820 - val_true_loss: 1.2318\n",
      "Epoch 614/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.7203 - reconstruction_loss: 1891.8595 - kl_loss: 100.8594 - false_loss: 0.0989 - true_loss: 1.1812 - val_loss: 6403.2373 - val_reconstruction_loss: 1897.1254 - val_kl_loss: 98.8755 - val_false_loss: 14.2802 - val_true_loss: 1.2317\n",
      "Epoch 615/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6623 - reconstruction_loss: 1891.7710 - kl_loss: 100.1856 - false_loss: 0.0989 - true_loss: 1.1811 - val_loss: 6402.6968 - val_reconstruction_loss: 1897.1245 - val_kl_loss: 98.8757 - val_false_loss: 14.2784 - val_true_loss: 1.2317\n",
      "Epoch 616/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.8218 - reconstruction_loss: 1891.4541 - kl_loss: 100.3950 - false_loss: 0.0989 - true_loss: 1.1811 - val_loss: 6402.1440 - val_reconstruction_loss: 1897.1237 - val_kl_loss: 98.8759 - val_false_loss: 14.2766 - val_true_loss: 1.2316\n",
      "Epoch 617/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.1874 - reconstruction_loss: 1892.0109 - kl_loss: 100.4717 - false_loss: 0.0989 - true_loss: 1.1810 - val_loss: 6401.5942 - val_reconstruction_loss: 1897.1227 - val_kl_loss: 98.8755 - val_false_loss: 14.2748 - val_true_loss: 1.2316\n",
      "Epoch 618/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.9965 - reconstruction_loss: 1892.0908 - kl_loss: 100.9677 - false_loss: 0.0989 - true_loss: 1.1810 - val_loss: 6401.0435 - val_reconstruction_loss: 1897.1219 - val_kl_loss: 98.8745 - val_false_loss: 14.2730 - val_true_loss: 1.2315\n",
      "Epoch 619/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.2448 - reconstruction_loss: 1892.5425 - kl_loss: 99.4642 - false_loss: 0.0988 - true_loss: 1.1809 - val_loss: 6400.4985 - val_reconstruction_loss: 1897.1213 - val_kl_loss: 98.8751 - val_false_loss: 14.2712 - val_true_loss: 1.2314\n",
      "Epoch 620/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.3308 - reconstruction_loss: 1892.0455 - kl_loss: 100.3476 - false_loss: 0.0988 - true_loss: 1.1808 - val_loss: 6399.9487 - val_reconstruction_loss: 1897.1205 - val_kl_loss: 98.8750 - val_false_loss: 14.2694 - val_true_loss: 1.2314\n",
      "Epoch 621/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.9365 - reconstruction_loss: 1891.7744 - kl_loss: 99.2493 - false_loss: 0.0988 - true_loss: 1.1808 - val_loss: 6399.3970 - val_reconstruction_loss: 1897.1196 - val_kl_loss: 98.8744 - val_false_loss: 14.2676 - val_true_loss: 1.2313\n",
      "Epoch 622/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.7903 - reconstruction_loss: 1891.7477 - kl_loss: 99.6832 - false_loss: 0.0988 - true_loss: 1.1807 - val_loss: 6398.8530 - val_reconstruction_loss: 1897.1189 - val_kl_loss: 98.8750 - val_false_loss: 14.2658 - val_true_loss: 1.2313\n",
      "Epoch 623/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.1556 - reconstruction_loss: 1891.3361 - kl_loss: 98.6388 - false_loss: 0.0988 - true_loss: 1.1807 - val_loss: 6398.3037 - val_reconstruction_loss: 1897.1180 - val_kl_loss: 98.8758 - val_false_loss: 14.2640 - val_true_loss: 1.2312\n",
      "Epoch 624/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.1830 - reconstruction_loss: 1891.4723 - kl_loss: 100.1851 - false_loss: 0.0988 - true_loss: 1.1806 - val_loss: 6397.7588 - val_reconstruction_loss: 1897.1172 - val_kl_loss: 98.8751 - val_false_loss: 14.2622 - val_true_loss: 1.2312\n",
      "Epoch 625/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2250.8410 - reconstruction_loss: 1892.0933 - kl_loss: 99.0707 - false_loss: 0.0988 - true_loss: 1.1805 - val_loss: 6397.2197 - val_reconstruction_loss: 1897.1167 - val_kl_loss: 98.8736 - val_false_loss: 14.2604 - val_true_loss: 1.2311\n",
      "Epoch 626/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.6043 - reconstruction_loss: 1892.2233 - kl_loss: 99.2712 - false_loss: 0.0988 - true_loss: 1.1805 - val_loss: 6396.6738 - val_reconstruction_loss: 1897.1160 - val_kl_loss: 98.8748 - val_false_loss: 14.2586 - val_true_loss: 1.2311\n",
      "Epoch 627/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.3916 - reconstruction_loss: 1891.6553 - kl_loss: 99.1722 - false_loss: 0.0988 - true_loss: 1.1804 - val_loss: 6396.1299 - val_reconstruction_loss: 1897.1150 - val_kl_loss: 98.8761 - val_false_loss: 14.2568 - val_true_loss: 1.2310\n",
      "Epoch 628/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.3010 - reconstruction_loss: 1891.8607 - kl_loss: 98.7737 - false_loss: 0.0988 - true_loss: 1.1804 - val_loss: 6395.5913 - val_reconstruction_loss: 1897.1145 - val_kl_loss: 98.8767 - val_false_loss: 14.2550 - val_true_loss: 1.2310\n",
      "Epoch 629/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4918 - reconstruction_loss: 1891.9873 - kl_loss: 100.3343 - false_loss: 0.0988 - true_loss: 1.1803 - val_loss: 6395.0439 - val_reconstruction_loss: 1897.1134 - val_kl_loss: 98.8781 - val_false_loss: 14.2532 - val_true_loss: 1.2309\n",
      "Epoch 630/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.5695 - reconstruction_loss: 1891.5551 - kl_loss: 100.4580 - false_loss: 0.0987 - true_loss: 1.1803 - val_loss: 6394.4937 - val_reconstruction_loss: 1897.1125 - val_kl_loss: 98.8796 - val_false_loss: 14.2514 - val_true_loss: 1.2309\n",
      "Epoch 631/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.9595 - reconstruction_loss: 1891.3239 - kl_loss: 100.0226 - false_loss: 0.0987 - true_loss: 1.1802 - val_loss: 6393.9565 - val_reconstruction_loss: 1897.1119 - val_kl_loss: 98.8809 - val_false_loss: 14.2496 - val_true_loss: 1.2308\n",
      "Epoch 632/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.3842 - reconstruction_loss: 1891.6698 - kl_loss: 99.2634 - false_loss: 0.0987 - true_loss: 1.1801 - val_loss: 6393.4146 - val_reconstruction_loss: 1897.1111 - val_kl_loss: 98.8830 - val_false_loss: 14.2478 - val_true_loss: 1.2308\n",
      "Epoch 633/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.7943 - reconstruction_loss: 1892.0277 - kl_loss: 99.7044 - false_loss: 0.0987 - true_loss: 1.1801 - val_loss: 6392.8740 - val_reconstruction_loss: 1897.1102 - val_kl_loss: 98.8837 - val_false_loss: 14.2460 - val_true_loss: 1.2307\n",
      "Epoch 634/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6642 - reconstruction_loss: 1891.7030 - kl_loss: 100.3356 - false_loss: 0.0987 - true_loss: 1.1800 - val_loss: 6392.3267 - val_reconstruction_loss: 1897.1094 - val_kl_loss: 98.8846 - val_false_loss: 14.2442 - val_true_loss: 1.2306\n",
      "Epoch 635/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.6647 - reconstruction_loss: 1892.0211 - kl_loss: 100.3590 - false_loss: 0.0987 - true_loss: 1.1800 - val_loss: 6391.7866 - val_reconstruction_loss: 1897.1086 - val_kl_loss: 98.8856 - val_false_loss: 14.2425 - val_true_loss: 1.2306\n",
      "Epoch 636/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.4757 - reconstruction_loss: 1891.9393 - kl_loss: 99.9087 - false_loss: 0.0987 - true_loss: 1.1799 - val_loss: 6391.2397 - val_reconstruction_loss: 1897.1079 - val_kl_loss: 98.8867 - val_false_loss: 14.2406 - val_true_loss: 1.2305\n",
      "Epoch 637/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.6421 - reconstruction_loss: 1891.3843 - kl_loss: 100.6850 - false_loss: 0.0987 - true_loss: 1.1798 - val_loss: 6390.6919 - val_reconstruction_loss: 1897.1071 - val_kl_loss: 98.8865 - val_false_loss: 14.2388 - val_true_loss: 1.2305\n",
      "Epoch 638/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3234 - reconstruction_loss: 1891.3760 - kl_loss: 99.7102 - false_loss: 0.0987 - true_loss: 1.1798 - val_loss: 6390.1543 - val_reconstruction_loss: 1897.1063 - val_kl_loss: 98.8869 - val_false_loss: 14.2371 - val_true_loss: 1.2304\n",
      "Epoch 639/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.3422 - reconstruction_loss: 1892.3090 - kl_loss: 100.6737 - false_loss: 0.0987 - true_loss: 1.1797 - val_loss: 6389.6074 - val_reconstruction_loss: 1897.1055 - val_kl_loss: 98.8885 - val_false_loss: 14.2353 - val_true_loss: 1.2304\n",
      "Epoch 640/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7902 - reconstruction_loss: 1891.7267 - kl_loss: 100.4563 - false_loss: 0.0986 - true_loss: 1.1796 - val_loss: 6389.0693 - val_reconstruction_loss: 1897.1046 - val_kl_loss: 98.8897 - val_false_loss: 14.2335 - val_true_loss: 1.2303\n",
      "Epoch 641/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.3099 - reconstruction_loss: 1891.4801 - kl_loss: 100.2476 - false_loss: 0.0986 - true_loss: 1.1796 - val_loss: 6388.5249 - val_reconstruction_loss: 1897.1038 - val_kl_loss: 98.8914 - val_false_loss: 14.2317 - val_true_loss: 1.2303\n",
      "Epoch 642/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.4288 - reconstruction_loss: 1891.4030 - kl_loss: 100.4177 - false_loss: 0.0986 - true_loss: 1.1795 - val_loss: 6387.9746 - val_reconstruction_loss: 1897.1029 - val_kl_loss: 98.8921 - val_false_loss: 14.2299 - val_true_loss: 1.2302\n",
      "Epoch 643/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.3405 - reconstruction_loss: 1891.5863 - kl_loss: 100.5944 - false_loss: 0.0986 - true_loss: 1.1794 - val_loss: 6387.4302 - val_reconstruction_loss: 1897.1021 - val_kl_loss: 98.8931 - val_false_loss: 14.2281 - val_true_loss: 1.2301\n",
      "Epoch 644/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.4437 - reconstruction_loss: 1891.2817 - kl_loss: 100.7165 - false_loss: 0.0986 - true_loss: 1.1794 - val_loss: 6386.8877 - val_reconstruction_loss: 1897.1014 - val_kl_loss: 98.8938 - val_false_loss: 14.2263 - val_true_loss: 1.2301\n",
      "Epoch 645/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.7600 - reconstruction_loss: 1891.9064 - kl_loss: 100.7285 - false_loss: 0.0986 - true_loss: 1.1793 - val_loss: 6386.3452 - val_reconstruction_loss: 1897.1006 - val_kl_loss: 98.8953 - val_false_loss: 14.2245 - val_true_loss: 1.2300\n",
      "Epoch 646/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.8248 - reconstruction_loss: 1891.4081 - kl_loss: 100.2288 - false_loss: 0.0986 - true_loss: 1.1793 - val_loss: 6385.7988 - val_reconstruction_loss: 1897.0999 - val_kl_loss: 98.8970 - val_false_loss: 14.2227 - val_true_loss: 1.2300\n",
      "Epoch 647/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.1878 - reconstruction_loss: 1891.6139 - kl_loss: 100.8239 - false_loss: 0.0986 - true_loss: 1.1792 - val_loss: 6385.2554 - val_reconstruction_loss: 1897.0989 - val_kl_loss: 98.8973 - val_false_loss: 14.2209 - val_true_loss: 1.2299\n",
      "Epoch 648/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.5817 - reconstruction_loss: 1892.0308 - kl_loss: 100.2930 - false_loss: 0.0986 - true_loss: 1.1791 - val_loss: 6384.7188 - val_reconstruction_loss: 1897.0983 - val_kl_loss: 98.8978 - val_false_loss: 14.2191 - val_true_loss: 1.2299\n",
      "Epoch 649/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.4065 - reconstruction_loss: 1891.7428 - kl_loss: 99.5004 - false_loss: 0.0986 - true_loss: 1.1791 - val_loss: 6384.1772 - val_reconstruction_loss: 1897.0974 - val_kl_loss: 98.8983 - val_false_loss: 14.2173 - val_true_loss: 1.2298\n",
      "Epoch 650/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.7527 - reconstruction_loss: 1891.5145 - kl_loss: 101.2692 - false_loss: 0.0986 - true_loss: 1.1790 - val_loss: 6383.6401 - val_reconstruction_loss: 1897.0967 - val_kl_loss: 98.8986 - val_false_loss: 14.2156 - val_true_loss: 1.2298\n",
      "Epoch 651/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.6540 - reconstruction_loss: 1891.7266 - kl_loss: 99.6305 - false_loss: 0.0985 - true_loss: 1.1789 - val_loss: 6383.0942 - val_reconstruction_loss: 1897.0958 - val_kl_loss: 98.8998 - val_false_loss: 14.2138 - val_true_loss: 1.2297\n",
      "Epoch 652/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.6947 - reconstruction_loss: 1891.5370 - kl_loss: 100.4501 - false_loss: 0.0985 - true_loss: 1.1789 - val_loss: 6382.5483 - val_reconstruction_loss: 1897.0950 - val_kl_loss: 98.9012 - val_false_loss: 14.2120 - val_true_loss: 1.2296\n",
      "Epoch 653/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0687 - reconstruction_loss: 1891.5363 - kl_loss: 100.4805 - false_loss: 0.0985 - true_loss: 1.1788 - val_loss: 6382.0083 - val_reconstruction_loss: 1897.0944 - val_kl_loss: 98.9024 - val_false_loss: 14.2102 - val_true_loss: 1.2296\n",
      "Epoch 654/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.5269 - reconstruction_loss: 1891.8496 - kl_loss: 100.6380 - false_loss: 0.0985 - true_loss: 1.1788 - val_loss: 6381.4644 - val_reconstruction_loss: 1897.0935 - val_kl_loss: 98.9032 - val_false_loss: 14.2084 - val_true_loss: 1.2295\n",
      "Epoch 655/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.9213 - reconstruction_loss: 1891.4912 - kl_loss: 100.0911 - false_loss: 0.0985 - true_loss: 1.1787 - val_loss: 6380.9253 - val_reconstruction_loss: 1897.0928 - val_kl_loss: 98.9028 - val_false_loss: 14.2066 - val_true_loss: 1.2295\n",
      "Epoch 656/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.2108 - reconstruction_loss: 1891.7246 - kl_loss: 100.5918 - false_loss: 0.0985 - true_loss: 1.1786 - val_loss: 6380.3833 - val_reconstruction_loss: 1897.0922 - val_kl_loss: 98.9036 - val_false_loss: 14.2048 - val_true_loss: 1.2294\n",
      "Epoch 657/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.2577 - reconstruction_loss: 1891.8153 - kl_loss: 100.4958 - false_loss: 0.0985 - true_loss: 1.1786 - val_loss: 6379.8433 - val_reconstruction_loss: 1897.0913 - val_kl_loss: 98.9041 - val_false_loss: 14.2030 - val_true_loss: 1.2294\n",
      "Epoch 658/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.0722 - reconstruction_loss: 1891.4017 - kl_loss: 100.3490 - false_loss: 0.0985 - true_loss: 1.1785 - val_loss: 6379.3013 - val_reconstruction_loss: 1897.0905 - val_kl_loss: 98.9036 - val_false_loss: 14.2013 - val_true_loss: 1.2293\n",
      "Epoch 659/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.5632 - reconstruction_loss: 1891.7148 - kl_loss: 99.6323 - false_loss: 0.0985 - true_loss: 1.1785 - val_loss: 6378.7642 - val_reconstruction_loss: 1897.0900 - val_kl_loss: 98.9042 - val_false_loss: 14.1995 - val_true_loss: 1.2293\n",
      "Epoch 660/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.4639 - reconstruction_loss: 1892.3571 - kl_loss: 99.8626 - false_loss: 0.0985 - true_loss: 1.1784 - val_loss: 6378.2212 - val_reconstruction_loss: 1897.0891 - val_kl_loss: 98.9053 - val_false_loss: 14.1977 - val_true_loss: 1.2292\n",
      "Epoch 661/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.9830 - reconstruction_loss: 1891.6730 - kl_loss: 100.1609 - false_loss: 0.0984 - true_loss: 1.1783 - val_loss: 6377.6797 - val_reconstruction_loss: 1897.0883 - val_kl_loss: 98.9062 - val_false_loss: 14.1959 - val_true_loss: 1.2292\n",
      "Epoch 662/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.5251 - reconstruction_loss: 1892.6864 - kl_loss: 100.3434 - false_loss: 0.0984 - true_loss: 1.1783 - val_loss: 6377.1377 - val_reconstruction_loss: 1897.0878 - val_kl_loss: 98.9063 - val_false_loss: 14.1941 - val_true_loss: 1.2291\n",
      "Epoch 663/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.1194 - reconstruction_loss: 1891.9584 - kl_loss: 99.7978 - false_loss: 0.0984 - true_loss: 1.1782 - val_loss: 6376.6030 - val_reconstruction_loss: 1897.0869 - val_kl_loss: 98.9066 - val_false_loss: 14.1924 - val_true_loss: 1.2291\n",
      "Epoch 664/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2802 - reconstruction_loss: 1891.4238 - kl_loss: 100.7996 - false_loss: 0.0984 - true_loss: 1.1782 - val_loss: 6376.0664 - val_reconstruction_loss: 1897.0861 - val_kl_loss: 98.9068 - val_false_loss: 14.1906 - val_true_loss: 1.2290\n",
      "Epoch 665/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.5864 - reconstruction_loss: 1891.0376 - kl_loss: 99.5145 - false_loss: 0.0984 - true_loss: 1.1781 - val_loss: 6375.5229 - val_reconstruction_loss: 1897.0852 - val_kl_loss: 98.9075 - val_false_loss: 14.1888 - val_true_loss: 1.2289\n",
      "Epoch 666/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4680 - reconstruction_loss: 1891.1714 - kl_loss: 100.1562 - false_loss: 0.0984 - true_loss: 1.1780 - val_loss: 6374.9819 - val_reconstruction_loss: 1897.0844 - val_kl_loss: 98.9080 - val_false_loss: 14.1870 - val_true_loss: 1.2289\n",
      "Epoch 667/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.7516 - reconstruction_loss: 1891.5145 - kl_loss: 100.7382 - false_loss: 0.0984 - true_loss: 1.1780 - val_loss: 6374.4419 - val_reconstruction_loss: 1897.0836 - val_kl_loss: 98.9081 - val_false_loss: 14.1852 - val_true_loss: 1.2288\n",
      "Epoch 668/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.6249 - reconstruction_loss: 1891.5972 - kl_loss: 100.4878 - false_loss: 0.0984 - true_loss: 1.1779 - val_loss: 6373.9043 - val_reconstruction_loss: 1897.0829 - val_kl_loss: 98.9078 - val_false_loss: 14.1835 - val_true_loss: 1.2288\n",
      "Epoch 669/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.7694 - reconstruction_loss: 1891.8873 - kl_loss: 99.3957 - false_loss: 0.0984 - true_loss: 1.1778 - val_loss: 6373.3560 - val_reconstruction_loss: 1897.0823 - val_kl_loss: 98.9088 - val_false_loss: 14.1817 - val_true_loss: 1.2287\n",
      "Epoch 670/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.9096 - reconstruction_loss: 1891.6483 - kl_loss: 101.3562 - false_loss: 0.0984 - true_loss: 1.1778 - val_loss: 6372.8164 - val_reconstruction_loss: 1897.0814 - val_kl_loss: 98.9098 - val_false_loss: 14.1799 - val_true_loss: 1.2287\n",
      "Epoch 671/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8247 - reconstruction_loss: 1891.5142 - kl_loss: 100.7614 - false_loss: 0.0984 - true_loss: 1.1777 - val_loss: 6372.2720 - val_reconstruction_loss: 1897.0806 - val_kl_loss: 98.9097 - val_false_loss: 14.1781 - val_true_loss: 1.2286\n",
      "Epoch 672/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.0668 - reconstruction_loss: 1891.2461 - kl_loss: 100.2836 - false_loss: 0.0983 - true_loss: 1.1777 - val_loss: 6371.7280 - val_reconstruction_loss: 1897.0797 - val_kl_loss: 98.9094 - val_false_loss: 14.1763 - val_true_loss: 1.2286\n",
      "Epoch 673/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4472 - reconstruction_loss: 1891.8751 - kl_loss: 100.7224 - false_loss: 0.0983 - true_loss: 1.1776 - val_loss: 6371.1865 - val_reconstruction_loss: 1897.0789 - val_kl_loss: 98.9098 - val_false_loss: 14.1745 - val_true_loss: 1.2285\n",
      "Epoch 674/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.7060 - reconstruction_loss: 1891.6283 - kl_loss: 100.4741 - false_loss: 0.0983 - true_loss: 1.1775 - val_loss: 6370.6479 - val_reconstruction_loss: 1897.0782 - val_kl_loss: 98.9102 - val_false_loss: 14.1727 - val_true_loss: 1.2284\n",
      "Epoch 675/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.2688 - reconstruction_loss: 1891.7100 - kl_loss: 100.5774 - false_loss: 0.0983 - true_loss: 1.1775 - val_loss: 6370.1074 - val_reconstruction_loss: 1897.0774 - val_kl_loss: 98.9100 - val_false_loss: 14.1709 - val_true_loss: 1.2284\n",
      "Epoch 676/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.2217 - reconstruction_loss: 1891.7538 - kl_loss: 99.9478 - false_loss: 0.0983 - true_loss: 1.1774 - val_loss: 6369.5635 - val_reconstruction_loss: 1897.0767 - val_kl_loss: 98.9095 - val_false_loss: 14.1692 - val_true_loss: 1.2283\n",
      "Epoch 677/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2236.0087 - reconstruction_loss: 1891.8604 - kl_loss: 100.3975 - false_loss: 0.0983 - true_loss: 1.1773 - val_loss: 6369.0283 - val_reconstruction_loss: 1897.0758 - val_kl_loss: 98.9093 - val_false_loss: 14.1674 - val_true_loss: 1.2283\n",
      "Epoch 678/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.6545 - reconstruction_loss: 1892.0958 - kl_loss: 100.3666 - false_loss: 0.0983 - true_loss: 1.1773 - val_loss: 6368.4932 - val_reconstruction_loss: 1897.0751 - val_kl_loss: 98.9094 - val_false_loss: 14.1656 - val_true_loss: 1.2282\n",
      "Epoch 679/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5457 - reconstruction_loss: 1891.3739 - kl_loss: 100.5750 - false_loss: 0.0983 - true_loss: 1.1772 - val_loss: 6367.9521 - val_reconstruction_loss: 1897.0743 - val_kl_loss: 98.9103 - val_false_loss: 14.1638 - val_true_loss: 1.2282\n",
      "Epoch 680/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.6650 - reconstruction_loss: 1891.4956 - kl_loss: 100.9111 - false_loss: 0.0983 - true_loss: 1.1772 - val_loss: 6367.4180 - val_reconstruction_loss: 1897.0737 - val_kl_loss: 98.9101 - val_false_loss: 14.1621 - val_true_loss: 1.2281\n",
      "Epoch 681/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6255 - reconstruction_loss: 1892.0494 - kl_loss: 100.0740 - false_loss: 0.0983 - true_loss: 1.1771 - val_loss: 6366.8779 - val_reconstruction_loss: 1897.0729 - val_kl_loss: 98.9103 - val_false_loss: 14.1603 - val_true_loss: 1.2281\n",
      "Epoch 682/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.3028 - reconstruction_loss: 1891.5153 - kl_loss: 100.4031 - false_loss: 0.0982 - true_loss: 1.1770 - val_loss: 6366.3350 - val_reconstruction_loss: 1897.0721 - val_kl_loss: 98.9108 - val_false_loss: 14.1585 - val_true_loss: 1.2280\n",
      "Epoch 683/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6639 - reconstruction_loss: 1891.4852 - kl_loss: 100.5698 - false_loss: 0.0982 - true_loss: 1.1770 - val_loss: 6365.7979 - val_reconstruction_loss: 1897.0715 - val_kl_loss: 98.9116 - val_false_loss: 14.1567 - val_true_loss: 1.2280\n",
      "Epoch 684/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8758 - reconstruction_loss: 1891.7701 - kl_loss: 101.0107 - false_loss: 0.0982 - true_loss: 1.1769 - val_loss: 6365.2656 - val_reconstruction_loss: 1897.0707 - val_kl_loss: 98.9125 - val_false_loss: 14.1550 - val_true_loss: 1.2279\n",
      "Epoch 685/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.3248 - reconstruction_loss: 1891.5126 - kl_loss: 101.3486 - false_loss: 0.0982 - true_loss: 1.1768 - val_loss: 6364.7305 - val_reconstruction_loss: 1897.0698 - val_kl_loss: 98.9130 - val_false_loss: 14.1532 - val_true_loss: 1.2279\n",
      "Epoch 686/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8963 - reconstruction_loss: 1891.4908 - kl_loss: 100.2994 - false_loss: 0.0982 - true_loss: 1.1768 - val_loss: 6364.1958 - val_reconstruction_loss: 1897.0690 - val_kl_loss: 98.9135 - val_false_loss: 14.1515 - val_true_loss: 1.2278\n",
      "Epoch 687/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.2450 - reconstruction_loss: 1891.6089 - kl_loss: 100.3597 - false_loss: 0.0982 - true_loss: 1.1767 - val_loss: 6363.6597 - val_reconstruction_loss: 1897.0685 - val_kl_loss: 98.9135 - val_false_loss: 14.1497 - val_true_loss: 1.2277\n",
      "Epoch 688/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.4791 - reconstruction_loss: 1891.1769 - kl_loss: 99.4891 - false_loss: 0.0982 - true_loss: 1.1767 - val_loss: 6363.1289 - val_reconstruction_loss: 1897.0676 - val_kl_loss: 98.9131 - val_false_loss: 14.1479 - val_true_loss: 1.2277\n",
      "Epoch 689/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.7475 - reconstruction_loss: 1891.7764 - kl_loss: 99.9754 - false_loss: 0.0982 - true_loss: 1.1766 - val_loss: 6362.5986 - val_reconstruction_loss: 1897.0667 - val_kl_loss: 98.9138 - val_false_loss: 14.1462 - val_true_loss: 1.2276\n",
      "Epoch 690/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.0135 - reconstruction_loss: 1891.1484 - kl_loss: 100.7186 - false_loss: 0.0982 - true_loss: 1.1765 - val_loss: 6362.0698 - val_reconstruction_loss: 1897.0662 - val_kl_loss: 98.9149 - val_false_loss: 14.1444 - val_true_loss: 1.2276\n",
      "Epoch 691/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.2204 - reconstruction_loss: 1891.4463 - kl_loss: 100.3358 - false_loss: 0.0982 - true_loss: 1.1765 - val_loss: 6361.5322 - val_reconstruction_loss: 1897.0653 - val_kl_loss: 98.9157 - val_false_loss: 14.1427 - val_true_loss: 1.2275\n",
      "Epoch 692/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.3309 - reconstruction_loss: 1891.4471 - kl_loss: 100.7673 - false_loss: 0.0982 - true_loss: 1.1764 - val_loss: 6360.9966 - val_reconstruction_loss: 1897.0645 - val_kl_loss: 98.9157 - val_false_loss: 14.1409 - val_true_loss: 1.2275\n",
      "Epoch 693/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.9835 - reconstruction_loss: 1891.6696 - kl_loss: 100.7796 - false_loss: 0.0981 - true_loss: 1.1763 - val_loss: 6360.4644 - val_reconstruction_loss: 1897.0637 - val_kl_loss: 98.9153 - val_false_loss: 14.1392 - val_true_loss: 1.2274\n",
      "Epoch 694/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.1725 - reconstruction_loss: 1891.3575 - kl_loss: 99.8697 - false_loss: 0.0981 - true_loss: 1.1763 - val_loss: 6359.9351 - val_reconstruction_loss: 1897.0630 - val_kl_loss: 98.9153 - val_false_loss: 14.1374 - val_true_loss: 1.2274\n",
      "Epoch 695/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2254.0937 - reconstruction_loss: 1891.8978 - kl_loss: 101.9181 - false_loss: 0.0981 - true_loss: 1.1762 - val_loss: 6359.4150 - val_reconstruction_loss: 1897.0625 - val_kl_loss: 98.9138 - val_false_loss: 14.1357 - val_true_loss: 1.2273\n",
      "Epoch 696/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.0190 - reconstruction_loss: 1892.5587 - kl_loss: 101.0663 - false_loss: 0.0981 - true_loss: 1.1762 - val_loss: 6358.8726 - val_reconstruction_loss: 1897.0616 - val_kl_loss: 98.9146 - val_false_loss: 14.1339 - val_true_loss: 1.2273\n",
      "Epoch 697/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.4773 - reconstruction_loss: 1892.0234 - kl_loss: 99.0950 - false_loss: 0.0981 - true_loss: 1.1761 - val_loss: 6358.3335 - val_reconstruction_loss: 1897.0608 - val_kl_loss: 98.9149 - val_false_loss: 14.1321 - val_true_loss: 1.2272\n",
      "Epoch 698/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7758 - reconstruction_loss: 1891.4052 - kl_loss: 99.8124 - false_loss: 0.0981 - true_loss: 1.1761 - val_loss: 6357.7881 - val_reconstruction_loss: 1897.0603 - val_kl_loss: 98.9156 - val_false_loss: 14.1303 - val_true_loss: 1.2272\n",
      "Epoch 699/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.0047 - reconstruction_loss: 1891.1006 - kl_loss: 100.2912 - false_loss: 0.0981 - true_loss: 1.1760 - val_loss: 6357.2646 - val_reconstruction_loss: 1897.0593 - val_kl_loss: 98.9161 - val_false_loss: 14.1286 - val_true_loss: 1.2271\n",
      "Epoch 700/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.0919 - reconstruction_loss: 1891.5941 - kl_loss: 100.3520 - false_loss: 0.0981 - true_loss: 1.1759 - val_loss: 6356.7358 - val_reconstruction_loss: 1897.0585 - val_kl_loss: 98.9160 - val_false_loss: 14.1269 - val_true_loss: 1.2271\n",
      "Epoch 701/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6017 - reconstruction_loss: 1891.4801 - kl_loss: 100.6550 - false_loss: 0.0981 - true_loss: 1.1759 - val_loss: 6356.1958 - val_reconstruction_loss: 1897.0579 - val_kl_loss: 98.9162 - val_false_loss: 14.1251 - val_true_loss: 1.2270\n",
      "Epoch 702/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.5463 - reconstruction_loss: 1891.4796 - kl_loss: 99.5445 - false_loss: 0.0981 - true_loss: 1.1758 - val_loss: 6355.6577 - val_reconstruction_loss: 1897.0573 - val_kl_loss: 98.9177 - val_false_loss: 14.1233 - val_true_loss: 1.2270\n",
      "Epoch 703/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0652 - reconstruction_loss: 1891.7186 - kl_loss: 100.6593 - false_loss: 0.0980 - true_loss: 1.1758 - val_loss: 6355.1270 - val_reconstruction_loss: 1897.0562 - val_kl_loss: 98.9187 - val_false_loss: 14.1216 - val_true_loss: 1.2269\n",
      "Epoch 704/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.7509 - reconstruction_loss: 1891.3877 - kl_loss: 100.4463 - false_loss: 0.0980 - true_loss: 1.1757 - val_loss: 6354.5972 - val_reconstruction_loss: 1897.0557 - val_kl_loss: 98.9190 - val_false_loss: 14.1198 - val_true_loss: 1.2268\n",
      "Epoch 705/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.5273 - reconstruction_loss: 1891.5508 - kl_loss: 100.9433 - false_loss: 0.0980 - true_loss: 1.1756 - val_loss: 6354.0586 - val_reconstruction_loss: 1897.0547 - val_kl_loss: 98.9193 - val_false_loss: 14.1180 - val_true_loss: 1.2268\n",
      "Epoch 706/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.8316 - reconstruction_loss: 1891.5054 - kl_loss: 100.1229 - false_loss: 0.0980 - true_loss: 1.1756 - val_loss: 6353.5200 - val_reconstruction_loss: 1897.0541 - val_kl_loss: 98.9199 - val_false_loss: 14.1163 - val_true_loss: 1.2267\n",
      "Epoch 707/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.4144 - reconstruction_loss: 1891.4120 - kl_loss: 100.4127 - false_loss: 0.0980 - true_loss: 1.1755 - val_loss: 6352.9912 - val_reconstruction_loss: 1897.0533 - val_kl_loss: 98.9204 - val_false_loss: 14.1145 - val_true_loss: 1.2267\n",
      "Epoch 708/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.5416 - reconstruction_loss: 1891.2744 - kl_loss: 100.6639 - false_loss: 0.0980 - true_loss: 1.1754 - val_loss: 6352.4551 - val_reconstruction_loss: 1897.0526 - val_kl_loss: 98.9200 - val_false_loss: 14.1127 - val_true_loss: 1.2266\n",
      "Epoch 709/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.7562 - reconstruction_loss: 1891.7217 - kl_loss: 99.6634 - false_loss: 0.0980 - true_loss: 1.1754 - val_loss: 6351.9253 - val_reconstruction_loss: 1897.0519 - val_kl_loss: 98.9205 - val_false_loss: 14.1110 - val_true_loss: 1.2266\n",
      "Epoch 710/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.9022 - reconstruction_loss: 1891.6097 - kl_loss: 99.4645 - false_loss: 0.0980 - true_loss: 1.1753 - val_loss: 6351.3936 - val_reconstruction_loss: 1897.0510 - val_kl_loss: 98.9217 - val_false_loss: 14.1092 - val_true_loss: 1.2265\n",
      "Epoch 711/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.6600 - reconstruction_loss: 1891.6572 - kl_loss: 100.6082 - false_loss: 0.0980 - true_loss: 1.1753 - val_loss: 6350.8599 - val_reconstruction_loss: 1897.0504 - val_kl_loss: 98.9223 - val_false_loss: 14.1075 - val_true_loss: 1.2265\n",
      "Epoch 712/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.9934 - reconstruction_loss: 1891.7933 - kl_loss: 99.8156 - false_loss: 0.0980 - true_loss: 1.1752 - val_loss: 6350.3237 - val_reconstruction_loss: 1897.0497 - val_kl_loss: 98.9225 - val_false_loss: 14.1057 - val_true_loss: 1.2264\n",
      "Epoch 713/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8782 - reconstruction_loss: 1891.9047 - kl_loss: 99.9933 - false_loss: 0.0980 - true_loss: 1.1751 - val_loss: 6349.8032 - val_reconstruction_loss: 1897.0490 - val_kl_loss: 98.9249 - val_false_loss: 14.1040 - val_true_loss: 1.2264\n",
      "Epoch 714/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.5371 - reconstruction_loss: 1891.4269 - kl_loss: 101.3982 - false_loss: 0.0979 - true_loss: 1.1751 - val_loss: 6349.2725 - val_reconstruction_loss: 1897.0481 - val_kl_loss: 98.9258 - val_false_loss: 14.1022 - val_true_loss: 1.2263\n",
      "Epoch 715/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.6516 - reconstruction_loss: 1891.5824 - kl_loss: 101.9980 - false_loss: 0.0979 - true_loss: 1.1750 - val_loss: 6348.7427 - val_reconstruction_loss: 1897.0472 - val_kl_loss: 98.9255 - val_false_loss: 14.1005 - val_true_loss: 1.2263\n",
      "Epoch 716/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.7200 - reconstruction_loss: 1891.4066 - kl_loss: 99.7828 - false_loss: 0.0979 - true_loss: 1.1750 - val_loss: 6348.2085 - val_reconstruction_loss: 1897.0466 - val_kl_loss: 98.9262 - val_false_loss: 14.0987 - val_true_loss: 1.2262\n",
      "Epoch 717/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8825 - reconstruction_loss: 1891.2334 - kl_loss: 100.4092 - false_loss: 0.0979 - true_loss: 1.1749 - val_loss: 6347.6763 - val_reconstruction_loss: 1897.0458 - val_kl_loss: 98.9267 - val_false_loss: 14.0970 - val_true_loss: 1.2261\n",
      "Epoch 718/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.7033 - reconstruction_loss: 1892.2609 - kl_loss: 100.6945 - false_loss: 0.0979 - true_loss: 1.1748 - val_loss: 6347.1421 - val_reconstruction_loss: 1897.0452 - val_kl_loss: 98.9287 - val_false_loss: 14.0952 - val_true_loss: 1.2261\n",
      "Epoch 719/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.4232 - reconstruction_loss: 1892.1963 - kl_loss: 100.8720 - false_loss: 0.0979 - true_loss: 1.1748 - val_loss: 6346.6187 - val_reconstruction_loss: 1897.0444 - val_kl_loss: 98.9299 - val_false_loss: 14.0935 - val_true_loss: 1.2260\n",
      "Epoch 720/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.4392 - reconstruction_loss: 1891.4877 - kl_loss: 101.2396 - false_loss: 0.0979 - true_loss: 1.1747 - val_loss: 6346.0908 - val_reconstruction_loss: 1897.0435 - val_kl_loss: 98.9303 - val_false_loss: 14.0917 - val_true_loss: 1.2260\n",
      "Epoch 721/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8509 - reconstruction_loss: 1891.3827 - kl_loss: 100.2116 - false_loss: 0.0979 - true_loss: 1.1747 - val_loss: 6345.5581 - val_reconstruction_loss: 1897.0426 - val_kl_loss: 98.9306 - val_false_loss: 14.0900 - val_true_loss: 1.2259\n",
      "Epoch 722/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.8302 - reconstruction_loss: 1891.3954 - kl_loss: 100.7430 - false_loss: 0.0979 - true_loss: 1.1746 - val_loss: 6345.0352 - val_reconstruction_loss: 1897.0420 - val_kl_loss: 98.9306 - val_false_loss: 14.0883 - val_true_loss: 1.2259\n",
      "Epoch 723/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.7937 - reconstruction_loss: 1891.2365 - kl_loss: 100.0704 - false_loss: 0.0979 - true_loss: 1.1745 - val_loss: 6344.5098 - val_reconstruction_loss: 1897.0411 - val_kl_loss: 98.9315 - val_false_loss: 14.0865 - val_true_loss: 1.2258\n",
      "Epoch 724/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5079 - reconstruction_loss: 1891.1693 - kl_loss: 100.4983 - false_loss: 0.0979 - true_loss: 1.1745 - val_loss: 6343.9785 - val_reconstruction_loss: 1897.0403 - val_kl_loss: 98.9315 - val_false_loss: 14.0848 - val_true_loss: 1.2258\n",
      "Epoch 725/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.5084 - reconstruction_loss: 1891.8114 - kl_loss: 99.8415 - false_loss: 0.0978 - true_loss: 1.1744 - val_loss: 6343.4556 - val_reconstruction_loss: 1897.0397 - val_kl_loss: 98.9321 - val_false_loss: 14.0831 - val_true_loss: 1.2257\n",
      "Epoch 726/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.1809 - reconstruction_loss: 1891.4471 - kl_loss: 99.0680 - false_loss: 0.0978 - true_loss: 1.1744 - val_loss: 6342.9238 - val_reconstruction_loss: 1897.0388 - val_kl_loss: 98.9314 - val_false_loss: 14.0813 - val_true_loss: 1.2257\n",
      "Epoch 727/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.6444 - reconstruction_loss: 1891.2627 - kl_loss: 97.8908 - false_loss: 0.0978 - true_loss: 1.1743 - val_loss: 6342.4004 - val_reconstruction_loss: 1897.0382 - val_kl_loss: 98.9315 - val_false_loss: 14.0796 - val_true_loss: 1.2256\n",
      "Epoch 728/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.4845 - reconstruction_loss: 1891.7181 - kl_loss: 98.6714 - false_loss: 0.0978 - true_loss: 1.1742 - val_loss: 6341.8779 - val_reconstruction_loss: 1897.0375 - val_kl_loss: 98.9324 - val_false_loss: 14.0778 - val_true_loss: 1.2256\n",
      "Epoch 729/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2264.9682 - reconstruction_loss: 1891.7072 - kl_loss: 99.0543 - false_loss: 0.0978 - true_loss: 1.1742 - val_loss: 6341.3477 - val_reconstruction_loss: 1897.0367 - val_kl_loss: 98.9317 - val_false_loss: 14.0761 - val_true_loss: 1.2256\n",
      "Epoch 730/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2260.1262 - reconstruction_loss: 1891.4452 - kl_loss: 98.5892 - false_loss: 0.0978 - true_loss: 1.1742 - val_loss: 6340.8130 - val_reconstruction_loss: 1897.0360 - val_kl_loss: 98.9321 - val_false_loss: 14.0743 - val_true_loss: 1.2255\n",
      "Epoch 731/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.9373 - reconstruction_loss: 1891.7758 - kl_loss: 97.0568 - false_loss: 0.0978 - true_loss: 1.1741 - val_loss: 6340.2876 - val_reconstruction_loss: 1897.0353 - val_kl_loss: 98.9327 - val_false_loss: 14.0726 - val_true_loss: 1.2255\n",
      "Epoch 732/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.9731 - reconstruction_loss: 1891.5619 - kl_loss: 98.2573 - false_loss: 0.0978 - true_loss: 1.1741 - val_loss: 6339.7612 - val_reconstruction_loss: 1897.0343 - val_kl_loss: 98.9318 - val_false_loss: 14.0709 - val_true_loss: 1.2254\n",
      "Epoch 733/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.4298 - reconstruction_loss: 1891.9589 - kl_loss: 96.0454 - false_loss: 0.0978 - true_loss: 1.1740 - val_loss: 6339.2339 - val_reconstruction_loss: 1897.0337 - val_kl_loss: 98.9326 - val_false_loss: 14.0691 - val_true_loss: 1.2254\n",
      "Epoch 734/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.3712 - reconstruction_loss: 1891.5956 - kl_loss: 97.8700 - false_loss: 0.0978 - true_loss: 1.1740 - val_loss: 6338.7021 - val_reconstruction_loss: 1897.0330 - val_kl_loss: 98.9318 - val_false_loss: 14.0674 - val_true_loss: 1.2253\n",
      "Epoch 735/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.2589 - reconstruction_loss: 1891.1498 - kl_loss: 97.5915 - false_loss: 0.0978 - true_loss: 1.1739 - val_loss: 6338.1792 - val_reconstruction_loss: 1897.0321 - val_kl_loss: 98.9305 - val_false_loss: 14.0656 - val_true_loss: 1.2253\n",
      "Epoch 736/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2260.9020 - reconstruction_loss: 1892.0288 - kl_loss: 96.7972 - false_loss: 0.0977 - true_loss: 1.1739 - val_loss: 6337.6475 - val_reconstruction_loss: 1897.0312 - val_kl_loss: 98.9315 - val_false_loss: 14.0639 - val_true_loss: 1.2252\n",
      "Epoch 737/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.8397 - reconstruction_loss: 1892.1152 - kl_loss: 98.4147 - false_loss: 0.0977 - true_loss: 1.1738 - val_loss: 6337.1147 - val_reconstruction_loss: 1897.0308 - val_kl_loss: 98.9309 - val_false_loss: 14.0621 - val_true_loss: 1.2252\n",
      "Epoch 738/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.8683 - reconstruction_loss: 1891.6681 - kl_loss: 97.7742 - false_loss: 0.0977 - true_loss: 1.1738 - val_loss: 6336.5864 - val_reconstruction_loss: 1897.0300 - val_kl_loss: 98.9311 - val_false_loss: 14.0604 - val_true_loss: 1.2251\n",
      "Epoch 739/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.4861 - reconstruction_loss: 1891.4121 - kl_loss: 98.1106 - false_loss: 0.0977 - true_loss: 1.1737 - val_loss: 6336.0659 - val_reconstruction_loss: 1897.0292 - val_kl_loss: 98.9318 - val_false_loss: 14.0587 - val_true_loss: 1.2251\n",
      "Epoch 740/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.3206 - reconstruction_loss: 1891.1439 - kl_loss: 99.1746 - false_loss: 0.0977 - true_loss: 1.1736 - val_loss: 6335.5400 - val_reconstruction_loss: 1897.0283 - val_kl_loss: 98.9340 - val_false_loss: 14.0569 - val_true_loss: 1.2250\n",
      "Epoch 741/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.0618 - reconstruction_loss: 1891.7269 - kl_loss: 99.7566 - false_loss: 0.0977 - true_loss: 1.1736 - val_loss: 6335.0151 - val_reconstruction_loss: 1897.0278 - val_kl_loss: 98.9343 - val_false_loss: 14.0552 - val_true_loss: 1.2250\n",
      "Epoch 742/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.3676 - reconstruction_loss: 1891.5902 - kl_loss: 100.3096 - false_loss: 0.0977 - true_loss: 1.1735 - val_loss: 6334.4834 - val_reconstruction_loss: 1897.0272 - val_kl_loss: 98.9334 - val_false_loss: 14.0534 - val_true_loss: 1.2250\n",
      "Epoch 743/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.5442 - reconstruction_loss: 1891.1436 - kl_loss: 98.3185 - false_loss: 0.0977 - true_loss: 1.1735 - val_loss: 6333.9521 - val_reconstruction_loss: 1897.0264 - val_kl_loss: 98.9336 - val_false_loss: 14.0517 - val_true_loss: 1.2249\n",
      "Epoch 744/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.0540 - reconstruction_loss: 1891.1398 - kl_loss: 100.0785 - false_loss: 0.0977 - true_loss: 1.1734 - val_loss: 6333.4238 - val_reconstruction_loss: 1897.0258 - val_kl_loss: 98.9343 - val_false_loss: 14.0500 - val_true_loss: 1.2248\n",
      "Epoch 745/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.1710 - reconstruction_loss: 1891.4912 - kl_loss: 99.7189 - false_loss: 0.0977 - true_loss: 1.1733 - val_loss: 6332.8989 - val_reconstruction_loss: 1897.0250 - val_kl_loss: 98.9347 - val_false_loss: 14.0482 - val_true_loss: 1.2248\n",
      "Epoch 746/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0803 - reconstruction_loss: 1891.4766 - kl_loss: 99.8030 - false_loss: 0.0977 - true_loss: 1.1733 - val_loss: 6332.3691 - val_reconstruction_loss: 1897.0243 - val_kl_loss: 98.9348 - val_false_loss: 14.0465 - val_true_loss: 1.2247\n",
      "Epoch 747/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.1834 - reconstruction_loss: 1891.4375 - kl_loss: 100.5120 - false_loss: 0.0976 - true_loss: 1.1732 - val_loss: 6331.8433 - val_reconstruction_loss: 1897.0236 - val_kl_loss: 98.9359 - val_false_loss: 14.0447 - val_true_loss: 1.2247\n",
      "Epoch 748/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.2600 - reconstruction_loss: 1891.4637 - kl_loss: 99.5896 - false_loss: 0.0976 - true_loss: 1.1731 - val_loss: 6331.3115 - val_reconstruction_loss: 1897.0228 - val_kl_loss: 98.9364 - val_false_loss: 14.0430 - val_true_loss: 1.2246\n",
      "Epoch 749/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.8553 - reconstruction_loss: 1891.9532 - kl_loss: 100.4183 - false_loss: 0.0976 - true_loss: 1.1731 - val_loss: 6330.7837 - val_reconstruction_loss: 1897.0220 - val_kl_loss: 98.9370 - val_false_loss: 14.0412 - val_true_loss: 1.2246\n",
      "Epoch 750/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0550 - reconstruction_loss: 1891.6265 - kl_loss: 99.5015 - false_loss: 0.0976 - true_loss: 1.1730 - val_loss: 6330.2583 - val_reconstruction_loss: 1897.0211 - val_kl_loss: 98.9386 - val_false_loss: 14.0395 - val_true_loss: 1.2245\n",
      "Epoch 751/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.8212 - reconstruction_loss: 1891.5997 - kl_loss: 98.9174 - false_loss: 0.0976 - true_loss: 1.1730 - val_loss: 6329.7378 - val_reconstruction_loss: 1897.0203 - val_kl_loss: 98.9396 - val_false_loss: 14.0378 - val_true_loss: 1.2245\n",
      "Epoch 752/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.1848 - reconstruction_loss: 1891.1631 - kl_loss: 100.1661 - false_loss: 0.0976 - true_loss: 1.1729 - val_loss: 6329.2061 - val_reconstruction_loss: 1897.0195 - val_kl_loss: 98.9408 - val_false_loss: 14.0360 - val_true_loss: 1.2244\n",
      "Epoch 753/2700\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2230.7126 - reconstruction_loss: 1891.1915 - kl_loss: 100.4133 - false_loss: 0.0976 - true_loss: 1.1729 - val_loss: 6328.6753 - val_reconstruction_loss: 1897.0187 - val_kl_loss: 98.9408 - val_false_loss: 14.0343 - val_true_loss: 1.2244\n",
      "Epoch 754/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5075 - reconstruction_loss: 1891.7002 - kl_loss: 100.4555 - false_loss: 0.0976 - true_loss: 1.1728 - val_loss: 6328.1528 - val_reconstruction_loss: 1897.0181 - val_kl_loss: 98.9410 - val_false_loss: 14.0326 - val_true_loss: 1.2243\n",
      "Epoch 755/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.2533 - reconstruction_loss: 1892.0293 - kl_loss: 100.2716 - false_loss: 0.0976 - true_loss: 1.1727 - val_loss: 6327.6367 - val_reconstruction_loss: 1897.0173 - val_kl_loss: 98.9411 - val_false_loss: 14.0309 - val_true_loss: 1.2242\n",
      "Epoch 756/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.4888 - reconstruction_loss: 1891.7856 - kl_loss: 100.3108 - false_loss: 0.0976 - true_loss: 1.1727 - val_loss: 6327.1074 - val_reconstruction_loss: 1897.0166 - val_kl_loss: 98.9417 - val_false_loss: 14.0291 - val_true_loss: 1.2242\n",
      "Epoch 757/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.4423 - reconstruction_loss: 1891.7184 - kl_loss: 100.8617 - false_loss: 0.0975 - true_loss: 1.1726 - val_loss: 6326.5850 - val_reconstruction_loss: 1897.0159 - val_kl_loss: 98.9431 - val_false_loss: 14.0274 - val_true_loss: 1.2241\n",
      "Epoch 758/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.8376 - reconstruction_loss: 1891.7238 - kl_loss: 100.1739 - false_loss: 0.0975 - true_loss: 1.1726 - val_loss: 6326.0591 - val_reconstruction_loss: 1897.0151 - val_kl_loss: 98.9451 - val_false_loss: 14.0257 - val_true_loss: 1.2241\n",
      "Epoch 759/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.7338 - reconstruction_loss: 1891.5656 - kl_loss: 100.5010 - false_loss: 0.0975 - true_loss: 1.1725 - val_loss: 6325.5371 - val_reconstruction_loss: 1897.0144 - val_kl_loss: 98.9456 - val_false_loss: 14.0239 - val_true_loss: 1.2240\n",
      "Epoch 760/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7185 - reconstruction_loss: 1891.1102 - kl_loss: 100.4091 - false_loss: 0.0975 - true_loss: 1.1724 - val_loss: 6325.0229 - val_reconstruction_loss: 1897.0137 - val_kl_loss: 98.9457 - val_false_loss: 14.0222 - val_true_loss: 1.2240\n",
      "Epoch 761/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6566 - reconstruction_loss: 1891.5653 - kl_loss: 99.7275 - false_loss: 0.0975 - true_loss: 1.1724 - val_loss: 6324.5020 - val_reconstruction_loss: 1897.0128 - val_kl_loss: 98.9460 - val_false_loss: 14.0205 - val_true_loss: 1.2239\n",
      "Epoch 762/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5670 - reconstruction_loss: 1891.6361 - kl_loss: 100.0365 - false_loss: 0.0975 - true_loss: 1.1723 - val_loss: 6323.9741 - val_reconstruction_loss: 1897.0122 - val_kl_loss: 98.9460 - val_false_loss: 14.0188 - val_true_loss: 1.2239\n",
      "Epoch 763/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.9313 - reconstruction_loss: 1891.6105 - kl_loss: 100.3644 - false_loss: 0.0975 - true_loss: 1.1723 - val_loss: 6323.4487 - val_reconstruction_loss: 1897.0115 - val_kl_loss: 98.9461 - val_false_loss: 14.0171 - val_true_loss: 1.2238\n",
      "Epoch 764/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5724 - reconstruction_loss: 1891.2373 - kl_loss: 99.7954 - false_loss: 0.0975 - true_loss: 1.1722 - val_loss: 6322.9224 - val_reconstruction_loss: 1897.0107 - val_kl_loss: 98.9467 - val_false_loss: 14.0153 - val_true_loss: 1.2238\n",
      "Epoch 765/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6162 - reconstruction_loss: 1891.6826 - kl_loss: 100.9945 - false_loss: 0.0975 - true_loss: 1.1721 - val_loss: 6322.4033 - val_reconstruction_loss: 1897.0099 - val_kl_loss: 98.9463 - val_false_loss: 14.0136 - val_true_loss: 1.2237\n",
      "Epoch 766/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.6732 - reconstruction_loss: 1891.5651 - kl_loss: 99.9125 - false_loss: 0.0975 - true_loss: 1.1721 - val_loss: 6321.8818 - val_reconstruction_loss: 1897.0094 - val_kl_loss: 98.9457 - val_false_loss: 14.0119 - val_true_loss: 1.2237\n",
      "Epoch 767/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.6703 - reconstruction_loss: 1891.3882 - kl_loss: 100.0941 - false_loss: 0.0975 - true_loss: 1.1720 - val_loss: 6321.3604 - val_reconstruction_loss: 1897.0084 - val_kl_loss: 98.9456 - val_false_loss: 14.0102 - val_true_loss: 1.2236\n",
      "Epoch 768/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.4438 - reconstruction_loss: 1891.0746 - kl_loss: 100.9368 - false_loss: 0.0974 - true_loss: 1.1720 - val_loss: 6320.8359 - val_reconstruction_loss: 1897.0078 - val_kl_loss: 98.9454 - val_false_loss: 14.0084 - val_true_loss: 1.2236\n",
      "Epoch 769/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1498 - reconstruction_loss: 1892.5111 - kl_loss: 100.5086 - false_loss: 0.0974 - true_loss: 1.1719 - val_loss: 6320.3130 - val_reconstruction_loss: 1897.0073 - val_kl_loss: 98.9451 - val_false_loss: 14.0067 - val_true_loss: 1.2235\n",
      "Epoch 770/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.6408 - reconstruction_loss: 1891.2891 - kl_loss: 100.2633 - false_loss: 0.0974 - true_loss: 1.1718 - val_loss: 6319.7925 - val_reconstruction_loss: 1897.0065 - val_kl_loss: 98.9454 - val_false_loss: 14.0050 - val_true_loss: 1.2235\n",
      "Epoch 771/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0965 - reconstruction_loss: 1891.3688 - kl_loss: 99.8820 - false_loss: 0.0974 - true_loss: 1.1718 - val_loss: 6319.2676 - val_reconstruction_loss: 1897.0060 - val_kl_loss: 98.9458 - val_false_loss: 14.0033 - val_true_loss: 1.2234\n",
      "Epoch 772/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.1785 - reconstruction_loss: 1891.7695 - kl_loss: 100.0363 - false_loss: 0.0974 - true_loss: 1.1717 - val_loss: 6318.7451 - val_reconstruction_loss: 1897.0051 - val_kl_loss: 98.9458 - val_false_loss: 14.0015 - val_true_loss: 1.2234\n",
      "Epoch 773/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4472 - reconstruction_loss: 1891.4611 - kl_loss: 100.3925 - false_loss: 0.0974 - true_loss: 1.1717 - val_loss: 6318.2266 - val_reconstruction_loss: 1897.0044 - val_kl_loss: 98.9466 - val_false_loss: 13.9998 - val_true_loss: 1.2233\n",
      "Epoch 774/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.5189 - reconstruction_loss: 1891.2677 - kl_loss: 100.5457 - false_loss: 0.0974 - true_loss: 1.1716 - val_loss: 6317.6992 - val_reconstruction_loss: 1897.0039 - val_kl_loss: 98.9480 - val_false_loss: 13.9981 - val_true_loss: 1.2233\n",
      "Epoch 775/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.0567 - reconstruction_loss: 1891.6293 - kl_loss: 101.3498 - false_loss: 0.0974 - true_loss: 1.1715 - val_loss: 6317.1787 - val_reconstruction_loss: 1897.0031 - val_kl_loss: 98.9488 - val_false_loss: 13.9964 - val_true_loss: 1.2232\n",
      "Epoch 776/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6730 - reconstruction_loss: 1891.3541 - kl_loss: 100.3640 - false_loss: 0.0974 - true_loss: 1.1715 - val_loss: 6316.6528 - val_reconstruction_loss: 1897.0021 - val_kl_loss: 98.9495 - val_false_loss: 13.9946 - val_true_loss: 1.2232\n",
      "Epoch 777/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.7263 - reconstruction_loss: 1891.2037 - kl_loss: 99.9254 - false_loss: 0.0974 - true_loss: 1.1714 - val_loss: 6316.1309 - val_reconstruction_loss: 1897.0015 - val_kl_loss: 98.9496 - val_false_loss: 13.9929 - val_true_loss: 1.2231\n",
      "Epoch 778/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.8950 - reconstruction_loss: 1891.3529 - kl_loss: 100.5640 - false_loss: 0.0974 - true_loss: 1.1714 - val_loss: 6315.6084 - val_reconstruction_loss: 1897.0006 - val_kl_loss: 98.9498 - val_false_loss: 13.9912 - val_true_loss: 1.2231\n",
      "Epoch 779/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8521 - reconstruction_loss: 1891.7100 - kl_loss: 101.0143 - false_loss: 0.0973 - true_loss: 1.1713 - val_loss: 6315.0825 - val_reconstruction_loss: 1897.0000 - val_kl_loss: 98.9501 - val_false_loss: 13.9895 - val_true_loss: 1.2230\n",
      "Epoch 780/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.5293 - reconstruction_loss: 1892.2354 - kl_loss: 100.9539 - false_loss: 0.0973 - true_loss: 1.1712 - val_loss: 6314.5566 - val_reconstruction_loss: 1896.9994 - val_kl_loss: 98.9505 - val_false_loss: 13.9877 - val_true_loss: 1.2230\n",
      "Epoch 781/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2234.0933 - reconstruction_loss: 1891.6484 - kl_loss: 101.1910 - false_loss: 0.0973 - true_loss: 1.1712 - val_loss: 6314.0381 - val_reconstruction_loss: 1896.9985 - val_kl_loss: 98.9502 - val_false_loss: 13.9860 - val_true_loss: 1.2229\n",
      "Epoch 782/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.0880 - reconstruction_loss: 1891.5938 - kl_loss: 100.6187 - false_loss: 0.0973 - true_loss: 1.1711 - val_loss: 6313.5186 - val_reconstruction_loss: 1896.9979 - val_kl_loss: 98.9501 - val_false_loss: 13.9843 - val_true_loss: 1.2229\n",
      "Epoch 783/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.5750 - reconstruction_loss: 1891.4554 - kl_loss: 100.7015 - false_loss: 0.0973 - true_loss: 1.1710 - val_loss: 6312.9956 - val_reconstruction_loss: 1896.9972 - val_kl_loss: 98.9500 - val_false_loss: 13.9826 - val_true_loss: 1.2228\n",
      "Epoch 784/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.8272 - reconstruction_loss: 1891.5361 - kl_loss: 99.9655 - false_loss: 0.0973 - true_loss: 1.1710 - val_loss: 6312.4785 - val_reconstruction_loss: 1896.9966 - val_kl_loss: 98.9503 - val_false_loss: 13.9809 - val_true_loss: 1.2228\n",
      "Epoch 785/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.2312 - reconstruction_loss: 1892.0182 - kl_loss: 100.6560 - false_loss: 0.0973 - true_loss: 1.1709 - val_loss: 6311.9517 - val_reconstruction_loss: 1896.9958 - val_kl_loss: 98.9512 - val_false_loss: 13.9791 - val_true_loss: 1.2227\n",
      "Epoch 786/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.2867 - reconstruction_loss: 1891.5680 - kl_loss: 100.8090 - false_loss: 0.0973 - true_loss: 1.1709 - val_loss: 6311.4297 - val_reconstruction_loss: 1896.9950 - val_kl_loss: 98.9523 - val_false_loss: 13.9774 - val_true_loss: 1.2226\n",
      "Epoch 787/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.6381 - reconstruction_loss: 1891.3335 - kl_loss: 100.6072 - false_loss: 0.0973 - true_loss: 1.1708 - val_loss: 6310.9092 - val_reconstruction_loss: 1896.9944 - val_kl_loss: 98.9536 - val_false_loss: 13.9757 - val_true_loss: 1.2226\n",
      "Epoch 788/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.5144 - reconstruction_loss: 1891.6396 - kl_loss: 100.6531 - false_loss: 0.0973 - true_loss: 1.1707 - val_loss: 6310.3853 - val_reconstruction_loss: 1896.9935 - val_kl_loss: 98.9552 - val_false_loss: 13.9740 - val_true_loss: 1.2225\n",
      "Epoch 789/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.6797 - reconstruction_loss: 1891.0928 - kl_loss: 100.9632 - false_loss: 0.0973 - true_loss: 1.1707 - val_loss: 6309.8755 - val_reconstruction_loss: 1896.9927 - val_kl_loss: 98.9562 - val_false_loss: 13.9723 - val_true_loss: 1.2225\n",
      "Epoch 790/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.6924 - reconstruction_loss: 1891.1733 - kl_loss: 101.5031 - false_loss: 0.0972 - true_loss: 1.1706 - val_loss: 6309.3530 - val_reconstruction_loss: 1896.9919 - val_kl_loss: 98.9567 - val_false_loss: 13.9706 - val_true_loss: 1.2224\n",
      "Epoch 791/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.9053 - reconstruction_loss: 1891.1149 - kl_loss: 100.8863 - false_loss: 0.0972 - true_loss: 1.1706 - val_loss: 6308.8296 - val_reconstruction_loss: 1896.9911 - val_kl_loss: 98.9575 - val_false_loss: 13.9688 - val_true_loss: 1.2224\n",
      "Epoch 792/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6925 - reconstruction_loss: 1891.3353 - kl_loss: 100.6417 - false_loss: 0.0972 - true_loss: 1.1705 - val_loss: 6308.3066 - val_reconstruction_loss: 1896.9905 - val_kl_loss: 98.9591 - val_false_loss: 13.9671 - val_true_loss: 1.2223\n",
      "Epoch 793/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.9493 - reconstruction_loss: 1891.4886 - kl_loss: 101.0228 - false_loss: 0.0972 - true_loss: 1.1704 - val_loss: 6307.7900 - val_reconstruction_loss: 1896.9899 - val_kl_loss: 98.9593 - val_false_loss: 13.9654 - val_true_loss: 1.2223\n",
      "Epoch 794/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0528 - reconstruction_loss: 1892.0248 - kl_loss: 100.6994 - false_loss: 0.0972 - true_loss: 1.1704 - val_loss: 6307.2739 - val_reconstruction_loss: 1896.9890 - val_kl_loss: 98.9595 - val_false_loss: 13.9637 - val_true_loss: 1.2222\n",
      "Epoch 795/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.0550 - reconstruction_loss: 1891.4122 - kl_loss: 101.2781 - false_loss: 0.0972 - true_loss: 1.1703 - val_loss: 6306.7568 - val_reconstruction_loss: 1896.9882 - val_kl_loss: 98.9591 - val_false_loss: 13.9620 - val_true_loss: 1.2222\n",
      "Epoch 796/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7964 - reconstruction_loss: 1891.4052 - kl_loss: 100.6865 - false_loss: 0.0972 - true_loss: 1.1703 - val_loss: 6306.2344 - val_reconstruction_loss: 1896.9878 - val_kl_loss: 98.9597 - val_false_loss: 13.9603 - val_true_loss: 1.2221\n",
      "Epoch 797/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.8953 - reconstruction_loss: 1891.4707 - kl_loss: 100.6644 - false_loss: 0.0972 - true_loss: 1.1702 - val_loss: 6305.7144 - val_reconstruction_loss: 1896.9869 - val_kl_loss: 98.9609 - val_false_loss: 13.9586 - val_true_loss: 1.2221\n",
      "Epoch 798/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.3430 - reconstruction_loss: 1891.6205 - kl_loss: 100.8409 - false_loss: 0.0972 - true_loss: 1.1701 - val_loss: 6305.2002 - val_reconstruction_loss: 1896.9861 - val_kl_loss: 98.9617 - val_false_loss: 13.9569 - val_true_loss: 1.2220\n",
      "Epoch 799/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.9671 - reconstruction_loss: 1891.6927 - kl_loss: 100.6369 - false_loss: 0.0972 - true_loss: 1.1701 - val_loss: 6304.6782 - val_reconstruction_loss: 1896.9854 - val_kl_loss: 98.9632 - val_false_loss: 13.9551 - val_true_loss: 1.2220\n",
      "Epoch 800/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.6441 - reconstruction_loss: 1891.8651 - kl_loss: 100.7830 - false_loss: 0.0971 - true_loss: 1.1700 - val_loss: 6304.1621 - val_reconstruction_loss: 1896.9846 - val_kl_loss: 98.9639 - val_false_loss: 13.9534 - val_true_loss: 1.2219\n",
      "Epoch 801/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.0740 - reconstruction_loss: 1891.3356 - kl_loss: 100.2741 - false_loss: 0.0971 - true_loss: 1.1699 - val_loss: 6303.6567 - val_reconstruction_loss: 1896.9840 - val_kl_loss: 98.9652 - val_false_loss: 13.9518 - val_true_loss: 1.2218\n",
      "Epoch 802/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.7831 - reconstruction_loss: 1891.5219 - kl_loss: 101.2434 - false_loss: 0.0971 - true_loss: 1.1699 - val_loss: 6303.1362 - val_reconstruction_loss: 1896.9833 - val_kl_loss: 98.9662 - val_false_loss: 13.9501 - val_true_loss: 1.2218\n",
      "Epoch 803/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8104 - reconstruction_loss: 1891.0211 - kl_loss: 100.9412 - false_loss: 0.0971 - true_loss: 1.1698 - val_loss: 6302.6167 - val_reconstruction_loss: 1896.9825 - val_kl_loss: 98.9661 - val_false_loss: 13.9483 - val_true_loss: 1.2217\n",
      "Epoch 804/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0519 - reconstruction_loss: 1891.0811 - kl_loss: 101.2229 - false_loss: 0.0971 - true_loss: 1.1698 - val_loss: 6302.0933 - val_reconstruction_loss: 1896.9818 - val_kl_loss: 98.9664 - val_false_loss: 13.9466 - val_true_loss: 1.2217\n",
      "Epoch 805/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.0590 - reconstruction_loss: 1891.2286 - kl_loss: 100.4862 - false_loss: 0.0971 - true_loss: 1.1697 - val_loss: 6301.5723 - val_reconstruction_loss: 1896.9812 - val_kl_loss: 98.9672 - val_false_loss: 13.9449 - val_true_loss: 1.2216\n",
      "Epoch 806/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.2935 - reconstruction_loss: 1891.2977 - kl_loss: 100.8684 - false_loss: 0.0971 - true_loss: 1.1696 - val_loss: 6301.0601 - val_reconstruction_loss: 1896.9803 - val_kl_loss: 98.9681 - val_false_loss: 13.9432 - val_true_loss: 1.2216\n",
      "Epoch 807/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.8253 - reconstruction_loss: 1891.5812 - kl_loss: 100.7632 - false_loss: 0.0971 - true_loss: 1.1696 - val_loss: 6300.5420 - val_reconstruction_loss: 1896.9795 - val_kl_loss: 98.9697 - val_false_loss: 13.9415 - val_true_loss: 1.2215\n",
      "Epoch 808/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.2084 - reconstruction_loss: 1891.4479 - kl_loss: 101.2813 - false_loss: 0.0971 - true_loss: 1.1695 - val_loss: 6300.0278 - val_reconstruction_loss: 1896.9788 - val_kl_loss: 98.9706 - val_false_loss: 13.9398 - val_true_loss: 1.2215\n",
      "Epoch 809/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.9721 - reconstruction_loss: 1891.3148 - kl_loss: 100.4282 - false_loss: 0.0971 - true_loss: 1.1695 - val_loss: 6299.5020 - val_reconstruction_loss: 1896.9781 - val_kl_loss: 98.9715 - val_false_loss: 13.9381 - val_true_loss: 1.2214\n",
      "Epoch 810/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.6612 - reconstruction_loss: 1891.1621 - kl_loss: 100.7089 - false_loss: 0.0971 - true_loss: 1.1694 - val_loss: 6298.9844 - val_reconstruction_loss: 1896.9773 - val_kl_loss: 98.9711 - val_false_loss: 13.9364 - val_true_loss: 1.2214\n",
      "Epoch 811/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.3655 - reconstruction_loss: 1891.2826 - kl_loss: 99.8216 - false_loss: 0.0970 - true_loss: 1.1693 - val_loss: 6298.4731 - val_reconstruction_loss: 1896.9767 - val_kl_loss: 98.9716 - val_false_loss: 13.9347 - val_true_loss: 1.2213\n",
      "Epoch 812/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.8703 - reconstruction_loss: 1890.9707 - kl_loss: 99.8389 - false_loss: 0.0970 - true_loss: 1.1693 - val_loss: 6297.9556 - val_reconstruction_loss: 1896.9761 - val_kl_loss: 98.9730 - val_false_loss: 13.9330 - val_true_loss: 1.2213\n",
      "Epoch 813/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2258.9488 - reconstruction_loss: 1891.6953 - kl_loss: 100.1561 - false_loss: 0.0970 - true_loss: 1.1692 - val_loss: 6297.4404 - val_reconstruction_loss: 1896.9752 - val_kl_loss: 98.9734 - val_false_loss: 13.9312 - val_true_loss: 1.2212\n",
      "Epoch 814/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.8231 - reconstruction_loss: 1892.0482 - kl_loss: 98.6227 - false_loss: 0.0970 - true_loss: 1.1692 - val_loss: 6296.9248 - val_reconstruction_loss: 1896.9746 - val_kl_loss: 98.9727 - val_false_loss: 13.9295 - val_true_loss: 1.2212\n",
      "Epoch 815/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.3192 - reconstruction_loss: 1891.3916 - kl_loss: 98.5915 - false_loss: 0.0970 - true_loss: 1.1691 - val_loss: 6296.4102 - val_reconstruction_loss: 1896.9739 - val_kl_loss: 98.9719 - val_false_loss: 13.9279 - val_true_loss: 1.2211\n",
      "Epoch 816/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.6978 - reconstruction_loss: 1891.3864 - kl_loss: 97.4157 - false_loss: 0.0970 - true_loss: 1.1691 - val_loss: 6295.8945 - val_reconstruction_loss: 1896.9731 - val_kl_loss: 98.9735 - val_false_loss: 13.9261 - val_true_loss: 1.2211\n",
      "Epoch 817/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.9299 - reconstruction_loss: 1892.2155 - kl_loss: 100.2323 - false_loss: 0.0970 - true_loss: 1.1690 - val_loss: 6295.3760 - val_reconstruction_loss: 1896.9725 - val_kl_loss: 98.9726 - val_false_loss: 13.9244 - val_true_loss: 1.2211\n",
      "Epoch 818/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.1302 - reconstruction_loss: 1891.9518 - kl_loss: 97.8148 - false_loss: 0.0970 - true_loss: 1.1690 - val_loss: 6294.8574 - val_reconstruction_loss: 1896.9718 - val_kl_loss: 98.9722 - val_false_loss: 13.9227 - val_true_loss: 1.2210\n",
      "Epoch 819/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5765 - reconstruction_loss: 1891.3221 - kl_loss: 97.8012 - false_loss: 0.0970 - true_loss: 1.1689 - val_loss: 6294.3413 - val_reconstruction_loss: 1896.9709 - val_kl_loss: 98.9721 - val_false_loss: 13.9210 - val_true_loss: 1.2210\n",
      "Epoch 820/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.3784 - reconstruction_loss: 1891.2816 - kl_loss: 98.9494 - false_loss: 0.0970 - true_loss: 1.1689 - val_loss: 6293.8193 - val_reconstruction_loss: 1896.9705 - val_kl_loss: 98.9708 - val_false_loss: 13.9193 - val_true_loss: 1.2209\n",
      "Epoch 821/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.0312 - reconstruction_loss: 1891.2784 - kl_loss: 99.0939 - false_loss: 0.0970 - true_loss: 1.1688 - val_loss: 6293.2964 - val_reconstruction_loss: 1896.9696 - val_kl_loss: 98.9705 - val_false_loss: 13.9176 - val_true_loss: 1.2209\n",
      "Epoch 822/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.5940 - reconstruction_loss: 1891.0547 - kl_loss: 98.7909 - false_loss: 0.0969 - true_loss: 1.1688 - val_loss: 6292.7803 - val_reconstruction_loss: 1896.9689 - val_kl_loss: 98.9713 - val_false_loss: 13.9159 - val_true_loss: 1.2208\n",
      "Epoch 823/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.5734 - reconstruction_loss: 1890.9103 - kl_loss: 98.9771 - false_loss: 0.0969 - true_loss: 1.1687 - val_loss: 6292.2617 - val_reconstruction_loss: 1896.9680 - val_kl_loss: 98.9716 - val_false_loss: 13.9142 - val_true_loss: 1.2208\n",
      "Epoch 824/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.7664 - reconstruction_loss: 1891.0992 - kl_loss: 99.5177 - false_loss: 0.0969 - true_loss: 1.1686 - val_loss: 6291.7422 - val_reconstruction_loss: 1896.9674 - val_kl_loss: 98.9722 - val_false_loss: 13.9125 - val_true_loss: 1.2207\n",
      "Epoch 825/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.5584 - reconstruction_loss: 1891.2158 - kl_loss: 99.5291 - false_loss: 0.0969 - true_loss: 1.1686 - val_loss: 6291.2275 - val_reconstruction_loss: 1896.9666 - val_kl_loss: 98.9729 - val_false_loss: 13.9108 - val_true_loss: 1.2206\n",
      "Epoch 826/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.9452 - reconstruction_loss: 1891.4633 - kl_loss: 99.9201 - false_loss: 0.0969 - true_loss: 1.1685 - val_loss: 6290.7065 - val_reconstruction_loss: 1896.9658 - val_kl_loss: 98.9744 - val_false_loss: 13.9090 - val_true_loss: 1.2206\n",
      "Epoch 827/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.1816 - reconstruction_loss: 1891.3544 - kl_loss: 99.4927 - false_loss: 0.0969 - true_loss: 1.1685 - val_loss: 6290.1958 - val_reconstruction_loss: 1896.9652 - val_kl_loss: 98.9761 - val_false_loss: 13.9074 - val_true_loss: 1.2205\n",
      "Epoch 828/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7131 - reconstruction_loss: 1891.5758 - kl_loss: 100.2736 - false_loss: 0.0969 - true_loss: 1.1684 - val_loss: 6289.6777 - val_reconstruction_loss: 1896.9645 - val_kl_loss: 98.9776 - val_false_loss: 13.9056 - val_true_loss: 1.2205\n",
      "Epoch 829/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.0670 - reconstruction_loss: 1891.2054 - kl_loss: 100.1422 - false_loss: 0.0969 - true_loss: 1.1683 - val_loss: 6289.1650 - val_reconstruction_loss: 1896.9635 - val_kl_loss: 98.9776 - val_false_loss: 13.9040 - val_true_loss: 1.2204\n",
      "Epoch 830/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.0060 - reconstruction_loss: 1891.5547 - kl_loss: 100.4417 - false_loss: 0.0969 - true_loss: 1.1683 - val_loss: 6288.6558 - val_reconstruction_loss: 1896.9628 - val_kl_loss: 98.9771 - val_false_loss: 13.9023 - val_true_loss: 1.2204\n",
      "Epoch 831/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8398 - reconstruction_loss: 1891.7592 - kl_loss: 99.5648 - false_loss: 0.0969 - true_loss: 1.1682 - val_loss: 6288.1436 - val_reconstruction_loss: 1896.9623 - val_kl_loss: 98.9773 - val_false_loss: 13.9006 - val_true_loss: 1.2203\n",
      "Epoch 832/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.8970 - reconstruction_loss: 1891.1758 - kl_loss: 101.0280 - false_loss: 0.0969 - true_loss: 1.1682 - val_loss: 6287.6250 - val_reconstruction_loss: 1896.9615 - val_kl_loss: 98.9771 - val_false_loss: 13.8989 - val_true_loss: 1.2203\n",
      "Epoch 833/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2229.4289 - reconstruction_loss: 1891.2826 - kl_loss: 100.3789 - false_loss: 0.0968 - true_loss: 1.1681 - val_loss: 6287.1074 - val_reconstruction_loss: 1896.9607 - val_kl_loss: 98.9776 - val_false_loss: 13.8972 - val_true_loss: 1.2202\n",
      "Epoch 834/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.9774 - reconstruction_loss: 1891.3405 - kl_loss: 100.8110 - false_loss: 0.0968 - true_loss: 1.1680 - val_loss: 6286.5908 - val_reconstruction_loss: 1896.9598 - val_kl_loss: 98.9790 - val_false_loss: 13.8955 - val_true_loss: 1.2202\n",
      "Epoch 835/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7787 - reconstruction_loss: 1891.4493 - kl_loss: 100.8759 - false_loss: 0.0968 - true_loss: 1.1680 - val_loss: 6286.0806 - val_reconstruction_loss: 1896.9592 - val_kl_loss: 98.9805 - val_false_loss: 13.8938 - val_true_loss: 1.2201\n",
      "Epoch 836/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.1718 - reconstruction_loss: 1891.3678 - kl_loss: 101.1796 - false_loss: 0.0968 - true_loss: 1.1679 - val_loss: 6285.5801 - val_reconstruction_loss: 1896.9586 - val_kl_loss: 98.9815 - val_false_loss: 13.8921 - val_true_loss: 1.2201\n",
      "Epoch 837/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0570 - reconstruction_loss: 1891.8014 - kl_loss: 100.7989 - false_loss: 0.0968 - true_loss: 1.1679 - val_loss: 6285.0684 - val_reconstruction_loss: 1896.9579 - val_kl_loss: 98.9835 - val_false_loss: 13.8904 - val_true_loss: 1.2200\n",
      "Epoch 838/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.7746 - reconstruction_loss: 1891.6167 - kl_loss: 101.3770 - false_loss: 0.0968 - true_loss: 1.1678 - val_loss: 6284.5591 - val_reconstruction_loss: 1896.9570 - val_kl_loss: 98.9841 - val_false_loss: 13.8888 - val_true_loss: 1.2200\n",
      "Epoch 839/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5448 - reconstruction_loss: 1891.1699 - kl_loss: 100.5195 - false_loss: 0.0968 - true_loss: 1.1677 - val_loss: 6284.0366 - val_reconstruction_loss: 1896.9564 - val_kl_loss: 98.9848 - val_false_loss: 13.8870 - val_true_loss: 1.2199\n",
      "Epoch 840/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.8837 - reconstruction_loss: 1891.2671 - kl_loss: 100.3655 - false_loss: 0.0968 - true_loss: 1.1677 - val_loss: 6283.5225 - val_reconstruction_loss: 1896.9558 - val_kl_loss: 98.9856 - val_false_loss: 13.8853 - val_true_loss: 1.2199\n",
      "Epoch 841/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1631 - reconstruction_loss: 1890.9781 - kl_loss: 101.1148 - false_loss: 0.0968 - true_loss: 1.1676 - val_loss: 6283.0078 - val_reconstruction_loss: 1896.9550 - val_kl_loss: 98.9867 - val_false_loss: 13.8836 - val_true_loss: 1.2198\n",
      "Epoch 842/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.2461 - reconstruction_loss: 1891.7672 - kl_loss: 100.7874 - false_loss: 0.0968 - true_loss: 1.1676 - val_loss: 6282.4897 - val_reconstruction_loss: 1896.9542 - val_kl_loss: 98.9878 - val_false_loss: 13.8819 - val_true_loss: 1.2197\n",
      "Epoch 843/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1385 - reconstruction_loss: 1891.5629 - kl_loss: 100.9907 - false_loss: 0.0968 - true_loss: 1.1675 - val_loss: 6281.9746 - val_reconstruction_loss: 1896.9534 - val_kl_loss: 98.9886 - val_false_loss: 13.8802 - val_true_loss: 1.2197\n",
      "Epoch 844/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.3337 - reconstruction_loss: 1891.0167 - kl_loss: 99.9840 - false_loss: 0.0967 - true_loss: 1.1674 - val_loss: 6281.4634 - val_reconstruction_loss: 1896.9526 - val_kl_loss: 98.9899 - val_false_loss: 13.8785 - val_true_loss: 1.2196\n",
      "Epoch 845/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.6949 - reconstruction_loss: 1891.7142 - kl_loss: 101.6610 - false_loss: 0.0967 - true_loss: 1.1674 - val_loss: 6280.9458 - val_reconstruction_loss: 1896.9518 - val_kl_loss: 98.9903 - val_false_loss: 13.8768 - val_true_loss: 1.2196\n",
      "Epoch 846/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0059 - reconstruction_loss: 1891.2877 - kl_loss: 100.3186 - false_loss: 0.0967 - true_loss: 1.1673 - val_loss: 6280.4312 - val_reconstruction_loss: 1896.9512 - val_kl_loss: 98.9906 - val_false_loss: 13.8751 - val_true_loss: 1.2195\n",
      "Epoch 847/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.3667 - reconstruction_loss: 1891.1400 - kl_loss: 101.0016 - false_loss: 0.0967 - true_loss: 1.1673 - val_loss: 6279.9170 - val_reconstruction_loss: 1896.9506 - val_kl_loss: 98.9905 - val_false_loss: 13.8734 - val_true_loss: 1.2195\n",
      "Epoch 848/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.7660 - reconstruction_loss: 1891.7416 - kl_loss: 100.2171 - false_loss: 0.0967 - true_loss: 1.1672 - val_loss: 6279.4048 - val_reconstruction_loss: 1896.9497 - val_kl_loss: 98.9905 - val_false_loss: 13.8718 - val_true_loss: 1.2194\n",
      "Epoch 849/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.5989 - reconstruction_loss: 1891.1354 - kl_loss: 100.8074 - false_loss: 0.0967 - true_loss: 1.1671 - val_loss: 6278.8882 - val_reconstruction_loss: 1896.9490 - val_kl_loss: 98.9906 - val_false_loss: 13.8701 - val_true_loss: 1.2194\n",
      "Epoch 850/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.7969 - reconstruction_loss: 1891.2480 - kl_loss: 100.3735 - false_loss: 0.0967 - true_loss: 1.1671 - val_loss: 6278.3867 - val_reconstruction_loss: 1896.9485 - val_kl_loss: 98.9904 - val_false_loss: 13.8684 - val_true_loss: 1.2193\n",
      "Epoch 851/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.1037 - reconstruction_loss: 1891.2377 - kl_loss: 99.9378 - false_loss: 0.0967 - true_loss: 1.1670 - val_loss: 6277.8730 - val_reconstruction_loss: 1896.9476 - val_kl_loss: 98.9902 - val_false_loss: 13.8667 - val_true_loss: 1.2193\n",
      "Epoch 852/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.9318 - reconstruction_loss: 1891.5375 - kl_loss: 100.8564 - false_loss: 0.0967 - true_loss: 1.1670 - val_loss: 6277.3628 - val_reconstruction_loss: 1896.9469 - val_kl_loss: 98.9901 - val_false_loss: 13.8650 - val_true_loss: 1.2192\n",
      "Epoch 853/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.4624 - reconstruction_loss: 1891.4589 - kl_loss: 99.6361 - false_loss: 0.0967 - true_loss: 1.1669 - val_loss: 6276.8608 - val_reconstruction_loss: 1896.9463 - val_kl_loss: 98.9909 - val_false_loss: 13.8634 - val_true_loss: 1.2192\n",
      "Epoch 854/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.6891 - reconstruction_loss: 1891.3813 - kl_loss: 100.9573 - false_loss: 0.0967 - true_loss: 1.1668 - val_loss: 6276.3486 - val_reconstruction_loss: 1896.9457 - val_kl_loss: 98.9915 - val_false_loss: 13.8617 - val_true_loss: 1.2191\n",
      "Epoch 855/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.6042 - reconstruction_loss: 1891.3590 - kl_loss: 101.1476 - false_loss: 0.0966 - true_loss: 1.1668 - val_loss: 6275.8413 - val_reconstruction_loss: 1896.9448 - val_kl_loss: 98.9921 - val_false_loss: 13.8600 - val_true_loss: 1.2191\n",
      "Epoch 856/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.9949 - reconstruction_loss: 1891.0474 - kl_loss: 100.6153 - false_loss: 0.0966 - true_loss: 1.1667 - val_loss: 6275.3325 - val_reconstruction_loss: 1896.9441 - val_kl_loss: 98.9923 - val_false_loss: 13.8583 - val_true_loss: 1.2190\n",
      "Epoch 857/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.5283 - reconstruction_loss: 1890.8369 - kl_loss: 100.4271 - false_loss: 0.0966 - true_loss: 1.1667 - val_loss: 6274.8271 - val_reconstruction_loss: 1896.9436 - val_kl_loss: 98.9927 - val_false_loss: 13.8567 - val_true_loss: 1.2190\n",
      "Epoch 858/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3065 - reconstruction_loss: 1890.8364 - kl_loss: 99.9100 - false_loss: 0.0966 - true_loss: 1.1666 - val_loss: 6274.3086 - val_reconstruction_loss: 1896.9427 - val_kl_loss: 98.9932 - val_false_loss: 13.8550 - val_true_loss: 1.2189\n",
      "Epoch 859/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0442 - reconstruction_loss: 1891.6138 - kl_loss: 100.3908 - false_loss: 0.0966 - true_loss: 1.1665 - val_loss: 6273.7954 - val_reconstruction_loss: 1896.9420 - val_kl_loss: 98.9938 - val_false_loss: 13.8533 - val_true_loss: 1.2188\n",
      "Epoch 860/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.2147 - reconstruction_loss: 1891.5988 - kl_loss: 99.7500 - false_loss: 0.0966 - true_loss: 1.1665 - val_loss: 6273.2871 - val_reconstruction_loss: 1896.9410 - val_kl_loss: 98.9938 - val_false_loss: 13.8516 - val_true_loss: 1.2188\n",
      "Epoch 861/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.0584 - reconstruction_loss: 1891.3339 - kl_loss: 100.7026 - false_loss: 0.0966 - true_loss: 1.1664 - val_loss: 6272.7788 - val_reconstruction_loss: 1896.9404 - val_kl_loss: 98.9942 - val_false_loss: 13.8499 - val_true_loss: 1.2187\n",
      "Epoch 862/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.2964 - reconstruction_loss: 1891.0951 - kl_loss: 100.4848 - false_loss: 0.0966 - true_loss: 1.1664 - val_loss: 6272.2720 - val_reconstruction_loss: 1896.9398 - val_kl_loss: 98.9947 - val_false_loss: 13.8483 - val_true_loss: 1.2187\n",
      "Epoch 863/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.3998 - reconstruction_loss: 1890.9803 - kl_loss: 100.7020 - false_loss: 0.0966 - true_loss: 1.1663 - val_loss: 6271.7598 - val_reconstruction_loss: 1896.9388 - val_kl_loss: 98.9959 - val_false_loss: 13.8466 - val_true_loss: 1.2186\n",
      "Epoch 864/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.5528 - reconstruction_loss: 1891.4189 - kl_loss: 100.7814 - false_loss: 0.0966 - true_loss: 1.1662 - val_loss: 6271.2495 - val_reconstruction_loss: 1896.9384 - val_kl_loss: 98.9965 - val_false_loss: 13.8449 - val_true_loss: 1.2186\n",
      "Epoch 865/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.6804 - reconstruction_loss: 1891.6840 - kl_loss: 101.2560 - false_loss: 0.0966 - true_loss: 1.1662 - val_loss: 6270.7358 - val_reconstruction_loss: 1896.9376 - val_kl_loss: 98.9965 - val_false_loss: 13.8432 - val_true_loss: 1.2185\n",
      "Epoch 866/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.2803 - reconstruction_loss: 1891.3315 - kl_loss: 101.5622 - false_loss: 0.0965 - true_loss: 1.1661 - val_loss: 6270.2334 - val_reconstruction_loss: 1896.9368 - val_kl_loss: 98.9958 - val_false_loss: 13.8415 - val_true_loss: 1.2185\n",
      "Epoch 867/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.3847 - reconstruction_loss: 1891.3496 - kl_loss: 100.0781 - false_loss: 0.0965 - true_loss: 1.1661 - val_loss: 6269.7275 - val_reconstruction_loss: 1896.9365 - val_kl_loss: 98.9958 - val_false_loss: 13.8399 - val_true_loss: 1.2184\n",
      "Epoch 868/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.8340 - reconstruction_loss: 1891.8560 - kl_loss: 100.1292 - false_loss: 0.0965 - true_loss: 1.1660 - val_loss: 6269.2178 - val_reconstruction_loss: 1896.9357 - val_kl_loss: 98.9957 - val_false_loss: 13.8382 - val_true_loss: 1.2184\n",
      "Epoch 869/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.3503 - reconstruction_loss: 1891.7875 - kl_loss: 100.2261 - false_loss: 0.0965 - true_loss: 1.1659 - val_loss: 6268.7075 - val_reconstruction_loss: 1896.9349 - val_kl_loss: 98.9965 - val_false_loss: 13.8365 - val_true_loss: 1.2183\n",
      "Epoch 870/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.2976 - reconstruction_loss: 1891.1488 - kl_loss: 100.6291 - false_loss: 0.0965 - true_loss: 1.1659 - val_loss: 6268.1958 - val_reconstruction_loss: 1896.9343 - val_kl_loss: 98.9968 - val_false_loss: 13.8348 - val_true_loss: 1.2183\n",
      "Epoch 871/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.2449 - reconstruction_loss: 1890.8804 - kl_loss: 99.5639 - false_loss: 0.0965 - true_loss: 1.1658 - val_loss: 6267.6812 - val_reconstruction_loss: 1896.9335 - val_kl_loss: 98.9969 - val_false_loss: 13.8331 - val_true_loss: 1.2182\n",
      "Epoch 872/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.5196 - reconstruction_loss: 1891.6359 - kl_loss: 100.1885 - false_loss: 0.0965 - true_loss: 1.1658 - val_loss: 6267.1646 - val_reconstruction_loss: 1896.9330 - val_kl_loss: 98.9969 - val_false_loss: 13.8314 - val_true_loss: 1.2182\n",
      "Epoch 873/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0569 - reconstruction_loss: 1891.7378 - kl_loss: 100.1477 - false_loss: 0.0965 - true_loss: 1.1657 - val_loss: 6266.6602 - val_reconstruction_loss: 1896.9323 - val_kl_loss: 98.9976 - val_false_loss: 13.8298 - val_true_loss: 1.2181\n",
      "Epoch 874/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8481 - reconstruction_loss: 1891.5773 - kl_loss: 100.1328 - false_loss: 0.0965 - true_loss: 1.1656 - val_loss: 6266.1484 - val_reconstruction_loss: 1896.9315 - val_kl_loss: 98.9981 - val_false_loss: 13.8281 - val_true_loss: 1.2181\n",
      "Epoch 875/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.5869 - reconstruction_loss: 1891.9131 - kl_loss: 100.6446 - false_loss: 0.0965 - true_loss: 1.1656 - val_loss: 6265.6421 - val_reconstruction_loss: 1896.9307 - val_kl_loss: 98.9979 - val_false_loss: 13.8264 - val_true_loss: 1.2180\n",
      "Epoch 876/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.5170 - reconstruction_loss: 1891.2938 - kl_loss: 100.4063 - false_loss: 0.0965 - true_loss: 1.1655 - val_loss: 6265.1353 - val_reconstruction_loss: 1896.9301 - val_kl_loss: 98.9985 - val_false_loss: 13.8247 - val_true_loss: 1.2180\n",
      "Epoch 877/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.4988 - reconstruction_loss: 1891.2845 - kl_loss: 98.4889 - false_loss: 0.0964 - true_loss: 1.1655 - val_loss: 6264.6270 - val_reconstruction_loss: 1896.9293 - val_kl_loss: 98.9987 - val_false_loss: 13.8230 - val_true_loss: 1.2179\n",
      "Epoch 878/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.5521 - reconstruction_loss: 1890.9503 - kl_loss: 99.2570 - false_loss: 0.0964 - true_loss: 1.1654 - val_loss: 6264.1250 - val_reconstruction_loss: 1896.9286 - val_kl_loss: 98.9996 - val_false_loss: 13.8214 - val_true_loss: 1.2179\n",
      "Epoch 879/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.9393 - reconstruction_loss: 1890.7894 - kl_loss: 99.3172 - false_loss: 0.0964 - true_loss: 1.1654 - val_loss: 6263.6113 - val_reconstruction_loss: 1896.9279 - val_kl_loss: 99.0007 - val_false_loss: 13.8197 - val_true_loss: 1.2178\n",
      "Epoch 880/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.7094 - reconstruction_loss: 1891.2123 - kl_loss: 99.9425 - false_loss: 0.0964 - true_loss: 1.1653 - val_loss: 6263.1094 - val_reconstruction_loss: 1896.9271 - val_kl_loss: 99.0025 - val_false_loss: 13.8180 - val_true_loss: 1.2178\n",
      "Epoch 881/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.3483 - reconstruction_loss: 1891.0854 - kl_loss: 99.6798 - false_loss: 0.0964 - true_loss: 1.1653 - val_loss: 6262.5981 - val_reconstruction_loss: 1896.9263 - val_kl_loss: 99.0022 - val_false_loss: 13.8163 - val_true_loss: 1.2178\n",
      "Epoch 882/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.5151 - reconstruction_loss: 1890.7611 - kl_loss: 99.3350 - false_loss: 0.0964 - true_loss: 1.1652 - val_loss: 6262.0908 - val_reconstruction_loss: 1896.9255 - val_kl_loss: 99.0021 - val_false_loss: 13.8147 - val_true_loss: 1.2177\n",
      "Epoch 883/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.2370 - reconstruction_loss: 1890.9357 - kl_loss: 99.7765 - false_loss: 0.0964 - true_loss: 1.1651 - val_loss: 6261.5791 - val_reconstruction_loss: 1896.9250 - val_kl_loss: 99.0023 - val_false_loss: 13.8130 - val_true_loss: 1.2176\n",
      "Epoch 884/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.2134 - reconstruction_loss: 1891.3549 - kl_loss: 99.6259 - false_loss: 0.0964 - true_loss: 1.1651 - val_loss: 6261.0771 - val_reconstruction_loss: 1896.9241 - val_kl_loss: 99.0022 - val_false_loss: 13.8113 - val_true_loss: 1.2176\n",
      "Epoch 885/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2235.0945 - reconstruction_loss: 1891.1298 - kl_loss: 100.4285 - false_loss: 0.0964 - true_loss: 1.1650 - val_loss: 6260.5786 - val_reconstruction_loss: 1896.9235 - val_kl_loss: 99.0018 - val_false_loss: 13.8097 - val_true_loss: 1.2175\n",
      "Epoch 886/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.1595 - reconstruction_loss: 1891.5601 - kl_loss: 100.3684 - false_loss: 0.0964 - true_loss: 1.1650 - val_loss: 6260.0718 - val_reconstruction_loss: 1896.9229 - val_kl_loss: 99.0021 - val_false_loss: 13.8080 - val_true_loss: 1.2175\n",
      "Epoch 887/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.3700 - reconstruction_loss: 1891.6576 - kl_loss: 100.3276 - false_loss: 0.0964 - true_loss: 1.1649 - val_loss: 6259.5693 - val_reconstruction_loss: 1896.9221 - val_kl_loss: 99.0020 - val_false_loss: 13.8064 - val_true_loss: 1.2174\n",
      "Epoch 888/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0389 - reconstruction_loss: 1891.0931 - kl_loss: 99.6046 - false_loss: 0.0963 - true_loss: 1.1649 - val_loss: 6259.0654 - val_reconstruction_loss: 1896.9214 - val_kl_loss: 99.0019 - val_false_loss: 13.8047 - val_true_loss: 1.2174\n",
      "Epoch 889/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.1148 - reconstruction_loss: 1891.0983 - kl_loss: 99.6330 - false_loss: 0.0963 - true_loss: 1.1648 - val_loss: 6258.5605 - val_reconstruction_loss: 1896.9207 - val_kl_loss: 99.0020 - val_false_loss: 13.8030 - val_true_loss: 1.2173\n",
      "Epoch 890/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.5864 - reconstruction_loss: 1890.8646 - kl_loss: 100.5041 - false_loss: 0.0963 - true_loss: 1.1647 - val_loss: 6258.0522 - val_reconstruction_loss: 1896.9200 - val_kl_loss: 99.0020 - val_false_loss: 13.8014 - val_true_loss: 1.2173\n",
      "Epoch 891/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.8796 - reconstruction_loss: 1891.9037 - kl_loss: 100.5562 - false_loss: 0.0963 - true_loss: 1.1647 - val_loss: 6257.5493 - val_reconstruction_loss: 1896.9192 - val_kl_loss: 99.0017 - val_false_loss: 13.7997 - val_true_loss: 1.2172\n",
      "Epoch 892/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.5180 - reconstruction_loss: 1891.6273 - kl_loss: 100.2730 - false_loss: 0.0963 - true_loss: 1.1646 - val_loss: 6257.0396 - val_reconstruction_loss: 1896.9186 - val_kl_loss: 99.0020 - val_false_loss: 13.7980 - val_true_loss: 1.2172\n",
      "Epoch 893/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3664 - reconstruction_loss: 1891.1305 - kl_loss: 100.6180 - false_loss: 0.0963 - true_loss: 1.1646 - val_loss: 6256.5337 - val_reconstruction_loss: 1896.9178 - val_kl_loss: 99.0016 - val_false_loss: 13.7964 - val_true_loss: 1.2171\n",
      "Epoch 894/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.8548 - reconstruction_loss: 1891.3666 - kl_loss: 100.5083 - false_loss: 0.0963 - true_loss: 1.1645 - val_loss: 6256.0381 - val_reconstruction_loss: 1896.9172 - val_kl_loss: 99.0021 - val_false_loss: 13.7947 - val_true_loss: 1.2171\n",
      "Epoch 895/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8047 - reconstruction_loss: 1891.6494 - kl_loss: 100.7504 - false_loss: 0.0963 - true_loss: 1.1645 - val_loss: 6255.5347 - val_reconstruction_loss: 1896.9164 - val_kl_loss: 99.0036 - val_false_loss: 13.7931 - val_true_loss: 1.2170\n",
      "Epoch 896/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.2095 - reconstruction_loss: 1890.9996 - kl_loss: 100.4932 - false_loss: 0.0963 - true_loss: 1.1644 - val_loss: 6255.0312 - val_reconstruction_loss: 1896.9158 - val_kl_loss: 99.0059 - val_false_loss: 13.7914 - val_true_loss: 1.2170\n",
      "Epoch 897/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.1133 - reconstruction_loss: 1891.7119 - kl_loss: 100.5303 - false_loss: 0.0963 - true_loss: 1.1643 - val_loss: 6254.5327 - val_reconstruction_loss: 1896.9152 - val_kl_loss: 99.0070 - val_false_loss: 13.7897 - val_true_loss: 1.2169\n",
      "Epoch 898/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.0467 - reconstruction_loss: 1892.2021 - kl_loss: 101.0452 - false_loss: 0.0963 - true_loss: 1.1643 - val_loss: 6254.0342 - val_reconstruction_loss: 1896.9143 - val_kl_loss: 99.0080 - val_false_loss: 13.7881 - val_true_loss: 1.2169\n",
      "Epoch 899/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.4095 - reconstruction_loss: 1891.2484 - kl_loss: 99.8095 - false_loss: 0.0962 - true_loss: 1.1642 - val_loss: 6253.5254 - val_reconstruction_loss: 1896.9135 - val_kl_loss: 99.0082 - val_false_loss: 13.7864 - val_true_loss: 1.2168\n",
      "Epoch 900/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.1091 - reconstruction_loss: 1891.1874 - kl_loss: 100.3436 - false_loss: 0.0962 - true_loss: 1.1642 - val_loss: 6253.0239 - val_reconstruction_loss: 1896.9130 - val_kl_loss: 99.0090 - val_false_loss: 13.7848 - val_true_loss: 1.2168\n",
      "Epoch 901/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.9964 - reconstruction_loss: 1891.3658 - kl_loss: 100.6987 - false_loss: 0.0962 - true_loss: 1.1641 - val_loss: 6252.5176 - val_reconstruction_loss: 1896.9122 - val_kl_loss: 99.0091 - val_false_loss: 13.7831 - val_true_loss: 1.2167\n",
      "Epoch 902/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.2386 - reconstruction_loss: 1891.0648 - kl_loss: 100.6474 - false_loss: 0.0962 - true_loss: 1.1641 - val_loss: 6252.0186 - val_reconstruction_loss: 1896.9115 - val_kl_loss: 99.0094 - val_false_loss: 13.7815 - val_true_loss: 1.2167\n",
      "Epoch 903/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8921 - reconstruction_loss: 1891.3148 - kl_loss: 101.0080 - false_loss: 0.0962 - true_loss: 1.1640 - val_loss: 6251.5107 - val_reconstruction_loss: 1896.9109 - val_kl_loss: 99.0093 - val_false_loss: 13.7798 - val_true_loss: 1.2166\n",
      "Epoch 904/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.7837 - reconstruction_loss: 1891.5625 - kl_loss: 100.4874 - false_loss: 0.0962 - true_loss: 1.1639 - val_loss: 6251.0103 - val_reconstruction_loss: 1896.9100 - val_kl_loss: 99.0091 - val_false_loss: 13.7781 - val_true_loss: 1.2166\n",
      "Epoch 905/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.6854 - reconstruction_loss: 1891.2207 - kl_loss: 100.3611 - false_loss: 0.0962 - true_loss: 1.1639 - val_loss: 6250.5073 - val_reconstruction_loss: 1896.9094 - val_kl_loss: 99.0091 - val_false_loss: 13.7765 - val_true_loss: 1.2165\n",
      "Epoch 906/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.1922 - reconstruction_loss: 1891.2799 - kl_loss: 100.6378 - false_loss: 0.0962 - true_loss: 1.1638 - val_loss: 6250.0068 - val_reconstruction_loss: 1896.9087 - val_kl_loss: 99.0089 - val_false_loss: 13.7748 - val_true_loss: 1.2165\n",
      "Epoch 907/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8111 - reconstruction_loss: 1891.1652 - kl_loss: 101.4318 - false_loss: 0.0962 - true_loss: 1.1638 - val_loss: 6249.5010 - val_reconstruction_loss: 1896.9081 - val_kl_loss: 99.0085 - val_false_loss: 13.7732 - val_true_loss: 1.2164\n",
      "Epoch 908/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.8291 - reconstruction_loss: 1891.2090 - kl_loss: 101.0453 - false_loss: 0.0962 - true_loss: 1.1637 - val_loss: 6248.9956 - val_reconstruction_loss: 1896.9075 - val_kl_loss: 99.0088 - val_false_loss: 13.7715 - val_true_loss: 1.2164\n",
      "Epoch 909/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.1481 - reconstruction_loss: 1891.4264 - kl_loss: 100.8612 - false_loss: 0.0962 - true_loss: 1.1636 - val_loss: 6248.4888 - val_reconstruction_loss: 1896.9066 - val_kl_loss: 99.0084 - val_false_loss: 13.7698 - val_true_loss: 1.2163\n",
      "Epoch 910/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.4333 - reconstruction_loss: 1890.9335 - kl_loss: 100.9713 - false_loss: 0.0961 - true_loss: 1.1636 - val_loss: 6247.9873 - val_reconstruction_loss: 1896.9060 - val_kl_loss: 99.0078 - val_false_loss: 13.7682 - val_true_loss: 1.2163\n",
      "Epoch 911/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.8365 - reconstruction_loss: 1891.2983 - kl_loss: 100.2244 - false_loss: 0.0961 - true_loss: 1.1635 - val_loss: 6247.4761 - val_reconstruction_loss: 1896.9054 - val_kl_loss: 99.0077 - val_false_loss: 13.7665 - val_true_loss: 1.2162\n",
      "Epoch 912/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1699 - reconstruction_loss: 1891.1273 - kl_loss: 99.2091 - false_loss: 0.0961 - true_loss: 1.1635 - val_loss: 6246.9639 - val_reconstruction_loss: 1896.9047 - val_kl_loss: 99.0080 - val_false_loss: 13.7648 - val_true_loss: 1.2162\n",
      "Epoch 913/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.7986 - reconstruction_loss: 1890.9196 - kl_loss: 99.6601 - false_loss: 0.0961 - true_loss: 1.1634 - val_loss: 6246.4541 - val_reconstruction_loss: 1896.9041 - val_kl_loss: 99.0083 - val_false_loss: 13.7631 - val_true_loss: 1.2161\n",
      "Epoch 914/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.2857 - reconstruction_loss: 1891.3350 - kl_loss: 100.3319 - false_loss: 0.0961 - true_loss: 1.1634 - val_loss: 6245.9424 - val_reconstruction_loss: 1896.9032 - val_kl_loss: 99.0085 - val_false_loss: 13.7614 - val_true_loss: 1.2161\n",
      "Epoch 915/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.4859 - reconstruction_loss: 1891.6094 - kl_loss: 100.1036 - false_loss: 0.0961 - true_loss: 1.1633 - val_loss: 6245.4341 - val_reconstruction_loss: 1896.9025 - val_kl_loss: 99.0086 - val_false_loss: 13.7598 - val_true_loss: 1.2160\n",
      "Epoch 916/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.0364 - reconstruction_loss: 1891.7150 - kl_loss: 100.8505 - false_loss: 0.0961 - true_loss: 1.1632 - val_loss: 6244.9292 - val_reconstruction_loss: 1896.9019 - val_kl_loss: 99.0086 - val_false_loss: 13.7581 - val_true_loss: 1.2160\n",
      "Epoch 917/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.7751 - reconstruction_loss: 1891.4030 - kl_loss: 100.7517 - false_loss: 0.0961 - true_loss: 1.1632 - val_loss: 6244.4282 - val_reconstruction_loss: 1896.9010 - val_kl_loss: 99.0092 - val_false_loss: 13.7564 - val_true_loss: 1.2159\n",
      "Epoch 918/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.4349 - reconstruction_loss: 1891.4039 - kl_loss: 101.3317 - false_loss: 0.0961 - true_loss: 1.1631 - val_loss: 6243.9277 - val_reconstruction_loss: 1896.9003 - val_kl_loss: 99.0102 - val_false_loss: 13.7548 - val_true_loss: 1.2159\n",
      "Epoch 919/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.6969 - reconstruction_loss: 1891.1149 - kl_loss: 101.5872 - false_loss: 0.0961 - true_loss: 1.1631 - val_loss: 6243.4214 - val_reconstruction_loss: 1896.8997 - val_kl_loss: 99.0111 - val_false_loss: 13.7531 - val_true_loss: 1.2158\n",
      "Epoch 920/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.0667 - reconstruction_loss: 1891.1923 - kl_loss: 101.4401 - false_loss: 0.0961 - true_loss: 1.1630 - val_loss: 6242.9116 - val_reconstruction_loss: 1896.8989 - val_kl_loss: 99.0117 - val_false_loss: 13.7514 - val_true_loss: 1.2158\n",
      "Epoch 921/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3605 - reconstruction_loss: 1891.3502 - kl_loss: 101.2850 - false_loss: 0.0960 - true_loss: 1.1629 - val_loss: 6242.4092 - val_reconstruction_loss: 1896.8983 - val_kl_loss: 99.0117 - val_false_loss: 13.7498 - val_true_loss: 1.2157\n",
      "Epoch 922/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3642 - reconstruction_loss: 1891.3252 - kl_loss: 101.2928 - false_loss: 0.0960 - true_loss: 1.1629 - val_loss: 6241.9062 - val_reconstruction_loss: 1896.8977 - val_kl_loss: 99.0118 - val_false_loss: 13.7481 - val_true_loss: 1.2157\n",
      "Epoch 923/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.2647 - reconstruction_loss: 1891.7568 - kl_loss: 101.5778 - false_loss: 0.0960 - true_loss: 1.1628 - val_loss: 6241.4023 - val_reconstruction_loss: 1896.8969 - val_kl_loss: 99.0108 - val_false_loss: 13.7465 - val_true_loss: 1.2156\n",
      "Epoch 924/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.8203 - reconstruction_loss: 1890.9502 - kl_loss: 100.1242 - false_loss: 0.0960 - true_loss: 1.1628 - val_loss: 6240.8950 - val_reconstruction_loss: 1896.8962 - val_kl_loss: 99.0104 - val_false_loss: 13.7448 - val_true_loss: 1.2156\n",
      "Epoch 925/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.8635 - reconstruction_loss: 1891.2313 - kl_loss: 100.0149 - false_loss: 0.0960 - true_loss: 1.1627 - val_loss: 6240.3862 - val_reconstruction_loss: 1896.8956 - val_kl_loss: 99.0107 - val_false_loss: 13.7431 - val_true_loss: 1.2155\n",
      "Epoch 926/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.6793 - reconstruction_loss: 1891.3350 - kl_loss: 100.6349 - false_loss: 0.0960 - true_loss: 1.1626 - val_loss: 6239.8804 - val_reconstruction_loss: 1896.8950 - val_kl_loss: 99.0114 - val_false_loss: 13.7414 - val_true_loss: 1.2155\n",
      "Epoch 927/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.3135 - reconstruction_loss: 1891.1412 - kl_loss: 100.5327 - false_loss: 0.0960 - true_loss: 1.1626 - val_loss: 6239.3672 - val_reconstruction_loss: 1896.8943 - val_kl_loss: 99.0116 - val_false_loss: 13.7398 - val_true_loss: 1.2154\n",
      "Epoch 928/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1858 - reconstruction_loss: 1890.9711 - kl_loss: 100.9109 - false_loss: 0.0960 - true_loss: 1.1625 - val_loss: 6238.8623 - val_reconstruction_loss: 1896.8937 - val_kl_loss: 99.0120 - val_false_loss: 13.7381 - val_true_loss: 1.2154\n",
      "Epoch 929/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7828 - reconstruction_loss: 1891.3964 - kl_loss: 100.5713 - false_loss: 0.0960 - true_loss: 1.1625 - val_loss: 6238.3618 - val_reconstruction_loss: 1896.8928 - val_kl_loss: 99.0128 - val_false_loss: 13.7364 - val_true_loss: 1.2153\n",
      "Epoch 930/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.9859 - reconstruction_loss: 1891.2965 - kl_loss: 100.6529 - false_loss: 0.0960 - true_loss: 1.1624 - val_loss: 6237.8540 - val_reconstruction_loss: 1896.8925 - val_kl_loss: 99.0131 - val_false_loss: 13.7348 - val_true_loss: 1.2153\n",
      "Epoch 931/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.1836 - reconstruction_loss: 1891.6761 - kl_loss: 101.3125 - false_loss: 0.0960 - true_loss: 1.1623 - val_loss: 6237.3501 - val_reconstruction_loss: 1896.8916 - val_kl_loss: 99.0136 - val_false_loss: 13.7331 - val_true_loss: 1.2152\n",
      "Epoch 932/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.2117 - reconstruction_loss: 1891.3175 - kl_loss: 100.7862 - false_loss: 0.0959 - true_loss: 1.1623 - val_loss: 6236.8486 - val_reconstruction_loss: 1896.8909 - val_kl_loss: 99.0134 - val_false_loss: 13.7315 - val_true_loss: 1.2152\n",
      "Epoch 933/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.8949 - reconstruction_loss: 1891.1001 - kl_loss: 101.5129 - false_loss: 0.0959 - true_loss: 1.1622 - val_loss: 6236.3501 - val_reconstruction_loss: 1896.8903 - val_kl_loss: 99.0129 - val_false_loss: 13.7298 - val_true_loss: 1.2151\n",
      "Epoch 934/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0334 - reconstruction_loss: 1891.1050 - kl_loss: 100.0772 - false_loss: 0.0959 - true_loss: 1.1622 - val_loss: 6235.8472 - val_reconstruction_loss: 1896.8896 - val_kl_loss: 99.0126 - val_false_loss: 13.7282 - val_true_loss: 1.2151\n",
      "Epoch 935/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1227 - reconstruction_loss: 1890.7749 - kl_loss: 100.9099 - false_loss: 0.0959 - true_loss: 1.1621 - val_loss: 6235.3457 - val_reconstruction_loss: 1896.8890 - val_kl_loss: 99.0122 - val_false_loss: 13.7265 - val_true_loss: 1.2150\n",
      "Epoch 936/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.2879 - reconstruction_loss: 1890.8691 - kl_loss: 100.4265 - false_loss: 0.0959 - true_loss: 1.1621 - val_loss: 6234.8462 - val_reconstruction_loss: 1896.8883 - val_kl_loss: 99.0123 - val_false_loss: 13.7249 - val_true_loss: 1.2150\n",
      "Epoch 937/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2233.4097 - reconstruction_loss: 1891.2299 - kl_loss: 100.6348 - false_loss: 0.0959 - true_loss: 1.1620 - val_loss: 6234.3398 - val_reconstruction_loss: 1896.8877 - val_kl_loss: 99.0127 - val_false_loss: 13.7232 - val_true_loss: 1.2149\n",
      "Epoch 938/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.8749 - reconstruction_loss: 1890.7227 - kl_loss: 100.5597 - false_loss: 0.0959 - true_loss: 1.1619 - val_loss: 6233.8384 - val_reconstruction_loss: 1896.8868 - val_kl_loss: 99.0131 - val_false_loss: 13.7215 - val_true_loss: 1.2149\n",
      "Epoch 939/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.0240 - reconstruction_loss: 1890.9340 - kl_loss: 100.4714 - false_loss: 0.0959 - true_loss: 1.1619 - val_loss: 6233.3335 - val_reconstruction_loss: 1896.8861 - val_kl_loss: 99.0146 - val_false_loss: 13.7199 - val_true_loss: 1.2148\n",
      "Epoch 940/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.2215 - reconstruction_loss: 1891.4095 - kl_loss: 100.1439 - false_loss: 0.0959 - true_loss: 1.1618 - val_loss: 6232.8311 - val_reconstruction_loss: 1896.8855 - val_kl_loss: 99.0161 - val_false_loss: 13.7182 - val_true_loss: 1.2148\n",
      "Epoch 941/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5681 - reconstruction_loss: 1891.2318 - kl_loss: 101.3308 - false_loss: 0.0959 - true_loss: 1.1618 - val_loss: 6232.3247 - val_reconstruction_loss: 1896.8849 - val_kl_loss: 99.0166 - val_false_loss: 13.7165 - val_true_loss: 1.2147\n",
      "Epoch 942/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.8174 - reconstruction_loss: 1891.3556 - kl_loss: 100.8917 - false_loss: 0.0959 - true_loss: 1.1617 - val_loss: 6231.8247 - val_reconstruction_loss: 1896.8843 - val_kl_loss: 99.0182 - val_false_loss: 13.7149 - val_true_loss: 1.2147\n",
      "Epoch 943/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.9314 - reconstruction_loss: 1892.1313 - kl_loss: 101.1665 - false_loss: 0.0958 - true_loss: 1.1616 - val_loss: 6231.3149 - val_reconstruction_loss: 1896.8837 - val_kl_loss: 99.0191 - val_false_loss: 13.7132 - val_true_loss: 1.2146\n",
      "Epoch 944/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.8613 - reconstruction_loss: 1891.3463 - kl_loss: 101.3455 - false_loss: 0.0958 - true_loss: 1.1616 - val_loss: 6230.8174 - val_reconstruction_loss: 1896.8829 - val_kl_loss: 99.0195 - val_false_loss: 13.7116 - val_true_loss: 1.2146\n",
      "Epoch 945/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2131 - reconstruction_loss: 1891.0160 - kl_loss: 100.7860 - false_loss: 0.0958 - true_loss: 1.1615 - val_loss: 6230.3110 - val_reconstruction_loss: 1896.8820 - val_kl_loss: 99.0204 - val_false_loss: 13.7099 - val_true_loss: 1.2145\n",
      "Epoch 946/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8764 - reconstruction_loss: 1890.9513 - kl_loss: 100.5224 - false_loss: 0.0958 - true_loss: 1.1615 - val_loss: 6229.8076 - val_reconstruction_loss: 1896.8815 - val_kl_loss: 99.0223 - val_false_loss: 13.7082 - val_true_loss: 1.2145\n",
      "Epoch 947/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.4743 - reconstruction_loss: 1890.8571 - kl_loss: 100.9037 - false_loss: 0.0958 - true_loss: 1.1614 - val_loss: 6229.3052 - val_reconstruction_loss: 1896.8807 - val_kl_loss: 99.0237 - val_false_loss: 13.7066 - val_true_loss: 1.2144\n",
      "Epoch 948/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.9485 - reconstruction_loss: 1891.2914 - kl_loss: 101.2150 - false_loss: 0.0958 - true_loss: 1.1614 - val_loss: 6228.7969 - val_reconstruction_loss: 1896.8800 - val_kl_loss: 99.0248 - val_false_loss: 13.7049 - val_true_loss: 1.2144\n",
      "Epoch 949/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.1837 - reconstruction_loss: 1890.8344 - kl_loss: 101.5179 - false_loss: 0.0958 - true_loss: 1.1613 - val_loss: 6228.2905 - val_reconstruction_loss: 1896.8792 - val_kl_loss: 99.0253 - val_false_loss: 13.7032 - val_true_loss: 1.2143\n",
      "Epoch 950/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9380 - reconstruction_loss: 1891.3706 - kl_loss: 101.4703 - false_loss: 0.0958 - true_loss: 1.1612 - val_loss: 6227.7900 - val_reconstruction_loss: 1896.8785 - val_kl_loss: 99.0255 - val_false_loss: 13.7016 - val_true_loss: 1.2143\n",
      "Epoch 951/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.9467 - reconstruction_loss: 1891.1177 - kl_loss: 100.8951 - false_loss: 0.0958 - true_loss: 1.1612 - val_loss: 6227.2915 - val_reconstruction_loss: 1896.8779 - val_kl_loss: 99.0265 - val_false_loss: 13.6999 - val_true_loss: 1.2142\n",
      "Epoch 952/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6052 - reconstruction_loss: 1891.3369 - kl_loss: 100.5203 - false_loss: 0.0958 - true_loss: 1.1611 - val_loss: 6226.7896 - val_reconstruction_loss: 1896.8772 - val_kl_loss: 99.0270 - val_false_loss: 13.6983 - val_true_loss: 1.2142\n",
      "Epoch 953/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.9128 - reconstruction_loss: 1891.3448 - kl_loss: 101.2795 - false_loss: 0.0958 - true_loss: 1.1611 - val_loss: 6226.2886 - val_reconstruction_loss: 1896.8765 - val_kl_loss: 99.0274 - val_false_loss: 13.6966 - val_true_loss: 1.2141\n",
      "Epoch 954/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.4545 - reconstruction_loss: 1891.3129 - kl_loss: 100.8362 - false_loss: 0.0958 - true_loss: 1.1610 - val_loss: 6225.7788 - val_reconstruction_loss: 1896.8756 - val_kl_loss: 99.0277 - val_false_loss: 13.6949 - val_true_loss: 1.2141\n",
      "Epoch 955/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.9630 - reconstruction_loss: 1891.1265 - kl_loss: 100.3766 - false_loss: 0.0957 - true_loss: 1.1609 - val_loss: 6225.2852 - val_reconstruction_loss: 1896.8752 - val_kl_loss: 99.0283 - val_false_loss: 13.6933 - val_true_loss: 1.2140\n",
      "Epoch 956/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.0967 - reconstruction_loss: 1891.2526 - kl_loss: 100.8151 - false_loss: 0.0957 - true_loss: 1.1609 - val_loss: 6224.7827 - val_reconstruction_loss: 1896.8744 - val_kl_loss: 99.0298 - val_false_loss: 13.6916 - val_true_loss: 1.2139\n",
      "Epoch 957/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.4689 - reconstruction_loss: 1890.7480 - kl_loss: 100.8431 - false_loss: 0.0957 - true_loss: 1.1608 - val_loss: 6224.2905 - val_reconstruction_loss: 1896.8737 - val_kl_loss: 99.0304 - val_false_loss: 13.6900 - val_true_loss: 1.2139\n",
      "Epoch 958/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.7806 - reconstruction_loss: 1890.7109 - kl_loss: 102.0870 - false_loss: 0.0957 - true_loss: 1.1608 - val_loss: 6223.7930 - val_reconstruction_loss: 1896.8729 - val_kl_loss: 99.0312 - val_false_loss: 13.6884 - val_true_loss: 1.2138\n",
      "Epoch 959/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.7368 - reconstruction_loss: 1891.3441 - kl_loss: 100.4773 - false_loss: 0.0957 - true_loss: 1.1607 - val_loss: 6223.2949 - val_reconstruction_loss: 1896.8724 - val_kl_loss: 99.0319 - val_false_loss: 13.6867 - val_true_loss: 1.2138\n",
      "Epoch 960/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6992 - reconstruction_loss: 1891.0604 - kl_loss: 100.5304 - false_loss: 0.0957 - true_loss: 1.1606 - val_loss: 6222.7954 - val_reconstruction_loss: 1896.8717 - val_kl_loss: 99.0331 - val_false_loss: 13.6851 - val_true_loss: 1.2137\n",
      "Epoch 961/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.0868 - reconstruction_loss: 1890.8409 - kl_loss: 101.0441 - false_loss: 0.0957 - true_loss: 1.1606 - val_loss: 6222.3032 - val_reconstruction_loss: 1896.8710 - val_kl_loss: 99.0344 - val_false_loss: 13.6835 - val_true_loss: 1.2137\n",
      "Epoch 962/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.5355 - reconstruction_loss: 1891.4054 - kl_loss: 101.6414 - false_loss: 0.0957 - true_loss: 1.1605 - val_loss: 6221.8037 - val_reconstruction_loss: 1896.8705 - val_kl_loss: 99.0345 - val_false_loss: 13.6818 - val_true_loss: 1.2136\n",
      "Epoch 963/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.1990 - reconstruction_loss: 1890.9615 - kl_loss: 101.0702 - false_loss: 0.0957 - true_loss: 1.1605 - val_loss: 6221.3037 - val_reconstruction_loss: 1896.8698 - val_kl_loss: 99.0350 - val_false_loss: 13.6802 - val_true_loss: 1.2136\n",
      "Epoch 964/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1662 - reconstruction_loss: 1890.7750 - kl_loss: 101.4011 - false_loss: 0.0957 - true_loss: 1.1604 - val_loss: 6220.8057 - val_reconstruction_loss: 1896.8689 - val_kl_loss: 99.0356 - val_false_loss: 13.6785 - val_true_loss: 1.2135\n",
      "Epoch 965/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.4917 - reconstruction_loss: 1891.5133 - kl_loss: 100.8386 - false_loss: 0.0957 - true_loss: 1.1603 - val_loss: 6220.3071 - val_reconstruction_loss: 1896.8685 - val_kl_loss: 99.0363 - val_false_loss: 13.6769 - val_true_loss: 1.2135\n",
      "Epoch 966/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.0565 - reconstruction_loss: 1891.5732 - kl_loss: 101.7554 - false_loss: 0.0956 - true_loss: 1.1603 - val_loss: 6219.8091 - val_reconstruction_loss: 1896.8677 - val_kl_loss: 99.0357 - val_false_loss: 13.6752 - val_true_loss: 1.2134\n",
      "Epoch 967/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.9502 - reconstruction_loss: 1891.4215 - kl_loss: 100.2440 - false_loss: 0.0956 - true_loss: 1.1602 - val_loss: 6219.3032 - val_reconstruction_loss: 1896.8669 - val_kl_loss: 99.0364 - val_false_loss: 13.6736 - val_true_loss: 1.2134\n",
      "Epoch 968/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.0184 - reconstruction_loss: 1890.9196 - kl_loss: 100.7057 - false_loss: 0.0956 - true_loss: 1.1602 - val_loss: 6218.8135 - val_reconstruction_loss: 1896.8662 - val_kl_loss: 99.0372 - val_false_loss: 13.6720 - val_true_loss: 1.2133\n",
      "Epoch 969/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1369 - reconstruction_loss: 1891.2260 - kl_loss: 101.3781 - false_loss: 0.0956 - true_loss: 1.1601 - val_loss: 6218.3179 - val_reconstruction_loss: 1896.8655 - val_kl_loss: 99.0374 - val_false_loss: 13.6703 - val_true_loss: 1.2133\n",
      "Epoch 970/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.9102 - reconstruction_loss: 1891.0231 - kl_loss: 101.2602 - false_loss: 0.0956 - true_loss: 1.1600 - val_loss: 6217.8184 - val_reconstruction_loss: 1896.8649 - val_kl_loss: 99.0378 - val_false_loss: 13.6687 - val_true_loss: 1.2132\n",
      "Epoch 971/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6767 - reconstruction_loss: 1890.8829 - kl_loss: 101.6140 - false_loss: 0.0956 - true_loss: 1.1600 - val_loss: 6217.3198 - val_reconstruction_loss: 1896.8640 - val_kl_loss: 99.0378 - val_false_loss: 13.6670 - val_true_loss: 1.2132\n",
      "Epoch 972/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.1534 - reconstruction_loss: 1891.3447 - kl_loss: 101.1832 - false_loss: 0.0956 - true_loss: 1.1599 - val_loss: 6216.8218 - val_reconstruction_loss: 1896.8635 - val_kl_loss: 99.0382 - val_false_loss: 13.6654 - val_true_loss: 1.2131\n",
      "Epoch 973/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.7826 - reconstruction_loss: 1891.3003 - kl_loss: 101.4932 - false_loss: 0.0956 - true_loss: 1.1599 - val_loss: 6216.3237 - val_reconstruction_loss: 1896.8629 - val_kl_loss: 99.0390 - val_false_loss: 13.6637 - val_true_loss: 1.2131\n",
      "Epoch 974/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.7536 - reconstruction_loss: 1891.4584 - kl_loss: 101.1623 - false_loss: 0.0956 - true_loss: 1.1598 - val_loss: 6215.8267 - val_reconstruction_loss: 1896.8621 - val_kl_loss: 99.0400 - val_false_loss: 13.6621 - val_true_loss: 1.2130\n",
      "Epoch 975/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.0676 - reconstruction_loss: 1891.6566 - kl_loss: 101.4854 - false_loss: 0.0956 - true_loss: 1.1598 - val_loss: 6215.3247 - val_reconstruction_loss: 1896.8615 - val_kl_loss: 99.0407 - val_false_loss: 13.6605 - val_true_loss: 1.2130\n",
      "Epoch 976/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.4578 - reconstruction_loss: 1890.8441 - kl_loss: 101.4639 - false_loss: 0.0956 - true_loss: 1.1597 - val_loss: 6214.8213 - val_reconstruction_loss: 1896.8607 - val_kl_loss: 99.0406 - val_false_loss: 13.6588 - val_true_loss: 1.2129\n",
      "Epoch 977/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.7289 - reconstruction_loss: 1891.0121 - kl_loss: 101.0539 - false_loss: 0.0955 - true_loss: 1.1596 - val_loss: 6214.3291 - val_reconstruction_loss: 1896.8601 - val_kl_loss: 99.0404 - val_false_loss: 13.6572 - val_true_loss: 1.2129\n",
      "Epoch 978/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.1023 - reconstruction_loss: 1891.1416 - kl_loss: 99.7446 - false_loss: 0.0955 - true_loss: 1.1596 - val_loss: 6213.8296 - val_reconstruction_loss: 1896.8594 - val_kl_loss: 99.0411 - val_false_loss: 13.6555 - val_true_loss: 1.2128\n",
      "Epoch 979/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.4344 - reconstruction_loss: 1890.9766 - kl_loss: 99.5819 - false_loss: 0.0955 - true_loss: 1.1595 - val_loss: 6213.3330 - val_reconstruction_loss: 1896.8588 - val_kl_loss: 99.0428 - val_false_loss: 13.6539 - val_true_loss: 1.2128\n",
      "Epoch 980/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.9417 - reconstruction_loss: 1891.3151 - kl_loss: 100.0311 - false_loss: 0.0955 - true_loss: 1.1595 - val_loss: 6212.8350 - val_reconstruction_loss: 1896.8580 - val_kl_loss: 99.0438 - val_false_loss: 13.6522 - val_true_loss: 1.2127\n",
      "Epoch 981/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.2755 - reconstruction_loss: 1891.2513 - kl_loss: 100.2141 - false_loss: 0.0955 - true_loss: 1.1594 - val_loss: 6212.3359 - val_reconstruction_loss: 1896.8574 - val_kl_loss: 99.0443 - val_false_loss: 13.6506 - val_true_loss: 1.2127\n",
      "Epoch 982/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7789 - reconstruction_loss: 1891.3008 - kl_loss: 100.9077 - false_loss: 0.0955 - true_loss: 1.1594 - val_loss: 6211.8501 - val_reconstruction_loss: 1896.8564 - val_kl_loss: 99.0441 - val_false_loss: 13.6490 - val_true_loss: 1.2126\n",
      "Epoch 983/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.9186 - reconstruction_loss: 1890.8002 - kl_loss: 100.3564 - false_loss: 0.0955 - true_loss: 1.1593 - val_loss: 6211.3462 - val_reconstruction_loss: 1896.8561 - val_kl_loss: 99.0442 - val_false_loss: 13.6473 - val_true_loss: 1.2126\n",
      "Epoch 984/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.3510 - reconstruction_loss: 1891.1270 - kl_loss: 100.7028 - false_loss: 0.0955 - true_loss: 1.1592 - val_loss: 6210.8569 - val_reconstruction_loss: 1896.8551 - val_kl_loss: 99.0447 - val_false_loss: 13.6457 - val_true_loss: 1.2125\n",
      "Epoch 985/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.5594 - reconstruction_loss: 1890.7990 - kl_loss: 100.8112 - false_loss: 0.0955 - true_loss: 1.1592 - val_loss: 6210.3633 - val_reconstruction_loss: 1896.8545 - val_kl_loss: 99.0459 - val_false_loss: 13.6441 - val_true_loss: 1.2125\n",
      "Epoch 986/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5163 - reconstruction_loss: 1890.7321 - kl_loss: 100.3239 - false_loss: 0.0955 - true_loss: 1.1591 - val_loss: 6209.8647 - val_reconstruction_loss: 1896.8538 - val_kl_loss: 99.0475 - val_false_loss: 13.6424 - val_true_loss: 1.2124\n",
      "Epoch 987/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7882 - reconstruction_loss: 1891.6744 - kl_loss: 101.6486 - false_loss: 0.0955 - true_loss: 1.1591 - val_loss: 6209.3682 - val_reconstruction_loss: 1896.8531 - val_kl_loss: 99.0486 - val_false_loss: 13.6408 - val_true_loss: 1.2124\n",
      "Epoch 988/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.9361 - reconstruction_loss: 1891.8544 - kl_loss: 101.0577 - false_loss: 0.0954 - true_loss: 1.1590 - val_loss: 6208.8691 - val_reconstruction_loss: 1896.8522 - val_kl_loss: 99.0496 - val_false_loss: 13.6391 - val_true_loss: 1.2123\n",
      "Epoch 989/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8513 - reconstruction_loss: 1891.4965 - kl_loss: 100.9353 - false_loss: 0.0954 - true_loss: 1.1589 - val_loss: 6208.3687 - val_reconstruction_loss: 1896.8518 - val_kl_loss: 99.0501 - val_false_loss: 13.6375 - val_true_loss: 1.2123\n",
      "Epoch 990/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4326 - reconstruction_loss: 1890.9844 - kl_loss: 101.0280 - false_loss: 0.0954 - true_loss: 1.1589 - val_loss: 6207.8696 - val_reconstruction_loss: 1896.8511 - val_kl_loss: 99.0498 - val_false_loss: 13.6359 - val_true_loss: 1.2122\n",
      "Epoch 991/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6804 - reconstruction_loss: 1891.1810 - kl_loss: 100.8006 - false_loss: 0.0954 - true_loss: 1.1588 - val_loss: 6207.3745 - val_reconstruction_loss: 1896.8502 - val_kl_loss: 99.0501 - val_false_loss: 13.6342 - val_true_loss: 1.2122\n",
      "Epoch 992/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2269 - reconstruction_loss: 1891.0342 - kl_loss: 101.4626 - false_loss: 0.0954 - true_loss: 1.1588 - val_loss: 6206.8804 - val_reconstruction_loss: 1896.8495 - val_kl_loss: 99.0500 - val_false_loss: 13.6326 - val_true_loss: 1.2121\n",
      "Epoch 993/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7761 - reconstruction_loss: 1891.1088 - kl_loss: 101.1104 - false_loss: 0.0954 - true_loss: 1.1587 - val_loss: 6206.3940 - val_reconstruction_loss: 1896.8489 - val_kl_loss: 99.0510 - val_false_loss: 13.6310 - val_true_loss: 1.2121\n",
      "Epoch 994/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.2991 - reconstruction_loss: 1891.0856 - kl_loss: 99.9450 - false_loss: 0.0954 - true_loss: 1.1587 - val_loss: 6205.8970 - val_reconstruction_loss: 1896.8481 - val_kl_loss: 99.0516 - val_false_loss: 13.6294 - val_true_loss: 1.2120\n",
      "Epoch 995/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.3842 - reconstruction_loss: 1891.0288 - kl_loss: 101.2699 - false_loss: 0.0954 - true_loss: 1.1586 - val_loss: 6205.3979 - val_reconstruction_loss: 1896.8475 - val_kl_loss: 99.0527 - val_false_loss: 13.6277 - val_true_loss: 1.2120\n",
      "Epoch 996/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.2719 - reconstruction_loss: 1891.3226 - kl_loss: 100.6959 - false_loss: 0.0954 - true_loss: 1.1585 - val_loss: 6204.8970 - val_reconstruction_loss: 1896.8469 - val_kl_loss: 99.0531 - val_false_loss: 13.6261 - val_true_loss: 1.2119\n",
      "Epoch 997/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.6591 - reconstruction_loss: 1891.0132 - kl_loss: 100.0992 - false_loss: 0.0954 - true_loss: 1.1585 - val_loss: 6204.3975 - val_reconstruction_loss: 1896.8462 - val_kl_loss: 99.0535 - val_false_loss: 13.6244 - val_true_loss: 1.2119\n",
      "Epoch 998/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6466 - reconstruction_loss: 1891.0059 - kl_loss: 100.7314 - false_loss: 0.0954 - true_loss: 1.1584 - val_loss: 6203.8989 - val_reconstruction_loss: 1896.8456 - val_kl_loss: 99.0533 - val_false_loss: 13.6228 - val_true_loss: 1.2118\n",
      "Epoch 999/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.9681 - reconstruction_loss: 1890.6318 - kl_loss: 100.9259 - false_loss: 0.0953 - true_loss: 1.1584 - val_loss: 6203.3975 - val_reconstruction_loss: 1896.8448 - val_kl_loss: 99.0536 - val_false_loss: 13.6211 - val_true_loss: 1.2118\n",
      "Epoch 1000/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.9779 - reconstruction_loss: 1891.3068 - kl_loss: 100.3243 - false_loss: 0.0953 - true_loss: 1.1583 - val_loss: 6202.9014 - val_reconstruction_loss: 1896.8441 - val_kl_loss: 99.0547 - val_false_loss: 13.6195 - val_true_loss: 1.2117\n",
      "Epoch 1001/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.6931 - reconstruction_loss: 1890.9943 - kl_loss: 100.6786 - false_loss: 0.0953 - true_loss: 1.1583 - val_loss: 6202.4121 - val_reconstruction_loss: 1896.8435 - val_kl_loss: 99.0562 - val_false_loss: 13.6179 - val_true_loss: 1.2117\n",
      "Epoch 1002/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.7173 - reconstruction_loss: 1890.9586 - kl_loss: 100.4184 - false_loss: 0.0953 - true_loss: 1.1582 - val_loss: 6201.9146 - val_reconstruction_loss: 1896.8429 - val_kl_loss: 99.0576 - val_false_loss: 13.6162 - val_true_loss: 1.2116\n",
      "Epoch 1003/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.8150 - reconstruction_loss: 1891.0826 - kl_loss: 100.5662 - false_loss: 0.0953 - true_loss: 1.1581 - val_loss: 6201.4170 - val_reconstruction_loss: 1896.8422 - val_kl_loss: 99.0588 - val_false_loss: 13.6146 - val_true_loss: 1.2115\n",
      "Epoch 1004/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.6048 - reconstruction_loss: 1891.2115 - kl_loss: 100.6140 - false_loss: 0.0953 - true_loss: 1.1581 - val_loss: 6200.9248 - val_reconstruction_loss: 1896.8416 - val_kl_loss: 99.0596 - val_false_loss: 13.6130 - val_true_loss: 1.2115\n",
      "Epoch 1005/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0468 - reconstruction_loss: 1891.5743 - kl_loss: 101.4614 - false_loss: 0.0953 - true_loss: 1.1580 - val_loss: 6200.4272 - val_reconstruction_loss: 1896.8407 - val_kl_loss: 99.0599 - val_false_loss: 13.6113 - val_true_loss: 1.2114\n",
      "Epoch 1006/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.5092 - reconstruction_loss: 1890.9467 - kl_loss: 100.6480 - false_loss: 0.0953 - true_loss: 1.1580 - val_loss: 6199.9370 - val_reconstruction_loss: 1896.8403 - val_kl_loss: 99.0602 - val_false_loss: 13.6097 - val_true_loss: 1.2114\n",
      "Epoch 1007/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.1540 - reconstruction_loss: 1891.0586 - kl_loss: 100.8109 - false_loss: 0.0953 - true_loss: 1.1579 - val_loss: 6199.4468 - val_reconstruction_loss: 1896.8396 - val_kl_loss: 99.0607 - val_false_loss: 13.6081 - val_true_loss: 1.2113\n",
      "Epoch 1008/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.6313 - reconstruction_loss: 1890.5258 - kl_loss: 101.5180 - false_loss: 0.0953 - true_loss: 1.1578 - val_loss: 6198.9512 - val_reconstruction_loss: 1896.8390 - val_kl_loss: 99.0605 - val_false_loss: 13.6064 - val_true_loss: 1.2113\n",
      "Epoch 1009/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.8856 - reconstruction_loss: 1891.5840 - kl_loss: 101.0279 - false_loss: 0.0953 - true_loss: 1.1578 - val_loss: 6198.4546 - val_reconstruction_loss: 1896.8383 - val_kl_loss: 99.0605 - val_false_loss: 13.6048 - val_true_loss: 1.2112\n",
      "Epoch 1010/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6708 - reconstruction_loss: 1890.8387 - kl_loss: 100.8247 - false_loss: 0.0953 - true_loss: 1.1577 - val_loss: 6197.9648 - val_reconstruction_loss: 1896.8376 - val_kl_loss: 99.0607 - val_false_loss: 13.6032 - val_true_loss: 1.2112\n",
      "Epoch 1011/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.2547 - reconstruction_loss: 1891.2148 - kl_loss: 101.2517 - false_loss: 0.0952 - true_loss: 1.1577 - val_loss: 6197.4629 - val_reconstruction_loss: 1896.8370 - val_kl_loss: 99.0605 - val_false_loss: 13.6015 - val_true_loss: 1.2111\n",
      "Epoch 1012/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1623 - reconstruction_loss: 1890.9637 - kl_loss: 99.5967 - false_loss: 0.0952 - true_loss: 1.1576 - val_loss: 6196.9722 - val_reconstruction_loss: 1896.8363 - val_kl_loss: 99.0603 - val_false_loss: 13.5999 - val_true_loss: 1.2111\n",
      "Epoch 1013/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.4062 - reconstruction_loss: 1890.9419 - kl_loss: 101.2227 - false_loss: 0.0952 - true_loss: 1.1576 - val_loss: 6196.4717 - val_reconstruction_loss: 1896.8357 - val_kl_loss: 99.0604 - val_false_loss: 13.5983 - val_true_loss: 1.2110\n",
      "Epoch 1014/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.2918 - reconstruction_loss: 1891.1198 - kl_loss: 99.0831 - false_loss: 0.0952 - true_loss: 1.1575 - val_loss: 6195.9771 - val_reconstruction_loss: 1896.8348 - val_kl_loss: 99.0606 - val_false_loss: 13.5966 - val_true_loss: 1.2110\n",
      "Epoch 1015/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.2213 - reconstruction_loss: 1890.7544 - kl_loss: 101.2775 - false_loss: 0.0952 - true_loss: 1.1574 - val_loss: 6195.4844 - val_reconstruction_loss: 1896.8344 - val_kl_loss: 99.0603 - val_false_loss: 13.5950 - val_true_loss: 1.2109\n",
      "Epoch 1016/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.3295 - reconstruction_loss: 1891.3291 - kl_loss: 101.1166 - false_loss: 0.0952 - true_loss: 1.1574 - val_loss: 6194.9912 - val_reconstruction_loss: 1896.8337 - val_kl_loss: 99.0608 - val_false_loss: 13.5934 - val_true_loss: 1.2109\n",
      "Epoch 1017/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.8475 - reconstruction_loss: 1891.2406 - kl_loss: 101.1889 - false_loss: 0.0952 - true_loss: 1.1573 - val_loss: 6194.4995 - val_reconstruction_loss: 1896.8328 - val_kl_loss: 99.0616 - val_false_loss: 13.5918 - val_true_loss: 1.2108\n",
      "Epoch 1018/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.9151 - reconstruction_loss: 1891.4844 - kl_loss: 100.6763 - false_loss: 0.0952 - true_loss: 1.1573 - val_loss: 6194.0068 - val_reconstruction_loss: 1896.8324 - val_kl_loss: 99.0620 - val_false_loss: 13.5901 - val_true_loss: 1.2108\n",
      "Epoch 1019/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.5069 - reconstruction_loss: 1891.2765 - kl_loss: 101.7441 - false_loss: 0.0952 - true_loss: 1.1572 - val_loss: 6193.5112 - val_reconstruction_loss: 1896.8315 - val_kl_loss: 99.0627 - val_false_loss: 13.5885 - val_true_loss: 1.2107\n",
      "Epoch 1020/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2764 - reconstruction_loss: 1891.5972 - kl_loss: 100.8523 - false_loss: 0.0952 - true_loss: 1.1572 - val_loss: 6193.0220 - val_reconstruction_loss: 1896.8312 - val_kl_loss: 99.0639 - val_false_loss: 13.5869 - val_true_loss: 1.2107\n",
      "Epoch 1021/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.3443 - reconstruction_loss: 1891.5253 - kl_loss: 100.3570 - false_loss: 0.0952 - true_loss: 1.1571 - val_loss: 6192.5322 - val_reconstruction_loss: 1896.8304 - val_kl_loss: 99.0646 - val_false_loss: 13.5853 - val_true_loss: 1.2106\n",
      "Epoch 1022/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.0814 - reconstruction_loss: 1891.1481 - kl_loss: 100.2743 - false_loss: 0.0951 - true_loss: 1.1570 - val_loss: 6192.0410 - val_reconstruction_loss: 1896.8296 - val_kl_loss: 99.0651 - val_false_loss: 13.5837 - val_true_loss: 1.2106\n",
      "Epoch 1023/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.2235 - reconstruction_loss: 1891.2814 - kl_loss: 100.0829 - false_loss: 0.0951 - true_loss: 1.1570 - val_loss: 6191.5439 - val_reconstruction_loss: 1896.8292 - val_kl_loss: 99.0653 - val_false_loss: 13.5820 - val_true_loss: 1.2105\n",
      "Epoch 1024/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3023 - reconstruction_loss: 1891.0333 - kl_loss: 100.4826 - false_loss: 0.0951 - true_loss: 1.1569 - val_loss: 6191.0449 - val_reconstruction_loss: 1896.8286 - val_kl_loss: 99.0651 - val_false_loss: 13.5804 - val_true_loss: 1.2105\n",
      "Epoch 1025/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.6774 - reconstruction_loss: 1891.4941 - kl_loss: 99.5162 - false_loss: 0.0951 - true_loss: 1.1569 - val_loss: 6190.5542 - val_reconstruction_loss: 1896.8280 - val_kl_loss: 99.0660 - val_false_loss: 13.5788 - val_true_loss: 1.2104\n",
      "Epoch 1026/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8339 - reconstruction_loss: 1891.2601 - kl_loss: 101.5842 - false_loss: 0.0951 - true_loss: 1.1568 - val_loss: 6190.0630 - val_reconstruction_loss: 1896.8273 - val_kl_loss: 99.0661 - val_false_loss: 13.5771 - val_true_loss: 1.2104\n",
      "Epoch 1027/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.6313 - reconstruction_loss: 1891.0802 - kl_loss: 101.4344 - false_loss: 0.0951 - true_loss: 1.1568 - val_loss: 6189.5659 - val_reconstruction_loss: 1896.8267 - val_kl_loss: 99.0662 - val_false_loss: 13.5755 - val_true_loss: 1.2103\n",
      "Epoch 1028/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.6138 - reconstruction_loss: 1890.9696 - kl_loss: 100.3543 - false_loss: 0.0951 - true_loss: 1.1567 - val_loss: 6189.0747 - val_reconstruction_loss: 1896.8258 - val_kl_loss: 99.0655 - val_false_loss: 13.5739 - val_true_loss: 1.2103\n",
      "Epoch 1029/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0707 - reconstruction_loss: 1890.9926 - kl_loss: 100.6203 - false_loss: 0.0951 - true_loss: 1.1566 - val_loss: 6188.5840 - val_reconstruction_loss: 1896.8253 - val_kl_loss: 99.0658 - val_false_loss: 13.5723 - val_true_loss: 1.2102\n",
      "Epoch 1030/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.8718 - reconstruction_loss: 1891.2281 - kl_loss: 101.4128 - false_loss: 0.0951 - true_loss: 1.1566 - val_loss: 6188.1021 - val_reconstruction_loss: 1896.8247 - val_kl_loss: 99.0655 - val_false_loss: 13.5707 - val_true_loss: 1.2102\n",
      "Epoch 1031/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.0957 - reconstruction_loss: 1891.4766 - kl_loss: 100.2407 - false_loss: 0.0951 - true_loss: 1.1565 - val_loss: 6187.6099 - val_reconstruction_loss: 1896.8241 - val_kl_loss: 99.0653 - val_false_loss: 13.5691 - val_true_loss: 1.2101\n",
      "Epoch 1032/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.0788 - reconstruction_loss: 1891.5494 - kl_loss: 101.8216 - false_loss: 0.0951 - true_loss: 1.1565 - val_loss: 6187.1206 - val_reconstruction_loss: 1896.8234 - val_kl_loss: 99.0647 - val_false_loss: 13.5675 - val_true_loss: 1.2101\n",
      "Epoch 1033/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.2913 - reconstruction_loss: 1891.4365 - kl_loss: 100.9752 - false_loss: 0.0950 - true_loss: 1.1564 - val_loss: 6186.6250 - val_reconstruction_loss: 1896.8226 - val_kl_loss: 99.0645 - val_false_loss: 13.5658 - val_true_loss: 1.2100\n",
      "Epoch 1034/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.4175 - reconstruction_loss: 1891.0209 - kl_loss: 99.8934 - false_loss: 0.0950 - true_loss: 1.1564 - val_loss: 6186.1431 - val_reconstruction_loss: 1896.8221 - val_kl_loss: 99.0644 - val_false_loss: 13.5642 - val_true_loss: 1.2100\n",
      "Epoch 1035/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.9442 - reconstruction_loss: 1890.8610 - kl_loss: 99.5265 - false_loss: 0.0950 - true_loss: 1.1563 - val_loss: 6185.6499 - val_reconstruction_loss: 1896.8214 - val_kl_loss: 99.0651 - val_false_loss: 13.5626 - val_true_loss: 1.2099\n",
      "Epoch 1036/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0145 - reconstruction_loss: 1890.9111 - kl_loss: 100.8452 - false_loss: 0.0950 - true_loss: 1.1563 - val_loss: 6185.1548 - val_reconstruction_loss: 1896.8207 - val_kl_loss: 99.0652 - val_false_loss: 13.5610 - val_true_loss: 1.2099\n",
      "Epoch 1037/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.4610 - reconstruction_loss: 1890.9606 - kl_loss: 100.9206 - false_loss: 0.0950 - true_loss: 1.1562 - val_loss: 6184.6670 - val_reconstruction_loss: 1896.8199 - val_kl_loss: 99.0649 - val_false_loss: 13.5594 - val_true_loss: 1.2098\n",
      "Epoch 1038/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.2434 - reconstruction_loss: 1891.3949 - kl_loss: 100.8737 - false_loss: 0.0950 - true_loss: 1.1561 - val_loss: 6184.1694 - val_reconstruction_loss: 1896.8195 - val_kl_loss: 99.0645 - val_false_loss: 13.5577 - val_true_loss: 1.2098\n",
      "Epoch 1039/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.2350 - reconstruction_loss: 1891.3633 - kl_loss: 100.1108 - false_loss: 0.0950 - true_loss: 1.1561 - val_loss: 6183.6787 - val_reconstruction_loss: 1896.8190 - val_kl_loss: 99.0641 - val_false_loss: 13.5561 - val_true_loss: 1.2097\n",
      "Epoch 1040/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.9291 - reconstruction_loss: 1891.1844 - kl_loss: 99.8065 - false_loss: 0.0950 - true_loss: 1.1560 - val_loss: 6183.1982 - val_reconstruction_loss: 1896.8180 - val_kl_loss: 99.0647 - val_false_loss: 13.5545 - val_true_loss: 1.2097\n",
      "Epoch 1041/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2229.1332 - reconstruction_loss: 1890.8522 - kl_loss: 100.4877 - false_loss: 0.0950 - true_loss: 1.1560 - val_loss: 6182.7085 - val_reconstruction_loss: 1896.8176 - val_kl_loss: 99.0653 - val_false_loss: 13.5529 - val_true_loss: 1.2096\n",
      "Epoch 1042/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.5897 - reconstruction_loss: 1890.8302 - kl_loss: 101.6032 - false_loss: 0.0950 - true_loss: 1.1559 - val_loss: 6182.2188 - val_reconstruction_loss: 1896.8168 - val_kl_loss: 99.0656 - val_false_loss: 13.5513 - val_true_loss: 1.2096\n",
      "Epoch 1043/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.7726 - reconstruction_loss: 1890.7484 - kl_loss: 101.0884 - false_loss: 0.0950 - true_loss: 1.1559 - val_loss: 6181.7295 - val_reconstruction_loss: 1896.8160 - val_kl_loss: 99.0666 - val_false_loss: 13.5497 - val_true_loss: 1.2095\n",
      "Epoch 1044/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4371 - reconstruction_loss: 1890.6747 - kl_loss: 100.8637 - false_loss: 0.0950 - true_loss: 1.1558 - val_loss: 6181.2402 - val_reconstruction_loss: 1896.8153 - val_kl_loss: 99.0683 - val_false_loss: 13.5481 - val_true_loss: 1.2095\n",
      "Epoch 1045/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.8318 - reconstruction_loss: 1891.4191 - kl_loss: 101.3492 - false_loss: 0.0949 - true_loss: 1.1557 - val_loss: 6180.7441 - val_reconstruction_loss: 1896.8149 - val_kl_loss: 99.0694 - val_false_loss: 13.5464 - val_true_loss: 1.2094\n",
      "Epoch 1046/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.9121 - reconstruction_loss: 1891.2621 - kl_loss: 101.0676 - false_loss: 0.0949 - true_loss: 1.1557 - val_loss: 6180.2666 - val_reconstruction_loss: 1896.8142 - val_kl_loss: 99.0701 - val_false_loss: 13.5449 - val_true_loss: 1.2094\n",
      "Epoch 1047/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.2906 - reconstruction_loss: 1891.4279 - kl_loss: 101.3055 - false_loss: 0.0949 - true_loss: 1.1556 - val_loss: 6179.7837 - val_reconstruction_loss: 1896.8134 - val_kl_loss: 99.0712 - val_false_loss: 13.5433 - val_true_loss: 1.2093\n",
      "Epoch 1048/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.6462 - reconstruction_loss: 1890.9219 - kl_loss: 102.4892 - false_loss: 0.0949 - true_loss: 1.1556 - val_loss: 6179.2891 - val_reconstruction_loss: 1896.8130 - val_kl_loss: 99.0711 - val_false_loss: 13.5416 - val_true_loss: 1.2093\n",
      "Epoch 1049/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.6357 - reconstruction_loss: 1891.6415 - kl_loss: 101.5328 - false_loss: 0.0949 - true_loss: 1.1555 - val_loss: 6178.7998 - val_reconstruction_loss: 1896.8123 - val_kl_loss: 99.0710 - val_false_loss: 13.5400 - val_true_loss: 1.2092\n",
      "Epoch 1050/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.6627 - reconstruction_loss: 1891.5654 - kl_loss: 100.6741 - false_loss: 0.0949 - true_loss: 1.1554 - val_loss: 6178.3071 - val_reconstruction_loss: 1896.8116 - val_kl_loss: 99.0712 - val_false_loss: 13.5384 - val_true_loss: 1.2092\n",
      "Epoch 1051/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.5475 - reconstruction_loss: 1891.1949 - kl_loss: 100.7349 - false_loss: 0.0949 - true_loss: 1.1554 - val_loss: 6177.8198 - val_reconstruction_loss: 1896.8107 - val_kl_loss: 99.0711 - val_false_loss: 13.5368 - val_true_loss: 1.2091\n",
      "Epoch 1052/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.5997 - reconstruction_loss: 1890.9395 - kl_loss: 100.1986 - false_loss: 0.0949 - true_loss: 1.1553 - val_loss: 6177.3306 - val_reconstruction_loss: 1896.8103 - val_kl_loss: 99.0713 - val_false_loss: 13.5352 - val_true_loss: 1.2091\n",
      "Epoch 1053/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.5472 - reconstruction_loss: 1891.1923 - kl_loss: 100.2687 - false_loss: 0.0949 - true_loss: 1.1553 - val_loss: 6176.8481 - val_reconstruction_loss: 1896.8096 - val_kl_loss: 99.0721 - val_false_loss: 13.5336 - val_true_loss: 1.2090\n",
      "Epoch 1054/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.3541 - reconstruction_loss: 1891.1602 - kl_loss: 100.3301 - false_loss: 0.0949 - true_loss: 1.1552 - val_loss: 6176.3774 - val_reconstruction_loss: 1896.8088 - val_kl_loss: 99.0730 - val_false_loss: 13.5320 - val_true_loss: 1.2090\n",
      "Epoch 1055/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6028 - reconstruction_loss: 1890.9199 - kl_loss: 100.6479 - false_loss: 0.0949 - true_loss: 1.1552 - val_loss: 6175.8916 - val_reconstruction_loss: 1896.8083 - val_kl_loss: 99.0742 - val_false_loss: 13.5304 - val_true_loss: 1.2089\n",
      "Epoch 1056/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.9823 - reconstruction_loss: 1890.6837 - kl_loss: 101.2112 - false_loss: 0.0948 - true_loss: 1.1551 - val_loss: 6175.4053 - val_reconstruction_loss: 1896.8076 - val_kl_loss: 99.0749 - val_false_loss: 13.5288 - val_true_loss: 1.2089\n",
      "Epoch 1057/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.5602 - reconstruction_loss: 1891.1587 - kl_loss: 101.0940 - false_loss: 0.0948 - true_loss: 1.1551 - val_loss: 6174.9165 - val_reconstruction_loss: 1896.8069 - val_kl_loss: 99.0749 - val_false_loss: 13.5272 - val_true_loss: 1.2088\n",
      "Epoch 1058/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.8919 - reconstruction_loss: 1890.5248 - kl_loss: 101.3340 - false_loss: 0.0948 - true_loss: 1.1550 - val_loss: 6174.4316 - val_reconstruction_loss: 1896.8063 - val_kl_loss: 99.0751 - val_false_loss: 13.5256 - val_true_loss: 1.2088\n",
      "Epoch 1059/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4379 - reconstruction_loss: 1891.0365 - kl_loss: 99.8313 - false_loss: 0.0948 - true_loss: 1.1549 - val_loss: 6173.9512 - val_reconstruction_loss: 1896.8060 - val_kl_loss: 99.0769 - val_false_loss: 13.5240 - val_true_loss: 1.2087\n",
      "Epoch 1060/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.7755 - reconstruction_loss: 1891.8032 - kl_loss: 101.0136 - false_loss: 0.0948 - true_loss: 1.1549 - val_loss: 6173.4692 - val_reconstruction_loss: 1896.8053 - val_kl_loss: 99.0784 - val_false_loss: 13.5224 - val_true_loss: 1.2087\n",
      "Epoch 1061/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7523 - reconstruction_loss: 1891.2740 - kl_loss: 101.0674 - false_loss: 0.0948 - true_loss: 1.1548 - val_loss: 6172.9805 - val_reconstruction_loss: 1896.8046 - val_kl_loss: 99.0794 - val_false_loss: 13.5208 - val_true_loss: 1.2086\n",
      "Epoch 1062/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2489 - reconstruction_loss: 1891.0277 - kl_loss: 101.5466 - false_loss: 0.0948 - true_loss: 1.1548 - val_loss: 6172.4917 - val_reconstruction_loss: 1896.8038 - val_kl_loss: 99.0800 - val_false_loss: 13.5192 - val_true_loss: 1.2085\n",
      "Epoch 1063/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5951 - reconstruction_loss: 1890.6241 - kl_loss: 100.9760 - false_loss: 0.0948 - true_loss: 1.1547 - val_loss: 6172.0063 - val_reconstruction_loss: 1896.8030 - val_kl_loss: 99.0810 - val_false_loss: 13.5176 - val_true_loss: 1.2085\n",
      "Epoch 1064/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.9350 - reconstruction_loss: 1890.9528 - kl_loss: 100.8581 - false_loss: 0.0948 - true_loss: 1.1546 - val_loss: 6171.5161 - val_reconstruction_loss: 1896.8025 - val_kl_loss: 99.0825 - val_false_loss: 13.5160 - val_true_loss: 1.2084\n",
      "Epoch 1065/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.2661 - reconstruction_loss: 1890.9630 - kl_loss: 101.2620 - false_loss: 0.0948 - true_loss: 1.1546 - val_loss: 6171.0356 - val_reconstruction_loss: 1896.8018 - val_kl_loss: 99.0834 - val_false_loss: 13.5144 - val_true_loss: 1.2084\n",
      "Epoch 1066/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7930 - reconstruction_loss: 1890.9996 - kl_loss: 101.1114 - false_loss: 0.0948 - true_loss: 1.1545 - val_loss: 6170.5483 - val_reconstruction_loss: 1896.8011 - val_kl_loss: 99.0842 - val_false_loss: 13.5128 - val_true_loss: 1.2083\n",
      "Epoch 1067/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4937 - reconstruction_loss: 1890.9564 - kl_loss: 101.3580 - false_loss: 0.0948 - true_loss: 1.1545 - val_loss: 6170.0605 - val_reconstruction_loss: 1896.8004 - val_kl_loss: 99.0856 - val_false_loss: 13.5112 - val_true_loss: 1.2083\n",
      "Epoch 1068/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.5459 - reconstruction_loss: 1890.9762 - kl_loss: 100.2808 - false_loss: 0.0947 - true_loss: 1.1544 - val_loss: 6169.5771 - val_reconstruction_loss: 1896.7998 - val_kl_loss: 99.0864 - val_false_loss: 13.5096 - val_true_loss: 1.2082\n",
      "Epoch 1069/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.9250 - reconstruction_loss: 1890.7240 - kl_loss: 101.2558 - false_loss: 0.0947 - true_loss: 1.1544 - val_loss: 6169.0908 - val_reconstruction_loss: 1896.7991 - val_kl_loss: 99.0866 - val_false_loss: 13.5080 - val_true_loss: 1.2082\n",
      "Epoch 1070/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5245 - reconstruction_loss: 1890.8228 - kl_loss: 101.5274 - false_loss: 0.0947 - true_loss: 1.1543 - val_loss: 6168.6128 - val_reconstruction_loss: 1896.7985 - val_kl_loss: 99.0866 - val_false_loss: 13.5064 - val_true_loss: 1.2081\n",
      "Epoch 1071/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.3211 - reconstruction_loss: 1890.6913 - kl_loss: 101.0210 - false_loss: 0.0947 - true_loss: 1.1542 - val_loss: 6168.1279 - val_reconstruction_loss: 1896.7979 - val_kl_loss: 99.0869 - val_false_loss: 13.5048 - val_true_loss: 1.2081\n",
      "Epoch 1072/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.4941 - reconstruction_loss: 1890.8683 - kl_loss: 100.9094 - false_loss: 0.0947 - true_loss: 1.1542 - val_loss: 6167.6445 - val_reconstruction_loss: 1896.7971 - val_kl_loss: 99.0877 - val_false_loss: 13.5032 - val_true_loss: 1.2080\n",
      "Epoch 1073/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.8013 - reconstruction_loss: 1890.6473 - kl_loss: 99.9677 - false_loss: 0.0947 - true_loss: 1.1541 - val_loss: 6167.1631 - val_reconstruction_loss: 1896.7965 - val_kl_loss: 99.0878 - val_false_loss: 13.5016 - val_true_loss: 1.2080\n",
      "Epoch 1074/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0509 - reconstruction_loss: 1890.9757 - kl_loss: 99.3602 - false_loss: 0.0947 - true_loss: 1.1541 - val_loss: 6166.6841 - val_reconstruction_loss: 1896.7959 - val_kl_loss: 99.0880 - val_false_loss: 13.5001 - val_true_loss: 1.2079\n",
      "Epoch 1075/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.9267 - reconstruction_loss: 1892.3441 - kl_loss: 99.7980 - false_loss: 0.0947 - true_loss: 1.1540 - val_loss: 6166.2012 - val_reconstruction_loss: 1896.7954 - val_kl_loss: 99.0872 - val_false_loss: 13.4985 - val_true_loss: 1.2079\n",
      "Epoch 1076/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2259.8699 - reconstruction_loss: 1892.0366 - kl_loss: 98.2602 - false_loss: 0.0947 - true_loss: 1.1540 - val_loss: 6165.7124 - val_reconstruction_loss: 1896.7948 - val_kl_loss: 99.0880 - val_false_loss: 13.4968 - val_true_loss: 1.2079\n",
      "Epoch 1077/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.1496 - reconstruction_loss: 1891.3949 - kl_loss: 98.6254 - false_loss: 0.0947 - true_loss: 1.1540 - val_loss: 6165.2319 - val_reconstruction_loss: 1896.7941 - val_kl_loss: 99.0878 - val_false_loss: 13.4953 - val_true_loss: 1.2078\n",
      "Epoch 1078/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2259.4355 - reconstruction_loss: 1891.1385 - kl_loss: 97.9650 - false_loss: 0.0947 - true_loss: 1.1539 - val_loss: 6164.7393 - val_reconstruction_loss: 1896.7935 - val_kl_loss: 99.0879 - val_false_loss: 13.4936 - val_true_loss: 1.2078\n",
      "Epoch 1079/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.4610 - reconstruction_loss: 1890.8207 - kl_loss: 97.8597 - false_loss: 0.0946 - true_loss: 1.1539 - val_loss: 6164.2617 - val_reconstruction_loss: 1896.7927 - val_kl_loss: 99.0878 - val_false_loss: 13.4921 - val_true_loss: 1.2077\n",
      "Epoch 1080/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.9893 - reconstruction_loss: 1890.8363 - kl_loss: 98.6507 - false_loss: 0.0946 - true_loss: 1.1538 - val_loss: 6163.7798 - val_reconstruction_loss: 1896.7921 - val_kl_loss: 99.0877 - val_false_loss: 13.4905 - val_true_loss: 1.2077\n",
      "Epoch 1081/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.9326 - reconstruction_loss: 1890.9962 - kl_loss: 98.4096 - false_loss: 0.0946 - true_loss: 1.1538 - val_loss: 6163.2910 - val_reconstruction_loss: 1896.7914 - val_kl_loss: 99.0879 - val_false_loss: 13.4889 - val_true_loss: 1.2076\n",
      "Epoch 1082/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.8031 - reconstruction_loss: 1891.0352 - kl_loss: 99.0588 - false_loss: 0.0946 - true_loss: 1.1537 - val_loss: 6162.8203 - val_reconstruction_loss: 1896.7908 - val_kl_loss: 99.0883 - val_false_loss: 13.4873 - val_true_loss: 1.2076\n",
      "Epoch 1083/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.4247 - reconstruction_loss: 1891.1525 - kl_loss: 100.0134 - false_loss: 0.0946 - true_loss: 1.1536 - val_loss: 6162.3340 - val_reconstruction_loss: 1896.7900 - val_kl_loss: 99.0892 - val_false_loss: 13.4857 - val_true_loss: 1.2075\n",
      "Epoch 1084/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.9509 - reconstruction_loss: 1890.8837 - kl_loss: 100.6530 - false_loss: 0.0946 - true_loss: 1.1536 - val_loss: 6161.8472 - val_reconstruction_loss: 1896.7893 - val_kl_loss: 99.0892 - val_false_loss: 13.4841 - val_true_loss: 1.2075\n",
      "Epoch 1085/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0776 - reconstruction_loss: 1890.9849 - kl_loss: 100.7462 - false_loss: 0.0946 - true_loss: 1.1535 - val_loss: 6161.3594 - val_reconstruction_loss: 1896.7889 - val_kl_loss: 99.0897 - val_false_loss: 13.4825 - val_true_loss: 1.2074\n",
      "Epoch 1086/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2605 - reconstruction_loss: 1891.3688 - kl_loss: 101.0248 - false_loss: 0.0946 - true_loss: 1.1535 - val_loss: 6160.8823 - val_reconstruction_loss: 1896.7882 - val_kl_loss: 99.0907 - val_false_loss: 13.4809 - val_true_loss: 1.2074\n",
      "Epoch 1087/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.3535 - reconstruction_loss: 1890.9503 - kl_loss: 100.8163 - false_loss: 0.0946 - true_loss: 1.1534 - val_loss: 6160.3984 - val_reconstruction_loss: 1896.7875 - val_kl_loss: 99.0921 - val_false_loss: 13.4793 - val_true_loss: 1.2073\n",
      "Epoch 1088/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.3581 - reconstruction_loss: 1890.9762 - kl_loss: 100.5615 - false_loss: 0.0946 - true_loss: 1.1533 - val_loss: 6159.9175 - val_reconstruction_loss: 1896.7870 - val_kl_loss: 99.0936 - val_false_loss: 13.4777 - val_true_loss: 1.2073\n",
      "Epoch 1089/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.9209 - reconstruction_loss: 1890.9315 - kl_loss: 100.6937 - false_loss: 0.0946 - true_loss: 1.1533 - val_loss: 6159.4355 - val_reconstruction_loss: 1896.7863 - val_kl_loss: 99.0945 - val_false_loss: 13.4761 - val_true_loss: 1.2072\n",
      "Epoch 1090/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.3540 - reconstruction_loss: 1891.1611 - kl_loss: 100.9069 - false_loss: 0.0946 - true_loss: 1.1532 - val_loss: 6158.9492 - val_reconstruction_loss: 1896.7855 - val_kl_loss: 99.0951 - val_false_loss: 13.4745 - val_true_loss: 1.2072\n",
      "Epoch 1091/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.6624 - reconstruction_loss: 1890.8403 - kl_loss: 100.7360 - false_loss: 0.0945 - true_loss: 1.1532 - val_loss: 6158.4653 - val_reconstruction_loss: 1896.7848 - val_kl_loss: 99.0958 - val_false_loss: 13.4729 - val_true_loss: 1.2071\n",
      "Epoch 1092/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2795 - reconstruction_loss: 1890.8773 - kl_loss: 99.7892 - false_loss: 0.0945 - true_loss: 1.1531 - val_loss: 6157.9897 - val_reconstruction_loss: 1896.7842 - val_kl_loss: 99.0970 - val_false_loss: 13.4714 - val_true_loss: 1.2071\n",
      "Epoch 1093/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2228.1920 - reconstruction_loss: 1890.5780 - kl_loss: 100.7573 - false_loss: 0.0945 - true_loss: 1.1531 - val_loss: 6157.5112 - val_reconstruction_loss: 1896.7834 - val_kl_loss: 99.0979 - val_false_loss: 13.4698 - val_true_loss: 1.2070\n",
      "Epoch 1094/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3109 - reconstruction_loss: 1890.8436 - kl_loss: 101.7783 - false_loss: 0.0945 - true_loss: 1.1530 - val_loss: 6157.0303 - val_reconstruction_loss: 1896.7827 - val_kl_loss: 99.0987 - val_false_loss: 13.4682 - val_true_loss: 1.2070\n",
      "Epoch 1095/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.5864 - reconstruction_loss: 1890.4974 - kl_loss: 101.6550 - false_loss: 0.0945 - true_loss: 1.1529 - val_loss: 6156.5469 - val_reconstruction_loss: 1896.7821 - val_kl_loss: 99.0991 - val_false_loss: 13.4666 - val_true_loss: 1.2069\n",
      "Epoch 1096/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2161 - reconstruction_loss: 1891.4951 - kl_loss: 101.1416 - false_loss: 0.0945 - true_loss: 1.1529 - val_loss: 6156.0640 - val_reconstruction_loss: 1896.7816 - val_kl_loss: 99.0996 - val_false_loss: 13.4650 - val_true_loss: 1.2069\n",
      "Epoch 1097/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8181 - reconstruction_loss: 1890.7172 - kl_loss: 101.5658 - false_loss: 0.0945 - true_loss: 1.1528 - val_loss: 6155.5767 - val_reconstruction_loss: 1896.7808 - val_kl_loss: 99.0995 - val_false_loss: 13.4634 - val_true_loss: 1.2068\n",
      "Epoch 1098/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.1052 - reconstruction_loss: 1891.2242 - kl_loss: 101.4538 - false_loss: 0.0945 - true_loss: 1.1528 - val_loss: 6155.0962 - val_reconstruction_loss: 1896.7803 - val_kl_loss: 99.0999 - val_false_loss: 13.4618 - val_true_loss: 1.2068\n",
      "Epoch 1099/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6910 - reconstruction_loss: 1891.4888 - kl_loss: 101.2279 - false_loss: 0.0945 - true_loss: 1.1527 - val_loss: 6154.6250 - val_reconstruction_loss: 1896.7798 - val_kl_loss: 99.1002 - val_false_loss: 13.4603 - val_true_loss: 1.2067\n",
      "Epoch 1100/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.3837 - reconstruction_loss: 1891.1476 - kl_loss: 101.3708 - false_loss: 0.0945 - true_loss: 1.1526 - val_loss: 6154.1411 - val_reconstruction_loss: 1896.7791 - val_kl_loss: 99.0997 - val_false_loss: 13.4587 - val_true_loss: 1.2067\n",
      "Epoch 1101/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.2906 - reconstruction_loss: 1891.3081 - kl_loss: 101.4016 - false_loss: 0.0945 - true_loss: 1.1526 - val_loss: 6153.6694 - val_reconstruction_loss: 1896.7783 - val_kl_loss: 99.0992 - val_false_loss: 13.4571 - val_true_loss: 1.2066\n",
      "Epoch 1102/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.0930 - reconstruction_loss: 1890.6735 - kl_loss: 101.5439 - false_loss: 0.0944 - true_loss: 1.1525 - val_loss: 6153.1890 - val_reconstruction_loss: 1896.7780 - val_kl_loss: 99.0989 - val_false_loss: 13.4556 - val_true_loss: 1.2066\n",
      "Epoch 1103/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.7878 - reconstruction_loss: 1891.2296 - kl_loss: 100.8046 - false_loss: 0.0944 - true_loss: 1.1525 - val_loss: 6152.7148 - val_reconstruction_loss: 1896.7772 - val_kl_loss: 99.0988 - val_false_loss: 13.4540 - val_true_loss: 1.2065\n",
      "Epoch 1104/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.4557 - reconstruction_loss: 1890.7783 - kl_loss: 100.8644 - false_loss: 0.0944 - true_loss: 1.1524 - val_loss: 6152.2319 - val_reconstruction_loss: 1896.7765 - val_kl_loss: 99.0984 - val_false_loss: 13.4524 - val_true_loss: 1.2065\n",
      "Epoch 1105/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.8182 - reconstruction_loss: 1891.0946 - kl_loss: 100.5599 - false_loss: 0.0944 - true_loss: 1.1524 - val_loss: 6151.7466 - val_reconstruction_loss: 1896.7760 - val_kl_loss: 99.0985 - val_false_loss: 13.4508 - val_true_loss: 1.2064\n",
      "Epoch 1106/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8103 - reconstruction_loss: 1890.8925 - kl_loss: 100.6858 - false_loss: 0.0944 - true_loss: 1.1523 - val_loss: 6151.2720 - val_reconstruction_loss: 1896.7753 - val_kl_loss: 99.0992 - val_false_loss: 13.4492 - val_true_loss: 1.2064\n",
      "Epoch 1107/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.6468 - reconstruction_loss: 1890.7638 - kl_loss: 101.5161 - false_loss: 0.0944 - true_loss: 1.1523 - val_loss: 6150.7925 - val_reconstruction_loss: 1896.7747 - val_kl_loss: 99.0998 - val_false_loss: 13.4477 - val_true_loss: 1.2063\n",
      "Epoch 1108/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6579 - reconstruction_loss: 1890.8770 - kl_loss: 100.8917 - false_loss: 0.0944 - true_loss: 1.1522 - val_loss: 6150.3105 - val_reconstruction_loss: 1896.7742 - val_kl_loss: 99.1000 - val_false_loss: 13.4461 - val_true_loss: 1.2063\n",
      "Epoch 1109/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.2633 - reconstruction_loss: 1890.7080 - kl_loss: 101.0878 - false_loss: 0.0944 - true_loss: 1.1521 - val_loss: 6149.8286 - val_reconstruction_loss: 1896.7734 - val_kl_loss: 99.1007 - val_false_loss: 13.4445 - val_true_loss: 1.2062\n",
      "Epoch 1110/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2281 - reconstruction_loss: 1890.9684 - kl_loss: 100.8668 - false_loss: 0.0944 - true_loss: 1.1521 - val_loss: 6149.3530 - val_reconstruction_loss: 1896.7728 - val_kl_loss: 99.1024 - val_false_loss: 13.4429 - val_true_loss: 1.2062\n",
      "Epoch 1111/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3336 - reconstruction_loss: 1890.9922 - kl_loss: 101.5300 - false_loss: 0.0944 - true_loss: 1.1520 - val_loss: 6148.8740 - val_reconstruction_loss: 1896.7722 - val_kl_loss: 99.1034 - val_false_loss: 13.4413 - val_true_loss: 1.2061\n",
      "Epoch 1112/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2836 - reconstruction_loss: 1890.6605 - kl_loss: 102.2928 - false_loss: 0.0944 - true_loss: 1.1520 - val_loss: 6148.3955 - val_reconstruction_loss: 1896.7715 - val_kl_loss: 99.1036 - val_false_loss: 13.4398 - val_true_loss: 1.2061\n",
      "Epoch 1113/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.3365 - reconstruction_loss: 1890.6309 - kl_loss: 101.1087 - false_loss: 0.0944 - true_loss: 1.1519 - val_loss: 6147.9150 - val_reconstruction_loss: 1896.7709 - val_kl_loss: 99.1039 - val_false_loss: 13.4382 - val_true_loss: 1.2060\n",
      "Epoch 1114/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.2778 - reconstruction_loss: 1890.7549 - kl_loss: 101.2855 - false_loss: 0.0943 - true_loss: 1.1519 - val_loss: 6147.4346 - val_reconstruction_loss: 1896.7701 - val_kl_loss: 99.1039 - val_false_loss: 13.4366 - val_true_loss: 1.2060\n",
      "Epoch 1115/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1391 - reconstruction_loss: 1891.0465 - kl_loss: 100.6400 - false_loss: 0.0943 - true_loss: 1.1518 - val_loss: 6146.9595 - val_reconstruction_loss: 1896.7697 - val_kl_loss: 99.1039 - val_false_loss: 13.4350 - val_true_loss: 1.2059\n",
      "Epoch 1116/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5513 - reconstruction_loss: 1890.9116 - kl_loss: 100.6298 - false_loss: 0.0943 - true_loss: 1.1517 - val_loss: 6146.4766 - val_reconstruction_loss: 1896.7689 - val_kl_loss: 99.1040 - val_false_loss: 13.4334 - val_true_loss: 1.2059\n",
      "Epoch 1117/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.8481 - reconstruction_loss: 1891.0973 - kl_loss: 100.6074 - false_loss: 0.0943 - true_loss: 1.1517 - val_loss: 6145.9971 - val_reconstruction_loss: 1896.7682 - val_kl_loss: 99.1041 - val_false_loss: 13.4318 - val_true_loss: 1.2058\n",
      "Epoch 1118/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.4693 - reconstruction_loss: 1891.1191 - kl_loss: 100.7415 - false_loss: 0.0943 - true_loss: 1.1516 - val_loss: 6145.5142 - val_reconstruction_loss: 1896.7675 - val_kl_loss: 99.1044 - val_false_loss: 13.4303 - val_true_loss: 1.2058\n",
      "Epoch 1119/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.3688 - reconstruction_loss: 1890.6426 - kl_loss: 100.8621 - false_loss: 0.0943 - true_loss: 1.1516 - val_loss: 6145.0425 - val_reconstruction_loss: 1896.7668 - val_kl_loss: 99.1045 - val_false_loss: 13.4287 - val_true_loss: 1.2057\n",
      "Epoch 1120/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8063 - reconstruction_loss: 1890.8043 - kl_loss: 101.3868 - false_loss: 0.0943 - true_loss: 1.1515 - val_loss: 6144.5591 - val_reconstruction_loss: 1896.7662 - val_kl_loss: 99.1041 - val_false_loss: 13.4271 - val_true_loss: 1.2057\n",
      "Epoch 1121/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6145 - reconstruction_loss: 1890.9374 - kl_loss: 98.9576 - false_loss: 0.0943 - true_loss: 1.1515 - val_loss: 6144.0815 - val_reconstruction_loss: 1896.7656 - val_kl_loss: 99.1049 - val_false_loss: 13.4255 - val_true_loss: 1.2056\n",
      "Epoch 1122/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8558 - reconstruction_loss: 1891.3325 - kl_loss: 100.5178 - false_loss: 0.0943 - true_loss: 1.1514 - val_loss: 6143.6025 - val_reconstruction_loss: 1896.7649 - val_kl_loss: 99.1059 - val_false_loss: 13.4239 - val_true_loss: 1.2056\n",
      "Epoch 1123/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1400 - reconstruction_loss: 1890.7094 - kl_loss: 101.7314 - false_loss: 0.0943 - true_loss: 1.1514 - val_loss: 6143.1270 - val_reconstruction_loss: 1896.7644 - val_kl_loss: 99.1057 - val_false_loss: 13.4224 - val_true_loss: 1.2055\n",
      "Epoch 1124/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0359 - reconstruction_loss: 1890.7104 - kl_loss: 100.6929 - false_loss: 0.0943 - true_loss: 1.1513 - val_loss: 6142.6450 - val_reconstruction_loss: 1896.7638 - val_kl_loss: 99.1060 - val_false_loss: 13.4208 - val_true_loss: 1.2055\n",
      "Epoch 1125/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.1317 - reconstruction_loss: 1891.0009 - kl_loss: 99.8540 - false_loss: 0.0942 - true_loss: 1.1512 - val_loss: 6142.1660 - val_reconstruction_loss: 1896.7631 - val_kl_loss: 99.1068 - val_false_loss: 13.4192 - val_true_loss: 1.2054\n",
      "Epoch 1126/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0051 - reconstruction_loss: 1890.8081 - kl_loss: 101.4132 - false_loss: 0.0942 - true_loss: 1.1512 - val_loss: 6141.6812 - val_reconstruction_loss: 1896.7623 - val_kl_loss: 99.1071 - val_false_loss: 13.4176 - val_true_loss: 1.2054\n",
      "Epoch 1127/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9583 - reconstruction_loss: 1890.5511 - kl_loss: 101.3812 - false_loss: 0.0942 - true_loss: 1.1511 - val_loss: 6141.1992 - val_reconstruction_loss: 1896.7617 - val_kl_loss: 99.1074 - val_false_loss: 13.4160 - val_true_loss: 1.2053\n",
      "Epoch 1128/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9825 - reconstruction_loss: 1891.0000 - kl_loss: 99.9500 - false_loss: 0.0942 - true_loss: 1.1511 - val_loss: 6140.7188 - val_reconstruction_loss: 1896.7612 - val_kl_loss: 99.1084 - val_false_loss: 13.4144 - val_true_loss: 1.2053\n",
      "Epoch 1129/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2270 - reconstruction_loss: 1890.9713 - kl_loss: 101.7858 - false_loss: 0.0942 - true_loss: 1.1510 - val_loss: 6140.2397 - val_reconstruction_loss: 1896.7606 - val_kl_loss: 99.1093 - val_false_loss: 13.4129 - val_true_loss: 1.2052\n",
      "Epoch 1130/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0224 - reconstruction_loss: 1890.4794 - kl_loss: 100.3068 - false_loss: 0.0942 - true_loss: 1.1510 - val_loss: 6139.7617 - val_reconstruction_loss: 1896.7600 - val_kl_loss: 99.1101 - val_false_loss: 13.4113 - val_true_loss: 1.2052\n",
      "Epoch 1131/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.9966 - reconstruction_loss: 1890.9678 - kl_loss: 101.5395 - false_loss: 0.0942 - true_loss: 1.1509 - val_loss: 6139.2793 - val_reconstruction_loss: 1896.7593 - val_kl_loss: 99.1106 - val_false_loss: 13.4097 - val_true_loss: 1.2051\n",
      "Epoch 1132/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.9619 - reconstruction_loss: 1891.6849 - kl_loss: 102.1589 - false_loss: 0.0942 - true_loss: 1.1508 - val_loss: 6138.8071 - val_reconstruction_loss: 1896.7585 - val_kl_loss: 99.1108 - val_false_loss: 13.4081 - val_true_loss: 1.2051\n",
      "Epoch 1133/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2255 - reconstruction_loss: 1891.4103 - kl_loss: 101.4975 - false_loss: 0.0942 - true_loss: 1.1508 - val_loss: 6138.3262 - val_reconstruction_loss: 1896.7581 - val_kl_loss: 99.1105 - val_false_loss: 13.4066 - val_true_loss: 1.2050\n",
      "Epoch 1134/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.8467 - reconstruction_loss: 1890.7744 - kl_loss: 101.4315 - false_loss: 0.0942 - true_loss: 1.1507 - val_loss: 6137.8481 - val_reconstruction_loss: 1896.7574 - val_kl_loss: 99.1106 - val_false_loss: 13.4050 - val_true_loss: 1.2050\n",
      "Epoch 1135/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.4804 - reconstruction_loss: 1890.8496 - kl_loss: 101.6538 - false_loss: 0.0942 - true_loss: 1.1507 - val_loss: 6137.3760 - val_reconstruction_loss: 1896.7568 - val_kl_loss: 99.1110 - val_false_loss: 13.4034 - val_true_loss: 1.2049\n",
      "Epoch 1136/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8166 - reconstruction_loss: 1890.8794 - kl_loss: 100.5093 - false_loss: 0.0942 - true_loss: 1.1506 - val_loss: 6136.8955 - val_reconstruction_loss: 1896.7561 - val_kl_loss: 99.1126 - val_false_loss: 13.4018 - val_true_loss: 1.2049\n",
      "Epoch 1137/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.5973 - reconstruction_loss: 1890.6869 - kl_loss: 100.8550 - false_loss: 0.0941 - true_loss: 1.1506 - val_loss: 6136.4224 - val_reconstruction_loss: 1896.7555 - val_kl_loss: 99.1127 - val_false_loss: 13.4003 - val_true_loss: 1.2048\n",
      "Epoch 1138/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.5054 - reconstruction_loss: 1891.3666 - kl_loss: 101.0535 - false_loss: 0.0941 - true_loss: 1.1505 - val_loss: 6135.9487 - val_reconstruction_loss: 1896.7550 - val_kl_loss: 99.1140 - val_false_loss: 13.3987 - val_true_loss: 1.2048\n",
      "Epoch 1139/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.7343 - reconstruction_loss: 1891.0049 - kl_loss: 99.7530 - false_loss: 0.0941 - true_loss: 1.1505 - val_loss: 6135.4819 - val_reconstruction_loss: 1896.7543 - val_kl_loss: 99.1148 - val_false_loss: 13.3972 - val_true_loss: 1.2047\n",
      "Epoch 1140/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.3425 - reconstruction_loss: 1890.6298 - kl_loss: 99.9229 - false_loss: 0.0941 - true_loss: 1.1504 - val_loss: 6135.0049 - val_reconstruction_loss: 1896.7537 - val_kl_loss: 99.1167 - val_false_loss: 13.3956 - val_true_loss: 1.2047\n",
      "Epoch 1141/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.7582 - reconstruction_loss: 1890.8970 - kl_loss: 100.6520 - false_loss: 0.0941 - true_loss: 1.1503 - val_loss: 6134.5312 - val_reconstruction_loss: 1896.7531 - val_kl_loss: 99.1178 - val_false_loss: 13.3940 - val_true_loss: 1.2046\n",
      "Epoch 1142/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.0238 - reconstruction_loss: 1891.6288 - kl_loss: 100.1217 - false_loss: 0.0941 - true_loss: 1.1503 - val_loss: 6134.0527 - val_reconstruction_loss: 1896.7523 - val_kl_loss: 99.1186 - val_false_loss: 13.3924 - val_true_loss: 1.2046\n",
      "Epoch 1143/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.5033 - reconstruction_loss: 1891.2106 - kl_loss: 101.4028 - false_loss: 0.0941 - true_loss: 1.1502 - val_loss: 6133.5767 - val_reconstruction_loss: 1896.7518 - val_kl_loss: 99.1189 - val_false_loss: 13.3909 - val_true_loss: 1.2045\n",
      "Epoch 1144/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7357 - reconstruction_loss: 1890.9637 - kl_loss: 101.3464 - false_loss: 0.0941 - true_loss: 1.1502 - val_loss: 6133.1050 - val_reconstruction_loss: 1896.7511 - val_kl_loss: 99.1197 - val_false_loss: 13.3893 - val_true_loss: 1.2045\n",
      "Epoch 1145/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2225.1396 - reconstruction_loss: 1891.0414 - kl_loss: 101.3458 - false_loss: 0.0941 - true_loss: 1.1501 - val_loss: 6132.6309 - val_reconstruction_loss: 1896.7505 - val_kl_loss: 99.1203 - val_false_loss: 13.3878 - val_true_loss: 1.2044\n",
      "Epoch 1146/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.8962 - reconstruction_loss: 1890.4481 - kl_loss: 101.5533 - false_loss: 0.0941 - true_loss: 1.1501 - val_loss: 6132.1528 - val_reconstruction_loss: 1896.7498 - val_kl_loss: 99.1202 - val_false_loss: 13.3862 - val_true_loss: 1.2044\n",
      "Epoch 1147/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.6593 - reconstruction_loss: 1891.1478 - kl_loss: 101.4389 - false_loss: 0.0941 - true_loss: 1.1500 - val_loss: 6131.6797 - val_reconstruction_loss: 1896.7491 - val_kl_loss: 99.1205 - val_false_loss: 13.3846 - val_true_loss: 1.2043\n",
      "Epoch 1148/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.3759 - reconstruction_loss: 1890.9166 - kl_loss: 101.0575 - false_loss: 0.0941 - true_loss: 1.1499 - val_loss: 6131.2036 - val_reconstruction_loss: 1896.7484 - val_kl_loss: 99.1213 - val_false_loss: 13.3831 - val_true_loss: 1.2043\n",
      "Epoch 1149/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4942 - reconstruction_loss: 1891.1754 - kl_loss: 100.1615 - false_loss: 0.0940 - true_loss: 1.1499 - val_loss: 6130.7363 - val_reconstruction_loss: 1896.7479 - val_kl_loss: 99.1228 - val_false_loss: 13.3815 - val_true_loss: 1.2042\n",
      "Epoch 1150/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.8325 - reconstruction_loss: 1891.2334 - kl_loss: 101.2704 - false_loss: 0.0940 - true_loss: 1.1498 - val_loss: 6130.2588 - val_reconstruction_loss: 1896.7473 - val_kl_loss: 99.1232 - val_false_loss: 13.3799 - val_true_loss: 1.2042\n",
      "Epoch 1151/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.8638 - reconstruction_loss: 1890.8491 - kl_loss: 101.4964 - false_loss: 0.0940 - true_loss: 1.1498 - val_loss: 6129.7852 - val_reconstruction_loss: 1896.7467 - val_kl_loss: 99.1233 - val_false_loss: 13.3784 - val_true_loss: 1.2041\n",
      "Epoch 1152/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7075 - reconstruction_loss: 1890.8705 - kl_loss: 100.6091 - false_loss: 0.0940 - true_loss: 1.1497 - val_loss: 6129.3140 - val_reconstruction_loss: 1896.7460 - val_kl_loss: 99.1244 - val_false_loss: 13.3768 - val_true_loss: 1.2041\n",
      "Epoch 1153/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3459 - reconstruction_loss: 1890.4238 - kl_loss: 100.8256 - false_loss: 0.0940 - true_loss: 1.1497 - val_loss: 6128.8442 - val_reconstruction_loss: 1896.7454 - val_kl_loss: 99.1263 - val_false_loss: 13.3753 - val_true_loss: 1.2040\n",
      "Epoch 1154/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.0389 - reconstruction_loss: 1890.9757 - kl_loss: 101.8342 - false_loss: 0.0940 - true_loss: 1.1496 - val_loss: 6128.3667 - val_reconstruction_loss: 1896.7449 - val_kl_loss: 99.1271 - val_false_loss: 13.3737 - val_true_loss: 1.2040\n",
      "Epoch 1155/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.4605 - reconstruction_loss: 1891.3060 - kl_loss: 101.4796 - false_loss: 0.0940 - true_loss: 1.1496 - val_loss: 6127.8950 - val_reconstruction_loss: 1896.7443 - val_kl_loss: 99.1274 - val_false_loss: 13.3721 - val_true_loss: 1.2039\n",
      "Epoch 1156/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.6377 - reconstruction_loss: 1891.1650 - kl_loss: 101.4767 - false_loss: 0.0940 - true_loss: 1.1495 - val_loss: 6127.4199 - val_reconstruction_loss: 1896.7439 - val_kl_loss: 99.1279 - val_false_loss: 13.3706 - val_true_loss: 1.2039\n",
      "Epoch 1157/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.3417 - reconstruction_loss: 1890.5387 - kl_loss: 101.0445 - false_loss: 0.0940 - true_loss: 1.1494 - val_loss: 6126.9482 - val_reconstruction_loss: 1896.7432 - val_kl_loss: 99.1286 - val_false_loss: 13.3690 - val_true_loss: 1.2038\n",
      "Epoch 1158/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.2745 - reconstruction_loss: 1890.5444 - kl_loss: 100.8826 - false_loss: 0.0940 - true_loss: 1.1494 - val_loss: 6126.4731 - val_reconstruction_loss: 1896.7424 - val_kl_loss: 99.1291 - val_false_loss: 13.3674 - val_true_loss: 1.2038\n",
      "Epoch 1159/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.9733 - reconstruction_loss: 1890.6683 - kl_loss: 101.8585 - false_loss: 0.0940 - true_loss: 1.1493 - val_loss: 6126.0039 - val_reconstruction_loss: 1896.7418 - val_kl_loss: 99.1291 - val_false_loss: 13.3659 - val_true_loss: 1.2037\n",
      "Epoch 1160/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.0737 - reconstruction_loss: 1890.8663 - kl_loss: 100.9416 - false_loss: 0.0939 - true_loss: 1.1493 - val_loss: 6125.5312 - val_reconstruction_loss: 1896.7413 - val_kl_loss: 99.1300 - val_false_loss: 13.3643 - val_true_loss: 1.2037\n",
      "Epoch 1161/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.3771 - reconstruction_loss: 1890.8275 - kl_loss: 101.0992 - false_loss: 0.0939 - true_loss: 1.1492 - val_loss: 6125.0615 - val_reconstruction_loss: 1896.7406 - val_kl_loss: 99.1308 - val_false_loss: 13.3628 - val_true_loss: 1.2036\n",
      "Epoch 1162/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7578 - reconstruction_loss: 1891.2104 - kl_loss: 101.1843 - false_loss: 0.0939 - true_loss: 1.1492 - val_loss: 6124.5859 - val_reconstruction_loss: 1896.7399 - val_kl_loss: 99.1321 - val_false_loss: 13.3612 - val_true_loss: 1.2036\n",
      "Epoch 1163/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4076 - reconstruction_loss: 1890.9010 - kl_loss: 101.7580 - false_loss: 0.0939 - true_loss: 1.1491 - val_loss: 6124.1128 - val_reconstruction_loss: 1896.7393 - val_kl_loss: 99.1335 - val_false_loss: 13.3597 - val_true_loss: 1.2035\n",
      "Epoch 1164/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0569 - reconstruction_loss: 1891.0135 - kl_loss: 101.2645 - false_loss: 0.0939 - true_loss: 1.1490 - val_loss: 6123.6357 - val_reconstruction_loss: 1896.7388 - val_kl_loss: 99.1351 - val_false_loss: 13.3581 - val_true_loss: 1.2035\n",
      "Epoch 1165/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.0106 - reconstruction_loss: 1891.2549 - kl_loss: 101.5042 - false_loss: 0.0939 - true_loss: 1.1490 - val_loss: 6123.1685 - val_reconstruction_loss: 1896.7380 - val_kl_loss: 99.1366 - val_false_loss: 13.3565 - val_true_loss: 1.2034\n",
      "Epoch 1166/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.1606 - reconstruction_loss: 1890.7906 - kl_loss: 100.6961 - false_loss: 0.0939 - true_loss: 1.1489 - val_loss: 6122.6938 - val_reconstruction_loss: 1896.7373 - val_kl_loss: 99.1381 - val_false_loss: 13.3550 - val_true_loss: 1.2034\n",
      "Epoch 1167/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4251 - reconstruction_loss: 1890.4976 - kl_loss: 101.6221 - false_loss: 0.0939 - true_loss: 1.1489 - val_loss: 6122.2310 - val_reconstruction_loss: 1896.7367 - val_kl_loss: 99.1395 - val_false_loss: 13.3534 - val_true_loss: 1.2033\n",
      "Epoch 1168/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.2407 - reconstruction_loss: 1890.5973 - kl_loss: 101.8239 - false_loss: 0.0939 - true_loss: 1.1488 - val_loss: 6121.7588 - val_reconstruction_loss: 1896.7360 - val_kl_loss: 99.1409 - val_false_loss: 13.3519 - val_true_loss: 1.2033\n",
      "Epoch 1169/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5718 - reconstruction_loss: 1891.6371 - kl_loss: 100.9131 - false_loss: 0.0939 - true_loss: 1.1488 - val_loss: 6121.2856 - val_reconstruction_loss: 1896.7352 - val_kl_loss: 99.1425 - val_false_loss: 13.3503 - val_true_loss: 1.2032\n",
      "Epoch 1170/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.0208 - reconstruction_loss: 1891.0575 - kl_loss: 101.3081 - false_loss: 0.0939 - true_loss: 1.1487 - val_loss: 6120.8164 - val_reconstruction_loss: 1896.7345 - val_kl_loss: 99.1435 - val_false_loss: 13.3488 - val_true_loss: 1.2032\n",
      "Epoch 1171/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0519 - reconstruction_loss: 1890.7568 - kl_loss: 101.4080 - false_loss: 0.0939 - true_loss: 1.1487 - val_loss: 6120.3423 - val_reconstruction_loss: 1896.7340 - val_kl_loss: 99.1440 - val_false_loss: 13.3472 - val_true_loss: 1.2031\n",
      "Epoch 1172/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.4213 - reconstruction_loss: 1890.5541 - kl_loss: 101.5628 - false_loss: 0.0938 - true_loss: 1.1486 - val_loss: 6119.8647 - val_reconstruction_loss: 1896.7334 - val_kl_loss: 99.1441 - val_false_loss: 13.3456 - val_true_loss: 1.2031\n",
      "Epoch 1173/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.9003 - reconstruction_loss: 1890.8510 - kl_loss: 100.9578 - false_loss: 0.0938 - true_loss: 1.1485 - val_loss: 6119.3955 - val_reconstruction_loss: 1896.7327 - val_kl_loss: 99.1450 - val_false_loss: 13.3441 - val_true_loss: 1.2030\n",
      "Epoch 1174/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5539 - reconstruction_loss: 1890.4316 - kl_loss: 101.9051 - false_loss: 0.0938 - true_loss: 1.1485 - val_loss: 6118.9229 - val_reconstruction_loss: 1896.7319 - val_kl_loss: 99.1459 - val_false_loss: 13.3425 - val_true_loss: 1.2030\n",
      "Epoch 1175/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.3036 - reconstruction_loss: 1891.4965 - kl_loss: 100.2662 - false_loss: 0.0938 - true_loss: 1.1484 - val_loss: 6118.4517 - val_reconstruction_loss: 1896.7314 - val_kl_loss: 99.1472 - val_false_loss: 13.3410 - val_true_loss: 1.2029\n",
      "Epoch 1176/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0208 - reconstruction_loss: 1890.7900 - kl_loss: 102.0661 - false_loss: 0.0938 - true_loss: 1.1484 - val_loss: 6117.9844 - val_reconstruction_loss: 1896.7308 - val_kl_loss: 99.1488 - val_false_loss: 13.3394 - val_true_loss: 1.2029\n",
      "Epoch 1177/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1201 - reconstruction_loss: 1891.0260 - kl_loss: 101.3887 - false_loss: 0.0938 - true_loss: 1.1483 - val_loss: 6117.5107 - val_reconstruction_loss: 1896.7301 - val_kl_loss: 99.1501 - val_false_loss: 13.3379 - val_true_loss: 1.2028\n",
      "Epoch 1178/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.5772 - reconstruction_loss: 1891.3309 - kl_loss: 101.2999 - false_loss: 0.0938 - true_loss: 1.1483 - val_loss: 6117.0493 - val_reconstruction_loss: 1896.7294 - val_kl_loss: 99.1518 - val_false_loss: 13.3363 - val_true_loss: 1.2028\n",
      "Epoch 1179/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.4942 - reconstruction_loss: 1891.1152 - kl_loss: 100.7392 - false_loss: 0.0938 - true_loss: 1.1482 - val_loss: 6116.5786 - val_reconstruction_loss: 1896.7290 - val_kl_loss: 99.1528 - val_false_loss: 13.3348 - val_true_loss: 1.2027\n",
      "Epoch 1180/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.6436 - reconstruction_loss: 1891.3695 - kl_loss: 101.1679 - false_loss: 0.0938 - true_loss: 1.1482 - val_loss: 6116.1113 - val_reconstruction_loss: 1896.7283 - val_kl_loss: 99.1525 - val_false_loss: 13.3332 - val_true_loss: 1.2027\n",
      "Epoch 1181/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.9611 - reconstruction_loss: 1891.3138 - kl_loss: 100.6066 - false_loss: 0.0938 - true_loss: 1.1481 - val_loss: 6115.6406 - val_reconstruction_loss: 1896.7277 - val_kl_loss: 99.1525 - val_false_loss: 13.3317 - val_true_loss: 1.2026\n",
      "Epoch 1182/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.1680 - reconstruction_loss: 1890.5449 - kl_loss: 100.9472 - false_loss: 0.0938 - true_loss: 1.1480 - val_loss: 6115.1636 - val_reconstruction_loss: 1896.7269 - val_kl_loss: 99.1535 - val_false_loss: 13.3301 - val_true_loss: 1.2026\n",
      "Epoch 1183/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7043 - reconstruction_loss: 1890.8007 - kl_loss: 100.9035 - false_loss: 0.0937 - true_loss: 1.1480 - val_loss: 6114.6968 - val_reconstruction_loss: 1896.7264 - val_kl_loss: 99.1536 - val_false_loss: 13.3286 - val_true_loss: 1.2025\n",
      "Epoch 1184/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0580 - reconstruction_loss: 1891.0028 - kl_loss: 101.0028 - false_loss: 0.0937 - true_loss: 1.1479 - val_loss: 6114.2222 - val_reconstruction_loss: 1896.7257 - val_kl_loss: 99.1542 - val_false_loss: 13.3270 - val_true_loss: 1.2025\n",
      "Epoch 1185/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0181 - reconstruction_loss: 1890.8667 - kl_loss: 100.9711 - false_loss: 0.0937 - true_loss: 1.1479 - val_loss: 6113.7500 - val_reconstruction_loss: 1896.7251 - val_kl_loss: 99.1555 - val_false_loss: 13.3255 - val_true_loss: 1.2024\n",
      "Epoch 1186/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2791 - reconstruction_loss: 1890.8470 - kl_loss: 101.5779 - false_loss: 0.0937 - true_loss: 1.1478 - val_loss: 6113.2783 - val_reconstruction_loss: 1896.7244 - val_kl_loss: 99.1563 - val_false_loss: 13.3239 - val_true_loss: 1.2024\n",
      "Epoch 1187/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7658 - reconstruction_loss: 1891.1689 - kl_loss: 102.1123 - false_loss: 0.0937 - true_loss: 1.1478 - val_loss: 6112.8105 - val_reconstruction_loss: 1896.7239 - val_kl_loss: 99.1566 - val_false_loss: 13.3224 - val_true_loss: 1.2023\n",
      "Epoch 1188/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.5239 - reconstruction_loss: 1891.2360 - kl_loss: 101.2941 - false_loss: 0.0937 - true_loss: 1.1477 - val_loss: 6112.3433 - val_reconstruction_loss: 1896.7233 - val_kl_loss: 99.1570 - val_false_loss: 13.3208 - val_true_loss: 1.2023\n",
      "Epoch 1189/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.9011 - reconstruction_loss: 1891.1577 - kl_loss: 100.8318 - false_loss: 0.0937 - true_loss: 1.1476 - val_loss: 6111.8711 - val_reconstruction_loss: 1896.7225 - val_kl_loss: 99.1581 - val_false_loss: 13.3193 - val_true_loss: 1.2022\n",
      "Epoch 1190/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1481 - reconstruction_loss: 1890.6237 - kl_loss: 101.9372 - false_loss: 0.0937 - true_loss: 1.1476 - val_loss: 6111.3989 - val_reconstruction_loss: 1896.7220 - val_kl_loss: 99.1582 - val_false_loss: 13.3177 - val_true_loss: 1.2022\n",
      "Epoch 1191/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9682 - reconstruction_loss: 1890.4795 - kl_loss: 101.5515 - false_loss: 0.0937 - true_loss: 1.1475 - val_loss: 6110.9297 - val_reconstruction_loss: 1896.7212 - val_kl_loss: 99.1578 - val_false_loss: 13.3162 - val_true_loss: 1.2021\n",
      "Epoch 1192/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7395 - reconstruction_loss: 1891.3016 - kl_loss: 100.5317 - false_loss: 0.0937 - true_loss: 1.1475 - val_loss: 6110.4604 - val_reconstruction_loss: 1896.7206 - val_kl_loss: 99.1585 - val_false_loss: 13.3146 - val_true_loss: 1.2021\n",
      "Epoch 1193/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9194 - reconstruction_loss: 1891.2145 - kl_loss: 101.3383 - false_loss: 0.0937 - true_loss: 1.1474 - val_loss: 6110.0034 - val_reconstruction_loss: 1896.7200 - val_kl_loss: 99.1597 - val_false_loss: 13.3131 - val_true_loss: 1.2020\n",
      "Epoch 1194/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4840 - reconstruction_loss: 1891.8339 - kl_loss: 100.4994 - false_loss: 0.0937 - true_loss: 1.1474 - val_loss: 6109.5347 - val_reconstruction_loss: 1896.7192 - val_kl_loss: 99.1600 - val_false_loss: 13.3116 - val_true_loss: 1.2020\n",
      "Epoch 1195/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9986 - reconstruction_loss: 1891.2408 - kl_loss: 101.3330 - false_loss: 0.0936 - true_loss: 1.1473 - val_loss: 6109.0703 - val_reconstruction_loss: 1896.7189 - val_kl_loss: 99.1601 - val_false_loss: 13.3100 - val_true_loss: 1.2019\n",
      "Epoch 1196/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0363 - reconstruction_loss: 1891.1748 - kl_loss: 101.7722 - false_loss: 0.0936 - true_loss: 1.1473 - val_loss: 6108.5962 - val_reconstruction_loss: 1896.7183 - val_kl_loss: 99.1609 - val_false_loss: 13.3085 - val_true_loss: 1.2019\n",
      "Epoch 1197/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2224.0416 - reconstruction_loss: 1890.8760 - kl_loss: 102.1345 - false_loss: 0.0936 - true_loss: 1.1472 - val_loss: 6108.1401 - val_reconstruction_loss: 1896.7179 - val_kl_loss: 99.1614 - val_false_loss: 13.3070 - val_true_loss: 1.2018\n",
      "Epoch 1198/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.9899 - reconstruction_loss: 1890.5680 - kl_loss: 101.5208 - false_loss: 0.0936 - true_loss: 1.1471 - val_loss: 6107.6694 - val_reconstruction_loss: 1896.7172 - val_kl_loss: 99.1622 - val_false_loss: 13.3054 - val_true_loss: 1.2018\n",
      "Epoch 1199/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.3068 - reconstruction_loss: 1890.3384 - kl_loss: 101.2593 - false_loss: 0.0936 - true_loss: 1.1471 - val_loss: 6107.2031 - val_reconstruction_loss: 1896.7164 - val_kl_loss: 99.1628 - val_false_loss: 13.3039 - val_true_loss: 1.2017\n",
      "Epoch 1200/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3257 - reconstruction_loss: 1891.1705 - kl_loss: 101.2324 - false_loss: 0.0936 - true_loss: 1.1470 - val_loss: 6106.7383 - val_reconstruction_loss: 1896.7161 - val_kl_loss: 99.1637 - val_false_loss: 13.3023 - val_true_loss: 1.2017\n",
      "Epoch 1201/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0870 - reconstruction_loss: 1890.9781 - kl_loss: 101.0030 - false_loss: 0.0936 - true_loss: 1.1470 - val_loss: 6106.2754 - val_reconstruction_loss: 1896.7153 - val_kl_loss: 99.1648 - val_false_loss: 13.3008 - val_true_loss: 1.2016\n",
      "Epoch 1202/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8268 - reconstruction_loss: 1890.8848 - kl_loss: 101.2191 - false_loss: 0.0936 - true_loss: 1.1469 - val_loss: 6105.8096 - val_reconstruction_loss: 1896.7148 - val_kl_loss: 99.1652 - val_false_loss: 13.2993 - val_true_loss: 1.2016\n",
      "Epoch 1203/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9433 - reconstruction_loss: 1890.9806 - kl_loss: 101.1633 - false_loss: 0.0936 - true_loss: 1.1469 - val_loss: 6105.3496 - val_reconstruction_loss: 1896.7141 - val_kl_loss: 99.1657 - val_false_loss: 13.2978 - val_true_loss: 1.2015\n",
      "Epoch 1204/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8404 - reconstruction_loss: 1890.7421 - kl_loss: 101.1677 - false_loss: 0.0936 - true_loss: 1.1468 - val_loss: 6104.8799 - val_reconstruction_loss: 1896.7134 - val_kl_loss: 99.1664 - val_false_loss: 13.2962 - val_true_loss: 1.2015\n",
      "Epoch 1205/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5010 - reconstruction_loss: 1890.6451 - kl_loss: 100.3954 - false_loss: 0.0936 - true_loss: 1.1467 - val_loss: 6104.4126 - val_reconstruction_loss: 1896.7128 - val_kl_loss: 99.1669 - val_false_loss: 13.2947 - val_true_loss: 1.2014\n",
      "Epoch 1206/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5209 - reconstruction_loss: 1891.1481 - kl_loss: 100.5900 - false_loss: 0.0936 - true_loss: 1.1467 - val_loss: 6103.9502 - val_reconstruction_loss: 1896.7123 - val_kl_loss: 99.1669 - val_false_loss: 13.2931 - val_true_loss: 1.2014\n",
      "Epoch 1207/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.9381 - reconstruction_loss: 1891.0121 - kl_loss: 100.8187 - false_loss: 0.0935 - true_loss: 1.1466 - val_loss: 6103.4819 - val_reconstruction_loss: 1896.7115 - val_kl_loss: 99.1664 - val_false_loss: 13.2916 - val_true_loss: 1.2013\n",
      "Epoch 1208/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.9846 - reconstruction_loss: 1890.8184 - kl_loss: 101.0348 - false_loss: 0.0935 - true_loss: 1.1466 - val_loss: 6103.0156 - val_reconstruction_loss: 1896.7108 - val_kl_loss: 99.1665 - val_false_loss: 13.2901 - val_true_loss: 1.2013\n",
      "Epoch 1209/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0283 - reconstruction_loss: 1890.8077 - kl_loss: 100.6835 - false_loss: 0.0935 - true_loss: 1.1465 - val_loss: 6102.5493 - val_reconstruction_loss: 1896.7102 - val_kl_loss: 99.1669 - val_false_loss: 13.2885 - val_true_loss: 1.2012\n",
      "Epoch 1210/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3892 - reconstruction_loss: 1890.7853 - kl_loss: 101.9487 - false_loss: 0.0935 - true_loss: 1.1465 - val_loss: 6102.0840 - val_reconstruction_loss: 1896.7097 - val_kl_loss: 99.1679 - val_false_loss: 13.2870 - val_true_loss: 1.2012\n",
      "Epoch 1211/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.6876 - reconstruction_loss: 1890.8590 - kl_loss: 101.5388 - false_loss: 0.0935 - true_loss: 1.1464 - val_loss: 6101.6157 - val_reconstruction_loss: 1896.7090 - val_kl_loss: 99.1683 - val_false_loss: 13.2854 - val_true_loss: 1.2011\n",
      "Epoch 1212/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0602 - reconstruction_loss: 1890.4830 - kl_loss: 101.1430 - false_loss: 0.0935 - true_loss: 1.1464 - val_loss: 6101.1562 - val_reconstruction_loss: 1896.7084 - val_kl_loss: 99.1690 - val_false_loss: 13.2839 - val_true_loss: 1.2011\n",
      "Epoch 1213/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8384 - reconstruction_loss: 1890.9237 - kl_loss: 101.8071 - false_loss: 0.0935 - true_loss: 1.1463 - val_loss: 6100.6958 - val_reconstruction_loss: 1896.7079 - val_kl_loss: 99.1699 - val_false_loss: 13.2824 - val_true_loss: 1.2010\n",
      "Epoch 1214/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.1455 - reconstruction_loss: 1891.2806 - kl_loss: 101.3910 - false_loss: 0.0935 - true_loss: 1.1462 - val_loss: 6100.2261 - val_reconstruction_loss: 1896.7073 - val_kl_loss: 99.1712 - val_false_loss: 13.2809 - val_true_loss: 1.2010\n",
      "Epoch 1215/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.9624 - reconstruction_loss: 1890.7324 - kl_loss: 101.3114 - false_loss: 0.0935 - true_loss: 1.1462 - val_loss: 6099.7607 - val_reconstruction_loss: 1896.7068 - val_kl_loss: 99.1723 - val_false_loss: 13.2793 - val_true_loss: 1.2009\n",
      "Epoch 1216/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3818 - reconstruction_loss: 1890.8379 - kl_loss: 101.5756 - false_loss: 0.0935 - true_loss: 1.1461 - val_loss: 6099.2944 - val_reconstruction_loss: 1896.7061 - val_kl_loss: 99.1735 - val_false_loss: 13.2778 - val_true_loss: 1.2009\n",
      "Epoch 1217/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0723 - reconstruction_loss: 1891.7450 - kl_loss: 101.7078 - false_loss: 0.0935 - true_loss: 1.1461 - val_loss: 6098.8320 - val_reconstruction_loss: 1896.7053 - val_kl_loss: 99.1744 - val_false_loss: 13.2763 - val_true_loss: 1.2008\n",
      "Epoch 1218/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1910 - reconstruction_loss: 1891.0636 - kl_loss: 100.9517 - false_loss: 0.0935 - true_loss: 1.1460 - val_loss: 6098.3784 - val_reconstruction_loss: 1896.7050 - val_kl_loss: 99.1757 - val_false_loss: 13.2748 - val_true_loss: 1.2008\n",
      "Epoch 1219/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.7762 - reconstruction_loss: 1890.7565 - kl_loss: 101.0679 - false_loss: 0.0934 - true_loss: 1.1460 - val_loss: 6097.9141 - val_reconstruction_loss: 1896.7042 - val_kl_loss: 99.1772 - val_false_loss: 13.2732 - val_true_loss: 1.2007\n",
      "Epoch 1220/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8748 - reconstruction_loss: 1890.7340 - kl_loss: 101.7620 - false_loss: 0.0934 - true_loss: 1.1459 - val_loss: 6097.4614 - val_reconstruction_loss: 1896.7035 - val_kl_loss: 99.1787 - val_false_loss: 13.2717 - val_true_loss: 1.2007\n",
      "Epoch 1221/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.6340 - reconstruction_loss: 1890.5322 - kl_loss: 101.9578 - false_loss: 0.0934 - true_loss: 1.1459 - val_loss: 6096.9971 - val_reconstruction_loss: 1896.7028 - val_kl_loss: 99.1799 - val_false_loss: 13.2702 - val_true_loss: 1.2006\n",
      "Epoch 1222/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0848 - reconstruction_loss: 1890.8086 - kl_loss: 101.7221 - false_loss: 0.0934 - true_loss: 1.1458 - val_loss: 6096.5386 - val_reconstruction_loss: 1896.7024 - val_kl_loss: 99.1808 - val_false_loss: 13.2687 - val_true_loss: 1.2006\n",
      "Epoch 1223/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3961 - reconstruction_loss: 1890.3434 - kl_loss: 102.2415 - false_loss: 0.0934 - true_loss: 1.1457 - val_loss: 6096.0723 - val_reconstruction_loss: 1896.7017 - val_kl_loss: 99.1820 - val_false_loss: 13.2672 - val_true_loss: 1.2005\n",
      "Epoch 1224/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7884 - reconstruction_loss: 1890.7831 - kl_loss: 101.8661 - false_loss: 0.0934 - true_loss: 1.1457 - val_loss: 6095.6079 - val_reconstruction_loss: 1896.7009 - val_kl_loss: 99.1832 - val_false_loss: 13.2656 - val_true_loss: 1.2005\n",
      "Epoch 1225/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.3744 - reconstruction_loss: 1890.8584 - kl_loss: 101.0376 - false_loss: 0.0934 - true_loss: 1.1456 - val_loss: 6095.1440 - val_reconstruction_loss: 1896.7002 - val_kl_loss: 99.1839 - val_false_loss: 13.2641 - val_true_loss: 1.2004\n",
      "Epoch 1226/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3934 - reconstruction_loss: 1890.8619 - kl_loss: 101.9407 - false_loss: 0.0934 - true_loss: 1.1456 - val_loss: 6094.6875 - val_reconstruction_loss: 1896.6998 - val_kl_loss: 99.1838 - val_false_loss: 13.2626 - val_true_loss: 1.2004\n",
      "Epoch 1227/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.0999 - reconstruction_loss: 1891.5267 - kl_loss: 100.9674 - false_loss: 0.0934 - true_loss: 1.1455 - val_loss: 6094.2314 - val_reconstruction_loss: 1896.6992 - val_kl_loss: 99.1835 - val_false_loss: 13.2611 - val_true_loss: 1.2003\n",
      "Epoch 1228/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.4749 - reconstruction_loss: 1890.8990 - kl_loss: 101.5821 - false_loss: 0.0934 - true_loss: 1.1455 - val_loss: 6093.7822 - val_reconstruction_loss: 1896.6986 - val_kl_loss: 99.1836 - val_false_loss: 13.2596 - val_true_loss: 1.2003\n",
      "Epoch 1229/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6938 - reconstruction_loss: 1890.3561 - kl_loss: 101.9381 - false_loss: 0.0934 - true_loss: 1.1454 - val_loss: 6093.3154 - val_reconstruction_loss: 1896.6980 - val_kl_loss: 99.1832 - val_false_loss: 13.2581 - val_true_loss: 1.2002\n",
      "Epoch 1230/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6890 - reconstruction_loss: 1890.8223 - kl_loss: 100.1660 - false_loss: 0.0933 - true_loss: 1.1454 - val_loss: 6092.8530 - val_reconstruction_loss: 1896.6973 - val_kl_loss: 99.1831 - val_false_loss: 13.2565 - val_true_loss: 1.2002\n",
      "Epoch 1231/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1706 - reconstruction_loss: 1890.9263 - kl_loss: 101.1560 - false_loss: 0.0933 - true_loss: 1.1453 - val_loss: 6092.3911 - val_reconstruction_loss: 1896.6968 - val_kl_loss: 99.1828 - val_false_loss: 13.2550 - val_true_loss: 1.2002\n",
      "Epoch 1232/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.0205 - reconstruction_loss: 1890.5524 - kl_loss: 100.8253 - false_loss: 0.0933 - true_loss: 1.1452 - val_loss: 6091.9277 - val_reconstruction_loss: 1896.6960 - val_kl_loss: 99.1832 - val_false_loss: 13.2535 - val_true_loss: 1.2001\n",
      "Epoch 1233/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.6826 - reconstruction_loss: 1890.7650 - kl_loss: 100.7480 - false_loss: 0.0933 - true_loss: 1.1452 - val_loss: 6091.4614 - val_reconstruction_loss: 1896.6954 - val_kl_loss: 99.1839 - val_false_loss: 13.2520 - val_true_loss: 1.2001\n",
      "Epoch 1234/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0755 - reconstruction_loss: 1890.5978 - kl_loss: 101.0040 - false_loss: 0.0933 - true_loss: 1.1451 - val_loss: 6091.0020 - val_reconstruction_loss: 1896.6947 - val_kl_loss: 99.1845 - val_false_loss: 13.2504 - val_true_loss: 1.2000\n",
      "Epoch 1235/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.8678 - reconstruction_loss: 1891.0453 - kl_loss: 100.5421 - false_loss: 0.0933 - true_loss: 1.1451 - val_loss: 6090.5386 - val_reconstruction_loss: 1896.6942 - val_kl_loss: 99.1848 - val_false_loss: 13.2489 - val_true_loss: 1.2000\n",
      "Epoch 1236/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.3120 - reconstruction_loss: 1890.8632 - kl_loss: 100.0226 - false_loss: 0.0933 - true_loss: 1.1450 - val_loss: 6090.0791 - val_reconstruction_loss: 1896.6936 - val_kl_loss: 99.1855 - val_false_loss: 13.2474 - val_true_loss: 1.1999\n",
      "Epoch 1237/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.0514 - reconstruction_loss: 1890.5485 - kl_loss: 99.9972 - false_loss: 0.0933 - true_loss: 1.1450 - val_loss: 6089.6162 - val_reconstruction_loss: 1896.6930 - val_kl_loss: 99.1857 - val_false_loss: 13.2459 - val_true_loss: 1.1999\n",
      "Epoch 1238/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8875 - reconstruction_loss: 1890.8750 - kl_loss: 100.0316 - false_loss: 0.0933 - true_loss: 1.1449 - val_loss: 6089.1558 - val_reconstruction_loss: 1896.6924 - val_kl_loss: 99.1865 - val_false_loss: 13.2443 - val_true_loss: 1.1998\n",
      "Epoch 1239/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3864 - reconstruction_loss: 1890.7369 - kl_loss: 100.8474 - false_loss: 0.0933 - true_loss: 1.1449 - val_loss: 6088.6909 - val_reconstruction_loss: 1896.6917 - val_kl_loss: 99.1871 - val_false_loss: 13.2428 - val_true_loss: 1.1998\n",
      "Epoch 1240/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3579 - reconstruction_loss: 1891.0472 - kl_loss: 100.3559 - false_loss: 0.0933 - true_loss: 1.1448 - val_loss: 6088.2314 - val_reconstruction_loss: 1896.6912 - val_kl_loss: 99.1880 - val_false_loss: 13.2413 - val_true_loss: 1.1997\n",
      "Epoch 1241/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.6313 - reconstruction_loss: 1890.4818 - kl_loss: 101.4739 - false_loss: 0.0933 - true_loss: 1.1448 - val_loss: 6087.7729 - val_reconstruction_loss: 1896.6904 - val_kl_loss: 99.1886 - val_false_loss: 13.2398 - val_true_loss: 1.1997\n",
      "Epoch 1242/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.5484 - reconstruction_loss: 1890.7477 - kl_loss: 101.7289 - false_loss: 0.0932 - true_loss: 1.1447 - val_loss: 6087.3062 - val_reconstruction_loss: 1896.6898 - val_kl_loss: 99.1899 - val_false_loss: 13.2382 - val_true_loss: 1.1996\n",
      "Epoch 1243/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.8471 - reconstruction_loss: 1890.6830 - kl_loss: 101.8323 - false_loss: 0.0932 - true_loss: 1.1446 - val_loss: 6086.8428 - val_reconstruction_loss: 1896.6893 - val_kl_loss: 99.1897 - val_false_loss: 13.2367 - val_true_loss: 1.1996\n",
      "Epoch 1244/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9196 - reconstruction_loss: 1890.4308 - kl_loss: 101.4466 - false_loss: 0.0932 - true_loss: 1.1446 - val_loss: 6086.3779 - val_reconstruction_loss: 1896.6886 - val_kl_loss: 99.1899 - val_false_loss: 13.2352 - val_true_loss: 1.1995\n",
      "Epoch 1245/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3953 - reconstruction_loss: 1890.8414 - kl_loss: 102.0768 - false_loss: 0.0932 - true_loss: 1.1445 - val_loss: 6085.9263 - val_reconstruction_loss: 1896.6882 - val_kl_loss: 99.1897 - val_false_loss: 13.2337 - val_true_loss: 1.1995\n",
      "Epoch 1246/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.0185 - reconstruction_loss: 1890.8568 - kl_loss: 100.4782 - false_loss: 0.0932 - true_loss: 1.1445 - val_loss: 6085.4712 - val_reconstruction_loss: 1896.6875 - val_kl_loss: 99.1892 - val_false_loss: 13.2322 - val_true_loss: 1.1994\n",
      "Epoch 1247/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.8648 - reconstruction_loss: 1890.6582 - kl_loss: 100.5917 - false_loss: 0.0932 - true_loss: 1.1444 - val_loss: 6085.0107 - val_reconstruction_loss: 1896.6868 - val_kl_loss: 99.1887 - val_false_loss: 13.2307 - val_true_loss: 1.1994\n",
      "Epoch 1248/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.8398 - reconstruction_loss: 1891.1927 - kl_loss: 101.0033 - false_loss: 0.0932 - true_loss: 1.1444 - val_loss: 6084.5474 - val_reconstruction_loss: 1896.6864 - val_kl_loss: 99.1895 - val_false_loss: 13.2292 - val_true_loss: 1.1994\n",
      "Epoch 1249/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2226.4699 - reconstruction_loss: 1890.5812 - kl_loss: 101.0911 - false_loss: 0.0932 - true_loss: 1.1443 - val_loss: 6084.0933 - val_reconstruction_loss: 1896.6857 - val_kl_loss: 99.1907 - val_false_loss: 13.2277 - val_true_loss: 1.1993\n",
      "Epoch 1250/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.9302 - reconstruction_loss: 1890.8687 - kl_loss: 102.0550 - false_loss: 0.0932 - true_loss: 1.1443 - val_loss: 6083.6318 - val_reconstruction_loss: 1896.6851 - val_kl_loss: 99.1918 - val_false_loss: 13.2261 - val_true_loss: 1.1993\n",
      "Epoch 1251/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.4944 - reconstruction_loss: 1891.2797 - kl_loss: 101.3589 - false_loss: 0.0932 - true_loss: 1.1442 - val_loss: 6083.1763 - val_reconstruction_loss: 1896.6844 - val_kl_loss: 99.1933 - val_false_loss: 13.2246 - val_true_loss: 1.1992\n",
      "Epoch 1252/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3865 - reconstruction_loss: 1890.8705 - kl_loss: 100.6928 - false_loss: 0.0932 - true_loss: 1.1441 - val_loss: 6082.7192 - val_reconstruction_loss: 1896.6838 - val_kl_loss: 99.1952 - val_false_loss: 13.2231 - val_true_loss: 1.1992\n",
      "Epoch 1253/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.6809 - reconstruction_loss: 1891.3096 - kl_loss: 101.3855 - false_loss: 0.0932 - true_loss: 1.1441 - val_loss: 6082.2524 - val_reconstruction_loss: 1896.6831 - val_kl_loss: 99.1947 - val_false_loss: 13.2216 - val_true_loss: 1.1991\n",
      "Epoch 1254/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.5158 - reconstruction_loss: 1891.3639 - kl_loss: 100.8009 - false_loss: 0.0931 - true_loss: 1.1440 - val_loss: 6081.7993 - val_reconstruction_loss: 1896.6825 - val_kl_loss: 99.1944 - val_false_loss: 13.2201 - val_true_loss: 1.1991\n",
      "Epoch 1255/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.1260 - reconstruction_loss: 1890.8229 - kl_loss: 101.3922 - false_loss: 0.0931 - true_loss: 1.1440 - val_loss: 6081.3452 - val_reconstruction_loss: 1896.6819 - val_kl_loss: 99.1948 - val_false_loss: 13.2186 - val_true_loss: 1.1990\n",
      "Epoch 1256/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.0014 - reconstruction_loss: 1890.5508 - kl_loss: 101.4855 - false_loss: 0.0931 - true_loss: 1.1439 - val_loss: 6080.8896 - val_reconstruction_loss: 1896.6814 - val_kl_loss: 99.1957 - val_false_loss: 13.2171 - val_true_loss: 1.1990\n",
      "Epoch 1257/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1068 - reconstruction_loss: 1890.7616 - kl_loss: 101.2256 - false_loss: 0.0931 - true_loss: 1.1439 - val_loss: 6080.4370 - val_reconstruction_loss: 1896.6807 - val_kl_loss: 99.1966 - val_false_loss: 13.2156 - val_true_loss: 1.1989\n",
      "Epoch 1258/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4583 - reconstruction_loss: 1890.5883 - kl_loss: 100.5317 - false_loss: 0.0931 - true_loss: 1.1438 - val_loss: 6079.9761 - val_reconstruction_loss: 1896.6801 - val_kl_loss: 99.1980 - val_false_loss: 13.2141 - val_true_loss: 1.1989\n",
      "Epoch 1259/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3278 - reconstruction_loss: 1891.0719 - kl_loss: 101.4896 - false_loss: 0.0931 - true_loss: 1.1438 - val_loss: 6079.5273 - val_reconstruction_loss: 1896.6796 - val_kl_loss: 99.1991 - val_false_loss: 13.2126 - val_true_loss: 1.1988\n",
      "Epoch 1260/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.7687 - reconstruction_loss: 1891.1605 - kl_loss: 101.7946 - false_loss: 0.0931 - true_loss: 1.1437 - val_loss: 6079.0698 - val_reconstruction_loss: 1896.6790 - val_kl_loss: 99.2003 - val_false_loss: 13.2111 - val_true_loss: 1.1988\n",
      "Epoch 1261/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2975 - reconstruction_loss: 1890.9009 - kl_loss: 101.0824 - false_loss: 0.0931 - true_loss: 1.1437 - val_loss: 6078.6118 - val_reconstruction_loss: 1896.6782 - val_kl_loss: 99.2014 - val_false_loss: 13.2096 - val_true_loss: 1.1987\n",
      "Epoch 1262/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2174 - reconstruction_loss: 1890.4644 - kl_loss: 100.6131 - false_loss: 0.0931 - true_loss: 1.1436 - val_loss: 6078.1533 - val_reconstruction_loss: 1896.6776 - val_kl_loss: 99.2022 - val_false_loss: 13.2081 - val_true_loss: 1.1987\n",
      "Epoch 1263/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3148 - reconstruction_loss: 1890.5961 - kl_loss: 100.5962 - false_loss: 0.0931 - true_loss: 1.1436 - val_loss: 6077.6895 - val_reconstruction_loss: 1896.6769 - val_kl_loss: 99.2030 - val_false_loss: 13.2065 - val_true_loss: 1.1986\n",
      "Epoch 1264/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2288 - reconstruction_loss: 1891.0792 - kl_loss: 101.7136 - false_loss: 0.0931 - true_loss: 1.1435 - val_loss: 6077.2388 - val_reconstruction_loss: 1896.6765 - val_kl_loss: 99.2040 - val_false_loss: 13.2050 - val_true_loss: 1.1986\n",
      "Epoch 1265/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.0588 - reconstruction_loss: 1890.7648 - kl_loss: 101.7443 - false_loss: 0.0931 - true_loss: 1.1434 - val_loss: 6076.7808 - val_reconstruction_loss: 1896.6758 - val_kl_loss: 99.2051 - val_false_loss: 13.2035 - val_true_loss: 1.1985\n",
      "Epoch 1266/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.0425 - reconstruction_loss: 1890.9580 - kl_loss: 101.6197 - false_loss: 0.0930 - true_loss: 1.1434 - val_loss: 6076.3228 - val_reconstruction_loss: 1896.6754 - val_kl_loss: 99.2063 - val_false_loss: 13.2020 - val_true_loss: 1.1985\n",
      "Epoch 1267/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4322 - reconstruction_loss: 1890.7260 - kl_loss: 101.4215 - false_loss: 0.0930 - true_loss: 1.1433 - val_loss: 6075.8662 - val_reconstruction_loss: 1896.6747 - val_kl_loss: 99.2072 - val_false_loss: 13.2005 - val_true_loss: 1.1984\n",
      "Epoch 1268/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.5372 - reconstruction_loss: 1890.8734 - kl_loss: 101.6959 - false_loss: 0.0930 - true_loss: 1.1433 - val_loss: 6075.4111 - val_reconstruction_loss: 1896.6740 - val_kl_loss: 99.2077 - val_false_loss: 13.1990 - val_true_loss: 1.1984\n",
      "Epoch 1269/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4962 - reconstruction_loss: 1890.8011 - kl_loss: 101.9348 - false_loss: 0.0930 - true_loss: 1.1432 - val_loss: 6074.9531 - val_reconstruction_loss: 1896.6736 - val_kl_loss: 99.2082 - val_false_loss: 13.1975 - val_true_loss: 1.1983\n",
      "Epoch 1270/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4786 - reconstruction_loss: 1890.5488 - kl_loss: 101.7862 - false_loss: 0.0930 - true_loss: 1.1432 - val_loss: 6074.4966 - val_reconstruction_loss: 1896.6729 - val_kl_loss: 99.2087 - val_false_loss: 13.1960 - val_true_loss: 1.1983\n",
      "Epoch 1271/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.9932 - reconstruction_loss: 1890.6747 - kl_loss: 101.7402 - false_loss: 0.0930 - true_loss: 1.1431 - val_loss: 6074.0371 - val_reconstruction_loss: 1896.6721 - val_kl_loss: 99.2090 - val_false_loss: 13.1945 - val_true_loss: 1.1982\n",
      "Epoch 1272/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5198 - reconstruction_loss: 1890.5331 - kl_loss: 101.9586 - false_loss: 0.0930 - true_loss: 1.1430 - val_loss: 6073.5850 - val_reconstruction_loss: 1896.6715 - val_kl_loss: 99.2093 - val_false_loss: 13.1930 - val_true_loss: 1.1982\n",
      "Epoch 1273/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.7457 - reconstruction_loss: 1890.3102 - kl_loss: 101.2249 - false_loss: 0.0930 - true_loss: 1.1430 - val_loss: 6073.1353 - val_reconstruction_loss: 1896.6709 - val_kl_loss: 99.2103 - val_false_loss: 13.1915 - val_true_loss: 1.1981\n",
      "Epoch 1274/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.7315 - reconstruction_loss: 1890.6139 - kl_loss: 101.5595 - false_loss: 0.0930 - true_loss: 1.1429 - val_loss: 6072.6826 - val_reconstruction_loss: 1896.6704 - val_kl_loss: 99.2106 - val_false_loss: 13.1900 - val_true_loss: 1.1981\n",
      "Epoch 1275/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1515 - reconstruction_loss: 1891.0909 - kl_loss: 100.9290 - false_loss: 0.0930 - true_loss: 1.1429 - val_loss: 6072.2427 - val_reconstruction_loss: 1896.6699 - val_kl_loss: 99.2115 - val_false_loss: 13.1886 - val_true_loss: 1.1980\n",
      "Epoch 1276/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.8974 - reconstruction_loss: 1890.8169 - kl_loss: 101.5290 - false_loss: 0.0930 - true_loss: 1.1428 - val_loss: 6071.7837 - val_reconstruction_loss: 1896.6693 - val_kl_loss: 99.2130 - val_false_loss: 13.1870 - val_true_loss: 1.1980\n",
      "Epoch 1277/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4658 - reconstruction_loss: 1890.3569 - kl_loss: 101.1751 - false_loss: 0.0930 - true_loss: 1.1428 - val_loss: 6071.3315 - val_reconstruction_loss: 1896.6686 - val_kl_loss: 99.2138 - val_false_loss: 13.1856 - val_true_loss: 1.1979\n",
      "Epoch 1278/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.8124 - reconstruction_loss: 1890.8138 - kl_loss: 101.3094 - false_loss: 0.0929 - true_loss: 1.1427 - val_loss: 6070.8701 - val_reconstruction_loss: 1896.6682 - val_kl_loss: 99.2146 - val_false_loss: 13.1840 - val_true_loss: 1.1979\n",
      "Epoch 1279/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1252 - reconstruction_loss: 1890.2388 - kl_loss: 101.3939 - false_loss: 0.0929 - true_loss: 1.1427 - val_loss: 6070.4102 - val_reconstruction_loss: 1896.6675 - val_kl_loss: 99.2154 - val_false_loss: 13.1825 - val_true_loss: 1.1978\n",
      "Epoch 1280/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1760 - reconstruction_loss: 1890.6246 - kl_loss: 101.5643 - false_loss: 0.0929 - true_loss: 1.1426 - val_loss: 6069.9551 - val_reconstruction_loss: 1896.6667 - val_kl_loss: 99.2158 - val_false_loss: 13.1810 - val_true_loss: 1.1978\n",
      "Epoch 1281/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6062 - reconstruction_loss: 1890.8912 - kl_loss: 101.3179 - false_loss: 0.0929 - true_loss: 1.1425 - val_loss: 6069.4985 - val_reconstruction_loss: 1896.6664 - val_kl_loss: 99.2159 - val_false_loss: 13.1795 - val_true_loss: 1.1977\n",
      "Epoch 1282/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4736 - reconstruction_loss: 1890.6163 - kl_loss: 101.0258 - false_loss: 0.0929 - true_loss: 1.1425 - val_loss: 6069.0430 - val_reconstruction_loss: 1896.6658 - val_kl_loss: 99.2159 - val_false_loss: 13.1780 - val_true_loss: 1.1977\n",
      "Epoch 1283/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.6533 - reconstruction_loss: 1891.3497 - kl_loss: 100.9594 - false_loss: 0.0929 - true_loss: 1.1424 - val_loss: 6068.5933 - val_reconstruction_loss: 1896.6653 - val_kl_loss: 99.2165 - val_false_loss: 13.1765 - val_true_loss: 1.1976\n",
      "Epoch 1284/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4432 - reconstruction_loss: 1891.3051 - kl_loss: 100.3061 - false_loss: 0.0929 - true_loss: 1.1424 - val_loss: 6068.1343 - val_reconstruction_loss: 1896.6647 - val_kl_loss: 99.2172 - val_false_loss: 13.1750 - val_true_loss: 1.1976\n",
      "Epoch 1285/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.7792 - reconstruction_loss: 1890.7715 - kl_loss: 100.4753 - false_loss: 0.0929 - true_loss: 1.1423 - val_loss: 6067.6899 - val_reconstruction_loss: 1896.6641 - val_kl_loss: 99.2176 - val_false_loss: 13.1736 - val_true_loss: 1.1975\n",
      "Epoch 1286/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.4249 - reconstruction_loss: 1890.7367 - kl_loss: 102.0517 - false_loss: 0.0929 - true_loss: 1.1423 - val_loss: 6067.2349 - val_reconstruction_loss: 1896.6633 - val_kl_loss: 99.2181 - val_false_loss: 13.1721 - val_true_loss: 1.1975\n",
      "Epoch 1287/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.7647 - reconstruction_loss: 1890.5851 - kl_loss: 101.7362 - false_loss: 0.0929 - true_loss: 1.1422 - val_loss: 6066.7837 - val_reconstruction_loss: 1896.6627 - val_kl_loss: 99.2187 - val_false_loss: 13.1706 - val_true_loss: 1.1974\n",
      "Epoch 1288/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8114 - reconstruction_loss: 1890.6791 - kl_loss: 101.5077 - false_loss: 0.0929 - true_loss: 1.1422 - val_loss: 6066.3296 - val_reconstruction_loss: 1896.6622 - val_kl_loss: 99.2188 - val_false_loss: 13.1691 - val_true_loss: 1.1974\n",
      "Epoch 1289/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.8948 - reconstruction_loss: 1890.4277 - kl_loss: 101.2139 - false_loss: 0.0929 - true_loss: 1.1421 - val_loss: 6065.8740 - val_reconstruction_loss: 1896.6615 - val_kl_loss: 99.2181 - val_false_loss: 13.1676 - val_true_loss: 1.1973\n",
      "Epoch 1290/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.8737 - reconstruction_loss: 1890.4781 - kl_loss: 100.9585 - false_loss: 0.0928 - true_loss: 1.1421 - val_loss: 6065.4219 - val_reconstruction_loss: 1896.6610 - val_kl_loss: 99.2187 - val_false_loss: 13.1661 - val_true_loss: 1.1973\n",
      "Epoch 1291/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.2812 - reconstruction_loss: 1891.1088 - kl_loss: 100.4405 - false_loss: 0.0928 - true_loss: 1.1420 - val_loss: 6064.9697 - val_reconstruction_loss: 1896.6604 - val_kl_loss: 99.2205 - val_false_loss: 13.1646 - val_true_loss: 1.1972\n",
      "Epoch 1292/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.9605 - reconstruction_loss: 1890.8688 - kl_loss: 101.9592 - false_loss: 0.0928 - true_loss: 1.1420 - val_loss: 6064.5166 - val_reconstruction_loss: 1896.6598 - val_kl_loss: 99.2213 - val_false_loss: 13.1631 - val_true_loss: 1.1972\n",
      "Epoch 1293/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.7175 - reconstruction_loss: 1890.3824 - kl_loss: 101.7987 - false_loss: 0.0928 - true_loss: 1.1419 - val_loss: 6064.0669 - val_reconstruction_loss: 1896.6592 - val_kl_loss: 99.2211 - val_false_loss: 13.1616 - val_true_loss: 1.1972\n",
      "Epoch 1294/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3755 - reconstruction_loss: 1891.0996 - kl_loss: 101.3641 - false_loss: 0.0928 - true_loss: 1.1418 - val_loss: 6063.6211 - val_reconstruction_loss: 1896.6587 - val_kl_loss: 99.2210 - val_false_loss: 13.1601 - val_true_loss: 1.1971\n",
      "Epoch 1295/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3293 - reconstruction_loss: 1891.5465 - kl_loss: 102.1231 - false_loss: 0.0928 - true_loss: 1.1418 - val_loss: 6063.1753 - val_reconstruction_loss: 1896.6580 - val_kl_loss: 99.2205 - val_false_loss: 13.1587 - val_true_loss: 1.1971\n",
      "Epoch 1296/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.3365 - reconstruction_loss: 1891.2223 - kl_loss: 101.4249 - false_loss: 0.0928 - true_loss: 1.1417 - val_loss: 6062.7227 - val_reconstruction_loss: 1896.6576 - val_kl_loss: 99.2214 - val_false_loss: 13.1572 - val_true_loss: 1.1970\n",
      "Epoch 1297/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.2261 - reconstruction_loss: 1890.7559 - kl_loss: 99.3854 - false_loss: 0.0928 - true_loss: 1.1417 - val_loss: 6062.2778 - val_reconstruction_loss: 1896.6569 - val_kl_loss: 99.2228 - val_false_loss: 13.1557 - val_true_loss: 1.1970\n",
      "Epoch 1298/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7066 - reconstruction_loss: 1890.5016 - kl_loss: 101.5438 - false_loss: 0.0928 - true_loss: 1.1416 - val_loss: 6061.8345 - val_reconstruction_loss: 1896.6564 - val_kl_loss: 99.2228 - val_false_loss: 13.1542 - val_true_loss: 1.1969\n",
      "Epoch 1299/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.3596 - reconstruction_loss: 1891.5391 - kl_loss: 101.1721 - false_loss: 0.0928 - true_loss: 1.1416 - val_loss: 6061.3828 - val_reconstruction_loss: 1896.6558 - val_kl_loss: 99.2233 - val_false_loss: 13.1528 - val_true_loss: 1.1969\n",
      "Epoch 1300/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.6299 - reconstruction_loss: 1890.6553 - kl_loss: 101.8530 - false_loss: 0.0928 - true_loss: 1.1415 - val_loss: 6060.9346 - val_reconstruction_loss: 1896.6550 - val_kl_loss: 99.2247 - val_false_loss: 13.1513 - val_true_loss: 1.1968\n",
      "Epoch 1301/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2225.8792 - reconstruction_loss: 1890.3680 - kl_loss: 101.6754 - false_loss: 0.0928 - true_loss: 1.1415 - val_loss: 6060.4888 - val_reconstruction_loss: 1896.6545 - val_kl_loss: 99.2263 - val_false_loss: 13.1498 - val_true_loss: 1.1968\n",
      "Epoch 1302/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5138 - reconstruction_loss: 1890.7842 - kl_loss: 101.4270 - false_loss: 0.0927 - true_loss: 1.1414 - val_loss: 6060.0293 - val_reconstruction_loss: 1896.6539 - val_kl_loss: 99.2273 - val_false_loss: 13.1483 - val_true_loss: 1.1967\n",
      "Epoch 1303/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.0679 - reconstruction_loss: 1890.6000 - kl_loss: 101.1548 - false_loss: 0.0927 - true_loss: 1.1413 - val_loss: 6059.5791 - val_reconstruction_loss: 1896.6533 - val_kl_loss: 99.2286 - val_false_loss: 13.1468 - val_true_loss: 1.1967\n",
      "Epoch 1304/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.1590 - reconstruction_loss: 1890.5001 - kl_loss: 101.7800 - false_loss: 0.0927 - true_loss: 1.1413 - val_loss: 6059.1240 - val_reconstruction_loss: 1896.6527 - val_kl_loss: 99.2291 - val_false_loss: 13.1453 - val_true_loss: 1.1966\n",
      "Epoch 1305/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.3300 - reconstruction_loss: 1890.6943 - kl_loss: 101.4835 - false_loss: 0.0927 - true_loss: 1.1412 - val_loss: 6058.6758 - val_reconstruction_loss: 1896.6522 - val_kl_loss: 99.2291 - val_false_loss: 13.1438 - val_true_loss: 1.1966\n",
      "Epoch 1306/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.1269 - reconstruction_loss: 1890.5236 - kl_loss: 101.2767 - false_loss: 0.0927 - true_loss: 1.1412 - val_loss: 6058.2271 - val_reconstruction_loss: 1896.6515 - val_kl_loss: 99.2286 - val_false_loss: 13.1423 - val_true_loss: 1.1965\n",
      "Epoch 1307/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.6861 - reconstruction_loss: 1891.1119 - kl_loss: 100.3197 - false_loss: 0.0927 - true_loss: 1.1411 - val_loss: 6057.7734 - val_reconstruction_loss: 1896.6508 - val_kl_loss: 99.2287 - val_false_loss: 13.1409 - val_true_loss: 1.1965\n",
      "Epoch 1308/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.9461 - reconstruction_loss: 1890.8223 - kl_loss: 100.8576 - false_loss: 0.0927 - true_loss: 1.1411 - val_loss: 6057.3267 - val_reconstruction_loss: 1896.6504 - val_kl_loss: 99.2284 - val_false_loss: 13.1394 - val_true_loss: 1.1964\n",
      "Epoch 1309/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.6600 - reconstruction_loss: 1891.4122 - kl_loss: 100.4379 - false_loss: 0.0927 - true_loss: 1.1410 - val_loss: 6056.8750 - val_reconstruction_loss: 1896.6498 - val_kl_loss: 99.2301 - val_false_loss: 13.1379 - val_true_loss: 1.1964\n",
      "Epoch 1310/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.5897 - reconstruction_loss: 1891.1595 - kl_loss: 101.2957 - false_loss: 0.0927 - true_loss: 1.1410 - val_loss: 6056.4287 - val_reconstruction_loss: 1896.6490 - val_kl_loss: 99.2308 - val_false_loss: 13.1364 - val_true_loss: 1.1964\n",
      "Epoch 1311/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.3234 - reconstruction_loss: 1890.5590 - kl_loss: 99.5259 - false_loss: 0.0927 - true_loss: 1.1409 - val_loss: 6055.9863 - val_reconstruction_loss: 1896.6484 - val_kl_loss: 99.2325 - val_false_loss: 13.1350 - val_true_loss: 1.1963\n",
      "Epoch 1312/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.4182 - reconstruction_loss: 1890.9943 - kl_loss: 100.9704 - false_loss: 0.0927 - true_loss: 1.1409 - val_loss: 6055.5376 - val_reconstruction_loss: 1896.6478 - val_kl_loss: 99.2329 - val_false_loss: 13.1335 - val_true_loss: 1.1963\n",
      "Epoch 1313/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7888 - reconstruction_loss: 1890.5238 - kl_loss: 101.6484 - false_loss: 0.0927 - true_loss: 1.1408 - val_loss: 6055.0908 - val_reconstruction_loss: 1896.6471 - val_kl_loss: 99.2329 - val_false_loss: 13.1320 - val_true_loss: 1.1962\n",
      "Epoch 1314/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.5916 - reconstruction_loss: 1890.8794 - kl_loss: 101.2009 - false_loss: 0.0926 - true_loss: 1.1408 - val_loss: 6054.6396 - val_reconstruction_loss: 1896.6467 - val_kl_loss: 99.2336 - val_false_loss: 13.1305 - val_true_loss: 1.1962\n",
      "Epoch 1315/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.0701 - reconstruction_loss: 1890.7251 - kl_loss: 100.8522 - false_loss: 0.0926 - true_loss: 1.1407 - val_loss: 6054.1899 - val_reconstruction_loss: 1896.6460 - val_kl_loss: 99.2348 - val_false_loss: 13.1290 - val_true_loss: 1.1961\n",
      "Epoch 1316/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2262 - reconstruction_loss: 1890.4196 - kl_loss: 100.3412 - false_loss: 0.0926 - true_loss: 1.1407 - val_loss: 6053.7417 - val_reconstruction_loss: 1896.6453 - val_kl_loss: 99.2358 - val_false_loss: 13.1275 - val_true_loss: 1.1961\n",
      "Epoch 1317/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7397 - reconstruction_loss: 1890.8512 - kl_loss: 100.9110 - false_loss: 0.0926 - true_loss: 1.1406 - val_loss: 6053.2900 - val_reconstruction_loss: 1896.6447 - val_kl_loss: 99.2365 - val_false_loss: 13.1261 - val_true_loss: 1.1960\n",
      "Epoch 1318/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.6498 - reconstruction_loss: 1890.6437 - kl_loss: 99.6254 - false_loss: 0.0926 - true_loss: 1.1406 - val_loss: 6052.8418 - val_reconstruction_loss: 1896.6443 - val_kl_loss: 99.2380 - val_false_loss: 13.1246 - val_true_loss: 1.1960\n",
      "Epoch 1319/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.1202 - reconstruction_loss: 1890.6357 - kl_loss: 101.6391 - false_loss: 0.0926 - true_loss: 1.1405 - val_loss: 6052.4019 - val_reconstruction_loss: 1896.6436 - val_kl_loss: 99.2383 - val_false_loss: 13.1231 - val_true_loss: 1.1959\n",
      "Epoch 1320/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.0700 - reconstruction_loss: 1890.3597 - kl_loss: 101.8726 - false_loss: 0.0926 - true_loss: 1.1405 - val_loss: 6051.9546 - val_reconstruction_loss: 1896.6428 - val_kl_loss: 99.2380 - val_false_loss: 13.1217 - val_true_loss: 1.1959\n",
      "Epoch 1321/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6724 - reconstruction_loss: 1890.9181 - kl_loss: 100.4649 - false_loss: 0.0926 - true_loss: 1.1404 - val_loss: 6051.5107 - val_reconstruction_loss: 1896.6423 - val_kl_loss: 99.2387 - val_false_loss: 13.1202 - val_true_loss: 1.1958\n",
      "Epoch 1322/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.2716 - reconstruction_loss: 1890.6400 - kl_loss: 99.1858 - false_loss: 0.0926 - true_loss: 1.1404 - val_loss: 6051.0610 - val_reconstruction_loss: 1896.6417 - val_kl_loss: 99.2397 - val_false_loss: 13.1187 - val_true_loss: 1.1958\n",
      "Epoch 1323/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5422 - reconstruction_loss: 1890.5654 - kl_loss: 99.9580 - false_loss: 0.0926 - true_loss: 1.1403 - val_loss: 6050.6143 - val_reconstruction_loss: 1896.6411 - val_kl_loss: 99.2411 - val_false_loss: 13.1172 - val_true_loss: 1.1957\n",
      "Epoch 1324/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5009 - reconstruction_loss: 1890.7798 - kl_loss: 100.4441 - false_loss: 0.0926 - true_loss: 1.1403 - val_loss: 6050.1606 - val_reconstruction_loss: 1896.6404 - val_kl_loss: 99.2411 - val_false_loss: 13.1157 - val_true_loss: 1.1957\n",
      "Epoch 1325/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3701 - reconstruction_loss: 1890.6290 - kl_loss: 100.6791 - false_loss: 0.0926 - true_loss: 1.1402 - val_loss: 6049.7100 - val_reconstruction_loss: 1896.6399 - val_kl_loss: 99.2414 - val_false_loss: 13.1143 - val_true_loss: 1.1956\n",
      "Epoch 1326/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.8890 - reconstruction_loss: 1890.4801 - kl_loss: 101.9293 - false_loss: 0.0925 - true_loss: 1.1401 - val_loss: 6049.2642 - val_reconstruction_loss: 1896.6393 - val_kl_loss: 99.2415 - val_false_loss: 13.1128 - val_true_loss: 1.1956\n",
      "Epoch 1327/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5145 - reconstruction_loss: 1890.8730 - kl_loss: 102.0333 - false_loss: 0.0925 - true_loss: 1.1401 - val_loss: 6048.8140 - val_reconstruction_loss: 1896.6387 - val_kl_loss: 99.2408 - val_false_loss: 13.1113 - val_true_loss: 1.1956\n",
      "Epoch 1328/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9159 - reconstruction_loss: 1890.5079 - kl_loss: 101.5278 - false_loss: 0.0925 - true_loss: 1.1400 - val_loss: 6048.3638 - val_reconstruction_loss: 1896.6379 - val_kl_loss: 99.2417 - val_false_loss: 13.1098 - val_true_loss: 1.1955\n",
      "Epoch 1329/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.8283 - reconstruction_loss: 1891.2700 - kl_loss: 100.9886 - false_loss: 0.0925 - true_loss: 1.1400 - val_loss: 6047.9146 - val_reconstruction_loss: 1896.6375 - val_kl_loss: 99.2431 - val_false_loss: 13.1083 - val_true_loss: 1.1955\n",
      "Epoch 1330/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.3614 - reconstruction_loss: 1890.7365 - kl_loss: 101.5516 - false_loss: 0.0925 - true_loss: 1.1399 - val_loss: 6047.4658 - val_reconstruction_loss: 1896.6368 - val_kl_loss: 99.2441 - val_false_loss: 13.1068 - val_true_loss: 1.1954\n",
      "Epoch 1331/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.7099 - reconstruction_loss: 1890.5055 - kl_loss: 101.5427 - false_loss: 0.0925 - true_loss: 1.1399 - val_loss: 6047.0205 - val_reconstruction_loss: 1896.6361 - val_kl_loss: 99.2452 - val_false_loss: 13.1054 - val_true_loss: 1.1954\n",
      "Epoch 1332/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3541 - reconstruction_loss: 1890.8827 - kl_loss: 100.7614 - false_loss: 0.0925 - true_loss: 1.1398 - val_loss: 6046.5718 - val_reconstruction_loss: 1896.6356 - val_kl_loss: 99.2461 - val_false_loss: 13.1039 - val_true_loss: 1.1953\n",
      "Epoch 1333/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.6577 - reconstruction_loss: 1890.5508 - kl_loss: 101.1877 - false_loss: 0.0925 - true_loss: 1.1398 - val_loss: 6046.1299 - val_reconstruction_loss: 1896.6351 - val_kl_loss: 99.2469 - val_false_loss: 13.1024 - val_true_loss: 1.1953\n",
      "Epoch 1334/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.3379 - reconstruction_loss: 1890.8676 - kl_loss: 100.5533 - false_loss: 0.0925 - true_loss: 1.1397 - val_loss: 6045.6851 - val_reconstruction_loss: 1896.6344 - val_kl_loss: 99.2467 - val_false_loss: 13.1010 - val_true_loss: 1.1952\n",
      "Epoch 1335/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.9154 - reconstruction_loss: 1890.6670 - kl_loss: 101.4062 - false_loss: 0.0925 - true_loss: 1.1396 - val_loss: 6045.2388 - val_reconstruction_loss: 1896.6339 - val_kl_loss: 99.2474 - val_false_loss: 13.0995 - val_true_loss: 1.1952\n",
      "Epoch 1336/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4277 - reconstruction_loss: 1890.8691 - kl_loss: 101.1531 - false_loss: 0.0925 - true_loss: 1.1396 - val_loss: 6044.7905 - val_reconstruction_loss: 1896.6333 - val_kl_loss: 99.2484 - val_false_loss: 13.0980 - val_true_loss: 1.1951\n",
      "Epoch 1337/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8810 - reconstruction_loss: 1890.7529 - kl_loss: 102.2683 - false_loss: 0.0925 - true_loss: 1.1395 - val_loss: 6044.3408 - val_reconstruction_loss: 1896.6326 - val_kl_loss: 99.2487 - val_false_loss: 13.0965 - val_true_loss: 1.1951\n",
      "Epoch 1338/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.7080 - reconstruction_loss: 1890.5341 - kl_loss: 101.2215 - false_loss: 0.0924 - true_loss: 1.1395 - val_loss: 6043.9009 - val_reconstruction_loss: 1896.6322 - val_kl_loss: 99.2493 - val_false_loss: 13.0951 - val_true_loss: 1.1950\n",
      "Epoch 1339/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.5502 - reconstruction_loss: 1890.7012 - kl_loss: 101.1846 - false_loss: 0.0924 - true_loss: 1.1394 - val_loss: 6043.4580 - val_reconstruction_loss: 1896.6316 - val_kl_loss: 99.2503 - val_false_loss: 13.0936 - val_true_loss: 1.1950\n",
      "Epoch 1340/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.3980 - reconstruction_loss: 1891.1158 - kl_loss: 100.2582 - false_loss: 0.0924 - true_loss: 1.1394 - val_loss: 6043.0117 - val_reconstruction_loss: 1896.6310 - val_kl_loss: 99.2519 - val_false_loss: 13.0922 - val_true_loss: 1.1949\n",
      "Epoch 1341/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.3520 - reconstruction_loss: 1891.2130 - kl_loss: 101.1819 - false_loss: 0.0924 - true_loss: 1.1393 - val_loss: 6042.5742 - val_reconstruction_loss: 1896.6304 - val_kl_loss: 99.2518 - val_false_loss: 13.0907 - val_true_loss: 1.1949\n",
      "Epoch 1342/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.9779 - reconstruction_loss: 1890.6816 - kl_loss: 101.4306 - false_loss: 0.0924 - true_loss: 1.1393 - val_loss: 6042.1294 - val_reconstruction_loss: 1896.6298 - val_kl_loss: 99.2515 - val_false_loss: 13.0893 - val_true_loss: 1.1948\n",
      "Epoch 1343/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3461 - reconstruction_loss: 1890.3037 - kl_loss: 101.2892 - false_loss: 0.0924 - true_loss: 1.1392 - val_loss: 6041.6846 - val_reconstruction_loss: 1896.6292 - val_kl_loss: 99.2521 - val_false_loss: 13.0878 - val_true_loss: 1.1948\n",
      "Epoch 1344/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.4588 - reconstruction_loss: 1891.0321 - kl_loss: 100.7703 - false_loss: 0.0924 - true_loss: 1.1392 - val_loss: 6041.2422 - val_reconstruction_loss: 1896.6285 - val_kl_loss: 99.2526 - val_false_loss: 13.0863 - val_true_loss: 1.1947\n",
      "Epoch 1345/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.3997 - reconstruction_loss: 1890.6138 - kl_loss: 100.5225 - false_loss: 0.0924 - true_loss: 1.1391 - val_loss: 6040.8042 - val_reconstruction_loss: 1896.6279 - val_kl_loss: 99.2532 - val_false_loss: 13.0849 - val_true_loss: 1.1947\n",
      "Epoch 1346/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.9939 - reconstruction_loss: 1890.1099 - kl_loss: 100.6502 - false_loss: 0.0924 - true_loss: 1.1391 - val_loss: 6040.3540 - val_reconstruction_loss: 1896.6273 - val_kl_loss: 99.2536 - val_false_loss: 13.0834 - val_true_loss: 1.1946\n",
      "Epoch 1347/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.3811 - reconstruction_loss: 1890.3330 - kl_loss: 100.1614 - false_loss: 0.0924 - true_loss: 1.1390 - val_loss: 6039.9111 - val_reconstruction_loss: 1896.6267 - val_kl_loss: 99.2545 - val_false_loss: 13.0819 - val_true_loss: 1.1946\n",
      "Epoch 1348/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.4661 - reconstruction_loss: 1890.8236 - kl_loss: 101.1571 - false_loss: 0.0924 - true_loss: 1.1390 - val_loss: 6039.4756 - val_reconstruction_loss: 1896.6260 - val_kl_loss: 99.2552 - val_false_loss: 13.0805 - val_true_loss: 1.1945\n",
      "Epoch 1349/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4121 - reconstruction_loss: 1890.9980 - kl_loss: 101.4813 - false_loss: 0.0924 - true_loss: 1.1389 - val_loss: 6039.0327 - val_reconstruction_loss: 1896.6256 - val_kl_loss: 99.2553 - val_false_loss: 13.0790 - val_true_loss: 1.1945\n",
      "Epoch 1350/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.6879 - reconstruction_loss: 1890.6571 - kl_loss: 101.4278 - false_loss: 0.0923 - true_loss: 1.1388 - val_loss: 6038.5928 - val_reconstruction_loss: 1896.6249 - val_kl_loss: 99.2555 - val_false_loss: 13.0776 - val_true_loss: 1.1945\n",
      "Epoch 1351/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.3484 - reconstruction_loss: 1890.7914 - kl_loss: 101.7678 - false_loss: 0.0923 - true_loss: 1.1388 - val_loss: 6038.1494 - val_reconstruction_loss: 1896.6241 - val_kl_loss: 99.2552 - val_false_loss: 13.0761 - val_true_loss: 1.1944\n",
      "Epoch 1352/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0476 - reconstruction_loss: 1890.5132 - kl_loss: 101.4344 - false_loss: 0.0923 - true_loss: 1.1387 - val_loss: 6037.7056 - val_reconstruction_loss: 1896.6235 - val_kl_loss: 99.2560 - val_false_loss: 13.0747 - val_true_loss: 1.1944\n",
      "Epoch 1353/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2224.5378 - reconstruction_loss: 1890.2114 - kl_loss: 100.4635 - false_loss: 0.0923 - true_loss: 1.1387 - val_loss: 6037.2681 - val_reconstruction_loss: 1896.6232 - val_kl_loss: 99.2567 - val_false_loss: 13.0732 - val_true_loss: 1.1943\n",
      "Epoch 1354/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5442 - reconstruction_loss: 1890.2831 - kl_loss: 101.3530 - false_loss: 0.0923 - true_loss: 1.1386 - val_loss: 6036.8306 - val_reconstruction_loss: 1896.6224 - val_kl_loss: 99.2567 - val_false_loss: 13.0718 - val_true_loss: 1.1943\n",
      "Epoch 1355/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.5260 - reconstruction_loss: 1890.6725 - kl_loss: 101.4856 - false_loss: 0.0923 - true_loss: 1.1386 - val_loss: 6036.3921 - val_reconstruction_loss: 1896.6217 - val_kl_loss: 99.2565 - val_false_loss: 13.0703 - val_true_loss: 1.1942\n",
      "Epoch 1356/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.9357 - reconstruction_loss: 1890.3180 - kl_loss: 101.5063 - false_loss: 0.0923 - true_loss: 1.1385 - val_loss: 6035.9565 - val_reconstruction_loss: 1896.6211 - val_kl_loss: 99.2559 - val_false_loss: 13.0689 - val_true_loss: 1.1942\n",
      "Epoch 1357/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.7744 - reconstruction_loss: 1891.0748 - kl_loss: 100.9689 - false_loss: 0.0923 - true_loss: 1.1385 - val_loss: 6035.5098 - val_reconstruction_loss: 1896.6207 - val_kl_loss: 99.2570 - val_false_loss: 13.0674 - val_true_loss: 1.1941\n",
      "Epoch 1358/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.3400 - reconstruction_loss: 1890.7983 - kl_loss: 100.6528 - false_loss: 0.0923 - true_loss: 1.1384 - val_loss: 6035.0791 - val_reconstruction_loss: 1896.6200 - val_kl_loss: 99.2582 - val_false_loss: 13.0660 - val_true_loss: 1.1941\n",
      "Epoch 1359/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.5718 - reconstruction_loss: 1890.8231 - kl_loss: 101.4988 - false_loss: 0.0923 - true_loss: 1.1384 - val_loss: 6034.6455 - val_reconstruction_loss: 1896.6193 - val_kl_loss: 99.2587 - val_false_loss: 13.0646 - val_true_loss: 1.1940\n",
      "Epoch 1360/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7319 - reconstruction_loss: 1890.3076 - kl_loss: 101.6374 - false_loss: 0.0923 - true_loss: 1.1383 - val_loss: 6034.2065 - val_reconstruction_loss: 1896.6189 - val_kl_loss: 99.2593 - val_false_loss: 13.0631 - val_true_loss: 1.1940\n",
      "Epoch 1361/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.3414 - reconstruction_loss: 1891.6918 - kl_loss: 100.3287 - false_loss: 0.0923 - true_loss: 1.1382 - val_loss: 6033.7627 - val_reconstruction_loss: 1896.6183 - val_kl_loss: 99.2591 - val_false_loss: 13.0617 - val_true_loss: 1.1939\n",
      "Epoch 1362/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4087 - reconstruction_loss: 1890.8784 - kl_loss: 100.8097 - false_loss: 0.0922 - true_loss: 1.1382 - val_loss: 6033.3208 - val_reconstruction_loss: 1896.6176 - val_kl_loss: 99.2594 - val_false_loss: 13.0602 - val_true_loss: 1.1939\n",
      "Epoch 1363/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2584 - reconstruction_loss: 1890.4404 - kl_loss: 101.6250 - false_loss: 0.0922 - true_loss: 1.1381 - val_loss: 6032.8921 - val_reconstruction_loss: 1896.6169 - val_kl_loss: 99.2595 - val_false_loss: 13.0588 - val_true_loss: 1.1938\n",
      "Epoch 1364/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.8496 - reconstruction_loss: 1890.8793 - kl_loss: 100.9053 - false_loss: 0.0922 - true_loss: 1.1381 - val_loss: 6032.4512 - val_reconstruction_loss: 1896.6165 - val_kl_loss: 99.2602 - val_false_loss: 13.0574 - val_true_loss: 1.1938\n",
      "Epoch 1365/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8057 - reconstruction_loss: 1890.7655 - kl_loss: 101.0494 - false_loss: 0.0922 - true_loss: 1.1380 - val_loss: 6032.0112 - val_reconstruction_loss: 1896.6158 - val_kl_loss: 99.2617 - val_false_loss: 13.0559 - val_true_loss: 1.1937\n",
      "Epoch 1366/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.7597 - reconstruction_loss: 1890.5902 - kl_loss: 102.2289 - false_loss: 0.0922 - true_loss: 1.1380 - val_loss: 6031.5659 - val_reconstruction_loss: 1896.6151 - val_kl_loss: 99.2629 - val_false_loss: 13.0544 - val_true_loss: 1.1937\n",
      "Epoch 1367/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.9995 - reconstruction_loss: 1890.7050 - kl_loss: 102.1858 - false_loss: 0.0922 - true_loss: 1.1379 - val_loss: 6031.1333 - val_reconstruction_loss: 1896.6145 - val_kl_loss: 99.2639 - val_false_loss: 13.0530 - val_true_loss: 1.1936\n",
      "Epoch 1368/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.3280 - reconstruction_loss: 1890.6415 - kl_loss: 101.8199 - false_loss: 0.0922 - true_loss: 1.1379 - val_loss: 6030.6914 - val_reconstruction_loss: 1896.6139 - val_kl_loss: 99.2643 - val_false_loss: 13.0515 - val_true_loss: 1.1936\n",
      "Epoch 1369/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.2132 - reconstruction_loss: 1890.7233 - kl_loss: 100.8507 - false_loss: 0.0922 - true_loss: 1.1378 - val_loss: 6030.2520 - val_reconstruction_loss: 1896.6134 - val_kl_loss: 99.2646 - val_false_loss: 13.0501 - val_true_loss: 1.1935\n",
      "Epoch 1370/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.4447 - reconstruction_loss: 1890.4479 - kl_loss: 99.8680 - false_loss: 0.0922 - true_loss: 1.1378 - val_loss: 6029.8218 - val_reconstruction_loss: 1896.6127 - val_kl_loss: 99.2649 - val_false_loss: 13.0487 - val_true_loss: 1.1935\n",
      "Epoch 1371/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.5220 - reconstruction_loss: 1890.4447 - kl_loss: 98.9174 - false_loss: 0.0922 - true_loss: 1.1377 - val_loss: 6029.3882 - val_reconstruction_loss: 1896.6122 - val_kl_loss: 99.2661 - val_false_loss: 13.0472 - val_true_loss: 1.1935\n",
      "Epoch 1372/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.6996 - reconstruction_loss: 1890.5605 - kl_loss: 99.8031 - false_loss: 0.0922 - true_loss: 1.1377 - val_loss: 6028.9541 - val_reconstruction_loss: 1896.6115 - val_kl_loss: 99.2656 - val_false_loss: 13.0458 - val_true_loss: 1.1934\n",
      "Epoch 1373/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.4446 - reconstruction_loss: 1890.4840 - kl_loss: 99.9345 - false_loss: 0.0922 - true_loss: 1.1376 - val_loss: 6028.5107 - val_reconstruction_loss: 1896.6110 - val_kl_loss: 99.2645 - val_false_loss: 13.0444 - val_true_loss: 1.1934\n",
      "Epoch 1374/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.9542 - reconstruction_loss: 1890.9928 - kl_loss: 99.6571 - false_loss: 0.0922 - true_loss: 1.1376 - val_loss: 6028.0703 - val_reconstruction_loss: 1896.6106 - val_kl_loss: 99.2644 - val_false_loss: 13.0429 - val_true_loss: 1.1933\n",
      "Epoch 1375/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.5465 - reconstruction_loss: 1891.3412 - kl_loss: 98.2897 - false_loss: 0.0921 - true_loss: 1.1375 - val_loss: 6027.6284 - val_reconstruction_loss: 1896.6099 - val_kl_loss: 99.2654 - val_false_loss: 13.0414 - val_true_loss: 1.1933\n",
      "Epoch 1376/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6438 - reconstruction_loss: 1891.1520 - kl_loss: 100.2923 - false_loss: 0.0921 - true_loss: 1.1375 - val_loss: 6027.2041 - val_reconstruction_loss: 1896.6095 - val_kl_loss: 99.2657 - val_false_loss: 13.0400 - val_true_loss: 1.1932\n",
      "Epoch 1377/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.8353 - reconstruction_loss: 1891.0083 - kl_loss: 101.6796 - false_loss: 0.0921 - true_loss: 1.1374 - val_loss: 6026.7617 - val_reconstruction_loss: 1896.6088 - val_kl_loss: 99.2655 - val_false_loss: 13.0386 - val_true_loss: 1.1932\n",
      "Epoch 1378/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.9286 - reconstruction_loss: 1890.7911 - kl_loss: 100.7189 - false_loss: 0.0921 - true_loss: 1.1374 - val_loss: 6026.3291 - val_reconstruction_loss: 1896.6084 - val_kl_loss: 99.2657 - val_false_loss: 13.0372 - val_true_loss: 1.1932\n",
      "Epoch 1379/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2820 - reconstruction_loss: 1890.4562 - kl_loss: 101.5756 - false_loss: 0.0921 - true_loss: 1.1373 - val_loss: 6025.8921 - val_reconstruction_loss: 1896.6078 - val_kl_loss: 99.2657 - val_false_loss: 13.0357 - val_true_loss: 1.1931\n",
      "Epoch 1380/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.5978 - reconstruction_loss: 1890.6595 - kl_loss: 100.4350 - false_loss: 0.0921 - true_loss: 1.1373 - val_loss: 6025.4541 - val_reconstruction_loss: 1896.6071 - val_kl_loss: 99.2658 - val_false_loss: 13.0343 - val_true_loss: 1.1931\n",
      "Epoch 1381/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.1794 - reconstruction_loss: 1890.5677 - kl_loss: 101.0253 - false_loss: 0.0921 - true_loss: 1.1372 - val_loss: 6025.0225 - val_reconstruction_loss: 1896.6064 - val_kl_loss: 99.2660 - val_false_loss: 13.0329 - val_true_loss: 1.1930\n",
      "Epoch 1382/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2738 - reconstruction_loss: 1890.4810 - kl_loss: 99.9812 - false_loss: 0.0921 - true_loss: 1.1372 - val_loss: 6024.5845 - val_reconstruction_loss: 1896.6060 - val_kl_loss: 99.2671 - val_false_loss: 13.0314 - val_true_loss: 1.1930\n",
      "Epoch 1383/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7709 - reconstruction_loss: 1890.7850 - kl_loss: 101.4612 - false_loss: 0.0921 - true_loss: 1.1371 - val_loss: 6024.1470 - val_reconstruction_loss: 1896.6053 - val_kl_loss: 99.2681 - val_false_loss: 13.0300 - val_true_loss: 1.1929\n",
      "Epoch 1384/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8702 - reconstruction_loss: 1891.2510 - kl_loss: 101.1140 - false_loss: 0.0921 - true_loss: 1.1370 - val_loss: 6023.7134 - val_reconstruction_loss: 1896.6046 - val_kl_loss: 99.2695 - val_false_loss: 13.0285 - val_true_loss: 1.1929\n",
      "Epoch 1385/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0620 - reconstruction_loss: 1890.8412 - kl_loss: 101.8670 - false_loss: 0.0921 - true_loss: 1.1370 - val_loss: 6023.2842 - val_reconstruction_loss: 1896.6042 - val_kl_loss: 99.2703 - val_false_loss: 13.0271 - val_true_loss: 1.1928\n",
      "Epoch 1386/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.6496 - reconstruction_loss: 1890.6958 - kl_loss: 101.8116 - false_loss: 0.0921 - true_loss: 1.1369 - val_loss: 6022.8525 - val_reconstruction_loss: 1896.6036 - val_kl_loss: 99.2709 - val_false_loss: 13.0257 - val_true_loss: 1.1928\n",
      "Epoch 1387/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6189 - reconstruction_loss: 1890.1586 - kl_loss: 101.4969 - false_loss: 0.0920 - true_loss: 1.1369 - val_loss: 6022.4199 - val_reconstruction_loss: 1896.6029 - val_kl_loss: 99.2717 - val_false_loss: 13.0243 - val_true_loss: 1.1927\n",
      "Epoch 1388/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.0665 - reconstruction_loss: 1890.7660 - kl_loss: 101.6709 - false_loss: 0.0920 - true_loss: 1.1368 - val_loss: 6021.9888 - val_reconstruction_loss: 1896.6025 - val_kl_loss: 99.2727 - val_false_loss: 13.0229 - val_true_loss: 1.1927\n",
      "Epoch 1389/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.4268 - reconstruction_loss: 1890.6982 - kl_loss: 101.3033 - false_loss: 0.0920 - true_loss: 1.1368 - val_loss: 6021.5596 - val_reconstruction_loss: 1896.6018 - val_kl_loss: 99.2739 - val_false_loss: 13.0214 - val_true_loss: 1.1926\n",
      "Epoch 1390/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8864 - reconstruction_loss: 1890.3783 - kl_loss: 101.3938 - false_loss: 0.0920 - true_loss: 1.1367 - val_loss: 6021.1235 - val_reconstruction_loss: 1896.6012 - val_kl_loss: 99.2748 - val_false_loss: 13.0200 - val_true_loss: 1.1926\n",
      "Epoch 1391/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.2581 - reconstruction_loss: 1890.8208 - kl_loss: 101.0052 - false_loss: 0.0920 - true_loss: 1.1367 - val_loss: 6020.6855 - val_reconstruction_loss: 1896.6005 - val_kl_loss: 99.2751 - val_false_loss: 13.0186 - val_true_loss: 1.1925\n",
      "Epoch 1392/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.8740 - reconstruction_loss: 1890.6683 - kl_loss: 101.4380 - false_loss: 0.0920 - true_loss: 1.1366 - val_loss: 6020.2485 - val_reconstruction_loss: 1896.6001 - val_kl_loss: 99.2759 - val_false_loss: 13.0171 - val_true_loss: 1.1925\n",
      "Epoch 1393/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.4658 - reconstruction_loss: 1890.2778 - kl_loss: 101.1251 - false_loss: 0.0920 - true_loss: 1.1366 - val_loss: 6019.8120 - val_reconstruction_loss: 1896.5992 - val_kl_loss: 99.2767 - val_false_loss: 13.0157 - val_true_loss: 1.1924\n",
      "Epoch 1394/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.0323 - reconstruction_loss: 1890.3771 - kl_loss: 101.8750 - false_loss: 0.0920 - true_loss: 1.1365 - val_loss: 6019.3843 - val_reconstruction_loss: 1896.5988 - val_kl_loss: 99.2770 - val_false_loss: 13.0143 - val_true_loss: 1.1924\n",
      "Epoch 1395/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.6360 - reconstruction_loss: 1891.0972 - kl_loss: 101.8105 - false_loss: 0.0920 - true_loss: 1.1364 - val_loss: 6018.9521 - val_reconstruction_loss: 1896.5983 - val_kl_loss: 99.2773 - val_false_loss: 13.0128 - val_true_loss: 1.1923\n",
      "Epoch 1396/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.5845 - reconstruction_loss: 1890.3422 - kl_loss: 102.1366 - false_loss: 0.0920 - true_loss: 1.1364 - val_loss: 6018.5220 - val_reconstruction_loss: 1896.5975 - val_kl_loss: 99.2782 - val_false_loss: 13.0114 - val_true_loss: 1.1923\n",
      "Epoch 1397/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.8526 - reconstruction_loss: 1890.3422 - kl_loss: 99.8240 - false_loss: 0.0920 - true_loss: 1.1363 - val_loss: 6018.0903 - val_reconstruction_loss: 1896.5970 - val_kl_loss: 99.2800 - val_false_loss: 13.0100 - val_true_loss: 1.1922\n",
      "Epoch 1398/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1430 - reconstruction_loss: 1891.3125 - kl_loss: 100.9984 - false_loss: 0.0920 - true_loss: 1.1363 - val_loss: 6017.6621 - val_reconstruction_loss: 1896.5966 - val_kl_loss: 99.2803 - val_false_loss: 13.0086 - val_true_loss: 1.1922\n",
      "Epoch 1399/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.2642 - reconstruction_loss: 1891.0620 - kl_loss: 101.2706 - false_loss: 0.0919 - true_loss: 1.1362 - val_loss: 6017.2251 - val_reconstruction_loss: 1896.5959 - val_kl_loss: 99.2798 - val_false_loss: 13.0071 - val_true_loss: 1.1922\n",
      "Epoch 1400/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7853 - reconstruction_loss: 1890.4532 - kl_loss: 101.1278 - false_loss: 0.0919 - true_loss: 1.1362 - val_loss: 6016.7983 - val_reconstruction_loss: 1896.5955 - val_kl_loss: 99.2803 - val_false_loss: 13.0057 - val_true_loss: 1.1921\n",
      "Epoch 1401/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.1092 - reconstruction_loss: 1890.5679 - kl_loss: 101.1460 - false_loss: 0.0919 - true_loss: 1.1361 - val_loss: 6016.3643 - val_reconstruction_loss: 1896.5947 - val_kl_loss: 99.2808 - val_false_loss: 13.0043 - val_true_loss: 1.1921\n",
      "Epoch 1402/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.5843 - reconstruction_loss: 1890.6562 - kl_loss: 101.0723 - false_loss: 0.0919 - true_loss: 1.1361 - val_loss: 6015.9312 - val_reconstruction_loss: 1896.5942 - val_kl_loss: 99.2819 - val_false_loss: 13.0029 - val_true_loss: 1.1920\n",
      "Epoch 1403/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.3825 - reconstruction_loss: 1890.3649 - kl_loss: 101.2292 - false_loss: 0.0919 - true_loss: 1.1360 - val_loss: 6015.5059 - val_reconstruction_loss: 1896.5938 - val_kl_loss: 99.2822 - val_false_loss: 13.0015 - val_true_loss: 1.1920\n",
      "Epoch 1404/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1273 - reconstruction_loss: 1890.6600 - kl_loss: 101.0250 - false_loss: 0.0919 - true_loss: 1.1360 - val_loss: 6015.0781 - val_reconstruction_loss: 1896.5931 - val_kl_loss: 99.2831 - val_false_loss: 13.0001 - val_true_loss: 1.1919\n",
      "Epoch 1405/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5352 - reconstruction_loss: 1890.3623 - kl_loss: 101.8350 - false_loss: 0.0919 - true_loss: 1.1359 - val_loss: 6014.6426 - val_reconstruction_loss: 1896.5925 - val_kl_loss: 99.2835 - val_false_loss: 12.9986 - val_true_loss: 1.1919\n",
      "Epoch 1406/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.6086 - reconstruction_loss: 1890.4662 - kl_loss: 101.7423 - false_loss: 0.0919 - true_loss: 1.1359 - val_loss: 6014.2070 - val_reconstruction_loss: 1896.5919 - val_kl_loss: 99.2839 - val_false_loss: 12.9972 - val_true_loss: 1.1918\n",
      "Epoch 1407/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3868 - reconstruction_loss: 1890.2490 - kl_loss: 101.5071 - false_loss: 0.0919 - true_loss: 1.1358 - val_loss: 6013.7764 - val_reconstruction_loss: 1896.5914 - val_kl_loss: 99.2832 - val_false_loss: 12.9958 - val_true_loss: 1.1918\n",
      "Epoch 1408/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1494 - reconstruction_loss: 1892.2350 - kl_loss: 101.1934 - false_loss: 0.0919 - true_loss: 1.1358 - val_loss: 6013.3398 - val_reconstruction_loss: 1896.5908 - val_kl_loss: 99.2841 - val_false_loss: 12.9943 - val_true_loss: 1.1917\n",
      "Epoch 1409/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.0063 - reconstruction_loss: 1893.1429 - kl_loss: 100.0972 - false_loss: 0.0919 - true_loss: 1.1357 - val_loss: 6012.9116 - val_reconstruction_loss: 1896.5902 - val_kl_loss: 99.2852 - val_false_loss: 12.9929 - val_true_loss: 1.1917\n",
      "Epoch 1410/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.3576 - reconstruction_loss: 1891.1724 - kl_loss: 100.5864 - false_loss: 0.0919 - true_loss: 1.1357 - val_loss: 6012.4727 - val_reconstruction_loss: 1896.5896 - val_kl_loss: 99.2852 - val_false_loss: 12.9915 - val_true_loss: 1.1916\n",
      "Epoch 1411/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9390 - reconstruction_loss: 1890.7784 - kl_loss: 101.0458 - false_loss: 0.0918 - true_loss: 1.1356 - val_loss: 6012.0366 - val_reconstruction_loss: 1896.5890 - val_kl_loss: 99.2854 - val_false_loss: 12.9900 - val_true_loss: 1.1916\n",
      "Epoch 1412/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.9749 - reconstruction_loss: 1890.5098 - kl_loss: 101.5151 - false_loss: 0.0918 - true_loss: 1.1355 - val_loss: 6011.6001 - val_reconstruction_loss: 1896.5884 - val_kl_loss: 99.2863 - val_false_loss: 12.9886 - val_true_loss: 1.1915\n",
      "Epoch 1413/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0516 - reconstruction_loss: 1890.7133 - kl_loss: 101.0984 - false_loss: 0.0918 - true_loss: 1.1355 - val_loss: 6011.1758 - val_reconstruction_loss: 1896.5879 - val_kl_loss: 99.2873 - val_false_loss: 12.9872 - val_true_loss: 1.1915\n",
      "Epoch 1414/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7655 - reconstruction_loss: 1890.1112 - kl_loss: 101.8919 - false_loss: 0.0918 - true_loss: 1.1354 - val_loss: 6010.7437 - val_reconstruction_loss: 1896.5872 - val_kl_loss: 99.2872 - val_false_loss: 12.9858 - val_true_loss: 1.1914\n",
      "Epoch 1415/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4638 - reconstruction_loss: 1890.6982 - kl_loss: 101.5198 - false_loss: 0.0918 - true_loss: 1.1354 - val_loss: 6010.3257 - val_reconstruction_loss: 1896.5867 - val_kl_loss: 99.2871 - val_false_loss: 12.9844 - val_true_loss: 1.1914\n",
      "Epoch 1416/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9947 - reconstruction_loss: 1890.5717 - kl_loss: 101.4398 - false_loss: 0.0918 - true_loss: 1.1353 - val_loss: 6009.8921 - val_reconstruction_loss: 1896.5859 - val_kl_loss: 99.2873 - val_false_loss: 12.9830 - val_true_loss: 1.1913\n",
      "Epoch 1417/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.3062 - reconstruction_loss: 1890.7196 - kl_loss: 101.8658 - false_loss: 0.0918 - true_loss: 1.1353 - val_loss: 6009.4673 - val_reconstruction_loss: 1896.5854 - val_kl_loss: 99.2881 - val_false_loss: 12.9816 - val_true_loss: 1.1913\n",
      "Epoch 1418/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8643 - reconstruction_loss: 1890.6367 - kl_loss: 101.2617 - false_loss: 0.0918 - true_loss: 1.1352 - val_loss: 6009.0376 - val_reconstruction_loss: 1896.5850 - val_kl_loss: 99.2894 - val_false_loss: 12.9802 - val_true_loss: 1.1912\n",
      "Epoch 1419/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4913 - reconstruction_loss: 1890.8394 - kl_loss: 101.5129 - false_loss: 0.0918 - true_loss: 1.1352 - val_loss: 6008.6055 - val_reconstruction_loss: 1896.5842 - val_kl_loss: 99.2904 - val_false_loss: 12.9787 - val_true_loss: 1.1912\n",
      "Epoch 1420/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2616 - reconstruction_loss: 1890.4434 - kl_loss: 101.8048 - false_loss: 0.0918 - true_loss: 1.1351 - val_loss: 6008.1777 - val_reconstruction_loss: 1896.5837 - val_kl_loss: 99.2904 - val_false_loss: 12.9773 - val_true_loss: 1.1911\n",
      "Epoch 1421/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.7195 - reconstruction_loss: 1890.4921 - kl_loss: 101.7120 - false_loss: 0.0918 - true_loss: 1.1351 - val_loss: 6007.7520 - val_reconstruction_loss: 1896.5830 - val_kl_loss: 99.2911 - val_false_loss: 12.9759 - val_true_loss: 1.1911\n",
      "Epoch 1422/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.4698 - reconstruction_loss: 1890.3209 - kl_loss: 100.7680 - false_loss: 0.0918 - true_loss: 1.1350 - val_loss: 6007.3232 - val_reconstruction_loss: 1896.5825 - val_kl_loss: 99.2920 - val_false_loss: 12.9745 - val_true_loss: 1.1911\n",
      "Epoch 1423/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.1579 - reconstruction_loss: 1890.2992 - kl_loss: 101.7451 - false_loss: 0.0918 - true_loss: 1.1350 - val_loss: 6006.9043 - val_reconstruction_loss: 1896.5820 - val_kl_loss: 99.2931 - val_false_loss: 12.9731 - val_true_loss: 1.1910\n",
      "Epoch 1424/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4467 - reconstruction_loss: 1890.3824 - kl_loss: 101.5961 - false_loss: 0.0917 - true_loss: 1.1349 - val_loss: 6006.4727 - val_reconstruction_loss: 1896.5812 - val_kl_loss: 99.2937 - val_false_loss: 12.9717 - val_true_loss: 1.1910\n",
      "Epoch 1425/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.3930 - reconstruction_loss: 1890.6094 - kl_loss: 102.0104 - false_loss: 0.0917 - true_loss: 1.1348 - val_loss: 6006.0479 - val_reconstruction_loss: 1896.5806 - val_kl_loss: 99.2941 - val_false_loss: 12.9703 - val_true_loss: 1.1909\n",
      "Epoch 1426/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.9972 - reconstruction_loss: 1890.7931 - kl_loss: 101.7353 - false_loss: 0.0917 - true_loss: 1.1348 - val_loss: 6005.6230 - val_reconstruction_loss: 1896.5801 - val_kl_loss: 99.2945 - val_false_loss: 12.9689 - val_true_loss: 1.1909\n",
      "Epoch 1427/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.8861 - reconstruction_loss: 1890.1027 - kl_loss: 101.1881 - false_loss: 0.0917 - true_loss: 1.1347 - val_loss: 6005.2021 - val_reconstruction_loss: 1896.5795 - val_kl_loss: 99.2959 - val_false_loss: 12.9675 - val_true_loss: 1.1908\n",
      "Epoch 1428/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3325 - reconstruction_loss: 1890.8033 - kl_loss: 101.7225 - false_loss: 0.0917 - true_loss: 1.1347 - val_loss: 6004.7725 - val_reconstruction_loss: 1896.5791 - val_kl_loss: 99.2969 - val_false_loss: 12.9661 - val_true_loss: 1.1908\n",
      "Epoch 1429/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7502 - reconstruction_loss: 1890.7491 - kl_loss: 102.0323 - false_loss: 0.0917 - true_loss: 1.1346 - val_loss: 6004.3384 - val_reconstruction_loss: 1896.5784 - val_kl_loss: 99.2963 - val_false_loss: 12.9647 - val_true_loss: 1.1907\n",
      "Epoch 1430/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7814 - reconstruction_loss: 1890.3329 - kl_loss: 101.3088 - false_loss: 0.0917 - true_loss: 1.1346 - val_loss: 6003.9229 - val_reconstruction_loss: 1896.5779 - val_kl_loss: 99.2964 - val_false_loss: 12.9633 - val_true_loss: 1.1907\n",
      "Epoch 1431/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.8357 - reconstruction_loss: 1890.3285 - kl_loss: 99.5943 - false_loss: 0.0917 - true_loss: 1.1345 - val_loss: 6003.4966 - val_reconstruction_loss: 1896.5774 - val_kl_loss: 99.2973 - val_false_loss: 12.9619 - val_true_loss: 1.1906\n",
      "Epoch 1432/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9226 - reconstruction_loss: 1890.4015 - kl_loss: 100.9261 - false_loss: 0.0917 - true_loss: 1.1345 - val_loss: 6003.0625 - val_reconstruction_loss: 1896.5769 - val_kl_loss: 99.2973 - val_false_loss: 12.9605 - val_true_loss: 1.1906\n",
      "Epoch 1433/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6779 - reconstruction_loss: 1890.7831 - kl_loss: 101.5528 - false_loss: 0.0917 - true_loss: 1.1344 - val_loss: 6002.6313 - val_reconstruction_loss: 1896.5762 - val_kl_loss: 99.2981 - val_false_loss: 12.9590 - val_true_loss: 1.1905\n",
      "Epoch 1434/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.1635 - reconstruction_loss: 1890.5416 - kl_loss: 101.4732 - false_loss: 0.0917 - true_loss: 1.1344 - val_loss: 6002.2061 - val_reconstruction_loss: 1896.5756 - val_kl_loss: 99.2986 - val_false_loss: 12.9576 - val_true_loss: 1.1905\n",
      "Epoch 1435/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.3062 - reconstruction_loss: 1890.2084 - kl_loss: 101.1025 - false_loss: 0.0917 - true_loss: 1.1343 - val_loss: 6001.7910 - val_reconstruction_loss: 1896.5750 - val_kl_loss: 99.2995 - val_false_loss: 12.9563 - val_true_loss: 1.1904\n",
      "Epoch 1436/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4084 - reconstruction_loss: 1890.2682 - kl_loss: 101.0265 - false_loss: 0.0916 - true_loss: 1.1343 - val_loss: 6001.3657 - val_reconstruction_loss: 1896.5745 - val_kl_loss: 99.3008 - val_false_loss: 12.9549 - val_true_loss: 1.1904\n",
      "Epoch 1437/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.2031 - reconstruction_loss: 1890.7467 - kl_loss: 101.5019 - false_loss: 0.0916 - true_loss: 1.1342 - val_loss: 6000.9419 - val_reconstruction_loss: 1896.5737 - val_kl_loss: 99.3020 - val_false_loss: 12.9535 - val_true_loss: 1.1903\n",
      "Epoch 1438/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.1630 - reconstruction_loss: 1890.7188 - kl_loss: 101.8211 - false_loss: 0.0916 - true_loss: 1.1341 - val_loss: 6000.5264 - val_reconstruction_loss: 1896.5731 - val_kl_loss: 99.3040 - val_false_loss: 12.9521 - val_true_loss: 1.1903\n",
      "Epoch 1439/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.8464 - reconstruction_loss: 1890.7559 - kl_loss: 100.9672 - false_loss: 0.0916 - true_loss: 1.1341 - val_loss: 6000.1030 - val_reconstruction_loss: 1896.5726 - val_kl_loss: 99.3048 - val_false_loss: 12.9507 - val_true_loss: 1.1903\n",
      "Epoch 1440/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.3683 - reconstruction_loss: 1891.1505 - kl_loss: 101.0187 - false_loss: 0.0916 - true_loss: 1.1341 - val_loss: 5999.6724 - val_reconstruction_loss: 1896.5720 - val_kl_loss: 99.3046 - val_false_loss: 12.9493 - val_true_loss: 1.1902\n",
      "Epoch 1441/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.8942 - reconstruction_loss: 1891.6522 - kl_loss: 100.1951 - false_loss: 0.0916 - true_loss: 1.1340 - val_loss: 5999.2515 - val_reconstruction_loss: 1896.5715 - val_kl_loss: 99.3056 - val_false_loss: 12.9479 - val_true_loss: 1.1902\n",
      "Epoch 1442/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.7164 - reconstruction_loss: 1890.6283 - kl_loss: 100.9863 - false_loss: 0.0916 - true_loss: 1.1339 - val_loss: 5998.8315 - val_reconstruction_loss: 1896.5709 - val_kl_loss: 99.3064 - val_false_loss: 12.9465 - val_true_loss: 1.1901\n",
      "Epoch 1443/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.2657 - reconstruction_loss: 1890.3844 - kl_loss: 101.7136 - false_loss: 0.0916 - true_loss: 1.1339 - val_loss: 5998.4048 - val_reconstruction_loss: 1896.5703 - val_kl_loss: 99.3070 - val_false_loss: 12.9451 - val_true_loss: 1.1901\n",
      "Epoch 1444/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.0827 - reconstruction_loss: 1890.3019 - kl_loss: 101.3560 - false_loss: 0.0916 - true_loss: 1.1338 - val_loss: 5997.9819 - val_reconstruction_loss: 1896.5698 - val_kl_loss: 99.3078 - val_false_loss: 12.9437 - val_true_loss: 1.1900\n",
      "Epoch 1445/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.0714 - reconstruction_loss: 1890.1879 - kl_loss: 101.6787 - false_loss: 0.0916 - true_loss: 1.1338 - val_loss: 5997.5645 - val_reconstruction_loss: 1896.5692 - val_kl_loss: 99.3093 - val_false_loss: 12.9423 - val_true_loss: 1.1900\n",
      "Epoch 1446/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3687 - reconstruction_loss: 1890.9894 - kl_loss: 101.6235 - false_loss: 0.0916 - true_loss: 1.1337 - val_loss: 5997.1436 - val_reconstruction_loss: 1896.5686 - val_kl_loss: 99.3104 - val_false_loss: 12.9409 - val_true_loss: 1.1899\n",
      "Epoch 1447/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.0688 - reconstruction_loss: 1890.4701 - kl_loss: 101.3940 - false_loss: 0.0916 - true_loss: 1.1337 - val_loss: 5996.7163 - val_reconstruction_loss: 1896.5680 - val_kl_loss: 99.3119 - val_false_loss: 12.9395 - val_true_loss: 1.1899\n",
      "Epoch 1448/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4819 - reconstruction_loss: 1890.6177 - kl_loss: 102.3963 - false_loss: 0.0915 - true_loss: 1.1336 - val_loss: 5996.2988 - val_reconstruction_loss: 1896.5675 - val_kl_loss: 99.3126 - val_false_loss: 12.9381 - val_true_loss: 1.1898\n",
      "Epoch 1449/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.1550 - reconstruction_loss: 1890.1754 - kl_loss: 100.3688 - false_loss: 0.0915 - true_loss: 1.1336 - val_loss: 5995.8726 - val_reconstruction_loss: 1896.5668 - val_kl_loss: 99.3129 - val_false_loss: 12.9367 - val_true_loss: 1.1898\n",
      "Epoch 1450/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.7054 - reconstruction_loss: 1890.2422 - kl_loss: 100.9296 - false_loss: 0.0915 - true_loss: 1.1335 - val_loss: 5995.4541 - val_reconstruction_loss: 1896.5662 - val_kl_loss: 99.3130 - val_false_loss: 12.9354 - val_true_loss: 1.1898\n",
      "Epoch 1451/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.2285 - reconstruction_loss: 1890.4121 - kl_loss: 101.1606 - false_loss: 0.0915 - true_loss: 1.1335 - val_loss: 5995.0356 - val_reconstruction_loss: 1896.5658 - val_kl_loss: 99.3127 - val_false_loss: 12.9340 - val_true_loss: 1.1897\n",
      "Epoch 1452/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.2530 - reconstruction_loss: 1891.0411 - kl_loss: 99.6761 - false_loss: 0.0915 - true_loss: 1.1334 - val_loss: 5994.6191 - val_reconstruction_loss: 1896.5651 - val_kl_loss: 99.3140 - val_false_loss: 12.9326 - val_true_loss: 1.1897\n",
      "Epoch 1453/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.1370 - reconstruction_loss: 1891.0883 - kl_loss: 101.0597 - false_loss: 0.0915 - true_loss: 1.1334 - val_loss: 5994.1904 - val_reconstruction_loss: 1896.5645 - val_kl_loss: 99.3142 - val_false_loss: 12.9312 - val_true_loss: 1.1896\n",
      "Epoch 1454/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9554 - reconstruction_loss: 1891.0039 - kl_loss: 100.3791 - false_loss: 0.0915 - true_loss: 1.1333 - val_loss: 5993.7759 - val_reconstruction_loss: 1896.5641 - val_kl_loss: 99.3149 - val_false_loss: 12.9298 - val_true_loss: 1.1896\n",
      "Epoch 1455/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2516 - reconstruction_loss: 1891.0648 - kl_loss: 101.0740 - false_loss: 0.0915 - true_loss: 1.1333 - val_loss: 5993.3618 - val_reconstruction_loss: 1896.5634 - val_kl_loss: 99.3160 - val_false_loss: 12.9285 - val_true_loss: 1.1895\n",
      "Epoch 1456/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.9589 - reconstruction_loss: 1890.9137 - kl_loss: 101.1918 - false_loss: 0.0915 - true_loss: 1.1332 - val_loss: 5992.9419 - val_reconstruction_loss: 1896.5627 - val_kl_loss: 99.3172 - val_false_loss: 12.9271 - val_true_loss: 1.1895\n",
      "Epoch 1457/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2219.9512 - reconstruction_loss: 1890.3099 - kl_loss: 101.6311 - false_loss: 0.0915 - true_loss: 1.1332 - val_loss: 5992.5269 - val_reconstruction_loss: 1896.5624 - val_kl_loss: 99.3178 - val_false_loss: 12.9257 - val_true_loss: 1.1894\n",
      "Epoch 1458/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3111 - reconstruction_loss: 1890.5083 - kl_loss: 102.2987 - false_loss: 0.0915 - true_loss: 1.1331 - val_loss: 5992.1089 - val_reconstruction_loss: 1896.5616 - val_kl_loss: 99.3183 - val_false_loss: 12.9243 - val_true_loss: 1.1894\n",
      "Epoch 1459/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.2173 - reconstruction_loss: 1890.7085 - kl_loss: 101.7552 - false_loss: 0.0915 - true_loss: 1.1330 - val_loss: 5991.6919 - val_reconstruction_loss: 1896.5610 - val_kl_loss: 99.3189 - val_false_loss: 12.9230 - val_true_loss: 1.1893\n",
      "Epoch 1460/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7890 - reconstruction_loss: 1890.5636 - kl_loss: 100.9688 - false_loss: 0.0915 - true_loss: 1.1330 - val_loss: 5991.2754 - val_reconstruction_loss: 1896.5607 - val_kl_loss: 99.3198 - val_false_loss: 12.9216 - val_true_loss: 1.1893\n",
      "Epoch 1461/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.3485 - reconstruction_loss: 1890.4635 - kl_loss: 101.6139 - false_loss: 0.0914 - true_loss: 1.1329 - val_loss: 5990.8555 - val_reconstruction_loss: 1896.5599 - val_kl_loss: 99.3203 - val_false_loss: 12.9202 - val_true_loss: 1.1892\n",
      "Epoch 1462/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8973 - reconstruction_loss: 1890.0312 - kl_loss: 101.9169 - false_loss: 0.0914 - true_loss: 1.1329 - val_loss: 5990.4341 - val_reconstruction_loss: 1896.5593 - val_kl_loss: 99.3203 - val_false_loss: 12.9188 - val_true_loss: 1.1892\n",
      "Epoch 1463/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.3686 - reconstruction_loss: 1890.1929 - kl_loss: 101.9398 - false_loss: 0.0914 - true_loss: 1.1328 - val_loss: 5990.0186 - val_reconstruction_loss: 1896.5586 - val_kl_loss: 99.3218 - val_false_loss: 12.9174 - val_true_loss: 1.1891\n",
      "Epoch 1464/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9279 - reconstruction_loss: 1890.8629 - kl_loss: 100.7985 - false_loss: 0.0914 - true_loss: 1.1328 - val_loss: 5989.5981 - val_reconstruction_loss: 1896.5582 - val_kl_loss: 99.3230 - val_false_loss: 12.9161 - val_true_loss: 1.1891\n",
      "Epoch 1465/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.3446 - reconstruction_loss: 1891.0137 - kl_loss: 100.4127 - false_loss: 0.0914 - true_loss: 1.1327 - val_loss: 5989.1812 - val_reconstruction_loss: 1896.5577 - val_kl_loss: 99.3234 - val_false_loss: 12.9147 - val_true_loss: 1.1890\n",
      "Epoch 1466/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0085 - reconstruction_loss: 1890.5771 - kl_loss: 100.2419 - false_loss: 0.0914 - true_loss: 1.1327 - val_loss: 5988.7607 - val_reconstruction_loss: 1896.5573 - val_kl_loss: 99.3236 - val_false_loss: 12.9133 - val_true_loss: 1.1890\n",
      "Epoch 1467/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.8401 - reconstruction_loss: 1890.4901 - kl_loss: 100.5911 - false_loss: 0.0914 - true_loss: 1.1326 - val_loss: 5988.3477 - val_reconstruction_loss: 1896.5565 - val_kl_loss: 99.3239 - val_false_loss: 12.9119 - val_true_loss: 1.1890\n",
      "Epoch 1468/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.4912 - reconstruction_loss: 1890.9271 - kl_loss: 101.1642 - false_loss: 0.0914 - true_loss: 1.1326 - val_loss: 5987.9307 - val_reconstruction_loss: 1896.5562 - val_kl_loss: 99.3238 - val_false_loss: 12.9106 - val_true_loss: 1.1889\n",
      "Epoch 1469/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.5630 - reconstruction_loss: 1890.5680 - kl_loss: 99.5188 - false_loss: 0.0914 - true_loss: 1.1325 - val_loss: 5987.5103 - val_reconstruction_loss: 1896.5555 - val_kl_loss: 99.3241 - val_false_loss: 12.9092 - val_true_loss: 1.1889\n",
      "Epoch 1470/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4543 - reconstruction_loss: 1890.2540 - kl_loss: 100.0038 - false_loss: 0.0914 - true_loss: 1.1325 - val_loss: 5987.0986 - val_reconstruction_loss: 1896.5551 - val_kl_loss: 99.3246 - val_false_loss: 12.9078 - val_true_loss: 1.1888\n",
      "Epoch 1471/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0417 - reconstruction_loss: 1890.0182 - kl_loss: 100.1274 - false_loss: 0.0914 - true_loss: 1.1324 - val_loss: 5986.6787 - val_reconstruction_loss: 1896.5543 - val_kl_loss: 99.3247 - val_false_loss: 12.9064 - val_true_loss: 1.1888\n",
      "Epoch 1472/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.1162 - reconstruction_loss: 1890.5967 - kl_loss: 100.3003 - false_loss: 0.0914 - true_loss: 1.1324 - val_loss: 5986.2637 - val_reconstruction_loss: 1896.5538 - val_kl_loss: 99.3248 - val_false_loss: 12.9051 - val_true_loss: 1.1887\n",
      "Epoch 1473/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8676 - reconstruction_loss: 1890.1324 - kl_loss: 99.6592 - false_loss: 0.0913 - true_loss: 1.1323 - val_loss: 5985.8535 - val_reconstruction_loss: 1896.5532 - val_kl_loss: 99.3253 - val_false_loss: 12.9037 - val_true_loss: 1.1887\n",
      "Epoch 1474/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0937 - reconstruction_loss: 1890.3451 - kl_loss: 100.4807 - false_loss: 0.0913 - true_loss: 1.1323 - val_loss: 5985.4375 - val_reconstruction_loss: 1896.5526 - val_kl_loss: 99.3249 - val_false_loss: 12.9024 - val_true_loss: 1.1886\n",
      "Epoch 1475/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4373 - reconstruction_loss: 1890.9038 - kl_loss: 99.8338 - false_loss: 0.0913 - true_loss: 1.1322 - val_loss: 5985.0195 - val_reconstruction_loss: 1896.5521 - val_kl_loss: 99.3251 - val_false_loss: 12.9010 - val_true_loss: 1.1886\n",
      "Epoch 1476/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3488 - reconstruction_loss: 1890.8203 - kl_loss: 101.0364 - false_loss: 0.0913 - true_loss: 1.1322 - val_loss: 5984.6006 - val_reconstruction_loss: 1896.5515 - val_kl_loss: 99.3256 - val_false_loss: 12.8996 - val_true_loss: 1.1885\n",
      "Epoch 1477/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.7980 - reconstruction_loss: 1890.6368 - kl_loss: 101.2979 - false_loss: 0.0913 - true_loss: 1.1321 - val_loss: 5984.1826 - val_reconstruction_loss: 1896.5510 - val_kl_loss: 99.3260 - val_false_loss: 12.8982 - val_true_loss: 1.1885\n",
      "Epoch 1478/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.7495 - reconstruction_loss: 1890.8864 - kl_loss: 101.5364 - false_loss: 0.0913 - true_loss: 1.1321 - val_loss: 5983.7676 - val_reconstruction_loss: 1896.5504 - val_kl_loss: 99.3261 - val_false_loss: 12.8969 - val_true_loss: 1.1884\n",
      "Epoch 1479/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.3219 - reconstruction_loss: 1890.6035 - kl_loss: 100.8094 - false_loss: 0.0913 - true_loss: 1.1320 - val_loss: 5983.3442 - val_reconstruction_loss: 1896.5498 - val_kl_loss: 99.3261 - val_false_loss: 12.8955 - val_true_loss: 1.1884\n",
      "Epoch 1480/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.8425 - reconstruction_loss: 1890.3014 - kl_loss: 101.1307 - false_loss: 0.0913 - true_loss: 1.1320 - val_loss: 5982.9355 - val_reconstruction_loss: 1896.5491 - val_kl_loss: 99.3260 - val_false_loss: 12.8941 - val_true_loss: 1.1884\n",
      "Epoch 1481/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.9307 - reconstruction_loss: 1890.7308 - kl_loss: 100.7044 - false_loss: 0.0913 - true_loss: 1.1319 - val_loss: 5982.5166 - val_reconstruction_loss: 1896.5487 - val_kl_loss: 99.3256 - val_false_loss: 12.8927 - val_true_loss: 1.1883\n",
      "Epoch 1482/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7666 - reconstruction_loss: 1890.6622 - kl_loss: 101.3999 - false_loss: 0.0913 - true_loss: 1.1319 - val_loss: 5982.0923 - val_reconstruction_loss: 1896.5483 - val_kl_loss: 99.3256 - val_false_loss: 12.8913 - val_true_loss: 1.1883\n",
      "Epoch 1483/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2732 - reconstruction_loss: 1890.4950 - kl_loss: 101.2287 - false_loss: 0.0913 - true_loss: 1.1318 - val_loss: 5981.6807 - val_reconstruction_loss: 1896.5477 - val_kl_loss: 99.3251 - val_false_loss: 12.8900 - val_true_loss: 1.1882\n",
      "Epoch 1484/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.4757 - reconstruction_loss: 1890.6279 - kl_loss: 101.1641 - false_loss: 0.0913 - true_loss: 1.1318 - val_loss: 5981.2637 - val_reconstruction_loss: 1896.5471 - val_kl_loss: 99.3260 - val_false_loss: 12.8886 - val_true_loss: 1.1882\n",
      "Epoch 1485/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0793 - reconstruction_loss: 1890.3236 - kl_loss: 100.8785 - false_loss: 0.0913 - true_loss: 1.1317 - val_loss: 5980.8389 - val_reconstruction_loss: 1896.5468 - val_kl_loss: 99.3266 - val_false_loss: 12.8872 - val_true_loss: 1.1881\n",
      "Epoch 1486/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.3175 - reconstruction_loss: 1890.5494 - kl_loss: 99.8217 - false_loss: 0.0912 - true_loss: 1.1317 - val_loss: 5980.4277 - val_reconstruction_loss: 1896.5460 - val_kl_loss: 99.3277 - val_false_loss: 12.8858 - val_true_loss: 1.1881\n",
      "Epoch 1487/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6221 - reconstruction_loss: 1890.5070 - kl_loss: 101.5879 - false_loss: 0.0912 - true_loss: 1.1316 - val_loss: 5980.0142 - val_reconstruction_loss: 1896.5454 - val_kl_loss: 99.3288 - val_false_loss: 12.8845 - val_true_loss: 1.1880\n",
      "Epoch 1488/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.1533 - reconstruction_loss: 1890.8300 - kl_loss: 100.8126 - false_loss: 0.0912 - true_loss: 1.1315 - val_loss: 5979.5991 - val_reconstruction_loss: 1896.5447 - val_kl_loss: 99.3295 - val_false_loss: 12.8831 - val_true_loss: 1.1880\n",
      "Epoch 1489/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.8887 - reconstruction_loss: 1890.6083 - kl_loss: 101.1423 - false_loss: 0.0912 - true_loss: 1.1315 - val_loss: 5979.1831 - val_reconstruction_loss: 1896.5443 - val_kl_loss: 99.3305 - val_false_loss: 12.8817 - val_true_loss: 1.1879\n",
      "Epoch 1490/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.8069 - reconstruction_loss: 1890.0851 - kl_loss: 101.4138 - false_loss: 0.0912 - true_loss: 1.1314 - val_loss: 5978.7632 - val_reconstruction_loss: 1896.5437 - val_kl_loss: 99.3309 - val_false_loss: 12.8804 - val_true_loss: 1.1879\n",
      "Epoch 1491/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4436 - reconstruction_loss: 1890.0660 - kl_loss: 101.2075 - false_loss: 0.0912 - true_loss: 1.1314 - val_loss: 5978.3359 - val_reconstruction_loss: 1896.5430 - val_kl_loss: 99.3312 - val_false_loss: 12.8790 - val_true_loss: 1.1878\n",
      "Epoch 1492/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.3331 - reconstruction_loss: 1890.6644 - kl_loss: 102.5386 - false_loss: 0.0912 - true_loss: 1.1313 - val_loss: 5977.9233 - val_reconstruction_loss: 1896.5426 - val_kl_loss: 99.3311 - val_false_loss: 12.8776 - val_true_loss: 1.1878\n",
      "Epoch 1493/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.6627 - reconstruction_loss: 1890.9922 - kl_loss: 98.8296 - false_loss: 0.0912 - true_loss: 1.1313 - val_loss: 5977.5181 - val_reconstruction_loss: 1896.5420 - val_kl_loss: 99.3309 - val_false_loss: 12.8763 - val_true_loss: 1.1878\n",
      "Epoch 1494/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.9406 - reconstruction_loss: 1890.6840 - kl_loss: 100.1034 - false_loss: 0.0912 - true_loss: 1.1313 - val_loss: 5977.1040 - val_reconstruction_loss: 1896.5414 - val_kl_loss: 99.3301 - val_false_loss: 12.8749 - val_true_loss: 1.1877\n",
      "Epoch 1495/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0638 - reconstruction_loss: 1890.6285 - kl_loss: 99.3286 - false_loss: 0.0912 - true_loss: 1.1312 - val_loss: 5976.6865 - val_reconstruction_loss: 1896.5406 - val_kl_loss: 99.3302 - val_false_loss: 12.8735 - val_true_loss: 1.1877\n",
      "Epoch 1496/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2120 - reconstruction_loss: 1890.2568 - kl_loss: 101.1433 - false_loss: 0.0912 - true_loss: 1.1311 - val_loss: 5976.2739 - val_reconstruction_loss: 1896.5403 - val_kl_loss: 99.3313 - val_false_loss: 12.8722 - val_true_loss: 1.1876\n",
      "Epoch 1497/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8536 - reconstruction_loss: 1890.1071 - kl_loss: 100.5182 - false_loss: 0.0912 - true_loss: 1.1311 - val_loss: 5975.8511 - val_reconstruction_loss: 1896.5397 - val_kl_loss: 99.3319 - val_false_loss: 12.8708 - val_true_loss: 1.1876\n",
      "Epoch 1498/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.8009 - reconstruction_loss: 1890.5391 - kl_loss: 101.5125 - false_loss: 0.0911 - true_loss: 1.1310 - val_loss: 5975.4355 - val_reconstruction_loss: 1896.5389 - val_kl_loss: 99.3316 - val_false_loss: 12.8694 - val_true_loss: 1.1875\n",
      "Epoch 1499/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9977 - reconstruction_loss: 1890.8433 - kl_loss: 100.9326 - false_loss: 0.0911 - true_loss: 1.1310 - val_loss: 5975.0220 - val_reconstruction_loss: 1896.5386 - val_kl_loss: 99.3310 - val_false_loss: 12.8680 - val_true_loss: 1.1875\n",
      "Epoch 1500/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5192 - reconstruction_loss: 1890.5283 - kl_loss: 100.1117 - false_loss: 0.0911 - true_loss: 1.1309 - val_loss: 5974.6025 - val_reconstruction_loss: 1896.5381 - val_kl_loss: 99.3319 - val_false_loss: 12.8667 - val_true_loss: 1.1874\n",
      "Epoch 1501/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.2462 - reconstruction_loss: 1890.4424 - kl_loss: 100.3855 - false_loss: 0.0911 - true_loss: 1.1309 - val_loss: 5974.1851 - val_reconstruction_loss: 1896.5375 - val_kl_loss: 99.3326 - val_false_loss: 12.8653 - val_true_loss: 1.1874\n",
      "Epoch 1502/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4854 - reconstruction_loss: 1890.7441 - kl_loss: 100.4694 - false_loss: 0.0911 - true_loss: 1.1308 - val_loss: 5973.7739 - val_reconstruction_loss: 1896.5370 - val_kl_loss: 99.3326 - val_false_loss: 12.8639 - val_true_loss: 1.1874\n",
      "Epoch 1503/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.5315 - reconstruction_loss: 1890.5062 - kl_loss: 98.2582 - false_loss: 0.0911 - true_loss: 1.1308 - val_loss: 5973.3623 - val_reconstruction_loss: 1896.5364 - val_kl_loss: 99.3341 - val_false_loss: 12.8626 - val_true_loss: 1.1873\n",
      "Epoch 1504/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.2383 - reconstruction_loss: 1890.4135 - kl_loss: 99.6114 - false_loss: 0.0911 - true_loss: 1.1308 - val_loss: 5972.9443 - val_reconstruction_loss: 1896.5358 - val_kl_loss: 99.3332 - val_false_loss: 12.8612 - val_true_loss: 1.1873\n",
      "Epoch 1505/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3633 - reconstruction_loss: 1890.5699 - kl_loss: 98.8826 - false_loss: 0.0911 - true_loss: 1.1307 - val_loss: 5972.5259 - val_reconstruction_loss: 1896.5353 - val_kl_loss: 99.3328 - val_false_loss: 12.8598 - val_true_loss: 1.1872\n",
      "Epoch 1506/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.6948 - reconstruction_loss: 1890.2994 - kl_loss: 100.2299 - false_loss: 0.0911 - true_loss: 1.1307 - val_loss: 5972.1206 - val_reconstruction_loss: 1896.5348 - val_kl_loss: 99.3324 - val_false_loss: 12.8585 - val_true_loss: 1.1872\n",
      "Epoch 1507/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0856 - reconstruction_loss: 1890.0853 - kl_loss: 100.9905 - false_loss: 0.0911 - true_loss: 1.1306 - val_loss: 5971.7095 - val_reconstruction_loss: 1896.5342 - val_kl_loss: 99.3324 - val_false_loss: 12.8571 - val_true_loss: 1.1872\n",
      "Epoch 1508/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4807 - reconstruction_loss: 1890.6138 - kl_loss: 101.0566 - false_loss: 0.0911 - true_loss: 1.1306 - val_loss: 5971.2983 - val_reconstruction_loss: 1896.5337 - val_kl_loss: 99.3325 - val_false_loss: 12.8558 - val_true_loss: 1.1871\n",
      "Epoch 1509/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9138 - reconstruction_loss: 1890.6046 - kl_loss: 100.5147 - false_loss: 0.0911 - true_loss: 1.1305 - val_loss: 5970.8828 - val_reconstruction_loss: 1896.5332 - val_kl_loss: 99.3334 - val_false_loss: 12.8544 - val_true_loss: 1.1871\n",
      "Epoch 1510/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8892 - reconstruction_loss: 1890.7471 - kl_loss: 101.1639 - false_loss: 0.0911 - true_loss: 1.1304 - val_loss: 5970.4692 - val_reconstruction_loss: 1896.5327 - val_kl_loss: 99.3341 - val_false_loss: 12.8530 - val_true_loss: 1.1870\n",
      "Epoch 1511/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.3292 - reconstruction_loss: 1890.3793 - kl_loss: 101.0866 - false_loss: 0.0910 - true_loss: 1.1304 - val_loss: 5970.0581 - val_reconstruction_loss: 1896.5322 - val_kl_loss: 99.3358 - val_false_loss: 12.8517 - val_true_loss: 1.1870\n",
      "Epoch 1512/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.0125 - reconstruction_loss: 1890.7155 - kl_loss: 101.6566 - false_loss: 0.0910 - true_loss: 1.1303 - val_loss: 5969.6504 - val_reconstruction_loss: 1896.5317 - val_kl_loss: 99.3372 - val_false_loss: 12.8503 - val_true_loss: 1.1869\n",
      "Epoch 1513/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9565 - reconstruction_loss: 1890.8090 - kl_loss: 100.6839 - false_loss: 0.0910 - true_loss: 1.1303 - val_loss: 5969.2344 - val_reconstruction_loss: 1896.5310 - val_kl_loss: 99.3384 - val_false_loss: 12.8490 - val_true_loss: 1.1869\n",
      "Epoch 1514/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.3089 - reconstruction_loss: 1890.9242 - kl_loss: 100.5169 - false_loss: 0.0910 - true_loss: 1.1302 - val_loss: 5968.8135 - val_reconstruction_loss: 1896.5304 - val_kl_loss: 99.3385 - val_false_loss: 12.8476 - val_true_loss: 1.1868\n",
      "Epoch 1515/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.4988 - reconstruction_loss: 1891.1967 - kl_loss: 101.3959 - false_loss: 0.0910 - true_loss: 1.1302 - val_loss: 5968.4019 - val_reconstruction_loss: 1896.5299 - val_kl_loss: 99.3382 - val_false_loss: 12.8462 - val_true_loss: 1.1868\n",
      "Epoch 1516/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6843 - reconstruction_loss: 1890.6207 - kl_loss: 99.8848 - false_loss: 0.0910 - true_loss: 1.1301 - val_loss: 5967.9863 - val_reconstruction_loss: 1896.5293 - val_kl_loss: 99.3390 - val_false_loss: 12.8449 - val_true_loss: 1.1867\n",
      "Epoch 1517/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.3062 - reconstruction_loss: 1889.9769 - kl_loss: 100.6571 - false_loss: 0.0910 - true_loss: 1.1301 - val_loss: 5967.5742 - val_reconstruction_loss: 1896.5287 - val_kl_loss: 99.3398 - val_false_loss: 12.8435 - val_true_loss: 1.1867\n",
      "Epoch 1518/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.0432 - reconstruction_loss: 1890.4918 - kl_loss: 101.4899 - false_loss: 0.0910 - true_loss: 1.1300 - val_loss: 5967.1616 - val_reconstruction_loss: 1896.5281 - val_kl_loss: 99.3407 - val_false_loss: 12.8421 - val_true_loss: 1.1866\n",
      "Epoch 1519/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9853 - reconstruction_loss: 1890.3657 - kl_loss: 101.9890 - false_loss: 0.0910 - true_loss: 1.1300 - val_loss: 5966.7524 - val_reconstruction_loss: 1896.5276 - val_kl_loss: 99.3419 - val_false_loss: 12.8408 - val_true_loss: 1.1866\n",
      "Epoch 1520/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.3401 - reconstruction_loss: 1890.1573 - kl_loss: 101.7759 - false_loss: 0.0910 - true_loss: 1.1299 - val_loss: 5966.3374 - val_reconstruction_loss: 1896.5270 - val_kl_loss: 99.3429 - val_false_loss: 12.8394 - val_true_loss: 1.1865\n",
      "Epoch 1521/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8935 - reconstruction_loss: 1890.8104 - kl_loss: 99.6007 - false_loss: 0.0910 - true_loss: 1.1299 - val_loss: 5965.9204 - val_reconstruction_loss: 1896.5265 - val_kl_loss: 99.3440 - val_false_loss: 12.8380 - val_true_loss: 1.1865\n",
      "Epoch 1522/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.9837 - reconstruction_loss: 1890.9800 - kl_loss: 101.4664 - false_loss: 0.0910 - true_loss: 1.1298 - val_loss: 5965.5117 - val_reconstruction_loss: 1896.5259 - val_kl_loss: 99.3443 - val_false_loss: 12.8367 - val_true_loss: 1.1865\n",
      "Epoch 1523/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.3266 - reconstruction_loss: 1890.4313 - kl_loss: 101.1647 - false_loss: 0.0909 - true_loss: 1.1298 - val_loss: 5965.1074 - val_reconstruction_loss: 1896.5254 - val_kl_loss: 99.3448 - val_false_loss: 12.8354 - val_true_loss: 1.1864\n",
      "Epoch 1524/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7143 - reconstruction_loss: 1890.3213 - kl_loss: 100.0782 - false_loss: 0.0909 - true_loss: 1.1297 - val_loss: 5964.6978 - val_reconstruction_loss: 1896.5247 - val_kl_loss: 99.3445 - val_false_loss: 12.8340 - val_true_loss: 1.1864\n",
      "Epoch 1525/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2244.9988 - reconstruction_loss: 1890.2588 - kl_loss: 99.8564 - false_loss: 0.0909 - true_loss: 1.1297 - val_loss: 5964.2876 - val_reconstruction_loss: 1896.5242 - val_kl_loss: 99.3457 - val_false_loss: 12.8326 - val_true_loss: 1.1863\n",
      "Epoch 1526/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.7405 - reconstruction_loss: 1890.4702 - kl_loss: 98.4905 - false_loss: 0.0909 - true_loss: 1.1296 - val_loss: 5963.8887 - val_reconstruction_loss: 1896.5237 - val_kl_loss: 99.3451 - val_false_loss: 12.8313 - val_true_loss: 1.1863\n",
      "Epoch 1527/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.1928 - reconstruction_loss: 1890.5380 - kl_loss: 99.2898 - false_loss: 0.0909 - true_loss: 1.1296 - val_loss: 5963.4839 - val_reconstruction_loss: 1896.5232 - val_kl_loss: 99.3455 - val_false_loss: 12.8300 - val_true_loss: 1.1863\n",
      "Epoch 1528/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.3781 - reconstruction_loss: 1890.3853 - kl_loss: 98.7696 - false_loss: 0.0909 - true_loss: 1.1296 - val_loss: 5963.0654 - val_reconstruction_loss: 1896.5225 - val_kl_loss: 99.3457 - val_false_loss: 12.8286 - val_true_loss: 1.1862\n",
      "Epoch 1529/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.4810 - reconstruction_loss: 1890.4203 - kl_loss: 98.8841 - false_loss: 0.0909 - true_loss: 1.1295 - val_loss: 5962.6519 - val_reconstruction_loss: 1896.5220 - val_kl_loss: 99.3451 - val_false_loss: 12.8273 - val_true_loss: 1.1862\n",
      "Epoch 1530/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.9201 - reconstruction_loss: 1890.5367 - kl_loss: 98.5121 - false_loss: 0.0909 - true_loss: 1.1295 - val_loss: 5962.2451 - val_reconstruction_loss: 1896.5215 - val_kl_loss: 99.3461 - val_false_loss: 12.8259 - val_true_loss: 1.1862\n",
      "Epoch 1531/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.3000 - reconstruction_loss: 1890.2623 - kl_loss: 99.2534 - false_loss: 0.0909 - true_loss: 1.1294 - val_loss: 5961.8359 - val_reconstruction_loss: 1896.5210 - val_kl_loss: 99.3459 - val_false_loss: 12.8246 - val_true_loss: 1.1861\n",
      "Epoch 1532/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.2405 - reconstruction_loss: 1890.1891 - kl_loss: 99.3677 - false_loss: 0.0909 - true_loss: 1.1294 - val_loss: 5961.4351 - val_reconstruction_loss: 1896.5204 - val_kl_loss: 99.3460 - val_false_loss: 12.8232 - val_true_loss: 1.1861\n",
      "Epoch 1533/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.0688 - reconstruction_loss: 1890.1265 - kl_loss: 99.3175 - false_loss: 0.0909 - true_loss: 1.1293 - val_loss: 5961.0225 - val_reconstruction_loss: 1896.5198 - val_kl_loss: 99.3456 - val_false_loss: 12.8219 - val_true_loss: 1.1861\n",
      "Epoch 1534/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.7156 - reconstruction_loss: 1890.0690 - kl_loss: 98.5128 - false_loss: 0.0909 - true_loss: 1.1293 - val_loss: 5960.6104 - val_reconstruction_loss: 1896.5192 - val_kl_loss: 99.3457 - val_false_loss: 12.8205 - val_true_loss: 1.1860\n",
      "Epoch 1535/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.2422 - reconstruction_loss: 1890.4508 - kl_loss: 98.3423 - false_loss: 0.0909 - true_loss: 1.1292 - val_loss: 5960.2080 - val_reconstruction_loss: 1896.5187 - val_kl_loss: 99.3469 - val_false_loss: 12.8192 - val_true_loss: 1.1860\n",
      "Epoch 1536/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.3875 - reconstruction_loss: 1890.7540 - kl_loss: 99.7072 - false_loss: 0.0908 - true_loss: 1.1292 - val_loss: 5959.7910 - val_reconstruction_loss: 1896.5182 - val_kl_loss: 99.3463 - val_false_loss: 12.8178 - val_true_loss: 1.1859\n",
      "Epoch 1537/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.4795 - reconstruction_loss: 1891.2926 - kl_loss: 98.9992 - false_loss: 0.0908 - true_loss: 1.1291 - val_loss: 5959.3975 - val_reconstruction_loss: 1896.5178 - val_kl_loss: 99.3470 - val_false_loss: 12.8165 - val_true_loss: 1.1859\n",
      "Epoch 1538/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6182 - reconstruction_loss: 1890.6958 - kl_loss: 98.4681 - false_loss: 0.0908 - true_loss: 1.1291 - val_loss: 5958.9917 - val_reconstruction_loss: 1896.5172 - val_kl_loss: 99.3473 - val_false_loss: 12.8152 - val_true_loss: 1.1859\n",
      "Epoch 1539/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8567 - reconstruction_loss: 1890.9225 - kl_loss: 99.2023 - false_loss: 0.0908 - true_loss: 1.1290 - val_loss: 5958.5815 - val_reconstruction_loss: 1896.5165 - val_kl_loss: 99.3480 - val_false_loss: 12.8138 - val_true_loss: 1.1858\n",
      "Epoch 1540/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.6159 - reconstruction_loss: 1890.2451 - kl_loss: 99.3126 - false_loss: 0.0908 - true_loss: 1.1290 - val_loss: 5958.1748 - val_reconstruction_loss: 1896.5161 - val_kl_loss: 99.3482 - val_false_loss: 12.8125 - val_true_loss: 1.1858\n",
      "Epoch 1541/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1079 - reconstruction_loss: 1890.0360 - kl_loss: 99.7058 - false_loss: 0.0908 - true_loss: 1.1289 - val_loss: 5957.7676 - val_reconstruction_loss: 1896.5155 - val_kl_loss: 99.3487 - val_false_loss: 12.8111 - val_true_loss: 1.1857\n",
      "Epoch 1542/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.0472 - reconstruction_loss: 1890.4281 - kl_loss: 98.8562 - false_loss: 0.0908 - true_loss: 1.1289 - val_loss: 5957.3643 - val_reconstruction_loss: 1896.5149 - val_kl_loss: 99.3494 - val_false_loss: 12.8098 - val_true_loss: 1.1857\n",
      "Epoch 1543/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4125 - reconstruction_loss: 1890.3334 - kl_loss: 100.1665 - false_loss: 0.0908 - true_loss: 1.1288 - val_loss: 5956.9570 - val_reconstruction_loss: 1896.5145 - val_kl_loss: 99.3500 - val_false_loss: 12.8085 - val_true_loss: 1.1856\n",
      "Epoch 1544/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.7649 - reconstruction_loss: 1890.9213 - kl_loss: 100.6862 - false_loss: 0.0908 - true_loss: 1.1288 - val_loss: 5956.5493 - val_reconstruction_loss: 1896.5142 - val_kl_loss: 99.3508 - val_false_loss: 12.8071 - val_true_loss: 1.1856\n",
      "Epoch 1545/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.5528 - reconstruction_loss: 1890.8549 - kl_loss: 101.0244 - false_loss: 0.0908 - true_loss: 1.1287 - val_loss: 5956.1416 - val_reconstruction_loss: 1896.5134 - val_kl_loss: 99.3509 - val_false_loss: 12.8058 - val_true_loss: 1.1855\n",
      "Epoch 1546/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4034 - reconstruction_loss: 1890.5006 - kl_loss: 99.8146 - false_loss: 0.0908 - true_loss: 1.1287 - val_loss: 5955.7329 - val_reconstruction_loss: 1896.5129 - val_kl_loss: 99.3504 - val_false_loss: 12.8044 - val_true_loss: 1.1855\n",
      "Epoch 1547/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0797 - reconstruction_loss: 1890.0800 - kl_loss: 100.2792 - false_loss: 0.0908 - true_loss: 1.1286 - val_loss: 5955.3276 - val_reconstruction_loss: 1896.5123 - val_kl_loss: 99.3502 - val_false_loss: 12.8031 - val_true_loss: 1.1855\n",
      "Epoch 1548/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.2209 - reconstruction_loss: 1890.7059 - kl_loss: 100.8062 - false_loss: 0.0908 - true_loss: 1.1286 - val_loss: 5954.9121 - val_reconstruction_loss: 1896.5118 - val_kl_loss: 99.3502 - val_false_loss: 12.8017 - val_true_loss: 1.1854\n",
      "Epoch 1549/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.0795 - reconstruction_loss: 1890.2983 - kl_loss: 101.0373 - false_loss: 0.0907 - true_loss: 1.1285 - val_loss: 5954.4971 - val_reconstruction_loss: 1896.5111 - val_kl_loss: 99.3504 - val_false_loss: 12.8004 - val_true_loss: 1.1854\n",
      "Epoch 1550/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.0659 - reconstruction_loss: 1889.9408 - kl_loss: 101.1640 - false_loss: 0.0907 - true_loss: 1.1285 - val_loss: 5954.0879 - val_reconstruction_loss: 1896.5106 - val_kl_loss: 99.3507 - val_false_loss: 12.7990 - val_true_loss: 1.1853\n",
      "Epoch 1551/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.2431 - reconstruction_loss: 1890.5248 - kl_loss: 102.0402 - false_loss: 0.0907 - true_loss: 1.1284 - val_loss: 5953.6792 - val_reconstruction_loss: 1896.5100 - val_kl_loss: 99.3513 - val_false_loss: 12.7977 - val_true_loss: 1.1853\n",
      "Epoch 1552/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.3715 - reconstruction_loss: 1890.3195 - kl_loss: 100.7521 - false_loss: 0.0907 - true_loss: 1.1284 - val_loss: 5953.2705 - val_reconstruction_loss: 1896.5095 - val_kl_loss: 99.3518 - val_false_loss: 12.7963 - val_true_loss: 1.1852\n",
      "Epoch 1553/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.5447 - reconstruction_loss: 1890.5791 - kl_loss: 100.8832 - false_loss: 0.0907 - true_loss: 1.1283 - val_loss: 5952.8584 - val_reconstruction_loss: 1896.5092 - val_kl_loss: 99.3526 - val_false_loss: 12.7950 - val_true_loss: 1.1852\n",
      "Epoch 1554/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.0386 - reconstruction_loss: 1890.2456 - kl_loss: 101.4312 - false_loss: 0.0907 - true_loss: 1.1283 - val_loss: 5952.4487 - val_reconstruction_loss: 1896.5085 - val_kl_loss: 99.3537 - val_false_loss: 12.7936 - val_true_loss: 1.1851\n",
      "Epoch 1555/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.4747 - reconstruction_loss: 1890.1495 - kl_loss: 101.4440 - false_loss: 0.0907 - true_loss: 1.1282 - val_loss: 5952.0337 - val_reconstruction_loss: 1896.5078 - val_kl_loss: 99.3547 - val_false_loss: 12.7922 - val_true_loss: 1.1851\n",
      "Epoch 1556/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.6736 - reconstruction_loss: 1890.4849 - kl_loss: 101.8864 - false_loss: 0.0907 - true_loss: 1.1282 - val_loss: 5951.6274 - val_reconstruction_loss: 1896.5074 - val_kl_loss: 99.3555 - val_false_loss: 12.7909 - val_true_loss: 1.1850\n",
      "Epoch 1557/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.3554 - reconstruction_loss: 1890.1678 - kl_loss: 99.4353 - false_loss: 0.0907 - true_loss: 1.1281 - val_loss: 5951.2295 - val_reconstruction_loss: 1896.5068 - val_kl_loss: 99.3576 - val_false_loss: 12.7896 - val_true_loss: 1.1850\n",
      "Epoch 1558/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.7665 - reconstruction_loss: 1890.8271 - kl_loss: 101.0541 - false_loss: 0.0907 - true_loss: 1.1281 - val_loss: 5950.8223 - val_reconstruction_loss: 1896.5062 - val_kl_loss: 99.3565 - val_false_loss: 12.7882 - val_true_loss: 1.1849\n",
      "Epoch 1559/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.6105 - reconstruction_loss: 1890.6891 - kl_loss: 99.4770 - false_loss: 0.0907 - true_loss: 1.1280 - val_loss: 5950.4048 - val_reconstruction_loss: 1896.5056 - val_kl_loss: 99.3566 - val_false_loss: 12.7869 - val_true_loss: 1.1849\n",
      "Epoch 1560/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.4032 - reconstruction_loss: 1890.2563 - kl_loss: 98.7961 - false_loss: 0.0907 - true_loss: 1.1280 - val_loss: 5949.9971 - val_reconstruction_loss: 1896.5051 - val_kl_loss: 99.3581 - val_false_loss: 12.7855 - val_true_loss: 1.1849\n",
      "Epoch 1561/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2231.1630 - reconstruction_loss: 1890.9556 - kl_loss: 101.0673 - false_loss: 0.0907 - true_loss: 1.1279 - val_loss: 5949.6040 - val_reconstruction_loss: 1896.5046 - val_kl_loss: 99.3591 - val_false_loss: 12.7842 - val_true_loss: 1.1848\n",
      "Epoch 1562/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.1972 - reconstruction_loss: 1890.4491 - kl_loss: 100.9145 - false_loss: 0.0906 - true_loss: 1.1279 - val_loss: 5949.1978 - val_reconstruction_loss: 1896.5042 - val_kl_loss: 99.3594 - val_false_loss: 12.7829 - val_true_loss: 1.1848\n",
      "Epoch 1563/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.8389 - reconstruction_loss: 1890.2642 - kl_loss: 101.0771 - false_loss: 0.0906 - true_loss: 1.1278 - val_loss: 5948.7896 - val_reconstruction_loss: 1896.5037 - val_kl_loss: 99.3603 - val_false_loss: 12.7815 - val_true_loss: 1.1847\n",
      "Epoch 1564/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.2392 - reconstruction_loss: 1890.7944 - kl_loss: 101.9649 - false_loss: 0.0906 - true_loss: 1.1278 - val_loss: 5948.3813 - val_reconstruction_loss: 1896.5031 - val_kl_loss: 99.3605 - val_false_loss: 12.7802 - val_true_loss: 1.1847\n",
      "Epoch 1565/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.6607 - reconstruction_loss: 1890.1158 - kl_loss: 101.4577 - false_loss: 0.0906 - true_loss: 1.1277 - val_loss: 5947.9751 - val_reconstruction_loss: 1896.5026 - val_kl_loss: 99.3609 - val_false_loss: 12.7789 - val_true_loss: 1.1846\n",
      "Epoch 1566/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9203 - reconstruction_loss: 1890.0902 - kl_loss: 101.1530 - false_loss: 0.0906 - true_loss: 1.1277 - val_loss: 5947.5669 - val_reconstruction_loss: 1896.5020 - val_kl_loss: 99.3613 - val_false_loss: 12.7775 - val_true_loss: 1.1846\n",
      "Epoch 1567/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7323 - reconstruction_loss: 1890.8414 - kl_loss: 100.4188 - false_loss: 0.0906 - true_loss: 1.1276 - val_loss: 5947.1611 - val_reconstruction_loss: 1896.5015 - val_kl_loss: 99.3618 - val_false_loss: 12.7762 - val_true_loss: 1.1845\n",
      "Epoch 1568/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.2820 - reconstruction_loss: 1891.1031 - kl_loss: 99.0317 - false_loss: 0.0906 - true_loss: 1.1276 - val_loss: 5946.7520 - val_reconstruction_loss: 1896.5009 - val_kl_loss: 99.3625 - val_false_loss: 12.7748 - val_true_loss: 1.1845\n",
      "Epoch 1569/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.0297 - reconstruction_loss: 1890.8873 - kl_loss: 99.8098 - false_loss: 0.0906 - true_loss: 1.1275 - val_loss: 5946.3496 - val_reconstruction_loss: 1896.5004 - val_kl_loss: 99.3636 - val_false_loss: 12.7735 - val_true_loss: 1.1844\n",
      "Epoch 1570/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.5953 - reconstruction_loss: 1890.5629 - kl_loss: 100.3645 - false_loss: 0.0906 - true_loss: 1.1275 - val_loss: 5945.9468 - val_reconstruction_loss: 1896.4999 - val_kl_loss: 99.3647 - val_false_loss: 12.7722 - val_true_loss: 1.1844\n",
      "Epoch 1571/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.3376 - reconstruction_loss: 1890.4731 - kl_loss: 100.0490 - false_loss: 0.0906 - true_loss: 1.1274 - val_loss: 5945.5396 - val_reconstruction_loss: 1896.4993 - val_kl_loss: 99.3651 - val_false_loss: 12.7708 - val_true_loss: 1.1844\n",
      "Epoch 1572/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1646 - reconstruction_loss: 1890.1742 - kl_loss: 99.9912 - false_loss: 0.0906 - true_loss: 1.1274 - val_loss: 5945.1416 - val_reconstruction_loss: 1896.4985 - val_kl_loss: 99.3645 - val_false_loss: 12.7695 - val_true_loss: 1.1843\n",
      "Epoch 1573/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.1169 - reconstruction_loss: 1890.2599 - kl_loss: 99.3078 - false_loss: 0.0906 - true_loss: 1.1273 - val_loss: 5944.7329 - val_reconstruction_loss: 1896.4982 - val_kl_loss: 99.3652 - val_false_loss: 12.7682 - val_true_loss: 1.1843\n",
      "Epoch 1574/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.8989 - reconstruction_loss: 1890.3109 - kl_loss: 99.3966 - false_loss: 0.0906 - true_loss: 1.1273 - val_loss: 5944.3237 - val_reconstruction_loss: 1896.4976 - val_kl_loss: 99.3665 - val_false_loss: 12.7668 - val_true_loss: 1.1842\n",
      "Epoch 1575/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.3203 - reconstruction_loss: 1890.4388 - kl_loss: 99.0338 - false_loss: 0.0905 - true_loss: 1.1272 - val_loss: 5943.9165 - val_reconstruction_loss: 1896.4969 - val_kl_loss: 99.3660 - val_false_loss: 12.7655 - val_true_loss: 1.1842\n",
      "Epoch 1576/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.1838 - reconstruction_loss: 1890.4219 - kl_loss: 99.2037 - false_loss: 0.0905 - true_loss: 1.1272 - val_loss: 5943.5059 - val_reconstruction_loss: 1896.4966 - val_kl_loss: 99.3668 - val_false_loss: 12.7641 - val_true_loss: 1.1841\n",
      "Epoch 1577/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.9231 - reconstruction_loss: 1890.5570 - kl_loss: 98.5782 - false_loss: 0.0905 - true_loss: 1.1271 - val_loss: 5943.1011 - val_reconstruction_loss: 1896.4961 - val_kl_loss: 99.3669 - val_false_loss: 12.7628 - val_true_loss: 1.1841\n",
      "Epoch 1578/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.9649 - reconstruction_loss: 1890.8795 - kl_loss: 99.0567 - false_loss: 0.0905 - true_loss: 1.1271 - val_loss: 5942.6860 - val_reconstruction_loss: 1896.4956 - val_kl_loss: 99.3676 - val_false_loss: 12.7614 - val_true_loss: 1.1841\n",
      "Epoch 1579/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.8889 - reconstruction_loss: 1890.6261 - kl_loss: 99.1411 - false_loss: 0.0905 - true_loss: 1.1270 - val_loss: 5942.2764 - val_reconstruction_loss: 1896.4949 - val_kl_loss: 99.3684 - val_false_loss: 12.7601 - val_true_loss: 1.1840\n",
      "Epoch 1580/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3631 - reconstruction_loss: 1891.2012 - kl_loss: 100.9616 - false_loss: 0.0905 - true_loss: 1.1270 - val_loss: 5941.8750 - val_reconstruction_loss: 1896.4945 - val_kl_loss: 99.3686 - val_false_loss: 12.7588 - val_true_loss: 1.1840\n",
      "Epoch 1581/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.9552 - reconstruction_loss: 1891.1610 - kl_loss: 100.3467 - false_loss: 0.0905 - true_loss: 1.1269 - val_loss: 5941.4668 - val_reconstruction_loss: 1896.4940 - val_kl_loss: 99.3688 - val_false_loss: 12.7574 - val_true_loss: 1.1839\n",
      "Epoch 1582/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.3993 - reconstruction_loss: 1890.4860 - kl_loss: 100.5969 - false_loss: 0.0905 - true_loss: 1.1269 - val_loss: 5941.0620 - val_reconstruction_loss: 1896.4935 - val_kl_loss: 99.3693 - val_false_loss: 12.7561 - val_true_loss: 1.1839\n",
      "Epoch 1583/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9973 - reconstruction_loss: 1890.2086 - kl_loss: 100.8092 - false_loss: 0.0905 - true_loss: 1.1268 - val_loss: 5940.6611 - val_reconstruction_loss: 1896.4930 - val_kl_loss: 99.3694 - val_false_loss: 12.7548 - val_true_loss: 1.1838\n",
      "Epoch 1584/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.2417 - reconstruction_loss: 1890.0453 - kl_loss: 100.8234 - false_loss: 0.0905 - true_loss: 1.1268 - val_loss: 5940.2510 - val_reconstruction_loss: 1896.4924 - val_kl_loss: 99.3691 - val_false_loss: 12.7534 - val_true_loss: 1.1838\n",
      "Epoch 1585/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.1727 - reconstruction_loss: 1890.2783 - kl_loss: 100.9672 - false_loss: 0.0905 - true_loss: 1.1267 - val_loss: 5939.8389 - val_reconstruction_loss: 1896.4919 - val_kl_loss: 99.3695 - val_false_loss: 12.7521 - val_true_loss: 1.1837\n",
      "Epoch 1586/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.4963 - reconstruction_loss: 1890.7985 - kl_loss: 100.4956 - false_loss: 0.0905 - true_loss: 1.1267 - val_loss: 5939.4341 - val_reconstruction_loss: 1896.4915 - val_kl_loss: 99.3699 - val_false_loss: 12.7507 - val_true_loss: 1.1837\n",
      "Epoch 1587/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5855 - reconstruction_loss: 1890.1187 - kl_loss: 100.6249 - false_loss: 0.0904 - true_loss: 1.1266 - val_loss: 5939.0308 - val_reconstruction_loss: 1896.4907 - val_kl_loss: 99.3703 - val_false_loss: 12.7494 - val_true_loss: 1.1836\n",
      "Epoch 1588/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.4825 - reconstruction_loss: 1889.9479 - kl_loss: 100.1714 - false_loss: 0.0904 - true_loss: 1.1266 - val_loss: 5938.6338 - val_reconstruction_loss: 1896.4902 - val_kl_loss: 99.3711 - val_false_loss: 12.7481 - val_true_loss: 1.1836\n",
      "Epoch 1589/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0488 - reconstruction_loss: 1890.1973 - kl_loss: 99.9311 - false_loss: 0.0904 - true_loss: 1.1265 - val_loss: 5938.2280 - val_reconstruction_loss: 1896.4897 - val_kl_loss: 99.3722 - val_false_loss: 12.7467 - val_true_loss: 1.1835\n",
      "Epoch 1590/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8065 - reconstruction_loss: 1890.4745 - kl_loss: 100.3613 - false_loss: 0.0904 - true_loss: 1.1265 - val_loss: 5937.8237 - val_reconstruction_loss: 1896.4891 - val_kl_loss: 99.3736 - val_false_loss: 12.7454 - val_true_loss: 1.1835\n",
      "Epoch 1591/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.4112 - reconstruction_loss: 1890.6143 - kl_loss: 100.8704 - false_loss: 0.0904 - true_loss: 1.1264 - val_loss: 5937.4160 - val_reconstruction_loss: 1896.4886 - val_kl_loss: 99.3739 - val_false_loss: 12.7441 - val_true_loss: 1.1834\n",
      "Epoch 1592/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.3078 - reconstruction_loss: 1890.5780 - kl_loss: 101.1560 - false_loss: 0.0904 - true_loss: 1.1264 - val_loss: 5937.0112 - val_reconstruction_loss: 1896.4882 - val_kl_loss: 99.3735 - val_false_loss: 12.7427 - val_true_loss: 1.1834\n",
      "Epoch 1593/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.2731 - reconstruction_loss: 1890.4508 - kl_loss: 101.6332 - false_loss: 0.0904 - true_loss: 1.1263 - val_loss: 5936.6094 - val_reconstruction_loss: 1896.4877 - val_kl_loss: 99.3736 - val_false_loss: 12.7414 - val_true_loss: 1.1833\n",
      "Epoch 1594/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.1404 - reconstruction_loss: 1890.7609 - kl_loss: 101.0194 - false_loss: 0.0904 - true_loss: 1.1263 - val_loss: 5936.2075 - val_reconstruction_loss: 1896.4873 - val_kl_loss: 99.3740 - val_false_loss: 12.7401 - val_true_loss: 1.1833\n",
      "Epoch 1595/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.6697 - reconstruction_loss: 1890.4146 - kl_loss: 101.1791 - false_loss: 0.0904 - true_loss: 1.1262 - val_loss: 5935.8086 - val_reconstruction_loss: 1896.4867 - val_kl_loss: 99.3749 - val_false_loss: 12.7388 - val_true_loss: 1.1832\n",
      "Epoch 1596/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2730 - reconstruction_loss: 1890.4789 - kl_loss: 100.8782 - false_loss: 0.0904 - true_loss: 1.1262 - val_loss: 5935.4072 - val_reconstruction_loss: 1896.4860 - val_kl_loss: 99.3755 - val_false_loss: 12.7374 - val_true_loss: 1.1832\n",
      "Epoch 1597/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.5561 - reconstruction_loss: 1890.2568 - kl_loss: 100.4778 - false_loss: 0.0904 - true_loss: 1.1261 - val_loss: 5935.0137 - val_reconstruction_loss: 1896.4854 - val_kl_loss: 99.3759 - val_false_loss: 12.7361 - val_true_loss: 1.1832\n",
      "Epoch 1598/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2258.3652 - reconstruction_loss: 1890.3629 - kl_loss: 101.3877 - false_loss: 0.0904 - true_loss: 1.1261 - val_loss: 5934.6138 - val_reconstruction_loss: 1896.4850 - val_kl_loss: 99.3752 - val_false_loss: 12.7348 - val_true_loss: 1.1832\n",
      "Epoch 1599/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.2898 - reconstruction_loss: 1890.4381 - kl_loss: 99.3825 - false_loss: 0.0904 - true_loss: 1.1260 - val_loss: 5934.2188 - val_reconstruction_loss: 1896.4844 - val_kl_loss: 99.3758 - val_false_loss: 12.7335 - val_true_loss: 1.1831\n",
      "Epoch 1600/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0701 - reconstruction_loss: 1890.5449 - kl_loss: 99.2628 - false_loss: 0.0903 - true_loss: 1.1260 - val_loss: 5933.8184 - val_reconstruction_loss: 1896.4838 - val_kl_loss: 99.3747 - val_false_loss: 12.7322 - val_true_loss: 1.1831\n",
      "Epoch 1601/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.3253 - reconstruction_loss: 1890.5426 - kl_loss: 100.1263 - false_loss: 0.0903 - true_loss: 1.1260 - val_loss: 5933.4199 - val_reconstruction_loss: 1896.4834 - val_kl_loss: 99.3745 - val_false_loss: 12.7309 - val_true_loss: 1.1831\n",
      "Epoch 1602/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2254.8725 - reconstruction_loss: 1891.5209 - kl_loss: 96.5575 - false_loss: 0.0903 - true_loss: 1.1259 - val_loss: 5933.0156 - val_reconstruction_loss: 1896.4829 - val_kl_loss: 99.3735 - val_false_loss: 12.7296 - val_true_loss: 1.1830\n",
      "Epoch 1603/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.4452 - reconstruction_loss: 1891.0411 - kl_loss: 96.5468 - false_loss: 0.0903 - true_loss: 1.1259 - val_loss: 5932.6030 - val_reconstruction_loss: 1896.4824 - val_kl_loss: 99.3728 - val_false_loss: 12.7282 - val_true_loss: 1.1830\n",
      "Epoch 1604/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.5010 - reconstruction_loss: 1890.4766 - kl_loss: 98.8778 - false_loss: 0.0903 - true_loss: 1.1258 - val_loss: 5932.1978 - val_reconstruction_loss: 1896.4817 - val_kl_loss: 99.3727 - val_false_loss: 12.7269 - val_true_loss: 1.1829\n",
      "Epoch 1605/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6333 - reconstruction_loss: 1890.2643 - kl_loss: 99.2787 - false_loss: 0.0903 - true_loss: 1.1258 - val_loss: 5931.7988 - val_reconstruction_loss: 1896.4811 - val_kl_loss: 99.3728 - val_false_loss: 12.7255 - val_true_loss: 1.1829\n",
      "Epoch 1606/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9896 - reconstruction_loss: 1890.0023 - kl_loss: 100.6880 - false_loss: 0.0903 - true_loss: 1.1257 - val_loss: 5931.3960 - val_reconstruction_loss: 1896.4807 - val_kl_loss: 99.3727 - val_false_loss: 12.7242 - val_true_loss: 1.1828\n",
      "Epoch 1607/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.6631 - reconstruction_loss: 1890.5908 - kl_loss: 100.6448 - false_loss: 0.0903 - true_loss: 1.1257 - val_loss: 5930.9971 - val_reconstruction_loss: 1896.4801 - val_kl_loss: 99.3726 - val_false_loss: 12.7229 - val_true_loss: 1.1828\n",
      "Epoch 1608/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.0628 - reconstruction_loss: 1890.3744 - kl_loss: 100.8222 - false_loss: 0.0903 - true_loss: 1.1256 - val_loss: 5930.5952 - val_reconstruction_loss: 1896.4795 - val_kl_loss: 99.3727 - val_false_loss: 12.7216 - val_true_loss: 1.1827\n",
      "Epoch 1609/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.4235 - reconstruction_loss: 1890.0078 - kl_loss: 100.7827 - false_loss: 0.0903 - true_loss: 1.1256 - val_loss: 5930.1943 - val_reconstruction_loss: 1896.4791 - val_kl_loss: 99.3728 - val_false_loss: 12.7203 - val_true_loss: 1.1827\n",
      "Epoch 1610/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8542 - reconstruction_loss: 1890.0732 - kl_loss: 101.7109 - false_loss: 0.0903 - true_loss: 1.1255 - val_loss: 5929.7881 - val_reconstruction_loss: 1896.4785 - val_kl_loss: 99.3734 - val_false_loss: 12.7189 - val_true_loss: 1.1826\n",
      "Epoch 1611/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1893 - reconstruction_loss: 1890.2682 - kl_loss: 101.2482 - false_loss: 0.0903 - true_loss: 1.1255 - val_loss: 5929.3916 - val_reconstruction_loss: 1896.4778 - val_kl_loss: 99.3743 - val_false_loss: 12.7176 - val_true_loss: 1.1826\n",
      "Epoch 1612/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.7755 - reconstruction_loss: 1890.5844 - kl_loss: 101.4891 - false_loss: 0.0903 - true_loss: 1.1254 - val_loss: 5928.9922 - val_reconstruction_loss: 1896.4774 - val_kl_loss: 99.3744 - val_false_loss: 12.7163 - val_true_loss: 1.1825\n",
      "Epoch 1613/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2216.7853 - reconstruction_loss: 1891.1479 - kl_loss: 101.5200 - false_loss: 0.0902 - true_loss: 1.1254 - val_loss: 5928.5947 - val_reconstruction_loss: 1896.4768 - val_kl_loss: 99.3746 - val_false_loss: 12.7150 - val_true_loss: 1.1825\n",
      "Epoch 1614/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4663 - reconstruction_loss: 1890.1714 - kl_loss: 101.2538 - false_loss: 0.0902 - true_loss: 1.1253 - val_loss: 5928.1943 - val_reconstruction_loss: 1896.4762 - val_kl_loss: 99.3744 - val_false_loss: 12.7137 - val_true_loss: 1.1824\n",
      "Epoch 1615/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.1296 - reconstruction_loss: 1890.4717 - kl_loss: 100.6769 - false_loss: 0.0902 - true_loss: 1.1252 - val_loss: 5927.8071 - val_reconstruction_loss: 1896.4758 - val_kl_loss: 99.3748 - val_false_loss: 12.7124 - val_true_loss: 1.1824\n",
      "Epoch 1616/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8909 - reconstruction_loss: 1890.8048 - kl_loss: 100.8832 - false_loss: 0.0902 - true_loss: 1.1252 - val_loss: 5927.4092 - val_reconstruction_loss: 1896.4752 - val_kl_loss: 99.3746 - val_false_loss: 12.7111 - val_true_loss: 1.1824\n",
      "Epoch 1617/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3523 - reconstruction_loss: 1890.3042 - kl_loss: 101.4683 - false_loss: 0.0902 - true_loss: 1.1251 - val_loss: 5927.0137 - val_reconstruction_loss: 1896.4747 - val_kl_loss: 99.3751 - val_false_loss: 12.7098 - val_true_loss: 1.1823\n",
      "Epoch 1618/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.2954 - reconstruction_loss: 1890.3058 - kl_loss: 101.4766 - false_loss: 0.0902 - true_loss: 1.1251 - val_loss: 5926.6138 - val_reconstruction_loss: 1896.4741 - val_kl_loss: 99.3758 - val_false_loss: 12.7085 - val_true_loss: 1.1823\n",
      "Epoch 1619/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.2771 - reconstruction_loss: 1890.0361 - kl_loss: 102.1775 - false_loss: 0.0902 - true_loss: 1.1250 - val_loss: 5926.2124 - val_reconstruction_loss: 1896.4735 - val_kl_loss: 99.3763 - val_false_loss: 12.7072 - val_true_loss: 1.1822\n",
      "Epoch 1620/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8238 - reconstruction_loss: 1890.1405 - kl_loss: 101.8940 - false_loss: 0.0902 - true_loss: 1.1250 - val_loss: 5925.8101 - val_reconstruction_loss: 1896.4730 - val_kl_loss: 99.3767 - val_false_loss: 12.7058 - val_true_loss: 1.1822\n",
      "Epoch 1621/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7251 - reconstruction_loss: 1889.8984 - kl_loss: 101.8174 - false_loss: 0.0902 - true_loss: 1.1249 - val_loss: 5925.4150 - val_reconstruction_loss: 1896.4724 - val_kl_loss: 99.3778 - val_false_loss: 12.7045 - val_true_loss: 1.1821\n",
      "Epoch 1622/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6914 - reconstruction_loss: 1890.9054 - kl_loss: 100.6221 - false_loss: 0.0902 - true_loss: 1.1249 - val_loss: 5925.0229 - val_reconstruction_loss: 1896.4718 - val_kl_loss: 99.3781 - val_false_loss: 12.7032 - val_true_loss: 1.1821\n",
      "Epoch 1623/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5732 - reconstruction_loss: 1890.5645 - kl_loss: 98.7503 - false_loss: 0.0902 - true_loss: 1.1248 - val_loss: 5924.6162 - val_reconstruction_loss: 1896.4713 - val_kl_loss: 99.3776 - val_false_loss: 12.7019 - val_true_loss: 1.1820\n",
      "Epoch 1624/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.0767 - reconstruction_loss: 1890.2274 - kl_loss: 99.5967 - false_loss: 0.0902 - true_loss: 1.1248 - val_loss: 5924.2202 - val_reconstruction_loss: 1896.4708 - val_kl_loss: 99.3782 - val_false_loss: 12.7006 - val_true_loss: 1.1820\n",
      "Epoch 1625/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1526 - reconstruction_loss: 1890.3739 - kl_loss: 99.3918 - false_loss: 0.0902 - true_loss: 1.1247 - val_loss: 5923.8213 - val_reconstruction_loss: 1896.4702 - val_kl_loss: 99.3787 - val_false_loss: 12.6993 - val_true_loss: 1.1820\n",
      "Epoch 1626/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.9854 - reconstruction_loss: 1890.2753 - kl_loss: 100.4528 - false_loss: 0.0901 - true_loss: 1.1247 - val_loss: 5923.4263 - val_reconstruction_loss: 1896.4697 - val_kl_loss: 99.3774 - val_false_loss: 12.6980 - val_true_loss: 1.1819\n",
      "Epoch 1627/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.8208 - reconstruction_loss: 1890.9155 - kl_loss: 98.6307 - false_loss: 0.0901 - true_loss: 1.1247 - val_loss: 5923.0273 - val_reconstruction_loss: 1896.4692 - val_kl_loss: 99.3782 - val_false_loss: 12.6967 - val_true_loss: 1.1819\n",
      "Epoch 1628/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.5402 - reconstruction_loss: 1890.6678 - kl_loss: 99.8312 - false_loss: 0.0901 - true_loss: 1.1246 - val_loss: 5922.6284 - val_reconstruction_loss: 1896.4688 - val_kl_loss: 99.3791 - val_false_loss: 12.6953 - val_true_loss: 1.1818\n",
      "Epoch 1629/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0636 - reconstruction_loss: 1890.3389 - kl_loss: 99.7432 - false_loss: 0.0901 - true_loss: 1.1246 - val_loss: 5922.2280 - val_reconstruction_loss: 1896.4680 - val_kl_loss: 99.3802 - val_false_loss: 12.6940 - val_true_loss: 1.1818\n",
      "Epoch 1630/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9614 - reconstruction_loss: 1890.1876 - kl_loss: 100.5193 - false_loss: 0.0901 - true_loss: 1.1245 - val_loss: 5921.8301 - val_reconstruction_loss: 1896.4675 - val_kl_loss: 99.3806 - val_false_loss: 12.6927 - val_true_loss: 1.1818\n",
      "Epoch 1631/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.2779 - reconstruction_loss: 1890.6654 - kl_loss: 100.9723 - false_loss: 0.0901 - true_loss: 1.1245 - val_loss: 5921.4326 - val_reconstruction_loss: 1896.4669 - val_kl_loss: 99.3813 - val_false_loss: 12.6914 - val_true_loss: 1.1817\n",
      "Epoch 1632/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.5761 - reconstruction_loss: 1890.4225 - kl_loss: 99.6108 - false_loss: 0.0901 - true_loss: 1.1244 - val_loss: 5921.0249 - val_reconstruction_loss: 1896.4664 - val_kl_loss: 99.3817 - val_false_loss: 12.6901 - val_true_loss: 1.1817\n",
      "Epoch 1633/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.2303 - reconstruction_loss: 1890.2466 - kl_loss: 99.5596 - false_loss: 0.0901 - true_loss: 1.1244 - val_loss: 5920.6245 - val_reconstruction_loss: 1896.4659 - val_kl_loss: 99.3815 - val_false_loss: 12.6887 - val_true_loss: 1.1816\n",
      "Epoch 1634/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.2014 - reconstruction_loss: 1890.2933 - kl_loss: 99.0771 - false_loss: 0.0901 - true_loss: 1.1243 - val_loss: 5920.2236 - val_reconstruction_loss: 1896.4655 - val_kl_loss: 99.3815 - val_false_loss: 12.6874 - val_true_loss: 1.1816\n",
      "Epoch 1635/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1227 - reconstruction_loss: 1890.4526 - kl_loss: 98.0885 - false_loss: 0.0901 - true_loss: 1.1243 - val_loss: 5919.8335 - val_reconstruction_loss: 1896.4648 - val_kl_loss: 99.3823 - val_false_loss: 12.6861 - val_true_loss: 1.1815\n",
      "Epoch 1636/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.9626 - reconstruction_loss: 1890.3627 - kl_loss: 99.9155 - false_loss: 0.0901 - true_loss: 1.1242 - val_loss: 5919.4370 - val_reconstruction_loss: 1896.4644 - val_kl_loss: 99.3816 - val_false_loss: 12.6848 - val_true_loss: 1.1815\n",
      "Epoch 1637/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6411 - reconstruction_loss: 1890.6676 - kl_loss: 97.5431 - false_loss: 0.0901 - true_loss: 1.1242 - val_loss: 5919.0498 - val_reconstruction_loss: 1896.4639 - val_kl_loss: 99.3817 - val_false_loss: 12.6835 - val_true_loss: 1.1815\n",
      "Epoch 1638/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.2455 - reconstruction_loss: 1890.8109 - kl_loss: 98.9928 - false_loss: 0.0901 - true_loss: 1.1242 - val_loss: 5918.6558 - val_reconstruction_loss: 1896.4634 - val_kl_loss: 99.3815 - val_false_loss: 12.6823 - val_true_loss: 1.1814\n",
      "Epoch 1639/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1956 - reconstruction_loss: 1890.8789 - kl_loss: 98.7949 - false_loss: 0.0900 - true_loss: 1.1241 - val_loss: 5918.2710 - val_reconstruction_loss: 1896.4628 - val_kl_loss: 99.3816 - val_false_loss: 12.6810 - val_true_loss: 1.1814\n",
      "Epoch 1640/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.6024 - reconstruction_loss: 1890.1378 - kl_loss: 99.0181 - false_loss: 0.0900 - true_loss: 1.1241 - val_loss: 5917.8926 - val_reconstruction_loss: 1896.4622 - val_kl_loss: 99.3816 - val_false_loss: 12.6797 - val_true_loss: 1.1813\n",
      "Epoch 1641/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.0473 - reconstruction_loss: 1890.0557 - kl_loss: 99.7431 - false_loss: 0.0900 - true_loss: 1.1240 - val_loss: 5917.4951 - val_reconstruction_loss: 1896.4617 - val_kl_loss: 99.3817 - val_false_loss: 12.6784 - val_true_loss: 1.1813\n",
      "Epoch 1642/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9143 - reconstruction_loss: 1890.5006 - kl_loss: 100.5153 - false_loss: 0.0900 - true_loss: 1.1240 - val_loss: 5917.1021 - val_reconstruction_loss: 1896.4612 - val_kl_loss: 99.3813 - val_false_loss: 12.6771 - val_true_loss: 1.1812\n",
      "Epoch 1643/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.3154 - reconstruction_loss: 1890.6915 - kl_loss: 99.9279 - false_loss: 0.0900 - true_loss: 1.1239 - val_loss: 5916.7070 - val_reconstruction_loss: 1896.4609 - val_kl_loss: 99.3819 - val_false_loss: 12.6758 - val_true_loss: 1.1812\n",
      "Epoch 1644/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5262 - reconstruction_loss: 1890.3418 - kl_loss: 99.6877 - false_loss: 0.0900 - true_loss: 1.1239 - val_loss: 5916.3184 - val_reconstruction_loss: 1896.4602 - val_kl_loss: 99.3825 - val_false_loss: 12.6746 - val_true_loss: 1.1812\n",
      "Epoch 1645/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5300 - reconstruction_loss: 1890.3340 - kl_loss: 100.5909 - false_loss: 0.0900 - true_loss: 1.1238 - val_loss: 5915.9233 - val_reconstruction_loss: 1896.4596 - val_kl_loss: 99.3820 - val_false_loss: 12.6733 - val_true_loss: 1.1811\n",
      "Epoch 1646/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4810 - reconstruction_loss: 1890.6387 - kl_loss: 100.3440 - false_loss: 0.0900 - true_loss: 1.1238 - val_loss: 5915.5303 - val_reconstruction_loss: 1896.4592 - val_kl_loss: 99.3824 - val_false_loss: 12.6720 - val_true_loss: 1.1811\n",
      "Epoch 1647/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.3111 - reconstruction_loss: 1890.1229 - kl_loss: 99.1768 - false_loss: 0.0900 - true_loss: 1.1237 - val_loss: 5915.1372 - val_reconstruction_loss: 1896.4586 - val_kl_loss: 99.3830 - val_false_loss: 12.6707 - val_true_loss: 1.1810\n",
      "Epoch 1648/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1364 - reconstruction_loss: 1889.9498 - kl_loss: 101.1997 - false_loss: 0.0900 - true_loss: 1.1237 - val_loss: 5914.7471 - val_reconstruction_loss: 1896.4580 - val_kl_loss: 99.3833 - val_false_loss: 12.6694 - val_true_loss: 1.1810\n",
      "Epoch 1649/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2952 - reconstruction_loss: 1890.4409 - kl_loss: 99.8083 - false_loss: 0.0900 - true_loss: 1.1236 - val_loss: 5914.3628 - val_reconstruction_loss: 1896.4576 - val_kl_loss: 99.3839 - val_false_loss: 12.6681 - val_true_loss: 1.1809\n",
      "Epoch 1650/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.3525 - reconstruction_loss: 1890.2090 - kl_loss: 101.1533 - false_loss: 0.0900 - true_loss: 1.1236 - val_loss: 5913.9683 - val_reconstruction_loss: 1896.4570 - val_kl_loss: 99.3842 - val_false_loss: 12.6668 - val_true_loss: 1.1809\n",
      "Epoch 1651/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.2831 - reconstruction_loss: 1889.9896 - kl_loss: 100.6093 - false_loss: 0.0900 - true_loss: 1.1235 - val_loss: 5913.5825 - val_reconstruction_loss: 1896.4564 - val_kl_loss: 99.3843 - val_false_loss: 12.6656 - val_true_loss: 1.1808\n",
      "Epoch 1652/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.6768 - reconstruction_loss: 1890.2871 - kl_loss: 101.0710 - false_loss: 0.0899 - true_loss: 1.1235 - val_loss: 5913.1924 - val_reconstruction_loss: 1896.4558 - val_kl_loss: 99.3849 - val_false_loss: 12.6643 - val_true_loss: 1.1808\n",
      "Epoch 1653/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.0339 - reconstruction_loss: 1890.5059 - kl_loss: 101.2586 - false_loss: 0.0899 - true_loss: 1.1234 - val_loss: 5912.8052 - val_reconstruction_loss: 1896.4554 - val_kl_loss: 99.3853 - val_false_loss: 12.6630 - val_true_loss: 1.1807\n",
      "Epoch 1654/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2963 - reconstruction_loss: 1890.1328 - kl_loss: 101.8063 - false_loss: 0.0899 - true_loss: 1.1234 - val_loss: 5912.4209 - val_reconstruction_loss: 1896.4548 - val_kl_loss: 99.3860 - val_false_loss: 12.6617 - val_true_loss: 1.1807\n",
      "Epoch 1655/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.2941 - reconstruction_loss: 1889.9404 - kl_loss: 100.4228 - false_loss: 0.0899 - true_loss: 1.1233 - val_loss: 5912.0410 - val_reconstruction_loss: 1896.4541 - val_kl_loss: 99.3872 - val_false_loss: 12.6605 - val_true_loss: 1.1807\n",
      "Epoch 1656/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.6626 - reconstruction_loss: 1890.9834 - kl_loss: 99.2404 - false_loss: 0.0899 - true_loss: 1.1233 - val_loss: 5911.6646 - val_reconstruction_loss: 1896.4535 - val_kl_loss: 99.3875 - val_false_loss: 12.6592 - val_true_loss: 1.1806\n",
      "Epoch 1657/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.8580 - reconstruction_loss: 1891.4806 - kl_loss: 99.3482 - false_loss: 0.0899 - true_loss: 1.1232 - val_loss: 5911.2705 - val_reconstruction_loss: 1896.4531 - val_kl_loss: 99.3875 - val_false_loss: 12.6579 - val_true_loss: 1.1806\n",
      "Epoch 1658/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1213 - reconstruction_loss: 1891.4503 - kl_loss: 99.3965 - false_loss: 0.0899 - true_loss: 1.1232 - val_loss: 5910.8818 - val_reconstruction_loss: 1896.4526 - val_kl_loss: 99.3876 - val_false_loss: 12.6566 - val_true_loss: 1.1805\n",
      "Epoch 1659/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.2264 - reconstruction_loss: 1890.7915 - kl_loss: 99.2172 - false_loss: 0.0899 - true_loss: 1.1231 - val_loss: 5910.4844 - val_reconstruction_loss: 1896.4521 - val_kl_loss: 99.3884 - val_false_loss: 12.6553 - val_true_loss: 1.1805\n",
      "Epoch 1660/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6741 - reconstruction_loss: 1890.4736 - kl_loss: 99.5443 - false_loss: 0.0899 - true_loss: 1.1231 - val_loss: 5910.1089 - val_reconstruction_loss: 1896.4515 - val_kl_loss: 99.3892 - val_false_loss: 12.6541 - val_true_loss: 1.1805\n",
      "Epoch 1661/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.1360 - reconstruction_loss: 1890.4894 - kl_loss: 98.9393 - false_loss: 0.0899 - true_loss: 1.1230 - val_loss: 5909.7334 - val_reconstruction_loss: 1896.4509 - val_kl_loss: 99.3898 - val_false_loss: 12.6529 - val_true_loss: 1.1804\n",
      "Epoch 1662/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.6862 - reconstruction_loss: 1890.3340 - kl_loss: 98.0061 - false_loss: 0.0899 - true_loss: 1.1230 - val_loss: 5909.3496 - val_reconstruction_loss: 1896.4506 - val_kl_loss: 99.3900 - val_false_loss: 12.6516 - val_true_loss: 1.1804\n",
      "Epoch 1663/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6968 - reconstruction_loss: 1890.4410 - kl_loss: 100.1916 - false_loss: 0.0899 - true_loss: 1.1229 - val_loss: 5908.9668 - val_reconstruction_loss: 1896.4500 - val_kl_loss: 99.3892 - val_false_loss: 12.6503 - val_true_loss: 1.1804\n",
      "Epoch 1664/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.1334 - reconstruction_loss: 1890.4351 - kl_loss: 98.7389 - false_loss: 0.0899 - true_loss: 1.1229 - val_loss: 5908.5757 - val_reconstruction_loss: 1896.4495 - val_kl_loss: 99.3890 - val_false_loss: 12.6490 - val_true_loss: 1.1803\n",
      "Epoch 1665/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2223.9921 - reconstruction_loss: 1890.2760 - kl_loss: 99.6422 - false_loss: 0.0898 - true_loss: 1.1229 - val_loss: 5908.1821 - val_reconstruction_loss: 1896.4490 - val_kl_loss: 99.3891 - val_false_loss: 12.6478 - val_true_loss: 1.1803\n",
      "Epoch 1666/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.0649 - reconstruction_loss: 1890.0629 - kl_loss: 100.7052 - false_loss: 0.0898 - true_loss: 1.1228 - val_loss: 5907.7930 - val_reconstruction_loss: 1896.4484 - val_kl_loss: 99.3893 - val_false_loss: 12.6465 - val_true_loss: 1.1802\n",
      "Epoch 1667/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3881 - reconstruction_loss: 1889.9506 - kl_loss: 100.8632 - false_loss: 0.0898 - true_loss: 1.1227 - val_loss: 5907.4092 - val_reconstruction_loss: 1896.4479 - val_kl_loss: 99.3899 - val_false_loss: 12.6452 - val_true_loss: 1.1802\n",
      "Epoch 1668/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6614 - reconstruction_loss: 1890.7621 - kl_loss: 101.6140 - false_loss: 0.0898 - true_loss: 1.1227 - val_loss: 5907.0293 - val_reconstruction_loss: 1896.4474 - val_kl_loss: 99.3905 - val_false_loss: 12.6440 - val_true_loss: 1.1801\n",
      "Epoch 1669/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.0590 - reconstruction_loss: 1890.2032 - kl_loss: 101.5178 - false_loss: 0.0898 - true_loss: 1.1226 - val_loss: 5906.6431 - val_reconstruction_loss: 1896.4468 - val_kl_loss: 99.3912 - val_false_loss: 12.6427 - val_true_loss: 1.1801\n",
      "Epoch 1670/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.8350 - reconstruction_loss: 1890.1642 - kl_loss: 101.8286 - false_loss: 0.0898 - true_loss: 1.1226 - val_loss: 5906.2642 - val_reconstruction_loss: 1896.4464 - val_kl_loss: 99.3918 - val_false_loss: 12.6414 - val_true_loss: 1.1800\n",
      "Epoch 1671/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.4464 - reconstruction_loss: 1889.9323 - kl_loss: 101.6139 - false_loss: 0.0898 - true_loss: 1.1225 - val_loss: 5905.8862 - val_reconstruction_loss: 1896.4459 - val_kl_loss: 99.3918 - val_false_loss: 12.6402 - val_true_loss: 1.1800\n",
      "Epoch 1672/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.4989 - reconstruction_loss: 1890.8712 - kl_loss: 100.9242 - false_loss: 0.0898 - true_loss: 1.1225 - val_loss: 5905.5059 - val_reconstruction_loss: 1896.4456 - val_kl_loss: 99.3922 - val_false_loss: 12.6389 - val_true_loss: 1.1799\n",
      "Epoch 1673/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.5066 - reconstruction_loss: 1890.9886 - kl_loss: 101.5940 - false_loss: 0.0898 - true_loss: 1.1224 - val_loss: 5905.1235 - val_reconstruction_loss: 1896.4451 - val_kl_loss: 99.3926 - val_false_loss: 12.6377 - val_true_loss: 1.1799\n",
      "Epoch 1674/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.1159 - reconstruction_loss: 1890.4491 - kl_loss: 101.5770 - false_loss: 0.0898 - true_loss: 1.1224 - val_loss: 5904.7373 - val_reconstruction_loss: 1896.4445 - val_kl_loss: 99.3921 - val_false_loss: 12.6364 - val_true_loss: 1.1798\n",
      "Epoch 1675/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2584 - reconstruction_loss: 1890.2052 - kl_loss: 100.4649 - false_loss: 0.0898 - true_loss: 1.1223 - val_loss: 5904.3560 - val_reconstruction_loss: 1896.4440 - val_kl_loss: 99.3923 - val_false_loss: 12.6352 - val_true_loss: 1.1798\n",
      "Epoch 1676/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8071 - reconstruction_loss: 1890.0519 - kl_loss: 101.9175 - false_loss: 0.0898 - true_loss: 1.1223 - val_loss: 5903.9727 - val_reconstruction_loss: 1896.4434 - val_kl_loss: 99.3924 - val_false_loss: 12.6339 - val_true_loss: 1.1797\n",
      "Epoch 1677/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4436 - reconstruction_loss: 1890.2783 - kl_loss: 100.8896 - false_loss: 0.0897 - true_loss: 1.1222 - val_loss: 5903.5918 - val_reconstruction_loss: 1896.4429 - val_kl_loss: 99.3928 - val_false_loss: 12.6326 - val_true_loss: 1.1797\n",
      "Epoch 1678/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8034 - reconstruction_loss: 1890.1378 - kl_loss: 101.5844 - false_loss: 0.0897 - true_loss: 1.1222 - val_loss: 5903.2202 - val_reconstruction_loss: 1896.4423 - val_kl_loss: 99.3926 - val_false_loss: 12.6314 - val_true_loss: 1.1796\n",
      "Epoch 1679/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.7643 - reconstruction_loss: 1890.6123 - kl_loss: 100.1284 - false_loss: 0.0897 - true_loss: 1.1221 - val_loss: 5902.8296 - val_reconstruction_loss: 1896.4419 - val_kl_loss: 99.3929 - val_false_loss: 12.6301 - val_true_loss: 1.1796\n",
      "Epoch 1680/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9297 - reconstruction_loss: 1890.7842 - kl_loss: 100.8920 - false_loss: 0.0897 - true_loss: 1.1221 - val_loss: 5902.4434 - val_reconstruction_loss: 1896.4414 - val_kl_loss: 99.3928 - val_false_loss: 12.6289 - val_true_loss: 1.1796\n",
      "Epoch 1681/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9328 - reconstruction_loss: 1890.3369 - kl_loss: 99.9820 - false_loss: 0.0897 - true_loss: 1.1220 - val_loss: 5902.0591 - val_reconstruction_loss: 1896.4408 - val_kl_loss: 99.3932 - val_false_loss: 12.6276 - val_true_loss: 1.1795\n",
      "Epoch 1682/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.0986 - reconstruction_loss: 1890.3232 - kl_loss: 99.6589 - false_loss: 0.0897 - true_loss: 1.1220 - val_loss: 5901.6743 - val_reconstruction_loss: 1896.4403 - val_kl_loss: 99.3932 - val_false_loss: 12.6263 - val_true_loss: 1.1795\n",
      "Epoch 1683/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.8658 - reconstruction_loss: 1890.1793 - kl_loss: 99.7600 - false_loss: 0.0897 - true_loss: 1.1219 - val_loss: 5901.2900 - val_reconstruction_loss: 1896.4397 - val_kl_loss: 99.3927 - val_false_loss: 12.6251 - val_true_loss: 1.1794\n",
      "Epoch 1684/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.1495 - reconstruction_loss: 1890.2802 - kl_loss: 99.4413 - false_loss: 0.0897 - true_loss: 1.1219 - val_loss: 5900.9058 - val_reconstruction_loss: 1896.4392 - val_kl_loss: 99.3931 - val_false_loss: 12.6238 - val_true_loss: 1.1794\n",
      "Epoch 1685/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.3711 - reconstruction_loss: 1890.3732 - kl_loss: 99.7551 - false_loss: 0.0897 - true_loss: 1.1218 - val_loss: 5900.5234 - val_reconstruction_loss: 1896.4387 - val_kl_loss: 99.3944 - val_false_loss: 12.6225 - val_true_loss: 1.1794\n",
      "Epoch 1686/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.8045 - reconstruction_loss: 1890.5240 - kl_loss: 99.6123 - false_loss: 0.0897 - true_loss: 1.1218 - val_loss: 5900.1543 - val_reconstruction_loss: 1896.4380 - val_kl_loss: 99.3941 - val_false_loss: 12.6213 - val_true_loss: 1.1793\n",
      "Epoch 1687/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7245 - reconstruction_loss: 1890.4136 - kl_loss: 98.9672 - false_loss: 0.0897 - true_loss: 1.1217 - val_loss: 5899.7686 - val_reconstruction_loss: 1896.4376 - val_kl_loss: 99.3940 - val_false_loss: 12.6201 - val_true_loss: 1.1793\n",
      "Epoch 1688/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.8691 - reconstruction_loss: 1890.6699 - kl_loss: 99.2251 - false_loss: 0.0897 - true_loss: 1.1217 - val_loss: 5899.3848 - val_reconstruction_loss: 1896.4369 - val_kl_loss: 99.3942 - val_false_loss: 12.6188 - val_true_loss: 1.1792\n",
      "Epoch 1689/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.2291 - reconstruction_loss: 1890.3248 - kl_loss: 100.3477 - false_loss: 0.0897 - true_loss: 1.1216 - val_loss: 5898.9966 - val_reconstruction_loss: 1896.4364 - val_kl_loss: 99.3944 - val_false_loss: 12.6175 - val_true_loss: 1.1792\n",
      "Epoch 1690/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.7969 - reconstruction_loss: 1889.8467 - kl_loss: 100.6411 - false_loss: 0.0896 - true_loss: 1.1216 - val_loss: 5898.6143 - val_reconstruction_loss: 1896.4358 - val_kl_loss: 99.3949 - val_false_loss: 12.6163 - val_true_loss: 1.1791\n",
      "Epoch 1691/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.8419 - reconstruction_loss: 1889.9008 - kl_loss: 100.2678 - false_loss: 0.0896 - true_loss: 1.1215 - val_loss: 5898.2305 - val_reconstruction_loss: 1896.4353 - val_kl_loss: 99.3948 - val_false_loss: 12.6150 - val_true_loss: 1.1791\n",
      "Epoch 1692/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.3761 - reconstruction_loss: 1891.2252 - kl_loss: 101.2679 - false_loss: 0.0896 - true_loss: 1.1215 - val_loss: 5897.8428 - val_reconstruction_loss: 1896.4347 - val_kl_loss: 99.3955 - val_false_loss: 12.6137 - val_true_loss: 1.1791\n",
      "Epoch 1693/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8544 - reconstruction_loss: 1891.0658 - kl_loss: 101.4486 - false_loss: 0.0896 - true_loss: 1.1214 - val_loss: 5897.4570 - val_reconstruction_loss: 1896.4342 - val_kl_loss: 99.3967 - val_false_loss: 12.6124 - val_true_loss: 1.1790\n",
      "Epoch 1694/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.1331 - reconstruction_loss: 1890.4469 - kl_loss: 101.4790 - false_loss: 0.0896 - true_loss: 1.1214 - val_loss: 5897.0786 - val_reconstruction_loss: 1896.4337 - val_kl_loss: 99.3977 - val_false_loss: 12.6112 - val_true_loss: 1.1790\n",
      "Epoch 1695/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.7483 - reconstruction_loss: 1890.0377 - kl_loss: 101.5009 - false_loss: 0.0896 - true_loss: 1.1213 - val_loss: 5896.6953 - val_reconstruction_loss: 1896.4331 - val_kl_loss: 99.3986 - val_false_loss: 12.6099 - val_true_loss: 1.1789\n",
      "Epoch 1696/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9942 - reconstruction_loss: 1889.9668 - kl_loss: 101.6447 - false_loss: 0.0896 - true_loss: 1.1213 - val_loss: 5896.3096 - val_reconstruction_loss: 1896.4326 - val_kl_loss: 99.4002 - val_false_loss: 12.6087 - val_true_loss: 1.1789\n",
      "Epoch 1697/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.0592 - reconstruction_loss: 1889.9066 - kl_loss: 101.4099 - false_loss: 0.0896 - true_loss: 1.1212 - val_loss: 5895.9219 - val_reconstruction_loss: 1896.4320 - val_kl_loss: 99.4007 - val_false_loss: 12.6074 - val_true_loss: 1.1788\n",
      "Epoch 1698/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.7859 - reconstruction_loss: 1890.3091 - kl_loss: 101.7907 - false_loss: 0.0896 - true_loss: 1.1212 - val_loss: 5895.5405 - val_reconstruction_loss: 1896.4316 - val_kl_loss: 99.4010 - val_false_loss: 12.6061 - val_true_loss: 1.1788\n",
      "Epoch 1699/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1462 - reconstruction_loss: 1890.1715 - kl_loss: 101.5267 - false_loss: 0.0896 - true_loss: 1.1211 - val_loss: 5895.1514 - val_reconstruction_loss: 1896.4310 - val_kl_loss: 99.4008 - val_false_loss: 12.6048 - val_true_loss: 1.1788\n",
      "Epoch 1700/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.7202 - reconstruction_loss: 1890.2946 - kl_loss: 100.4656 - false_loss: 0.0896 - true_loss: 1.1211 - val_loss: 5894.7734 - val_reconstruction_loss: 1896.4305 - val_kl_loss: 99.4011 - val_false_loss: 12.6036 - val_true_loss: 1.1787\n",
      "Epoch 1701/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.4229 - reconstruction_loss: 1890.3776 - kl_loss: 99.6752 - false_loss: 0.0896 - true_loss: 1.1210 - val_loss: 5894.3872 - val_reconstruction_loss: 1896.4301 - val_kl_loss: 99.4013 - val_false_loss: 12.6023 - val_true_loss: 1.1787\n",
      "Epoch 1702/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8221 - reconstruction_loss: 1890.2783 - kl_loss: 99.9535 - false_loss: 0.0896 - true_loss: 1.1210 - val_loss: 5893.9976 - val_reconstruction_loss: 1896.4294 - val_kl_loss: 99.4012 - val_false_loss: 12.6010 - val_true_loss: 1.1786\n",
      "Epoch 1703/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.0038 - reconstruction_loss: 1889.8099 - kl_loss: 100.5995 - false_loss: 0.0895 - true_loss: 1.1209 - val_loss: 5893.6167 - val_reconstruction_loss: 1896.4290 - val_kl_loss: 99.4012 - val_false_loss: 12.5998 - val_true_loss: 1.1786\n",
      "Epoch 1704/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.9190 - reconstruction_loss: 1890.3031 - kl_loss: 99.6944 - false_loss: 0.0895 - true_loss: 1.1209 - val_loss: 5893.2354 - val_reconstruction_loss: 1896.4283 - val_kl_loss: 99.4017 - val_false_loss: 12.5985 - val_true_loss: 1.1785\n",
      "Epoch 1705/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.6358 - reconstruction_loss: 1890.4230 - kl_loss: 100.6824 - false_loss: 0.0895 - true_loss: 1.1209 - val_loss: 5892.8535 - val_reconstruction_loss: 1896.4279 - val_kl_loss: 99.4026 - val_false_loss: 12.5973 - val_true_loss: 1.1785\n",
      "Epoch 1706/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.8271 - reconstruction_loss: 1890.0165 - kl_loss: 100.0927 - false_loss: 0.0895 - true_loss: 1.1208 - val_loss: 5892.4712 - val_reconstruction_loss: 1896.4272 - val_kl_loss: 99.4037 - val_false_loss: 12.5960 - val_true_loss: 1.1784\n",
      "Epoch 1707/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.1980 - reconstruction_loss: 1889.9288 - kl_loss: 99.3311 - false_loss: 0.0895 - true_loss: 1.1208 - val_loss: 5892.0845 - val_reconstruction_loss: 1896.4268 - val_kl_loss: 99.4049 - val_false_loss: 12.5947 - val_true_loss: 1.1784\n",
      "Epoch 1708/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.6575 - reconstruction_loss: 1890.2046 - kl_loss: 100.1491 - false_loss: 0.0895 - true_loss: 1.1207 - val_loss: 5891.6978 - val_reconstruction_loss: 1896.4261 - val_kl_loss: 99.4056 - val_false_loss: 12.5935 - val_true_loss: 1.1784\n",
      "Epoch 1709/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1405 - reconstruction_loss: 1890.1364 - kl_loss: 100.2891 - false_loss: 0.0895 - true_loss: 1.1207 - val_loss: 5891.3159 - val_reconstruction_loss: 1896.4257 - val_kl_loss: 99.4062 - val_false_loss: 12.5922 - val_true_loss: 1.1783\n",
      "Epoch 1710/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.1734 - reconstruction_loss: 1890.5029 - kl_loss: 100.6434 - false_loss: 0.0895 - true_loss: 1.1206 - val_loss: 5890.9302 - val_reconstruction_loss: 1896.4250 - val_kl_loss: 99.4065 - val_false_loss: 12.5909 - val_true_loss: 1.1783\n",
      "Epoch 1711/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.3164 - reconstruction_loss: 1890.7430 - kl_loss: 100.6170 - false_loss: 0.0895 - true_loss: 1.1206 - val_loss: 5890.5435 - val_reconstruction_loss: 1896.4246 - val_kl_loss: 99.4074 - val_false_loss: 12.5897 - val_true_loss: 1.1782\n",
      "Epoch 1712/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.8931 - reconstruction_loss: 1890.3018 - kl_loss: 101.0019 - false_loss: 0.0895 - true_loss: 1.1205 - val_loss: 5890.1553 - val_reconstruction_loss: 1896.4241 - val_kl_loss: 99.4080 - val_false_loss: 12.5884 - val_true_loss: 1.1782\n",
      "Epoch 1713/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1937 - reconstruction_loss: 1890.6041 - kl_loss: 101.1688 - false_loss: 0.0895 - true_loss: 1.1205 - val_loss: 5889.7783 - val_reconstruction_loss: 1896.4235 - val_kl_loss: 99.4086 - val_false_loss: 12.5871 - val_true_loss: 1.1781\n",
      "Epoch 1714/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.3983 - reconstruction_loss: 1890.5229 - kl_loss: 100.8532 - false_loss: 0.0895 - true_loss: 1.1204 - val_loss: 5889.3921 - val_reconstruction_loss: 1896.4231 - val_kl_loss: 99.4091 - val_false_loss: 12.5859 - val_true_loss: 1.1781\n",
      "Epoch 1715/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.0609 - reconstruction_loss: 1890.5275 - kl_loss: 100.7321 - false_loss: 0.0895 - true_loss: 1.1204 - val_loss: 5889.0020 - val_reconstruction_loss: 1896.4225 - val_kl_loss: 99.4091 - val_false_loss: 12.5846 - val_true_loss: 1.1780\n",
      "Epoch 1716/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.0532 - reconstruction_loss: 1890.3248 - kl_loss: 100.0412 - false_loss: 0.0894 - true_loss: 1.1203 - val_loss: 5888.6128 - val_reconstruction_loss: 1896.4219 - val_kl_loss: 99.4097 - val_false_loss: 12.5833 - val_true_loss: 1.1780\n",
      "Epoch 1717/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6248 - reconstruction_loss: 1889.9564 - kl_loss: 101.5663 - false_loss: 0.0894 - true_loss: 1.1203 - val_loss: 5888.2280 - val_reconstruction_loss: 1896.4214 - val_kl_loss: 99.4098 - val_false_loss: 12.5820 - val_true_loss: 1.1780\n",
      "Epoch 1718/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.3264 - reconstruction_loss: 1890.6547 - kl_loss: 101.4663 - false_loss: 0.0894 - true_loss: 1.1202 - val_loss: 5887.8354 - val_reconstruction_loss: 1896.4209 - val_kl_loss: 99.4103 - val_false_loss: 12.5807 - val_true_loss: 1.1779\n",
      "Epoch 1719/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8115 - reconstruction_loss: 1890.6222 - kl_loss: 100.8720 - false_loss: 0.0894 - true_loss: 1.1202 - val_loss: 5887.4565 - val_reconstruction_loss: 1896.4203 - val_kl_loss: 99.4112 - val_false_loss: 12.5795 - val_true_loss: 1.1779\n",
      "Epoch 1720/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.0363 - reconstruction_loss: 1890.4828 - kl_loss: 100.8174 - false_loss: 0.0894 - true_loss: 1.1201 - val_loss: 5887.0708 - val_reconstruction_loss: 1896.4197 - val_kl_loss: 99.4115 - val_false_loss: 12.5782 - val_true_loss: 1.1778\n",
      "Epoch 1721/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.1919 - reconstruction_loss: 1889.9498 - kl_loss: 99.4571 - false_loss: 0.0894 - true_loss: 1.1201 - val_loss: 5886.6851 - val_reconstruction_loss: 1896.4192 - val_kl_loss: 99.4118 - val_false_loss: 12.5769 - val_true_loss: 1.1778\n",
      "Epoch 1722/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2252.8146 - reconstruction_loss: 1890.3174 - kl_loss: 98.4057 - false_loss: 0.0894 - true_loss: 1.1200 - val_loss: 5886.2993 - val_reconstruction_loss: 1896.4187 - val_kl_loss: 99.4115 - val_false_loss: 12.5757 - val_true_loss: 1.1778\n",
      "Epoch 1723/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2595 - reconstruction_loss: 1890.7686 - kl_loss: 99.0787 - false_loss: 0.0894 - true_loss: 1.1200 - val_loss: 5885.9131 - val_reconstruction_loss: 1896.4183 - val_kl_loss: 99.4114 - val_false_loss: 12.5744 - val_true_loss: 1.1777\n",
      "Epoch 1724/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9349 - reconstruction_loss: 1891.0839 - kl_loss: 99.4537 - false_loss: 0.0894 - true_loss: 1.1199 - val_loss: 5885.5259 - val_reconstruction_loss: 1896.4177 - val_kl_loss: 99.4110 - val_false_loss: 12.5731 - val_true_loss: 1.1777\n",
      "Epoch 1725/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.7587 - reconstruction_loss: 1890.3802 - kl_loss: 99.8638 - false_loss: 0.0894 - true_loss: 1.1199 - val_loss: 5885.1357 - val_reconstruction_loss: 1896.4174 - val_kl_loss: 99.4104 - val_false_loss: 12.5718 - val_true_loss: 1.1776\n",
      "Epoch 1726/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.1355 - reconstruction_loss: 1890.2250 - kl_loss: 100.2537 - false_loss: 0.0894 - true_loss: 1.1198 - val_loss: 5884.7534 - val_reconstruction_loss: 1896.4169 - val_kl_loss: 99.4098 - val_false_loss: 12.5706 - val_true_loss: 1.1776\n",
      "Epoch 1727/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.9846 - reconstruction_loss: 1890.2129 - kl_loss: 99.6082 - false_loss: 0.0894 - true_loss: 1.1198 - val_loss: 5884.3613 - val_reconstruction_loss: 1896.4163 - val_kl_loss: 99.4098 - val_false_loss: 12.5693 - val_true_loss: 1.1775\n",
      "Epoch 1728/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9123 - reconstruction_loss: 1889.7740 - kl_loss: 101.0789 - false_loss: 0.0894 - true_loss: 1.1197 - val_loss: 5883.9751 - val_reconstruction_loss: 1896.4158 - val_kl_loss: 99.4102 - val_false_loss: 12.5680 - val_true_loss: 1.1775\n",
      "Epoch 1729/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.5563 - reconstruction_loss: 1891.2607 - kl_loss: 100.3456 - false_loss: 0.0893 - true_loss: 1.1197 - val_loss: 5883.5854 - val_reconstruction_loss: 1896.4152 - val_kl_loss: 99.4108 - val_false_loss: 12.5667 - val_true_loss: 1.1775\n",
      "Epoch 1730/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2466 - reconstruction_loss: 1890.5712 - kl_loss: 101.3578 - false_loss: 0.0893 - true_loss: 1.1196 - val_loss: 5883.1973 - val_reconstruction_loss: 1896.4147 - val_kl_loss: 99.4113 - val_false_loss: 12.5655 - val_true_loss: 1.1774\n",
      "Epoch 1731/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.1195 - reconstruction_loss: 1890.3481 - kl_loss: 101.5976 - false_loss: 0.0893 - true_loss: 1.1196 - val_loss: 5882.8159 - val_reconstruction_loss: 1896.4141 - val_kl_loss: 99.4114 - val_false_loss: 12.5642 - val_true_loss: 1.1774\n",
      "Epoch 1732/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0436 - reconstruction_loss: 1890.0814 - kl_loss: 101.3762 - false_loss: 0.0893 - true_loss: 1.1195 - val_loss: 5882.4277 - val_reconstruction_loss: 1896.4136 - val_kl_loss: 99.4113 - val_false_loss: 12.5629 - val_true_loss: 1.1773\n",
      "Epoch 1733/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.6968 - reconstruction_loss: 1890.2285 - kl_loss: 100.7890 - false_loss: 0.0893 - true_loss: 1.1195 - val_loss: 5882.0439 - val_reconstruction_loss: 1896.4132 - val_kl_loss: 99.4115 - val_false_loss: 12.5617 - val_true_loss: 1.1773\n",
      "Epoch 1734/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.7566 - reconstruction_loss: 1890.0065 - kl_loss: 101.4322 - false_loss: 0.0893 - true_loss: 1.1194 - val_loss: 5881.6611 - val_reconstruction_loss: 1896.4125 - val_kl_loss: 99.4122 - val_false_loss: 12.5604 - val_true_loss: 1.1772\n",
      "Epoch 1735/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3100 - reconstruction_loss: 1889.8431 - kl_loss: 101.9048 - false_loss: 0.0893 - true_loss: 1.1194 - val_loss: 5881.2837 - val_reconstruction_loss: 1896.4121 - val_kl_loss: 99.4132 - val_false_loss: 12.5592 - val_true_loss: 1.1772\n",
      "Epoch 1736/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.1763 - reconstruction_loss: 1889.7876 - kl_loss: 101.9800 - false_loss: 0.0893 - true_loss: 1.1193 - val_loss: 5880.8984 - val_reconstruction_loss: 1896.4114 - val_kl_loss: 99.4138 - val_false_loss: 12.5579 - val_true_loss: 1.1771\n",
      "Epoch 1737/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.8104 - reconstruction_loss: 1890.2662 - kl_loss: 101.2787 - false_loss: 0.0893 - true_loss: 1.1193 - val_loss: 5880.5171 - val_reconstruction_loss: 1896.4110 - val_kl_loss: 99.4148 - val_false_loss: 12.5566 - val_true_loss: 1.1771\n",
      "Epoch 1738/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.7157 - reconstruction_loss: 1890.5718 - kl_loss: 102.2064 - false_loss: 0.0893 - true_loss: 1.1192 - val_loss: 5880.1406 - val_reconstruction_loss: 1896.4106 - val_kl_loss: 99.4154 - val_false_loss: 12.5554 - val_true_loss: 1.1770\n",
      "Epoch 1739/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3738 - reconstruction_loss: 1890.3550 - kl_loss: 101.6369 - false_loss: 0.0893 - true_loss: 1.1192 - val_loss: 5879.7686 - val_reconstruction_loss: 1896.4102 - val_kl_loss: 99.4164 - val_false_loss: 12.5542 - val_true_loss: 1.1770\n",
      "Epoch 1740/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.1524 - reconstruction_loss: 1890.6105 - kl_loss: 101.5047 - false_loss: 0.0893 - true_loss: 1.1191 - val_loss: 5879.3779 - val_reconstruction_loss: 1896.4095 - val_kl_loss: 99.4172 - val_false_loss: 12.5529 - val_true_loss: 1.1769\n",
      "Epoch 1741/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8365 - reconstruction_loss: 1890.2472 - kl_loss: 100.2746 - false_loss: 0.0893 - true_loss: 1.1191 - val_loss: 5878.9951 - val_reconstruction_loss: 1896.4091 - val_kl_loss: 99.4183 - val_false_loss: 12.5516 - val_true_loss: 1.1769\n",
      "Epoch 1742/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1593 - reconstruction_loss: 1890.3506 - kl_loss: 101.9076 - false_loss: 0.0892 - true_loss: 1.1190 - val_loss: 5878.6094 - val_reconstruction_loss: 1896.4084 - val_kl_loss: 99.4195 - val_false_loss: 12.5504 - val_true_loss: 1.1768\n",
      "Epoch 1743/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7116 - reconstruction_loss: 1890.5161 - kl_loss: 101.7150 - false_loss: 0.0892 - true_loss: 1.1190 - val_loss: 5878.2358 - val_reconstruction_loss: 1896.4080 - val_kl_loss: 99.4207 - val_false_loss: 12.5491 - val_true_loss: 1.1768\n",
      "Epoch 1744/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.8174 - reconstruction_loss: 1890.3910 - kl_loss: 101.5649 - false_loss: 0.0892 - true_loss: 1.1189 - val_loss: 5877.8545 - val_reconstruction_loss: 1896.4075 - val_kl_loss: 99.4217 - val_false_loss: 12.5479 - val_true_loss: 1.1767\n",
      "Epoch 1745/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5200 - reconstruction_loss: 1889.9913 - kl_loss: 102.0923 - false_loss: 0.0892 - true_loss: 1.1188 - val_loss: 5877.4644 - val_reconstruction_loss: 1896.4067 - val_kl_loss: 99.4230 - val_false_loss: 12.5466 - val_true_loss: 1.1767\n",
      "Epoch 1746/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.5802 - reconstruction_loss: 1890.1230 - kl_loss: 102.2090 - false_loss: 0.0892 - true_loss: 1.1188 - val_loss: 5877.0830 - val_reconstruction_loss: 1896.4064 - val_kl_loss: 99.4232 - val_false_loss: 12.5453 - val_true_loss: 1.1766\n",
      "Epoch 1747/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.2941 - reconstruction_loss: 1889.9355 - kl_loss: 102.1212 - false_loss: 0.0892 - true_loss: 1.1187 - val_loss: 5876.7036 - val_reconstruction_loss: 1896.4058 - val_kl_loss: 99.4238 - val_false_loss: 12.5441 - val_true_loss: 1.1766\n",
      "Epoch 1748/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.2538 - reconstruction_loss: 1890.8131 - kl_loss: 101.6217 - false_loss: 0.0892 - true_loss: 1.1187 - val_loss: 5876.3169 - val_reconstruction_loss: 1896.4052 - val_kl_loss: 99.4243 - val_false_loss: 12.5428 - val_true_loss: 1.1766\n",
      "Epoch 1749/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.7772 - reconstruction_loss: 1891.5492 - kl_loss: 102.4368 - false_loss: 0.0892 - true_loss: 1.1186 - val_loss: 5875.9380 - val_reconstruction_loss: 1896.4049 - val_kl_loss: 99.4245 - val_false_loss: 12.5416 - val_true_loss: 1.1765\n",
      "Epoch 1750/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.5795 - reconstruction_loss: 1890.9570 - kl_loss: 101.9319 - false_loss: 0.0892 - true_loss: 1.1186 - val_loss: 5875.5479 - val_reconstruction_loss: 1896.4043 - val_kl_loss: 99.4254 - val_false_loss: 12.5403 - val_true_loss: 1.1765\n",
      "Epoch 1751/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.4207 - reconstruction_loss: 1890.2667 - kl_loss: 102.3272 - false_loss: 0.0892 - true_loss: 1.1185 - val_loss: 5875.1689 - val_reconstruction_loss: 1896.4038 - val_kl_loss: 99.4258 - val_false_loss: 12.5390 - val_true_loss: 1.1764\n",
      "Epoch 1752/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.7237 - reconstruction_loss: 1890.2057 - kl_loss: 101.4959 - false_loss: 0.0892 - true_loss: 1.1185 - val_loss: 5874.7871 - val_reconstruction_loss: 1896.4034 - val_kl_loss: 99.4252 - val_false_loss: 12.5378 - val_true_loss: 1.1764\n",
      "Epoch 1753/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.6962 - reconstruction_loss: 1890.6108 - kl_loss: 101.0292 - false_loss: 0.0892 - true_loss: 1.1184 - val_loss: 5874.3989 - val_reconstruction_loss: 1896.4030 - val_kl_loss: 99.4253 - val_false_loss: 12.5365 - val_true_loss: 1.1763\n",
      "Epoch 1754/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0817 - reconstruction_loss: 1890.6674 - kl_loss: 100.5663 - false_loss: 0.0892 - true_loss: 1.1184 - val_loss: 5874.0200 - val_reconstruction_loss: 1896.4025 - val_kl_loss: 99.4258 - val_false_loss: 12.5352 - val_true_loss: 1.1763\n",
      "Epoch 1755/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.1007 - reconstruction_loss: 1891.1285 - kl_loss: 100.2756 - false_loss: 0.0891 - true_loss: 1.1183 - val_loss: 5873.6499 - val_reconstruction_loss: 1896.4019 - val_kl_loss: 99.4265 - val_false_loss: 12.5340 - val_true_loss: 1.1762\n",
      "Epoch 1756/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.5424 - reconstruction_loss: 1890.6708 - kl_loss: 101.4506 - false_loss: 0.0891 - true_loss: 1.1183 - val_loss: 5873.2734 - val_reconstruction_loss: 1896.4014 - val_kl_loss: 99.4267 - val_false_loss: 12.5328 - val_true_loss: 1.1762\n",
      "Epoch 1757/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5948 - reconstruction_loss: 1890.2544 - kl_loss: 99.7662 - false_loss: 0.0891 - true_loss: 1.1183 - val_loss: 5872.8931 - val_reconstruction_loss: 1896.4008 - val_kl_loss: 99.4274 - val_false_loss: 12.5315 - val_true_loss: 1.1762\n",
      "Epoch 1758/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.5749 - reconstruction_loss: 1889.8262 - kl_loss: 100.2788 - false_loss: 0.0891 - true_loss: 1.1182 - val_loss: 5872.5298 - val_reconstruction_loss: 1896.4003 - val_kl_loss: 99.4267 - val_false_loss: 12.5303 - val_true_loss: 1.1761\n",
      "Epoch 1759/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.0020 - reconstruction_loss: 1890.0814 - kl_loss: 99.3814 - false_loss: 0.0891 - true_loss: 1.1182 - val_loss: 5872.1475 - val_reconstruction_loss: 1896.3997 - val_kl_loss: 99.4277 - val_false_loss: 12.5291 - val_true_loss: 1.1761\n",
      "Epoch 1760/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.1286 - reconstruction_loss: 1890.1139 - kl_loss: 98.8060 - false_loss: 0.0891 - true_loss: 1.1181 - val_loss: 5871.7681 - val_reconstruction_loss: 1896.3992 - val_kl_loss: 99.4278 - val_false_loss: 12.5278 - val_true_loss: 1.1760\n",
      "Epoch 1761/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.8505 - reconstruction_loss: 1890.2891 - kl_loss: 98.8108 - false_loss: 0.0891 - true_loss: 1.1181 - val_loss: 5871.3848 - val_reconstruction_loss: 1896.3986 - val_kl_loss: 99.4276 - val_false_loss: 12.5266 - val_true_loss: 1.1760\n",
      "Epoch 1762/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.0630 - reconstruction_loss: 1890.2428 - kl_loss: 100.4375 - false_loss: 0.0891 - true_loss: 1.1180 - val_loss: 5871.0005 - val_reconstruction_loss: 1896.3981 - val_kl_loss: 99.4274 - val_false_loss: 12.5253 - val_true_loss: 1.1760\n",
      "Epoch 1763/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.5024 - reconstruction_loss: 1889.9972 - kl_loss: 100.2123 - false_loss: 0.0891 - true_loss: 1.1180 - val_loss: 5870.6133 - val_reconstruction_loss: 1896.3976 - val_kl_loss: 99.4271 - val_false_loss: 12.5240 - val_true_loss: 1.1759\n",
      "Epoch 1764/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.5898 - reconstruction_loss: 1889.8208 - kl_loss: 101.5199 - false_loss: 0.0891 - true_loss: 1.1179 - val_loss: 5870.2339 - val_reconstruction_loss: 1896.3971 - val_kl_loss: 99.4273 - val_false_loss: 12.5228 - val_true_loss: 1.1759\n",
      "Epoch 1765/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4266 - reconstruction_loss: 1890.2338 - kl_loss: 101.1707 - false_loss: 0.0891 - true_loss: 1.1179 - val_loss: 5869.8564 - val_reconstruction_loss: 1896.3966 - val_kl_loss: 99.4275 - val_false_loss: 12.5215 - val_true_loss: 1.1758\n",
      "Epoch 1766/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6486 - reconstruction_loss: 1890.3026 - kl_loss: 100.4261 - false_loss: 0.0891 - true_loss: 1.1178 - val_loss: 5869.4741 - val_reconstruction_loss: 1896.3960 - val_kl_loss: 99.4267 - val_false_loss: 12.5203 - val_true_loss: 1.1758\n",
      "Epoch 1767/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.0997 - reconstruction_loss: 1890.4994 - kl_loss: 100.8203 - false_loss: 0.0891 - true_loss: 1.1178 - val_loss: 5869.0918 - val_reconstruction_loss: 1896.3958 - val_kl_loss: 99.4265 - val_false_loss: 12.5190 - val_true_loss: 1.1757\n",
      "Epoch 1768/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.5679 - reconstruction_loss: 1890.8209 - kl_loss: 100.7130 - false_loss: 0.0890 - true_loss: 1.1177 - val_loss: 5868.7134 - val_reconstruction_loss: 1896.3951 - val_kl_loss: 99.4265 - val_false_loss: 12.5178 - val_true_loss: 1.1757\n",
      "Epoch 1769/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2223.3141 - reconstruction_loss: 1890.1299 - kl_loss: 101.3582 - false_loss: 0.0890 - true_loss: 1.1177 - val_loss: 5868.3320 - val_reconstruction_loss: 1896.3948 - val_kl_loss: 99.4275 - val_false_loss: 12.5165 - val_true_loss: 1.1756\n",
      "Epoch 1770/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.3879 - reconstruction_loss: 1890.0536 - kl_loss: 100.5916 - false_loss: 0.0890 - true_loss: 1.1176 - val_loss: 5867.9497 - val_reconstruction_loss: 1896.3942 - val_kl_loss: 99.4277 - val_false_loss: 12.5153 - val_true_loss: 1.1756\n",
      "Epoch 1771/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.1256 - reconstruction_loss: 1890.5620 - kl_loss: 101.2674 - false_loss: 0.0890 - true_loss: 1.1176 - val_loss: 5867.5723 - val_reconstruction_loss: 1896.3938 - val_kl_loss: 99.4281 - val_false_loss: 12.5140 - val_true_loss: 1.1755\n",
      "Epoch 1772/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.2645 - reconstruction_loss: 1890.4530 - kl_loss: 100.4177 - false_loss: 0.0890 - true_loss: 1.1175 - val_loss: 5867.1938 - val_reconstruction_loss: 1896.3933 - val_kl_loss: 99.4285 - val_false_loss: 12.5128 - val_true_loss: 1.1755\n",
      "Epoch 1773/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.7291 - reconstruction_loss: 1890.0714 - kl_loss: 101.0994 - false_loss: 0.0890 - true_loss: 1.1175 - val_loss: 5866.8154 - val_reconstruction_loss: 1896.3928 - val_kl_loss: 99.4295 - val_false_loss: 12.5115 - val_true_loss: 1.1754\n",
      "Epoch 1774/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.1596 - reconstruction_loss: 1890.2944 - kl_loss: 101.9556 - false_loss: 0.0890 - true_loss: 1.1174 - val_loss: 5866.4316 - val_reconstruction_loss: 1896.3923 - val_kl_loss: 99.4311 - val_false_loss: 12.5103 - val_true_loss: 1.1754\n",
      "Epoch 1775/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.2609 - reconstruction_loss: 1890.3003 - kl_loss: 101.5178 - false_loss: 0.0890 - true_loss: 1.1174 - val_loss: 5866.0508 - val_reconstruction_loss: 1896.3917 - val_kl_loss: 99.4318 - val_false_loss: 12.5090 - val_true_loss: 1.1754\n",
      "Epoch 1776/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.8811 - reconstruction_loss: 1889.9733 - kl_loss: 100.3684 - false_loss: 0.0890 - true_loss: 1.1173 - val_loss: 5865.6768 - val_reconstruction_loss: 1896.3914 - val_kl_loss: 99.4330 - val_false_loss: 12.5078 - val_true_loss: 1.1753\n",
      "Epoch 1777/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3058 - reconstruction_loss: 1890.2544 - kl_loss: 101.4012 - false_loss: 0.0890 - true_loss: 1.1173 - val_loss: 5865.2988 - val_reconstruction_loss: 1896.3907 - val_kl_loss: 99.4345 - val_false_loss: 12.5065 - val_true_loss: 1.1753\n",
      "Epoch 1778/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.2000 - reconstruction_loss: 1889.8983 - kl_loss: 100.4761 - false_loss: 0.0890 - true_loss: 1.1172 - val_loss: 5864.9185 - val_reconstruction_loss: 1896.3903 - val_kl_loss: 99.4350 - val_false_loss: 12.5053 - val_true_loss: 1.1752\n",
      "Epoch 1779/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.7864 - reconstruction_loss: 1890.2418 - kl_loss: 101.8362 - false_loss: 0.0890 - true_loss: 1.1172 - val_loss: 5864.5376 - val_reconstruction_loss: 1896.3896 - val_kl_loss: 99.4356 - val_false_loss: 12.5040 - val_true_loss: 1.1752\n",
      "Epoch 1780/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4582 - reconstruction_loss: 1890.1499 - kl_loss: 101.5301 - false_loss: 0.0890 - true_loss: 1.1171 - val_loss: 5864.1670 - val_reconstruction_loss: 1896.3892 - val_kl_loss: 99.4367 - val_false_loss: 12.5028 - val_true_loss: 1.1751\n",
      "Epoch 1781/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.6284 - reconstruction_loss: 1890.5104 - kl_loss: 100.8240 - false_loss: 0.0889 - true_loss: 1.1171 - val_loss: 5863.7959 - val_reconstruction_loss: 1896.3888 - val_kl_loss: 99.4373 - val_false_loss: 12.5016 - val_true_loss: 1.1751\n",
      "Epoch 1782/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0161 - reconstruction_loss: 1890.4893 - kl_loss: 100.4252 - false_loss: 0.0889 - true_loss: 1.1170 - val_loss: 5863.4180 - val_reconstruction_loss: 1896.3882 - val_kl_loss: 99.4379 - val_false_loss: 12.5003 - val_true_loss: 1.1750\n",
      "Epoch 1783/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0834 - reconstruction_loss: 1890.2885 - kl_loss: 101.7431 - false_loss: 0.0889 - true_loss: 1.1170 - val_loss: 5863.0396 - val_reconstruction_loss: 1896.3877 - val_kl_loss: 99.4374 - val_false_loss: 12.4991 - val_true_loss: 1.1750\n",
      "Epoch 1784/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.5470 - reconstruction_loss: 1890.3971 - kl_loss: 102.0299 - false_loss: 0.0889 - true_loss: 1.1169 - val_loss: 5862.6616 - val_reconstruction_loss: 1896.3872 - val_kl_loss: 99.4379 - val_false_loss: 12.4978 - val_true_loss: 1.1749\n",
      "Epoch 1785/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.5920 - reconstruction_loss: 1890.2451 - kl_loss: 101.6415 - false_loss: 0.0889 - true_loss: 1.1169 - val_loss: 5862.2793 - val_reconstruction_loss: 1896.3866 - val_kl_loss: 99.4383 - val_false_loss: 12.4966 - val_true_loss: 1.1749\n",
      "Epoch 1786/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.3843 - reconstruction_loss: 1890.0800 - kl_loss: 100.6930 - false_loss: 0.0889 - true_loss: 1.1168 - val_loss: 5861.9092 - val_reconstruction_loss: 1896.3861 - val_kl_loss: 99.4387 - val_false_loss: 12.4954 - val_true_loss: 1.1749\n",
      "Epoch 1787/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7789 - reconstruction_loss: 1890.4017 - kl_loss: 100.1043 - false_loss: 0.0889 - true_loss: 1.1168 - val_loss: 5861.5337 - val_reconstruction_loss: 1896.3857 - val_kl_loss: 99.4394 - val_false_loss: 12.4941 - val_true_loss: 1.1748\n",
      "Epoch 1788/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.6903 - reconstruction_loss: 1890.2286 - kl_loss: 99.3078 - false_loss: 0.0889 - true_loss: 1.1167 - val_loss: 5861.1626 - val_reconstruction_loss: 1896.3851 - val_kl_loss: 99.4406 - val_false_loss: 12.4929 - val_true_loss: 1.1748\n",
      "Epoch 1789/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0590 - reconstruction_loss: 1890.0941 - kl_loss: 100.7723 - false_loss: 0.0889 - true_loss: 1.1167 - val_loss: 5860.7866 - val_reconstruction_loss: 1896.3846 - val_kl_loss: 99.4409 - val_false_loss: 12.4917 - val_true_loss: 1.1747\n",
      "Epoch 1790/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.7566 - reconstruction_loss: 1890.1488 - kl_loss: 100.8891 - false_loss: 0.0889 - true_loss: 1.1166 - val_loss: 5860.4077 - val_reconstruction_loss: 1896.3842 - val_kl_loss: 99.4408 - val_false_loss: 12.4904 - val_true_loss: 1.1747\n",
      "Epoch 1791/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7249 - reconstruction_loss: 1890.5770 - kl_loss: 99.4224 - false_loss: 0.0889 - true_loss: 1.1166 - val_loss: 5860.0254 - val_reconstruction_loss: 1896.3835 - val_kl_loss: 99.4413 - val_false_loss: 12.4891 - val_true_loss: 1.1747\n",
      "Epoch 1792/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.8699 - reconstruction_loss: 1889.8871 - kl_loss: 100.8500 - false_loss: 0.0889 - true_loss: 1.1165 - val_loss: 5859.6484 - val_reconstruction_loss: 1896.3832 - val_kl_loss: 99.4415 - val_false_loss: 12.4879 - val_true_loss: 1.1746\n",
      "Epoch 1793/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5025 - reconstruction_loss: 1889.9960 - kl_loss: 100.3918 - false_loss: 0.0889 - true_loss: 1.1165 - val_loss: 5859.2710 - val_reconstruction_loss: 1896.3826 - val_kl_loss: 99.4419 - val_false_loss: 12.4867 - val_true_loss: 1.1746\n",
      "Epoch 1794/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.8605 - reconstruction_loss: 1890.1991 - kl_loss: 100.9526 - false_loss: 0.0889 - true_loss: 1.1164 - val_loss: 5858.8950 - val_reconstruction_loss: 1896.3822 - val_kl_loss: 99.4418 - val_false_loss: 12.4854 - val_true_loss: 1.1745\n",
      "Epoch 1795/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.5565 - reconstruction_loss: 1889.8903 - kl_loss: 100.2932 - false_loss: 0.0888 - true_loss: 1.1164 - val_loss: 5858.5156 - val_reconstruction_loss: 1896.3817 - val_kl_loss: 99.4418 - val_false_loss: 12.4842 - val_true_loss: 1.1745\n",
      "Epoch 1796/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.6209 - reconstruction_loss: 1889.7886 - kl_loss: 101.5760 - false_loss: 0.0888 - true_loss: 1.1163 - val_loss: 5858.1353 - val_reconstruction_loss: 1896.3811 - val_kl_loss: 99.4417 - val_false_loss: 12.4829 - val_true_loss: 1.1744\n",
      "Epoch 1797/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.2329 - reconstruction_loss: 1890.6373 - kl_loss: 100.7960 - false_loss: 0.0888 - true_loss: 1.1163 - val_loss: 5857.7583 - val_reconstruction_loss: 1896.3807 - val_kl_loss: 99.4414 - val_false_loss: 12.4817 - val_true_loss: 1.1744\n",
      "Epoch 1798/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.1031 - reconstruction_loss: 1890.5277 - kl_loss: 101.5630 - false_loss: 0.0888 - true_loss: 1.1162 - val_loss: 5857.3799 - val_reconstruction_loss: 1896.3802 - val_kl_loss: 99.4413 - val_false_loss: 12.4804 - val_true_loss: 1.1743\n",
      "Epoch 1799/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.1247 - reconstruction_loss: 1890.2603 - kl_loss: 101.4587 - false_loss: 0.0888 - true_loss: 1.1162 - val_loss: 5856.9976 - val_reconstruction_loss: 1896.3798 - val_kl_loss: 99.4415 - val_false_loss: 12.4792 - val_true_loss: 1.1743\n",
      "Epoch 1800/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.2124 - reconstruction_loss: 1890.1045 - kl_loss: 101.6200 - false_loss: 0.0888 - true_loss: 1.1161 - val_loss: 5856.6226 - val_reconstruction_loss: 1896.3792 - val_kl_loss: 99.4425 - val_false_loss: 12.4779 - val_true_loss: 1.1743\n",
      "Epoch 1801/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.3116 - reconstruction_loss: 1889.9691 - kl_loss: 100.4774 - false_loss: 0.0888 - true_loss: 1.1161 - val_loss: 5856.2520 - val_reconstruction_loss: 1896.3787 - val_kl_loss: 99.4430 - val_false_loss: 12.4767 - val_true_loss: 1.1742\n",
      "Epoch 1802/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.5763 - reconstruction_loss: 1890.6193 - kl_loss: 101.4968 - false_loss: 0.0888 - true_loss: 1.1160 - val_loss: 5855.8760 - val_reconstruction_loss: 1896.3782 - val_kl_loss: 99.4436 - val_false_loss: 12.4755 - val_true_loss: 1.1742\n",
      "Epoch 1803/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.2414 - reconstruction_loss: 1889.9562 - kl_loss: 101.1604 - false_loss: 0.0888 - true_loss: 1.1160 - val_loss: 5855.4980 - val_reconstruction_loss: 1896.3778 - val_kl_loss: 99.4439 - val_false_loss: 12.4742 - val_true_loss: 1.1741\n",
      "Epoch 1804/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8089 - reconstruction_loss: 1889.7946 - kl_loss: 102.0552 - false_loss: 0.0888 - true_loss: 1.1159 - val_loss: 5855.1260 - val_reconstruction_loss: 1896.3772 - val_kl_loss: 99.4437 - val_false_loss: 12.4730 - val_true_loss: 1.1741\n",
      "Epoch 1805/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4236 - reconstruction_loss: 1890.0790 - kl_loss: 101.0101 - false_loss: 0.0888 - true_loss: 1.1159 - val_loss: 5854.7461 - val_reconstruction_loss: 1896.3767 - val_kl_loss: 99.4439 - val_false_loss: 12.4718 - val_true_loss: 1.1740\n",
      "Epoch 1806/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3133 - reconstruction_loss: 1890.2845 - kl_loss: 101.2143 - false_loss: 0.0888 - true_loss: 1.1158 - val_loss: 5854.3716 - val_reconstruction_loss: 1896.3762 - val_kl_loss: 99.4447 - val_false_loss: 12.4705 - val_true_loss: 1.1740\n",
      "Epoch 1807/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.1329 - reconstruction_loss: 1889.8989 - kl_loss: 101.1276 - false_loss: 0.0888 - true_loss: 1.1158 - val_loss: 5853.9985 - val_reconstruction_loss: 1896.3756 - val_kl_loss: 99.4454 - val_false_loss: 12.4693 - val_true_loss: 1.1739\n",
      "Epoch 1808/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.6440 - reconstruction_loss: 1889.7129 - kl_loss: 100.8020 - false_loss: 0.0887 - true_loss: 1.1158 - val_loss: 5853.6265 - val_reconstruction_loss: 1896.3751 - val_kl_loss: 99.4459 - val_false_loss: 12.4681 - val_true_loss: 1.1739\n",
      "Epoch 1809/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.3891 - reconstruction_loss: 1890.0615 - kl_loss: 100.1745 - false_loss: 0.0887 - true_loss: 1.1157 - val_loss: 5853.2490 - val_reconstruction_loss: 1896.3746 - val_kl_loss: 99.4464 - val_false_loss: 12.4668 - val_true_loss: 1.1739\n",
      "Epoch 1810/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.7940 - reconstruction_loss: 1890.8378 - kl_loss: 101.1010 - false_loss: 0.0887 - true_loss: 1.1157 - val_loss: 5852.8794 - val_reconstruction_loss: 1896.3741 - val_kl_loss: 99.4465 - val_false_loss: 12.4656 - val_true_loss: 1.1738\n",
      "Epoch 1811/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.3895 - reconstruction_loss: 1890.3053 - kl_loss: 100.0985 - false_loss: 0.0887 - true_loss: 1.1156 - val_loss: 5852.5029 - val_reconstruction_loss: 1896.3735 - val_kl_loss: 99.4466 - val_false_loss: 12.4644 - val_true_loss: 1.1738\n",
      "Epoch 1812/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2377 - reconstruction_loss: 1890.6373 - kl_loss: 100.4016 - false_loss: 0.0887 - true_loss: 1.1156 - val_loss: 5852.1309 - val_reconstruction_loss: 1896.3732 - val_kl_loss: 99.4467 - val_false_loss: 12.4632 - val_true_loss: 1.1737\n",
      "Epoch 1813/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.8679 - reconstruction_loss: 1890.2362 - kl_loss: 100.5943 - false_loss: 0.0887 - true_loss: 1.1155 - val_loss: 5851.7642 - val_reconstruction_loss: 1896.3726 - val_kl_loss: 99.4471 - val_false_loss: 12.4619 - val_true_loss: 1.1737\n",
      "Epoch 1814/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.6541 - reconstruction_loss: 1890.2753 - kl_loss: 99.0652 - false_loss: 0.0887 - true_loss: 1.1155 - val_loss: 5851.3921 - val_reconstruction_loss: 1896.3721 - val_kl_loss: 99.4481 - val_false_loss: 12.4607 - val_true_loss: 1.1737\n",
      "Epoch 1815/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8015 - reconstruction_loss: 1890.4999 - kl_loss: 100.3826 - false_loss: 0.0887 - true_loss: 1.1154 - val_loss: 5851.0142 - val_reconstruction_loss: 1896.3716 - val_kl_loss: 99.4480 - val_false_loss: 12.4595 - val_true_loss: 1.1736\n",
      "Epoch 1816/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5932 - reconstruction_loss: 1890.0485 - kl_loss: 99.8190 - false_loss: 0.0887 - true_loss: 1.1154 - val_loss: 5850.6460 - val_reconstruction_loss: 1896.3710 - val_kl_loss: 99.4483 - val_false_loss: 12.4583 - val_true_loss: 1.1736\n",
      "Epoch 1817/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.0627 - reconstruction_loss: 1889.8163 - kl_loss: 99.5819 - false_loss: 0.0887 - true_loss: 1.1153 - val_loss: 5850.2705 - val_reconstruction_loss: 1896.3705 - val_kl_loss: 99.4488 - val_false_loss: 12.4570 - val_true_loss: 1.1735\n",
      "Epoch 1818/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8219 - reconstruction_loss: 1889.7189 - kl_loss: 99.0372 - false_loss: 0.0887 - true_loss: 1.1153 - val_loss: 5849.8970 - val_reconstruction_loss: 1896.3700 - val_kl_loss: 99.4488 - val_false_loss: 12.4558 - val_true_loss: 1.1735\n",
      "Epoch 1819/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.5397 - reconstruction_loss: 1890.6989 - kl_loss: 99.0465 - false_loss: 0.0887 - true_loss: 1.1152 - val_loss: 5849.5220 - val_reconstruction_loss: 1896.3694 - val_kl_loss: 99.4480 - val_false_loss: 12.4546 - val_true_loss: 1.1735\n",
      "Epoch 1820/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0920 - reconstruction_loss: 1890.0577 - kl_loss: 99.1929 - false_loss: 0.0887 - true_loss: 1.1152 - val_loss: 5849.1499 - val_reconstruction_loss: 1896.3691 - val_kl_loss: 99.4484 - val_false_loss: 12.4533 - val_true_loss: 1.1734\n",
      "Epoch 1821/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2220.8733 - reconstruction_loss: 1890.1211 - kl_loss: 99.5062 - false_loss: 0.0886 - true_loss: 1.1152 - val_loss: 5848.7822 - val_reconstruction_loss: 1896.3685 - val_kl_loss: 99.4488 - val_false_loss: 12.4521 - val_true_loss: 1.1734\n",
      "Epoch 1822/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.7369 - reconstruction_loss: 1889.9703 - kl_loss: 100.6050 - false_loss: 0.0886 - true_loss: 1.1151 - val_loss: 5848.4048 - val_reconstruction_loss: 1896.3680 - val_kl_loss: 99.4486 - val_false_loss: 12.4509 - val_true_loss: 1.1733\n",
      "Epoch 1823/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.5545 - reconstruction_loss: 1890.0280 - kl_loss: 100.5445 - false_loss: 0.0886 - true_loss: 1.1151 - val_loss: 5848.0337 - val_reconstruction_loss: 1896.3676 - val_kl_loss: 99.4478 - val_false_loss: 12.4497 - val_true_loss: 1.1733\n",
      "Epoch 1824/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.2348 - reconstruction_loss: 1890.1924 - kl_loss: 100.0707 - false_loss: 0.0886 - true_loss: 1.1150 - val_loss: 5847.6528 - val_reconstruction_loss: 1896.3669 - val_kl_loss: 99.4483 - val_false_loss: 12.4484 - val_true_loss: 1.1733\n",
      "Epoch 1825/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.8814 - reconstruction_loss: 1890.4854 - kl_loss: 102.0663 - false_loss: 0.0886 - true_loss: 1.1150 - val_loss: 5847.2744 - val_reconstruction_loss: 1896.3667 - val_kl_loss: 99.4487 - val_false_loss: 12.4472 - val_true_loss: 1.1732\n",
      "Epoch 1826/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.0848 - reconstruction_loss: 1890.1494 - kl_loss: 101.5525 - false_loss: 0.0886 - true_loss: 1.1149 - val_loss: 5846.8975 - val_reconstruction_loss: 1896.3662 - val_kl_loss: 99.4487 - val_false_loss: 12.4459 - val_true_loss: 1.1732\n",
      "Epoch 1827/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.0403 - reconstruction_loss: 1889.7031 - kl_loss: 101.6861 - false_loss: 0.0886 - true_loss: 1.1148 - val_loss: 5846.5229 - val_reconstruction_loss: 1896.3657 - val_kl_loss: 99.4491 - val_false_loss: 12.4447 - val_true_loss: 1.1731\n",
      "Epoch 1828/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7583 - reconstruction_loss: 1890.2753 - kl_loss: 101.3044 - false_loss: 0.0886 - true_loss: 1.1148 - val_loss: 5846.1436 - val_reconstruction_loss: 1896.3651 - val_kl_loss: 99.4488 - val_false_loss: 12.4434 - val_true_loss: 1.1731\n",
      "Epoch 1829/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.5753 - reconstruction_loss: 1890.4248 - kl_loss: 100.6327 - false_loss: 0.0886 - true_loss: 1.1147 - val_loss: 5845.7710 - val_reconstruction_loss: 1896.3646 - val_kl_loss: 99.4484 - val_false_loss: 12.4422 - val_true_loss: 1.1730\n",
      "Epoch 1830/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8185 - reconstruction_loss: 1891.0020 - kl_loss: 101.6221 - false_loss: 0.0886 - true_loss: 1.1147 - val_loss: 5845.3916 - val_reconstruction_loss: 1896.3645 - val_kl_loss: 99.4488 - val_false_loss: 12.4410 - val_true_loss: 1.1730\n",
      "Epoch 1831/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.6354 - reconstruction_loss: 1891.6105 - kl_loss: 101.6003 - false_loss: 0.0886 - true_loss: 1.1146 - val_loss: 5845.0166 - val_reconstruction_loss: 1896.3640 - val_kl_loss: 99.4488 - val_false_loss: 12.4397 - val_true_loss: 1.1729\n",
      "Epoch 1832/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3776 - reconstruction_loss: 1890.1456 - kl_loss: 102.0591 - false_loss: 0.0886 - true_loss: 1.1146 - val_loss: 5844.6455 - val_reconstruction_loss: 1896.3634 - val_kl_loss: 99.4490 - val_false_loss: 12.4385 - val_true_loss: 1.1729\n",
      "Epoch 1833/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.3624 - reconstruction_loss: 1890.1719 - kl_loss: 101.7929 - false_loss: 0.0886 - true_loss: 1.1145 - val_loss: 5844.2695 - val_reconstruction_loss: 1896.3628 - val_kl_loss: 99.4488 - val_false_loss: 12.4373 - val_true_loss: 1.1728\n",
      "Epoch 1834/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.8680 - reconstruction_loss: 1890.0410 - kl_loss: 101.6385 - false_loss: 0.0885 - true_loss: 1.1145 - val_loss: 5843.8911 - val_reconstruction_loss: 1896.3624 - val_kl_loss: 99.4482 - val_false_loss: 12.4360 - val_true_loss: 1.1728\n",
      "Epoch 1835/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.2974 - reconstruction_loss: 1889.8398 - kl_loss: 100.8004 - false_loss: 0.0885 - true_loss: 1.1144 - val_loss: 5843.5288 - val_reconstruction_loss: 1896.3618 - val_kl_loss: 99.4483 - val_false_loss: 12.4348 - val_true_loss: 1.1728\n",
      "Epoch 1836/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.0791 - reconstruction_loss: 1890.3516 - kl_loss: 101.7467 - false_loss: 0.0885 - true_loss: 1.1144 - val_loss: 5843.1553 - val_reconstruction_loss: 1896.3616 - val_kl_loss: 99.4484 - val_false_loss: 12.4336 - val_true_loss: 1.1727\n",
      "Epoch 1837/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5596 - reconstruction_loss: 1890.2386 - kl_loss: 100.7923 - false_loss: 0.0885 - true_loss: 1.1143 - val_loss: 5842.7871 - val_reconstruction_loss: 1896.3610 - val_kl_loss: 99.4485 - val_false_loss: 12.4324 - val_true_loss: 1.1727\n",
      "Epoch 1838/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.7679 - reconstruction_loss: 1889.9388 - kl_loss: 101.1263 - false_loss: 0.0885 - true_loss: 1.1143 - val_loss: 5842.4106 - val_reconstruction_loss: 1896.3605 - val_kl_loss: 99.4491 - val_false_loss: 12.4312 - val_true_loss: 1.1726\n",
      "Epoch 1839/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.6731 - reconstruction_loss: 1889.8525 - kl_loss: 102.4424 - false_loss: 0.0885 - true_loss: 1.1142 - val_loss: 5842.0371 - val_reconstruction_loss: 1896.3599 - val_kl_loss: 99.4492 - val_false_loss: 12.4299 - val_true_loss: 1.1726\n",
      "Epoch 1840/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6616 - reconstruction_loss: 1890.4427 - kl_loss: 102.1609 - false_loss: 0.0885 - true_loss: 1.1142 - val_loss: 5841.6680 - val_reconstruction_loss: 1896.3594 - val_kl_loss: 99.4487 - val_false_loss: 12.4287 - val_true_loss: 1.1725\n",
      "Epoch 1841/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8018 - reconstruction_loss: 1890.2936 - kl_loss: 100.0958 - false_loss: 0.0885 - true_loss: 1.1141 - val_loss: 5841.2998 - val_reconstruction_loss: 1896.3590 - val_kl_loss: 99.4484 - val_false_loss: 12.4275 - val_true_loss: 1.1725\n",
      "Epoch 1842/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.1552 - reconstruction_loss: 1890.1893 - kl_loss: 100.6041 - false_loss: 0.0885 - true_loss: 1.1141 - val_loss: 5840.9307 - val_reconstruction_loss: 1896.3585 - val_kl_loss: 99.4485 - val_false_loss: 12.4263 - val_true_loss: 1.1725\n",
      "Epoch 1843/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.4340 - reconstruction_loss: 1890.2510 - kl_loss: 101.4137 - false_loss: 0.0885 - true_loss: 1.1140 - val_loss: 5840.5571 - val_reconstruction_loss: 1896.3580 - val_kl_loss: 99.4494 - val_false_loss: 12.4251 - val_true_loss: 1.1724\n",
      "Epoch 1844/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4381 - reconstruction_loss: 1890.1664 - kl_loss: 101.0877 - false_loss: 0.0885 - true_loss: 1.1140 - val_loss: 5840.1914 - val_reconstruction_loss: 1896.3575 - val_kl_loss: 99.4499 - val_false_loss: 12.4239 - val_true_loss: 1.1724\n",
      "Epoch 1845/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6010 - reconstruction_loss: 1890.1854 - kl_loss: 101.6312 - false_loss: 0.0885 - true_loss: 1.1139 - val_loss: 5839.8169 - val_reconstruction_loss: 1896.3569 - val_kl_loss: 99.4502 - val_false_loss: 12.4226 - val_true_loss: 1.1723\n",
      "Epoch 1846/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.8856 - reconstruction_loss: 1889.7467 - kl_loss: 101.0604 - false_loss: 0.0885 - true_loss: 1.1139 - val_loss: 5839.4473 - val_reconstruction_loss: 1896.3564 - val_kl_loss: 99.4509 - val_false_loss: 12.4214 - val_true_loss: 1.1723\n",
      "Epoch 1847/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7932 - reconstruction_loss: 1890.2262 - kl_loss: 101.1787 - false_loss: 0.0884 - true_loss: 1.1138 - val_loss: 5839.0688 - val_reconstruction_loss: 1896.3560 - val_kl_loss: 99.4515 - val_false_loss: 12.4202 - val_true_loss: 1.1722\n",
      "Epoch 1848/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.7953 - reconstruction_loss: 1890.2438 - kl_loss: 101.0995 - false_loss: 0.0884 - true_loss: 1.1138 - val_loss: 5838.7031 - val_reconstruction_loss: 1896.3555 - val_kl_loss: 99.4526 - val_false_loss: 12.4190 - val_true_loss: 1.1722\n",
      "Epoch 1849/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.0170 - reconstruction_loss: 1889.9824 - kl_loss: 101.3367 - false_loss: 0.0884 - true_loss: 1.1137 - val_loss: 5838.3315 - val_reconstruction_loss: 1896.3551 - val_kl_loss: 99.4547 - val_false_loss: 12.4177 - val_true_loss: 1.1721\n",
      "Epoch 1850/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.2731 - reconstruction_loss: 1890.8184 - kl_loss: 100.2042 - false_loss: 0.0884 - true_loss: 1.1137 - val_loss: 5837.9712 - val_reconstruction_loss: 1896.3546 - val_kl_loss: 99.4557 - val_false_loss: 12.4165 - val_true_loss: 1.1721\n",
      "Epoch 1851/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0638 - reconstruction_loss: 1890.3610 - kl_loss: 100.7440 - false_loss: 0.0884 - true_loss: 1.1136 - val_loss: 5837.5972 - val_reconstruction_loss: 1896.3540 - val_kl_loss: 99.4563 - val_false_loss: 12.4153 - val_true_loss: 1.1721\n",
      "Epoch 1852/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.7763 - reconstruction_loss: 1890.4701 - kl_loss: 101.7448 - false_loss: 0.0884 - true_loss: 1.1136 - val_loss: 5837.2251 - val_reconstruction_loss: 1896.3535 - val_kl_loss: 99.4570 - val_false_loss: 12.4141 - val_true_loss: 1.1720\n",
      "Epoch 1853/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.8796 - reconstruction_loss: 1889.9623 - kl_loss: 101.2782 - false_loss: 0.0884 - true_loss: 1.1135 - val_loss: 5836.8516 - val_reconstruction_loss: 1896.3531 - val_kl_loss: 99.4578 - val_false_loss: 12.4128 - val_true_loss: 1.1720\n",
      "Epoch 1854/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5376 - reconstruction_loss: 1890.5513 - kl_loss: 100.9347 - false_loss: 0.0884 - true_loss: 1.1135 - val_loss: 5836.4849 - val_reconstruction_loss: 1896.3525 - val_kl_loss: 99.4590 - val_false_loss: 12.4116 - val_true_loss: 1.1719\n",
      "Epoch 1855/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.9833 - reconstruction_loss: 1890.4105 - kl_loss: 100.9842 - false_loss: 0.0884 - true_loss: 1.1134 - val_loss: 5836.1143 - val_reconstruction_loss: 1896.3521 - val_kl_loss: 99.4599 - val_false_loss: 12.4104 - val_true_loss: 1.1719\n",
      "Epoch 1856/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.8869 - reconstruction_loss: 1890.1254 - kl_loss: 100.4421 - false_loss: 0.0884 - true_loss: 1.1134 - val_loss: 5835.7451 - val_reconstruction_loss: 1896.3514 - val_kl_loss: 99.4595 - val_false_loss: 12.4092 - val_true_loss: 1.1719\n",
      "Epoch 1857/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.7157 - reconstruction_loss: 1889.9635 - kl_loss: 100.3647 - false_loss: 0.0884 - true_loss: 1.1134 - val_loss: 5835.3726 - val_reconstruction_loss: 1896.3511 - val_kl_loss: 99.4594 - val_false_loss: 12.4080 - val_true_loss: 1.1718\n",
      "Epoch 1858/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.9983 - reconstruction_loss: 1890.3021 - kl_loss: 101.1100 - false_loss: 0.0884 - true_loss: 1.1133 - val_loss: 5834.9971 - val_reconstruction_loss: 1896.3505 - val_kl_loss: 99.4602 - val_false_loss: 12.4067 - val_true_loss: 1.1718\n",
      "Epoch 1859/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.0313 - reconstruction_loss: 1889.9945 - kl_loss: 101.6419 - false_loss: 0.0884 - true_loss: 1.1133 - val_loss: 5834.6201 - val_reconstruction_loss: 1896.3499 - val_kl_loss: 99.4607 - val_false_loss: 12.4055 - val_true_loss: 1.1717\n",
      "Epoch 1860/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.6531 - reconstruction_loss: 1890.0654 - kl_loss: 101.6488 - false_loss: 0.0883 - true_loss: 1.1132 - val_loss: 5834.2524 - val_reconstruction_loss: 1896.3496 - val_kl_loss: 99.4612 - val_false_loss: 12.4043 - val_true_loss: 1.1717\n",
      "Epoch 1861/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.7671 - reconstruction_loss: 1889.8551 - kl_loss: 101.1713 - false_loss: 0.0883 - true_loss: 1.1132 - val_loss: 5833.8774 - val_reconstruction_loss: 1896.3490 - val_kl_loss: 99.4615 - val_false_loss: 12.4031 - val_true_loss: 1.1716\n",
      "Epoch 1862/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.2345 - reconstruction_loss: 1889.7882 - kl_loss: 101.6014 - false_loss: 0.0883 - true_loss: 1.1131 - val_loss: 5833.5010 - val_reconstruction_loss: 1896.3484 - val_kl_loss: 99.4620 - val_false_loss: 12.4018 - val_true_loss: 1.1716\n",
      "Epoch 1863/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6315 - reconstruction_loss: 1890.3379 - kl_loss: 101.5170 - false_loss: 0.0883 - true_loss: 1.1131 - val_loss: 5833.1279 - val_reconstruction_loss: 1896.3480 - val_kl_loss: 99.4622 - val_false_loss: 12.4006 - val_true_loss: 1.1715\n",
      "Epoch 1864/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.9971 - reconstruction_loss: 1890.2733 - kl_loss: 102.0643 - false_loss: 0.0883 - true_loss: 1.1130 - val_loss: 5832.7588 - val_reconstruction_loss: 1896.3478 - val_kl_loss: 99.4629 - val_false_loss: 12.3994 - val_true_loss: 1.1715\n",
      "Epoch 1865/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.9123 - reconstruction_loss: 1890.2445 - kl_loss: 102.1468 - false_loss: 0.0883 - true_loss: 1.1129 - val_loss: 5832.3892 - val_reconstruction_loss: 1896.3472 - val_kl_loss: 99.4632 - val_false_loss: 12.3982 - val_true_loss: 1.1714\n",
      "Epoch 1866/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.6024 - reconstruction_loss: 1889.9674 - kl_loss: 101.3317 - false_loss: 0.0883 - true_loss: 1.1129 - val_loss: 5832.0171 - val_reconstruction_loss: 1896.3466 - val_kl_loss: 99.4639 - val_false_loss: 12.3969 - val_true_loss: 1.1714\n",
      "Epoch 1867/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.9927 - reconstruction_loss: 1889.9038 - kl_loss: 103.2539 - false_loss: 0.0883 - true_loss: 1.1128 - val_loss: 5831.6489 - val_reconstruction_loss: 1896.3462 - val_kl_loss: 99.4651 - val_false_loss: 12.3957 - val_true_loss: 1.1713\n",
      "Epoch 1868/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.6382 - reconstruction_loss: 1890.5865 - kl_loss: 101.3333 - false_loss: 0.0883 - true_loss: 1.1128 - val_loss: 5831.2778 - val_reconstruction_loss: 1896.3456 - val_kl_loss: 99.4664 - val_false_loss: 12.3945 - val_true_loss: 1.1713\n",
      "Epoch 1869/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.2637 - reconstruction_loss: 1890.4023 - kl_loss: 102.1553 - false_loss: 0.0883 - true_loss: 1.1127 - val_loss: 5830.9019 - val_reconstruction_loss: 1896.3453 - val_kl_loss: 99.4671 - val_false_loss: 12.3932 - val_true_loss: 1.1712\n",
      "Epoch 1870/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.2149 - reconstruction_loss: 1889.8895 - kl_loss: 102.0678 - false_loss: 0.0883 - true_loss: 1.1127 - val_loss: 5830.5342 - val_reconstruction_loss: 1896.3447 - val_kl_loss: 99.4674 - val_false_loss: 12.3920 - val_true_loss: 1.1712\n",
      "Epoch 1871/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.3995 - reconstruction_loss: 1890.5009 - kl_loss: 100.1667 - false_loss: 0.0883 - true_loss: 1.1127 - val_loss: 5830.1714 - val_reconstruction_loss: 1896.3441 - val_kl_loss: 99.4671 - val_false_loss: 12.3908 - val_true_loss: 1.1712\n",
      "Epoch 1872/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0223 - reconstruction_loss: 1889.7191 - kl_loss: 99.6706 - false_loss: 0.0883 - true_loss: 1.1126 - val_loss: 5829.7930 - val_reconstruction_loss: 1896.3438 - val_kl_loss: 99.4671 - val_false_loss: 12.3896 - val_true_loss: 1.1711\n",
      "Epoch 1873/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2232.2799 - reconstruction_loss: 1889.6527 - kl_loss: 99.7720 - false_loss: 0.0883 - true_loss: 1.1126 - val_loss: 5829.4390 - val_reconstruction_loss: 1896.3431 - val_kl_loss: 99.4674 - val_false_loss: 12.3884 - val_true_loss: 1.1711\n",
      "Epoch 1874/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.6816 - reconstruction_loss: 1890.4668 - kl_loss: 99.6134 - false_loss: 0.0882 - true_loss: 1.1125 - val_loss: 5829.0659 - val_reconstruction_loss: 1896.3425 - val_kl_loss: 99.4671 - val_false_loss: 12.3872 - val_true_loss: 1.1711\n",
      "Epoch 1875/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6058 - reconstruction_loss: 1890.1061 - kl_loss: 97.9407 - false_loss: 0.0882 - true_loss: 1.1125 - val_loss: 5828.6973 - val_reconstruction_loss: 1896.3424 - val_kl_loss: 99.4680 - val_false_loss: 12.3860 - val_true_loss: 1.1710\n",
      "Epoch 1876/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4692 - reconstruction_loss: 1890.0605 - kl_loss: 99.9094 - false_loss: 0.0882 - true_loss: 1.1124 - val_loss: 5828.3311 - val_reconstruction_loss: 1896.3418 - val_kl_loss: 99.4678 - val_false_loss: 12.3848 - val_true_loss: 1.1710\n",
      "Epoch 1877/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.9140 - reconstruction_loss: 1890.4684 - kl_loss: 99.0756 - false_loss: 0.0882 - true_loss: 1.1124 - val_loss: 5827.9517 - val_reconstruction_loss: 1896.3413 - val_kl_loss: 99.4670 - val_false_loss: 12.3835 - val_true_loss: 1.1710\n",
      "Epoch 1878/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.9807 - reconstruction_loss: 1890.9393 - kl_loss: 98.5822 - false_loss: 0.0882 - true_loss: 1.1124 - val_loss: 5827.5796 - val_reconstruction_loss: 1896.3411 - val_kl_loss: 99.4673 - val_false_loss: 12.3823 - val_true_loss: 1.1709\n",
      "Epoch 1879/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0146 - reconstruction_loss: 1890.4092 - kl_loss: 98.9509 - false_loss: 0.0882 - true_loss: 1.1123 - val_loss: 5827.2012 - val_reconstruction_loss: 1896.3405 - val_kl_loss: 99.4667 - val_false_loss: 12.3811 - val_true_loss: 1.1709\n",
      "Epoch 1880/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.3869 - reconstruction_loss: 1890.7183 - kl_loss: 99.1864 - false_loss: 0.0882 - true_loss: 1.1123 - val_loss: 5826.8301 - val_reconstruction_loss: 1896.3400 - val_kl_loss: 99.4673 - val_false_loss: 12.3798 - val_true_loss: 1.1708\n",
      "Epoch 1881/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.7035 - reconstruction_loss: 1890.5568 - kl_loss: 98.4634 - false_loss: 0.0882 - true_loss: 1.1122 - val_loss: 5826.4492 - val_reconstruction_loss: 1896.3395 - val_kl_loss: 99.4683 - val_false_loss: 12.3786 - val_true_loss: 1.1708\n",
      "Epoch 1882/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1875 - reconstruction_loss: 1890.0043 - kl_loss: 98.4204 - false_loss: 0.0882 - true_loss: 1.1122 - val_loss: 5826.0820 - val_reconstruction_loss: 1896.3391 - val_kl_loss: 99.4685 - val_false_loss: 12.3774 - val_true_loss: 1.1708\n",
      "Epoch 1883/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.1485 - reconstruction_loss: 1889.7534 - kl_loss: 100.1406 - false_loss: 0.0882 - true_loss: 1.1121 - val_loss: 5825.7100 - val_reconstruction_loss: 1896.3385 - val_kl_loss: 99.4687 - val_false_loss: 12.3761 - val_true_loss: 1.1707\n",
      "Epoch 1884/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3548 - reconstruction_loss: 1889.6783 - kl_loss: 99.8755 - false_loss: 0.0882 - true_loss: 1.1121 - val_loss: 5825.3389 - val_reconstruction_loss: 1896.3380 - val_kl_loss: 99.4690 - val_false_loss: 12.3749 - val_true_loss: 1.1707\n",
      "Epoch 1885/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.2368 - reconstruction_loss: 1889.7715 - kl_loss: 99.8722 - false_loss: 0.0882 - true_loss: 1.1120 - val_loss: 5824.9668 - val_reconstruction_loss: 1896.3375 - val_kl_loss: 99.4694 - val_false_loss: 12.3737 - val_true_loss: 1.1706\n",
      "Epoch 1886/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8430 - reconstruction_loss: 1890.2662 - kl_loss: 101.3167 - false_loss: 0.0882 - true_loss: 1.1120 - val_loss: 5824.5972 - val_reconstruction_loss: 1896.3369 - val_kl_loss: 99.4702 - val_false_loss: 12.3725 - val_true_loss: 1.1706\n",
      "Epoch 1887/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.5472 - reconstruction_loss: 1889.8896 - kl_loss: 101.6807 - false_loss: 0.0881 - true_loss: 1.1119 - val_loss: 5824.2202 - val_reconstruction_loss: 1896.3363 - val_kl_loss: 99.4706 - val_false_loss: 12.3712 - val_true_loss: 1.1705\n",
      "Epoch 1888/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.0546 - reconstruction_loss: 1890.1071 - kl_loss: 101.5207 - false_loss: 0.0881 - true_loss: 1.1119 - val_loss: 5823.8491 - val_reconstruction_loss: 1896.3361 - val_kl_loss: 99.4711 - val_false_loss: 12.3700 - val_true_loss: 1.1705\n",
      "Epoch 1889/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.5906 - reconstruction_loss: 1890.0902 - kl_loss: 100.9165 - false_loss: 0.0881 - true_loss: 1.1118 - val_loss: 5823.4785 - val_reconstruction_loss: 1896.3354 - val_kl_loss: 99.4715 - val_false_loss: 12.3688 - val_true_loss: 1.1704\n",
      "Epoch 1890/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.5197 - reconstruction_loss: 1889.7412 - kl_loss: 102.2195 - false_loss: 0.0881 - true_loss: 1.1118 - val_loss: 5823.1084 - val_reconstruction_loss: 1896.3348 - val_kl_loss: 99.4717 - val_false_loss: 12.3676 - val_true_loss: 1.1704\n",
      "Epoch 1891/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.7302 - reconstruction_loss: 1890.0773 - kl_loss: 101.6613 - false_loss: 0.0881 - true_loss: 1.1117 - val_loss: 5822.7373 - val_reconstruction_loss: 1896.3344 - val_kl_loss: 99.4728 - val_false_loss: 12.3664 - val_true_loss: 1.1703\n",
      "Epoch 1892/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5715 - reconstruction_loss: 1889.9340 - kl_loss: 101.3181 - false_loss: 0.0881 - true_loss: 1.1117 - val_loss: 5822.3672 - val_reconstruction_loss: 1896.3340 - val_kl_loss: 99.4741 - val_false_loss: 12.3651 - val_true_loss: 1.1703\n",
      "Epoch 1893/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.5723 - reconstruction_loss: 1889.9264 - kl_loss: 101.9898 - false_loss: 0.0881 - true_loss: 1.1116 - val_loss: 5821.9951 - val_reconstruction_loss: 1896.3334 - val_kl_loss: 99.4747 - val_false_loss: 12.3639 - val_true_loss: 1.1702\n",
      "Epoch 1894/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.9750 - reconstruction_loss: 1890.1224 - kl_loss: 101.8456 - false_loss: 0.0881 - true_loss: 1.1116 - val_loss: 5821.6260 - val_reconstruction_loss: 1896.3329 - val_kl_loss: 99.4753 - val_false_loss: 12.3627 - val_true_loss: 1.1702\n",
      "Epoch 1895/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.7458 - reconstruction_loss: 1890.4811 - kl_loss: 100.3348 - false_loss: 0.0881 - true_loss: 1.1115 - val_loss: 5821.2573 - val_reconstruction_loss: 1896.3324 - val_kl_loss: 99.4761 - val_false_loss: 12.3615 - val_true_loss: 1.1702\n",
      "Epoch 1896/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.5932 - reconstruction_loss: 1890.0596 - kl_loss: 101.4618 - false_loss: 0.0881 - true_loss: 1.1115 - val_loss: 5820.8872 - val_reconstruction_loss: 1896.3323 - val_kl_loss: 99.4767 - val_false_loss: 12.3603 - val_true_loss: 1.1701\n",
      "Epoch 1897/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.9007 - reconstruction_loss: 1890.3785 - kl_loss: 101.1466 - false_loss: 0.0881 - true_loss: 1.1114 - val_loss: 5820.5229 - val_reconstruction_loss: 1896.3317 - val_kl_loss: 99.4771 - val_false_loss: 12.3591 - val_true_loss: 1.1701\n",
      "Epoch 1898/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.4071 - reconstruction_loss: 1890.2548 - kl_loss: 101.9742 - false_loss: 0.0881 - true_loss: 1.1114 - val_loss: 5820.1548 - val_reconstruction_loss: 1896.3311 - val_kl_loss: 99.4776 - val_false_loss: 12.3578 - val_true_loss: 1.1700\n",
      "Epoch 1899/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4556 - reconstruction_loss: 1890.2451 - kl_loss: 101.7834 - false_loss: 0.0881 - true_loss: 1.1113 - val_loss: 5819.7822 - val_reconstruction_loss: 1896.3307 - val_kl_loss: 99.4774 - val_false_loss: 12.3566 - val_true_loss: 1.1700\n",
      "Epoch 1900/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4659 - reconstruction_loss: 1890.5391 - kl_loss: 100.7995 - false_loss: 0.0880 - true_loss: 1.1113 - val_loss: 5819.4209 - val_reconstruction_loss: 1896.3303 - val_kl_loss: 99.4771 - val_false_loss: 12.3554 - val_true_loss: 1.1699\n",
      "Epoch 1901/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4335 - reconstruction_loss: 1890.4965 - kl_loss: 100.5789 - false_loss: 0.0880 - true_loss: 1.1112 - val_loss: 5819.0542 - val_reconstruction_loss: 1896.3298 - val_kl_loss: 99.4775 - val_false_loss: 12.3542 - val_true_loss: 1.1699\n",
      "Epoch 1902/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.9011 - reconstruction_loss: 1890.1271 - kl_loss: 102.0958 - false_loss: 0.0880 - true_loss: 1.1112 - val_loss: 5818.6865 - val_reconstruction_loss: 1896.3292 - val_kl_loss: 99.4773 - val_false_loss: 12.3530 - val_true_loss: 1.1699\n",
      "Epoch 1903/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.5142 - reconstruction_loss: 1889.8813 - kl_loss: 101.8575 - false_loss: 0.0880 - true_loss: 1.1111 - val_loss: 5818.3213 - val_reconstruction_loss: 1896.3287 - val_kl_loss: 99.4775 - val_false_loss: 12.3518 - val_true_loss: 1.1698\n",
      "Epoch 1904/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.9316 - reconstruction_loss: 1890.1600 - kl_loss: 101.0790 - false_loss: 0.0880 - true_loss: 1.1111 - val_loss: 5817.9541 - val_reconstruction_loss: 1896.3284 - val_kl_loss: 99.4781 - val_false_loss: 12.3506 - val_true_loss: 1.1698\n",
      "Epoch 1905/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.9713 - reconstruction_loss: 1890.7206 - kl_loss: 102.4697 - false_loss: 0.0880 - true_loss: 1.1110 - val_loss: 5817.5918 - val_reconstruction_loss: 1896.3280 - val_kl_loss: 99.4782 - val_false_loss: 12.3494 - val_true_loss: 1.1697\n",
      "Epoch 1906/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5482 - reconstruction_loss: 1890.2233 - kl_loss: 101.5467 - false_loss: 0.0880 - true_loss: 1.1110 - val_loss: 5817.2236 - val_reconstruction_loss: 1896.3274 - val_kl_loss: 99.4780 - val_false_loss: 12.3482 - val_true_loss: 1.1697\n",
      "Epoch 1907/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.9341 - reconstruction_loss: 1890.3325 - kl_loss: 101.1739 - false_loss: 0.0880 - true_loss: 1.1109 - val_loss: 5816.8638 - val_reconstruction_loss: 1896.3268 - val_kl_loss: 99.4778 - val_false_loss: 12.3470 - val_true_loss: 1.1697\n",
      "Epoch 1908/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.5326 - reconstruction_loss: 1890.2648 - kl_loss: 101.4035 - false_loss: 0.0880 - true_loss: 1.1109 - val_loss: 5816.5015 - val_reconstruction_loss: 1896.3265 - val_kl_loss: 99.4782 - val_false_loss: 12.3458 - val_true_loss: 1.1696\n",
      "Epoch 1909/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8466 - reconstruction_loss: 1889.9803 - kl_loss: 99.7956 - false_loss: 0.0880 - true_loss: 1.1108 - val_loss: 5816.1416 - val_reconstruction_loss: 1896.3259 - val_kl_loss: 99.4796 - val_false_loss: 12.3446 - val_true_loss: 1.1696\n",
      "Epoch 1910/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.0973 - reconstruction_loss: 1889.8016 - kl_loss: 102.1315 - false_loss: 0.0880 - true_loss: 1.1108 - val_loss: 5815.7764 - val_reconstruction_loss: 1896.3253 - val_kl_loss: 99.4807 - val_false_loss: 12.3434 - val_true_loss: 1.1695\n",
      "Epoch 1911/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.6388 - reconstruction_loss: 1890.2437 - kl_loss: 100.6003 - false_loss: 0.0880 - true_loss: 1.1107 - val_loss: 5815.4048 - val_reconstruction_loss: 1896.3250 - val_kl_loss: 99.4818 - val_false_loss: 12.3422 - val_true_loss: 1.1695\n",
      "Epoch 1912/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.4381 - reconstruction_loss: 1890.7416 - kl_loss: 102.1055 - false_loss: 0.0880 - true_loss: 1.1107 - val_loss: 5815.0474 - val_reconstruction_loss: 1896.3243 - val_kl_loss: 99.4819 - val_false_loss: 12.3410 - val_true_loss: 1.1694\n",
      "Epoch 1913/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.1342 - reconstruction_loss: 1890.4476 - kl_loss: 101.0070 - false_loss: 0.0880 - true_loss: 1.1106 - val_loss: 5814.6860 - val_reconstruction_loss: 1896.3241 - val_kl_loss: 99.4814 - val_false_loss: 12.3398 - val_true_loss: 1.1694\n",
      "Epoch 1914/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.5030 - reconstruction_loss: 1890.0973 - kl_loss: 99.0760 - false_loss: 0.0879 - true_loss: 1.1106 - val_loss: 5814.3223 - val_reconstruction_loss: 1896.3236 - val_kl_loss: 99.4823 - val_false_loss: 12.3386 - val_true_loss: 1.1694\n",
      "Epoch 1915/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0340 - reconstruction_loss: 1890.2650 - kl_loss: 100.1978 - false_loss: 0.0879 - true_loss: 1.1106 - val_loss: 5813.9595 - val_reconstruction_loss: 1896.3231 - val_kl_loss: 99.4821 - val_false_loss: 12.3374 - val_true_loss: 1.1693\n",
      "Epoch 1916/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2009 - reconstruction_loss: 1890.1158 - kl_loss: 99.0835 - false_loss: 0.0879 - true_loss: 1.1105 - val_loss: 5813.5879 - val_reconstruction_loss: 1896.3228 - val_kl_loss: 99.4825 - val_false_loss: 12.3362 - val_true_loss: 1.1693\n",
      "Epoch 1917/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.0013 - reconstruction_loss: 1889.9938 - kl_loss: 101.1112 - false_loss: 0.0879 - true_loss: 1.1105 - val_loss: 5813.2192 - val_reconstruction_loss: 1896.3221 - val_kl_loss: 99.4822 - val_false_loss: 12.3350 - val_true_loss: 1.1692\n",
      "Epoch 1918/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1538 - reconstruction_loss: 1890.1168 - kl_loss: 100.0461 - false_loss: 0.0879 - true_loss: 1.1104 - val_loss: 5812.8555 - val_reconstruction_loss: 1896.3217 - val_kl_loss: 99.4823 - val_false_loss: 12.3338 - val_true_loss: 1.1692\n",
      "Epoch 1919/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.2729 - reconstruction_loss: 1889.9951 - kl_loss: 101.0173 - false_loss: 0.0879 - true_loss: 1.1104 - val_loss: 5812.4829 - val_reconstruction_loss: 1896.3212 - val_kl_loss: 99.4829 - val_false_loss: 12.3326 - val_true_loss: 1.1691\n",
      "Epoch 1920/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.7964 - reconstruction_loss: 1889.9971 - kl_loss: 101.0090 - false_loss: 0.0879 - true_loss: 1.1103 - val_loss: 5812.1094 - val_reconstruction_loss: 1896.3207 - val_kl_loss: 99.4837 - val_false_loss: 12.3314 - val_true_loss: 1.1691\n",
      "Epoch 1921/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.7464 - reconstruction_loss: 1890.0660 - kl_loss: 101.1481 - false_loss: 0.0879 - true_loss: 1.1103 - val_loss: 5811.7471 - val_reconstruction_loss: 1896.3203 - val_kl_loss: 99.4839 - val_false_loss: 12.3302 - val_true_loss: 1.1691\n",
      "Epoch 1922/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.5684 - reconstruction_loss: 1890.3802 - kl_loss: 101.6392 - false_loss: 0.0879 - true_loss: 1.1102 - val_loss: 5811.3794 - val_reconstruction_loss: 1896.3197 - val_kl_loss: 99.4840 - val_false_loss: 12.3290 - val_true_loss: 1.1690\n",
      "Epoch 1923/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.8871 - reconstruction_loss: 1889.8646 - kl_loss: 100.7089 - false_loss: 0.0879 - true_loss: 1.1102 - val_loss: 5811.0117 - val_reconstruction_loss: 1896.3192 - val_kl_loss: 99.4842 - val_false_loss: 12.3277 - val_true_loss: 1.1690\n",
      "Epoch 1924/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.2705 - reconstruction_loss: 1889.8232 - kl_loss: 102.7393 - false_loss: 0.0879 - true_loss: 1.1101 - val_loss: 5810.6460 - val_reconstruction_loss: 1896.3188 - val_kl_loss: 99.4844 - val_false_loss: 12.3265 - val_true_loss: 1.1689\n",
      "Epoch 1925/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2212.6933 - reconstruction_loss: 1889.8610 - kl_loss: 101.9708 - false_loss: 0.0879 - true_loss: 1.1101 - val_loss: 5810.2783 - val_reconstruction_loss: 1896.3182 - val_kl_loss: 99.4852 - val_false_loss: 12.3253 - val_true_loss: 1.1689\n",
      "Epoch 1926/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4700 - reconstruction_loss: 1890.1517 - kl_loss: 102.6134 - false_loss: 0.0879 - true_loss: 1.1100 - val_loss: 5809.9199 - val_reconstruction_loss: 1896.3177 - val_kl_loss: 99.4855 - val_false_loss: 12.3241 - val_true_loss: 1.1688\n",
      "Epoch 1927/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.3538 - reconstruction_loss: 1890.2271 - kl_loss: 102.3912 - false_loss: 0.0878 - true_loss: 1.1100 - val_loss: 5809.5503 - val_reconstruction_loss: 1896.3173 - val_kl_loss: 99.4859 - val_false_loss: 12.3229 - val_true_loss: 1.1688\n",
      "Epoch 1928/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.8878 - reconstruction_loss: 1889.9764 - kl_loss: 101.6862 - false_loss: 0.0878 - true_loss: 1.1099 - val_loss: 5809.1914 - val_reconstruction_loss: 1896.3170 - val_kl_loss: 99.4869 - val_false_loss: 12.3218 - val_true_loss: 1.1687\n",
      "Epoch 1929/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.6114 - reconstruction_loss: 1889.7939 - kl_loss: 101.6044 - false_loss: 0.0878 - true_loss: 1.1099 - val_loss: 5808.8262 - val_reconstruction_loss: 1896.3164 - val_kl_loss: 99.4876 - val_false_loss: 12.3205 - val_true_loss: 1.1687\n",
      "Epoch 1930/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.1339 - reconstruction_loss: 1889.9027 - kl_loss: 102.5622 - false_loss: 0.0878 - true_loss: 1.1098 - val_loss: 5808.4536 - val_reconstruction_loss: 1896.3159 - val_kl_loss: 99.4883 - val_false_loss: 12.3193 - val_true_loss: 1.1686\n",
      "Epoch 1931/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.5717 - reconstruction_loss: 1890.2211 - kl_loss: 102.4520 - false_loss: 0.0878 - true_loss: 1.1097 - val_loss: 5808.0879 - val_reconstruction_loss: 1896.3156 - val_kl_loss: 99.4890 - val_false_loss: 12.3181 - val_true_loss: 1.1686\n",
      "Epoch 1932/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.8955 - reconstruction_loss: 1889.8627 - kl_loss: 102.4241 - false_loss: 0.0878 - true_loss: 1.1097 - val_loss: 5807.7271 - val_reconstruction_loss: 1896.3149 - val_kl_loss: 99.4896 - val_false_loss: 12.3169 - val_true_loss: 1.1685\n",
      "Epoch 1933/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.8207 - reconstruction_loss: 1889.9469 - kl_loss: 102.5567 - false_loss: 0.0878 - true_loss: 1.1096 - val_loss: 5807.3618 - val_reconstruction_loss: 1896.3145 - val_kl_loss: 99.4894 - val_false_loss: 12.3157 - val_true_loss: 1.1685\n",
      "Epoch 1934/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.5140 - reconstruction_loss: 1889.8652 - kl_loss: 101.1839 - false_loss: 0.0878 - true_loss: 1.1096 - val_loss: 5806.9922 - val_reconstruction_loss: 1896.3142 - val_kl_loss: 99.4887 - val_false_loss: 12.3145 - val_true_loss: 1.1685\n",
      "Epoch 1935/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8365 - reconstruction_loss: 1890.0687 - kl_loss: 100.6693 - false_loss: 0.0878 - true_loss: 1.1095 - val_loss: 5806.6323 - val_reconstruction_loss: 1896.3136 - val_kl_loss: 99.4883 - val_false_loss: 12.3133 - val_true_loss: 1.1684\n",
      "Epoch 1936/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.8675 - reconstruction_loss: 1890.2401 - kl_loss: 102.5322 - false_loss: 0.0878 - true_loss: 1.1095 - val_loss: 5806.2695 - val_reconstruction_loss: 1896.3132 - val_kl_loss: 99.4888 - val_false_loss: 12.3121 - val_true_loss: 1.1684\n",
      "Epoch 1937/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.2417 - reconstruction_loss: 1890.2354 - kl_loss: 102.2383 - false_loss: 0.0878 - true_loss: 1.1094 - val_loss: 5805.8994 - val_reconstruction_loss: 1896.3127 - val_kl_loss: 99.4893 - val_false_loss: 12.3109 - val_true_loss: 1.1683\n",
      "Epoch 1938/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.4455 - reconstruction_loss: 1889.9854 - kl_loss: 102.1042 - false_loss: 0.0878 - true_loss: 1.1094 - val_loss: 5805.5303 - val_reconstruction_loss: 1896.3124 - val_kl_loss: 99.4894 - val_false_loss: 12.3097 - val_true_loss: 1.1683\n",
      "Epoch 1939/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.5499 - reconstruction_loss: 1889.9175 - kl_loss: 101.0722 - false_loss: 0.0878 - true_loss: 1.1093 - val_loss: 5805.1636 - val_reconstruction_loss: 1896.3118 - val_kl_loss: 99.4901 - val_false_loss: 12.3085 - val_true_loss: 1.1682\n",
      "Epoch 1940/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.3632 - reconstruction_loss: 1890.3444 - kl_loss: 102.2734 - false_loss: 0.0877 - true_loss: 1.1093 - val_loss: 5804.8066 - val_reconstruction_loss: 1896.3113 - val_kl_loss: 99.4912 - val_false_loss: 12.3073 - val_true_loss: 1.1682\n",
      "Epoch 1941/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.1636 - reconstruction_loss: 1889.8265 - kl_loss: 101.9324 - false_loss: 0.0877 - true_loss: 1.1092 - val_loss: 5804.4385 - val_reconstruction_loss: 1896.3109 - val_kl_loss: 99.4925 - val_false_loss: 12.3061 - val_true_loss: 1.1681\n",
      "Epoch 1942/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.9825 - reconstruction_loss: 1890.4927 - kl_loss: 102.4665 - false_loss: 0.0877 - true_loss: 1.1092 - val_loss: 5804.0718 - val_reconstruction_loss: 1896.3103 - val_kl_loss: 99.4934 - val_false_loss: 12.3049 - val_true_loss: 1.1681\n",
      "Epoch 1943/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.8291 - reconstruction_loss: 1890.3549 - kl_loss: 103.2692 - false_loss: 0.0877 - true_loss: 1.1091 - val_loss: 5803.7026 - val_reconstruction_loss: 1896.3098 - val_kl_loss: 99.4936 - val_false_loss: 12.3037 - val_true_loss: 1.1681\n",
      "Epoch 1944/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.1506 - reconstruction_loss: 1889.8104 - kl_loss: 101.9268 - false_loss: 0.0877 - true_loss: 1.1091 - val_loss: 5803.3350 - val_reconstruction_loss: 1896.3093 - val_kl_loss: 99.4934 - val_false_loss: 12.3025 - val_true_loss: 1.1680\n",
      "Epoch 1945/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.8588 - reconstruction_loss: 1890.0778 - kl_loss: 100.6136 - false_loss: 0.0877 - true_loss: 1.1090 - val_loss: 5802.9644 - val_reconstruction_loss: 1896.3088 - val_kl_loss: 99.4936 - val_false_loss: 12.3013 - val_true_loss: 1.1680\n",
      "Epoch 1946/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.1233 - reconstruction_loss: 1889.9537 - kl_loss: 99.6437 - false_loss: 0.0877 - true_loss: 1.1090 - val_loss: 5802.6025 - val_reconstruction_loss: 1896.3083 - val_kl_loss: 99.4945 - val_false_loss: 12.3001 - val_true_loss: 1.1679\n",
      "Epoch 1947/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.2178 - reconstruction_loss: 1890.5145 - kl_loss: 102.7675 - false_loss: 0.0877 - true_loss: 1.1089 - val_loss: 5802.2427 - val_reconstruction_loss: 1896.3079 - val_kl_loss: 99.4938 - val_false_loss: 12.2989 - val_true_loss: 1.1679\n",
      "Epoch 1948/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.0803 - reconstruction_loss: 1891.0522 - kl_loss: 99.9724 - false_loss: 0.0877 - true_loss: 1.1089 - val_loss: 5801.8916 - val_reconstruction_loss: 1896.3076 - val_kl_loss: 99.4947 - val_false_loss: 12.2977 - val_true_loss: 1.1678\n",
      "Epoch 1949/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.9702 - reconstruction_loss: 1890.1537 - kl_loss: 100.6100 - false_loss: 0.0877 - true_loss: 1.1089 - val_loss: 5801.5278 - val_reconstruction_loss: 1896.3071 - val_kl_loss: 99.4954 - val_false_loss: 12.2965 - val_true_loss: 1.1678\n",
      "Epoch 1950/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9803 - reconstruction_loss: 1889.8563 - kl_loss: 99.8366 - false_loss: 0.0877 - true_loss: 1.1088 - val_loss: 5801.1597 - val_reconstruction_loss: 1896.3065 - val_kl_loss: 99.4954 - val_false_loss: 12.2953 - val_true_loss: 1.1678\n",
      "Epoch 1951/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2113 - reconstruction_loss: 1889.9135 - kl_loss: 100.9937 - false_loss: 0.0877 - true_loss: 1.1088 - val_loss: 5800.8008 - val_reconstruction_loss: 1896.3060 - val_kl_loss: 99.4951 - val_false_loss: 12.2941 - val_true_loss: 1.1677\n",
      "Epoch 1952/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.7459 - reconstruction_loss: 1890.0449 - kl_loss: 99.5649 - false_loss: 0.0877 - true_loss: 1.1087 - val_loss: 5800.4399 - val_reconstruction_loss: 1896.3057 - val_kl_loss: 99.4958 - val_false_loss: 12.2929 - val_true_loss: 1.1677\n",
      "Epoch 1953/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.7433 - reconstruction_loss: 1890.2545 - kl_loss: 99.1643 - false_loss: 0.0877 - true_loss: 1.1087 - val_loss: 5800.0747 - val_reconstruction_loss: 1896.3052 - val_kl_loss: 99.4960 - val_false_loss: 12.2917 - val_true_loss: 1.1676\n",
      "Epoch 1954/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6140 - reconstruction_loss: 1890.0278 - kl_loss: 100.1356 - false_loss: 0.0876 - true_loss: 1.1086 - val_loss: 5799.7144 - val_reconstruction_loss: 1896.3046 - val_kl_loss: 99.4970 - val_false_loss: 12.2905 - val_true_loss: 1.1676\n",
      "Epoch 1955/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.9496 - reconstruction_loss: 1890.1343 - kl_loss: 99.4117 - false_loss: 0.0876 - true_loss: 1.1086 - val_loss: 5799.3472 - val_reconstruction_loss: 1896.3043 - val_kl_loss: 99.4973 - val_false_loss: 12.2893 - val_true_loss: 1.1675\n",
      "Epoch 1956/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.6811 - reconstruction_loss: 1889.9447 - kl_loss: 99.0540 - false_loss: 0.0876 - true_loss: 1.1086 - val_loss: 5798.9893 - val_reconstruction_loss: 1896.3037 - val_kl_loss: 99.4983 - val_false_loss: 12.2882 - val_true_loss: 1.1675\n",
      "Epoch 1957/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.9199 - reconstruction_loss: 1889.9213 - kl_loss: 98.3732 - false_loss: 0.0876 - true_loss: 1.1085 - val_loss: 5798.6235 - val_reconstruction_loss: 1896.3032 - val_kl_loss: 99.4983 - val_false_loss: 12.2870 - val_true_loss: 1.1675\n",
      "Epoch 1958/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4930 - reconstruction_loss: 1890.5127 - kl_loss: 99.5648 - false_loss: 0.0876 - true_loss: 1.1085 - val_loss: 5798.2637 - val_reconstruction_loss: 1896.3029 - val_kl_loss: 99.4988 - val_false_loss: 12.2858 - val_true_loss: 1.1674\n",
      "Epoch 1959/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.5625 - reconstruction_loss: 1890.0396 - kl_loss: 99.7805 - false_loss: 0.0876 - true_loss: 1.1084 - val_loss: 5797.8970 - val_reconstruction_loss: 1896.3022 - val_kl_loss: 99.4995 - val_false_loss: 12.2846 - val_true_loss: 1.1674\n",
      "Epoch 1960/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7653 - reconstruction_loss: 1890.0001 - kl_loss: 98.9775 - false_loss: 0.0876 - true_loss: 1.1084 - val_loss: 5797.5425 - val_reconstruction_loss: 1896.3019 - val_kl_loss: 99.5001 - val_false_loss: 12.2834 - val_true_loss: 1.1673\n",
      "Epoch 1961/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5770 - reconstruction_loss: 1889.9008 - kl_loss: 100.1313 - false_loss: 0.0876 - true_loss: 1.1083 - val_loss: 5797.1748 - val_reconstruction_loss: 1896.3013 - val_kl_loss: 99.5005 - val_false_loss: 12.2822 - val_true_loss: 1.1673\n",
      "Epoch 1962/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.5112 - reconstruction_loss: 1889.8844 - kl_loss: 99.5854 - false_loss: 0.0876 - true_loss: 1.1083 - val_loss: 5796.8105 - val_reconstruction_loss: 1896.3010 - val_kl_loss: 99.5017 - val_false_loss: 12.2810 - val_true_loss: 1.1673\n",
      "Epoch 1963/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.8598 - reconstruction_loss: 1890.1224 - kl_loss: 98.8850 - false_loss: 0.0876 - true_loss: 1.1083 - val_loss: 5796.4507 - val_reconstruction_loss: 1896.3004 - val_kl_loss: 99.5020 - val_false_loss: 12.2798 - val_true_loss: 1.1672\n",
      "Epoch 1964/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.7228 - reconstruction_loss: 1889.8854 - kl_loss: 100.4312 - false_loss: 0.0876 - true_loss: 1.1082 - val_loss: 5796.0884 - val_reconstruction_loss: 1896.2998 - val_kl_loss: 99.5027 - val_false_loss: 12.2786 - val_true_loss: 1.1672\n",
      "Epoch 1965/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.9799 - reconstruction_loss: 1889.8330 - kl_loss: 99.1622 - false_loss: 0.0876 - true_loss: 1.1082 - val_loss: 5795.7271 - val_reconstruction_loss: 1896.2996 - val_kl_loss: 99.5034 - val_false_loss: 12.2774 - val_true_loss: 1.1671\n",
      "Epoch 1966/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.1289 - reconstruction_loss: 1890.1566 - kl_loss: 98.4550 - false_loss: 0.0876 - true_loss: 1.1081 - val_loss: 5795.3579 - val_reconstruction_loss: 1896.2991 - val_kl_loss: 99.5031 - val_false_loss: 12.2762 - val_true_loss: 1.1671\n",
      "Epoch 1967/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.8677 - reconstruction_loss: 1890.5020 - kl_loss: 99.4312 - false_loss: 0.0876 - true_loss: 1.1081 - val_loss: 5794.9951 - val_reconstruction_loss: 1896.2987 - val_kl_loss: 99.5030 - val_false_loss: 12.2750 - val_true_loss: 1.1671\n",
      "Epoch 1968/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.4958 - reconstruction_loss: 1890.6605 - kl_loss: 97.7913 - false_loss: 0.0875 - true_loss: 1.1080 - val_loss: 5794.6313 - val_reconstruction_loss: 1896.2982 - val_kl_loss: 99.5038 - val_false_loss: 12.2738 - val_true_loss: 1.1670\n",
      "Epoch 1969/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8951 - reconstruction_loss: 1890.2770 - kl_loss: 99.8530 - false_loss: 0.0875 - true_loss: 1.1080 - val_loss: 5794.2681 - val_reconstruction_loss: 1896.2977 - val_kl_loss: 99.5042 - val_false_loss: 12.2726 - val_true_loss: 1.1670\n",
      "Epoch 1970/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.4170 - reconstruction_loss: 1890.6254 - kl_loss: 100.0781 - false_loss: 0.0875 - true_loss: 1.1079 - val_loss: 5793.8994 - val_reconstruction_loss: 1896.2972 - val_kl_loss: 99.5046 - val_false_loss: 12.2714 - val_true_loss: 1.1669\n",
      "Epoch 1971/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.7306 - reconstruction_loss: 1889.9020 - kl_loss: 100.9771 - false_loss: 0.0875 - true_loss: 1.1079 - val_loss: 5793.5317 - val_reconstruction_loss: 1896.2968 - val_kl_loss: 99.5051 - val_false_loss: 12.2702 - val_true_loss: 1.1669\n",
      "Epoch 1972/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.2532 - reconstruction_loss: 1890.2697 - kl_loss: 101.7073 - false_loss: 0.0875 - true_loss: 1.1078 - val_loss: 5793.1606 - val_reconstruction_loss: 1896.2963 - val_kl_loss: 99.5055 - val_false_loss: 12.2690 - val_true_loss: 1.1668\n",
      "Epoch 1973/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.3115 - reconstruction_loss: 1889.5477 - kl_loss: 100.5462 - false_loss: 0.0875 - true_loss: 1.1078 - val_loss: 5792.7979 - val_reconstruction_loss: 1896.2957 - val_kl_loss: 99.5065 - val_false_loss: 12.2678 - val_true_loss: 1.1668\n",
      "Epoch 1974/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.1729 - reconstruction_loss: 1889.6290 - kl_loss: 100.8827 - false_loss: 0.0875 - true_loss: 1.1077 - val_loss: 5792.4297 - val_reconstruction_loss: 1896.2952 - val_kl_loss: 99.5071 - val_false_loss: 12.2665 - val_true_loss: 1.1668\n",
      "Epoch 1975/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.8920 - reconstruction_loss: 1890.3505 - kl_loss: 100.9061 - false_loss: 0.0875 - true_loss: 1.1077 - val_loss: 5792.0620 - val_reconstruction_loss: 1896.2947 - val_kl_loss: 99.5079 - val_false_loss: 12.2653 - val_true_loss: 1.1667\n",
      "Epoch 1976/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.4570 - reconstruction_loss: 1890.3600 - kl_loss: 101.7032 - false_loss: 0.0875 - true_loss: 1.1076 - val_loss: 5791.7002 - val_reconstruction_loss: 1896.2943 - val_kl_loss: 99.5081 - val_false_loss: 12.2641 - val_true_loss: 1.1667\n",
      "Epoch 1977/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2215.5217 - reconstruction_loss: 1890.1815 - kl_loss: 101.5249 - false_loss: 0.0875 - true_loss: 1.1076 - val_loss: 5791.3345 - val_reconstruction_loss: 1896.2937 - val_kl_loss: 99.5085 - val_false_loss: 12.2629 - val_true_loss: 1.1666\n",
      "Epoch 1978/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.9723 - reconstruction_loss: 1889.9896 - kl_loss: 101.6935 - false_loss: 0.0875 - true_loss: 1.1075 - val_loss: 5790.9722 - val_reconstruction_loss: 1896.2933 - val_kl_loss: 99.5095 - val_false_loss: 12.2617 - val_true_loss: 1.1666\n",
      "Epoch 1979/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.0987 - reconstruction_loss: 1890.1888 - kl_loss: 101.1023 - false_loss: 0.0875 - true_loss: 1.1075 - val_loss: 5790.6118 - val_reconstruction_loss: 1896.2928 - val_kl_loss: 99.5105 - val_false_loss: 12.2605 - val_true_loss: 1.1665\n",
      "Epoch 1980/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.9061 - reconstruction_loss: 1890.3278 - kl_loss: 99.7325 - false_loss: 0.0875 - true_loss: 1.1075 - val_loss: 5790.2549 - val_reconstruction_loss: 1896.2924 - val_kl_loss: 99.5112 - val_false_loss: 12.2594 - val_true_loss: 1.1665\n",
      "Epoch 1981/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4142 - reconstruction_loss: 1889.8364 - kl_loss: 99.4311 - false_loss: 0.0874 - true_loss: 1.1074 - val_loss: 5789.8979 - val_reconstruction_loss: 1896.2919 - val_kl_loss: 99.5114 - val_false_loss: 12.2582 - val_true_loss: 1.1665\n",
      "Epoch 1982/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.1233 - reconstruction_loss: 1889.6459 - kl_loss: 100.5489 - false_loss: 0.0874 - true_loss: 1.1074 - val_loss: 5789.5391 - val_reconstruction_loss: 1896.2914 - val_kl_loss: 99.5113 - val_false_loss: 12.2570 - val_true_loss: 1.1664\n",
      "Epoch 1983/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4203 - reconstruction_loss: 1889.7499 - kl_loss: 100.1136 - false_loss: 0.0874 - true_loss: 1.1073 - val_loss: 5789.1860 - val_reconstruction_loss: 1896.2909 - val_kl_loss: 99.5114 - val_false_loss: 12.2559 - val_true_loss: 1.1664\n",
      "Epoch 1984/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0464 - reconstruction_loss: 1890.1171 - kl_loss: 99.4223 - false_loss: 0.0874 - true_loss: 1.1073 - val_loss: 5788.8276 - val_reconstruction_loss: 1896.2906 - val_kl_loss: 99.5122 - val_false_loss: 12.2547 - val_true_loss: 1.1663\n",
      "Epoch 1985/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5050 - reconstruction_loss: 1890.0573 - kl_loss: 99.5339 - false_loss: 0.0874 - true_loss: 1.1072 - val_loss: 5788.4673 - val_reconstruction_loss: 1896.2900 - val_kl_loss: 99.5133 - val_false_loss: 12.2535 - val_true_loss: 1.1663\n",
      "Epoch 1986/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7609 - reconstruction_loss: 1890.0156 - kl_loss: 99.0483 - false_loss: 0.0874 - true_loss: 1.1072 - val_loss: 5788.1099 - val_reconstruction_loss: 1896.2894 - val_kl_loss: 99.5138 - val_false_loss: 12.2523 - val_true_loss: 1.1663\n",
      "Epoch 1987/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0596 - reconstruction_loss: 1889.9556 - kl_loss: 99.0635 - false_loss: 0.0874 - true_loss: 1.1071 - val_loss: 5787.7524 - val_reconstruction_loss: 1896.2892 - val_kl_loss: 99.5143 - val_false_loss: 12.2511 - val_true_loss: 1.1662\n",
      "Epoch 1988/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9604 - reconstruction_loss: 1890.1641 - kl_loss: 99.2561 - false_loss: 0.0874 - true_loss: 1.1071 - val_loss: 5787.3945 - val_reconstruction_loss: 1896.2886 - val_kl_loss: 99.5153 - val_false_loss: 12.2499 - val_true_loss: 1.1662\n",
      "Epoch 1989/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.2096 - reconstruction_loss: 1890.0189 - kl_loss: 98.2393 - false_loss: 0.0874 - true_loss: 1.1071 - val_loss: 5787.0420 - val_reconstruction_loss: 1896.2880 - val_kl_loss: 99.5158 - val_false_loss: 12.2488 - val_true_loss: 1.1661\n",
      "Epoch 1990/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.0328 - reconstruction_loss: 1889.8856 - kl_loss: 101.0590 - false_loss: 0.0874 - true_loss: 1.1070 - val_loss: 5786.6904 - val_reconstruction_loss: 1896.2877 - val_kl_loss: 99.5158 - val_false_loss: 12.2476 - val_true_loss: 1.1661\n",
      "Epoch 1991/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.2134 - reconstruction_loss: 1889.8158 - kl_loss: 99.3675 - false_loss: 0.0874 - true_loss: 1.1070 - val_loss: 5786.3369 - val_reconstruction_loss: 1896.2874 - val_kl_loss: 99.5160 - val_false_loss: 12.2465 - val_true_loss: 1.1660\n",
      "Epoch 1992/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.7298 - reconstruction_loss: 1889.9230 - kl_loss: 100.4491 - false_loss: 0.0874 - true_loss: 1.1069 - val_loss: 5785.9858 - val_reconstruction_loss: 1896.2870 - val_kl_loss: 99.5162 - val_false_loss: 12.2453 - val_true_loss: 1.1660\n",
      "Epoch 1993/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3298 - reconstruction_loss: 1889.8483 - kl_loss: 99.3461 - false_loss: 0.0874 - true_loss: 1.1069 - val_loss: 5785.6240 - val_reconstruction_loss: 1896.2864 - val_kl_loss: 99.5164 - val_false_loss: 12.2441 - val_true_loss: 1.1660\n",
      "Epoch 1994/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.6941 - reconstruction_loss: 1890.0219 - kl_loss: 100.1610 - false_loss: 0.0874 - true_loss: 1.1068 - val_loss: 5785.2642 - val_reconstruction_loss: 1896.2859 - val_kl_loss: 99.5165 - val_false_loss: 12.2429 - val_true_loss: 1.1659\n",
      "Epoch 1995/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.8961 - reconstruction_loss: 1889.7085 - kl_loss: 99.6215 - false_loss: 0.0873 - true_loss: 1.1068 - val_loss: 5784.9014 - val_reconstruction_loss: 1896.2853 - val_kl_loss: 99.5168 - val_false_loss: 12.2417 - val_true_loss: 1.1659\n",
      "Epoch 1996/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.9426 - reconstruction_loss: 1889.5117 - kl_loss: 99.3421 - false_loss: 0.0873 - true_loss: 1.1067 - val_loss: 5784.5449 - val_reconstruction_loss: 1896.2849 - val_kl_loss: 99.5175 - val_false_loss: 12.2406 - val_true_loss: 1.1658\n",
      "Epoch 1997/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6385 - reconstruction_loss: 1890.9271 - kl_loss: 99.7978 - false_loss: 0.0873 - true_loss: 1.1067 - val_loss: 5784.1948 - val_reconstruction_loss: 1896.2844 - val_kl_loss: 99.5177 - val_false_loss: 12.2394 - val_true_loss: 1.1658\n",
      "Epoch 1998/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8170 - reconstruction_loss: 1890.1478 - kl_loss: 98.9294 - false_loss: 0.0873 - true_loss: 1.1067 - val_loss: 5783.8350 - val_reconstruction_loss: 1896.2839 - val_kl_loss: 99.5185 - val_false_loss: 12.2382 - val_true_loss: 1.1657\n",
      "Epoch 1999/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.7862 - reconstruction_loss: 1889.9127 - kl_loss: 98.3966 - false_loss: 0.0873 - true_loss: 1.1066 - val_loss: 5783.4810 - val_reconstruction_loss: 1896.2836 - val_kl_loss: 99.5192 - val_false_loss: 12.2371 - val_true_loss: 1.1657\n",
      "Epoch 2000/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9161 - reconstruction_loss: 1890.0267 - kl_loss: 99.0113 - false_loss: 0.0873 - true_loss: 1.1066 - val_loss: 5783.1191 - val_reconstruction_loss: 1896.2830 - val_kl_loss: 99.5191 - val_false_loss: 12.2359 - val_true_loss: 1.1657\n",
      "Epoch 2001/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.1491 - reconstruction_loss: 1889.9613 - kl_loss: 99.3201 - false_loss: 0.0873 - true_loss: 1.1065 - val_loss: 5782.7666 - val_reconstruction_loss: 1896.2825 - val_kl_loss: 99.5196 - val_false_loss: 12.2347 - val_true_loss: 1.1656\n",
      "Epoch 2002/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4132 - reconstruction_loss: 1890.0830 - kl_loss: 99.7458 - false_loss: 0.0873 - true_loss: 1.1065 - val_loss: 5782.4146 - val_reconstruction_loss: 1896.2821 - val_kl_loss: 99.5199 - val_false_loss: 12.2336 - val_true_loss: 1.1656\n",
      "Epoch 2003/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.5965 - reconstruction_loss: 1890.5049 - kl_loss: 100.5778 - false_loss: 0.0873 - true_loss: 1.1064 - val_loss: 5782.0581 - val_reconstruction_loss: 1896.2815 - val_kl_loss: 99.5197 - val_false_loss: 12.2324 - val_true_loss: 1.1655\n",
      "Epoch 2004/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.4327 - reconstruction_loss: 1889.7404 - kl_loss: 99.7916 - false_loss: 0.0873 - true_loss: 1.1064 - val_loss: 5781.6943 - val_reconstruction_loss: 1896.2810 - val_kl_loss: 99.5195 - val_false_loss: 12.2312 - val_true_loss: 1.1655\n",
      "Epoch 2005/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.2905 - reconstruction_loss: 1890.1729 - kl_loss: 100.0335 - false_loss: 0.0873 - true_loss: 1.1063 - val_loss: 5781.3389 - val_reconstruction_loss: 1896.2806 - val_kl_loss: 99.5198 - val_false_loss: 12.2300 - val_true_loss: 1.1654\n",
      "Epoch 2006/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.6858 - reconstruction_loss: 1890.1426 - kl_loss: 100.4079 - false_loss: 0.0873 - true_loss: 1.1063 - val_loss: 5780.9883 - val_reconstruction_loss: 1896.2802 - val_kl_loss: 99.5193 - val_false_loss: 12.2289 - val_true_loss: 1.1654\n",
      "Epoch 2007/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5261 - reconstruction_loss: 1889.6979 - kl_loss: 100.0777 - false_loss: 0.0873 - true_loss: 1.1063 - val_loss: 5780.6265 - val_reconstruction_loss: 1896.2798 - val_kl_loss: 99.5192 - val_false_loss: 12.2277 - val_true_loss: 1.1654\n",
      "Epoch 2008/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.0804 - reconstruction_loss: 1889.8365 - kl_loss: 100.1929 - false_loss: 0.0872 - true_loss: 1.1062 - val_loss: 5780.2622 - val_reconstruction_loss: 1896.2794 - val_kl_loss: 99.5189 - val_false_loss: 12.2265 - val_true_loss: 1.1653\n",
      "Epoch 2009/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3157 - reconstruction_loss: 1889.7676 - kl_loss: 100.1843 - false_loss: 0.0872 - true_loss: 1.1062 - val_loss: 5779.9019 - val_reconstruction_loss: 1896.2788 - val_kl_loss: 99.5183 - val_false_loss: 12.2253 - val_true_loss: 1.1653\n",
      "Epoch 2010/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2258 - reconstruction_loss: 1889.9427 - kl_loss: 98.6784 - false_loss: 0.0872 - true_loss: 1.1061 - val_loss: 5779.5430 - val_reconstruction_loss: 1896.2786 - val_kl_loss: 99.5189 - val_false_loss: 12.2241 - val_true_loss: 1.1652\n",
      "Epoch 2011/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.0244 - reconstruction_loss: 1890.0282 - kl_loss: 100.0354 - false_loss: 0.0872 - true_loss: 1.1061 - val_loss: 5779.1855 - val_reconstruction_loss: 1896.2781 - val_kl_loss: 99.5196 - val_false_loss: 12.2229 - val_true_loss: 1.1652\n",
      "Epoch 2012/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.3379 - reconstruction_loss: 1890.4528 - kl_loss: 101.4031 - false_loss: 0.0872 - true_loss: 1.1060 - val_loss: 5778.8311 - val_reconstruction_loss: 1896.2775 - val_kl_loss: 99.5197 - val_false_loss: 12.2218 - val_true_loss: 1.1651\n",
      "Epoch 2013/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.5449 - reconstruction_loss: 1890.1852 - kl_loss: 101.3336 - false_loss: 0.0872 - true_loss: 1.1060 - val_loss: 5778.4717 - val_reconstruction_loss: 1896.2771 - val_kl_loss: 99.5205 - val_false_loss: 12.2206 - val_true_loss: 1.1651\n",
      "Epoch 2014/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8577 - reconstruction_loss: 1889.8521 - kl_loss: 101.1442 - false_loss: 0.0872 - true_loss: 1.1059 - val_loss: 5778.1162 - val_reconstruction_loss: 1896.2766 - val_kl_loss: 99.5215 - val_false_loss: 12.2194 - val_true_loss: 1.1651\n",
      "Epoch 2015/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.8556 - reconstruction_loss: 1889.8802 - kl_loss: 100.9913 - false_loss: 0.0872 - true_loss: 1.1059 - val_loss: 5777.7622 - val_reconstruction_loss: 1896.2761 - val_kl_loss: 99.5215 - val_false_loss: 12.2182 - val_true_loss: 1.1650\n",
      "Epoch 2016/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1024 - reconstruction_loss: 1890.0924 - kl_loss: 100.0196 - false_loss: 0.0872 - true_loss: 1.1058 - val_loss: 5777.4043 - val_reconstruction_loss: 1896.2756 - val_kl_loss: 99.5212 - val_false_loss: 12.2171 - val_true_loss: 1.1650\n",
      "Epoch 2017/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.3056 - reconstruction_loss: 1890.4867 - kl_loss: 100.3438 - false_loss: 0.0872 - true_loss: 1.1058 - val_loss: 5777.0522 - val_reconstruction_loss: 1896.2751 - val_kl_loss: 99.5220 - val_false_loss: 12.2159 - val_true_loss: 1.1649\n",
      "Epoch 2018/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.8596 - reconstruction_loss: 1890.3424 - kl_loss: 99.0644 - false_loss: 0.0872 - true_loss: 1.1057 - val_loss: 5776.7085 - val_reconstruction_loss: 1896.2747 - val_kl_loss: 99.5233 - val_false_loss: 12.2148 - val_true_loss: 1.1649\n",
      "Epoch 2019/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0115 - reconstruction_loss: 1890.4496 - kl_loss: 100.5596 - false_loss: 0.0872 - true_loss: 1.1057 - val_loss: 5776.3521 - val_reconstruction_loss: 1896.2742 - val_kl_loss: 99.5237 - val_false_loss: 12.2136 - val_true_loss: 1.1648\n",
      "Epoch 2020/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.7877 - reconstruction_loss: 1890.1498 - kl_loss: 100.5758 - false_loss: 0.0872 - true_loss: 1.1056 - val_loss: 5775.9902 - val_reconstruction_loss: 1896.2737 - val_kl_loss: 99.5234 - val_false_loss: 12.2124 - val_true_loss: 1.1648\n",
      "Epoch 2021/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.6610 - reconstruction_loss: 1890.3969 - kl_loss: 100.8471 - false_loss: 0.0872 - true_loss: 1.1056 - val_loss: 5775.6318 - val_reconstruction_loss: 1896.2734 - val_kl_loss: 99.5233 - val_false_loss: 12.2112 - val_true_loss: 1.1647\n",
      "Epoch 2022/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.5793 - reconstruction_loss: 1890.3959 - kl_loss: 101.8708 - false_loss: 0.0871 - true_loss: 1.1055 - val_loss: 5775.2798 - val_reconstruction_loss: 1896.2728 - val_kl_loss: 99.5237 - val_false_loss: 12.2101 - val_true_loss: 1.1647\n",
      "Epoch 2023/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.0291 - reconstruction_loss: 1889.7587 - kl_loss: 101.8328 - false_loss: 0.0871 - true_loss: 1.1055 - val_loss: 5774.9272 - val_reconstruction_loss: 1896.2722 - val_kl_loss: 99.5246 - val_false_loss: 12.2089 - val_true_loss: 1.1647\n",
      "Epoch 2024/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.0236 - reconstruction_loss: 1890.2108 - kl_loss: 101.5224 - false_loss: 0.0871 - true_loss: 1.1055 - val_loss: 5774.5698 - val_reconstruction_loss: 1896.2720 - val_kl_loss: 99.5251 - val_false_loss: 12.2077 - val_true_loss: 1.1646\n",
      "Epoch 2025/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.2000 - reconstruction_loss: 1889.8253 - kl_loss: 100.3975 - false_loss: 0.0871 - true_loss: 1.1054 - val_loss: 5774.2222 - val_reconstruction_loss: 1896.2714 - val_kl_loss: 99.5249 - val_false_loss: 12.2066 - val_true_loss: 1.1646\n",
      "Epoch 2026/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.4942 - reconstruction_loss: 1889.8656 - kl_loss: 99.2954 - false_loss: 0.0871 - true_loss: 1.1054 - val_loss: 5773.8750 - val_reconstruction_loss: 1896.2710 - val_kl_loss: 99.5255 - val_false_loss: 12.2054 - val_true_loss: 1.1646\n",
      "Epoch 2027/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.1071 - reconstruction_loss: 1889.8314 - kl_loss: 98.7193 - false_loss: 0.0871 - true_loss: 1.1053 - val_loss: 5773.5215 - val_reconstruction_loss: 1896.2705 - val_kl_loss: 99.5254 - val_false_loss: 12.2043 - val_true_loss: 1.1645\n",
      "Epoch 2028/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.8765 - reconstruction_loss: 1890.1943 - kl_loss: 99.0726 - false_loss: 0.0871 - true_loss: 1.1053 - val_loss: 5773.1685 - val_reconstruction_loss: 1896.2699 - val_kl_loss: 99.5250 - val_false_loss: 12.2031 - val_true_loss: 1.1645\n",
      "Epoch 2029/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1833 - reconstruction_loss: 1890.1011 - kl_loss: 97.9832 - false_loss: 0.0871 - true_loss: 1.1053 - val_loss: 5772.8184 - val_reconstruction_loss: 1896.2695 - val_kl_loss: 99.5259 - val_false_loss: 12.2020 - val_true_loss: 1.1645\n",
      "Epoch 2030/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.4759 - reconstruction_loss: 1890.1982 - kl_loss: 98.2029 - false_loss: 0.0871 - true_loss: 1.1052 - val_loss: 5772.4590 - val_reconstruction_loss: 1896.2692 - val_kl_loss: 99.5246 - val_false_loss: 12.2008 - val_true_loss: 1.1644\n",
      "Epoch 2031/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.1129 - reconstruction_loss: 1889.9961 - kl_loss: 99.0487 - false_loss: 0.0871 - true_loss: 1.1052 - val_loss: 5772.0986 - val_reconstruction_loss: 1896.2689 - val_kl_loss: 99.5247 - val_false_loss: 12.1996 - val_true_loss: 1.1644\n",
      "Epoch 2032/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.4981 - reconstruction_loss: 1890.3793 - kl_loss: 99.9207 - false_loss: 0.0871 - true_loss: 1.1051 - val_loss: 5771.7358 - val_reconstruction_loss: 1896.2683 - val_kl_loss: 99.5248 - val_false_loss: 12.1984 - val_true_loss: 1.1643\n",
      "Epoch 2033/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.1373 - reconstruction_loss: 1890.1232 - kl_loss: 99.9608 - false_loss: 0.0871 - true_loss: 1.1051 - val_loss: 5771.3823 - val_reconstruction_loss: 1896.2678 - val_kl_loss: 99.5249 - val_false_loss: 12.1972 - val_true_loss: 1.1643\n",
      "Epoch 2034/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.2118 - reconstruction_loss: 1889.9323 - kl_loss: 100.6749 - false_loss: 0.0871 - true_loss: 1.1050 - val_loss: 5771.0273 - val_reconstruction_loss: 1896.2675 - val_kl_loss: 99.5258 - val_false_loss: 12.1961 - val_true_loss: 1.1642\n",
      "Epoch 2035/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.9320 - reconstruction_loss: 1889.4501 - kl_loss: 100.9605 - false_loss: 0.0871 - true_loss: 1.1050 - val_loss: 5770.6680 - val_reconstruction_loss: 1896.2668 - val_kl_loss: 99.5270 - val_false_loss: 12.1949 - val_true_loss: 1.1642\n",
      "Epoch 2036/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.2333 - reconstruction_loss: 1890.5498 - kl_loss: 101.4393 - false_loss: 0.0870 - true_loss: 1.1049 - val_loss: 5770.3159 - val_reconstruction_loss: 1896.2664 - val_kl_loss: 99.5276 - val_false_loss: 12.1937 - val_true_loss: 1.1641\n",
      "Epoch 2037/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.9536 - reconstruction_loss: 1889.8160 - kl_loss: 101.3683 - false_loss: 0.0870 - true_loss: 1.1049 - val_loss: 5769.9565 - val_reconstruction_loss: 1896.2660 - val_kl_loss: 99.5280 - val_false_loss: 12.1925 - val_true_loss: 1.1641\n",
      "Epoch 2038/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.9167 - reconstruction_loss: 1889.7103 - kl_loss: 101.9295 - false_loss: 0.0870 - true_loss: 1.1048 - val_loss: 5769.5962 - val_reconstruction_loss: 1896.2655 - val_kl_loss: 99.5286 - val_false_loss: 12.1914 - val_true_loss: 1.1641\n",
      "Epoch 2039/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8670 - reconstruction_loss: 1890.1157 - kl_loss: 101.4393 - false_loss: 0.0870 - true_loss: 1.1048 - val_loss: 5769.2358 - val_reconstruction_loss: 1896.2651 - val_kl_loss: 99.5290 - val_false_loss: 12.1902 - val_true_loss: 1.1640\n",
      "Epoch 2040/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6251 - reconstruction_loss: 1890.1670 - kl_loss: 102.3150 - false_loss: 0.0870 - true_loss: 1.1047 - val_loss: 5768.8774 - val_reconstruction_loss: 1896.2646 - val_kl_loss: 99.5300 - val_false_loss: 12.1890 - val_true_loss: 1.1640\n",
      "Epoch 2041/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6156 - reconstruction_loss: 1889.9449 - kl_loss: 101.1249 - false_loss: 0.0870 - true_loss: 1.1047 - val_loss: 5768.5166 - val_reconstruction_loss: 1896.2642 - val_kl_loss: 99.5304 - val_false_loss: 12.1878 - val_true_loss: 1.1639\n",
      "Epoch 2042/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4902 - reconstruction_loss: 1889.9039 - kl_loss: 102.2370 - false_loss: 0.0870 - true_loss: 1.1046 - val_loss: 5768.1650 - val_reconstruction_loss: 1896.2637 - val_kl_loss: 99.5300 - val_false_loss: 12.1866 - val_true_loss: 1.1639\n",
      "Epoch 2043/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2690 - reconstruction_loss: 1889.5963 - kl_loss: 100.8493 - false_loss: 0.0870 - true_loss: 1.1046 - val_loss: 5767.8096 - val_reconstruction_loss: 1896.2633 - val_kl_loss: 99.5304 - val_false_loss: 12.1855 - val_true_loss: 1.1639\n",
      "Epoch 2044/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.4050 - reconstruction_loss: 1889.7837 - kl_loss: 99.1034 - false_loss: 0.0870 - true_loss: 1.1045 - val_loss: 5767.4653 - val_reconstruction_loss: 1896.2628 - val_kl_loss: 99.5308 - val_false_loss: 12.1843 - val_true_loss: 1.1638\n",
      "Epoch 2045/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1744 - reconstruction_loss: 1890.2148 - kl_loss: 100.0165 - false_loss: 0.0870 - true_loss: 1.1045 - val_loss: 5767.1133 - val_reconstruction_loss: 1896.2622 - val_kl_loss: 99.5313 - val_false_loss: 12.1832 - val_true_loss: 1.1638\n",
      "Epoch 2046/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.3955 - reconstruction_loss: 1890.1426 - kl_loss: 98.3258 - false_loss: 0.0870 - true_loss: 1.1045 - val_loss: 5766.7607 - val_reconstruction_loss: 1896.2618 - val_kl_loss: 99.5311 - val_false_loss: 12.1820 - val_true_loss: 1.1637\n",
      "Epoch 2047/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.1322 - reconstruction_loss: 1890.8851 - kl_loss: 98.8980 - false_loss: 0.0870 - true_loss: 1.1044 - val_loss: 5766.4023 - val_reconstruction_loss: 1896.2616 - val_kl_loss: 99.5306 - val_false_loss: 12.1808 - val_true_loss: 1.1637\n",
      "Epoch 2048/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.1875 - reconstruction_loss: 1890.7448 - kl_loss: 97.3541 - false_loss: 0.0870 - true_loss: 1.1044 - val_loss: 5766.0498 - val_reconstruction_loss: 1896.2611 - val_kl_loss: 99.5312 - val_false_loss: 12.1797 - val_true_loss: 1.1637\n",
      "Epoch 2049/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.8917 - reconstruction_loss: 1890.1390 - kl_loss: 98.0134 - false_loss: 0.0869 - true_loss: 1.1044 - val_loss: 5765.6982 - val_reconstruction_loss: 1896.2607 - val_kl_loss: 99.5313 - val_false_loss: 12.1785 - val_true_loss: 1.1637\n",
      "Epoch 2050/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2267.2047 - reconstruction_loss: 1890.9196 - kl_loss: 91.9252 - false_loss: 0.0869 - true_loss: 1.1043 - val_loss: 5765.3672 - val_reconstruction_loss: 1896.2603 - val_kl_loss: 99.5321 - val_false_loss: 12.1774 - val_true_loss: 1.1636\n",
      "Epoch 2051/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.4992 - reconstruction_loss: 1890.5986 - kl_loss: 96.9990 - false_loss: 0.0869 - true_loss: 1.1043 - val_loss: 5765.0132 - val_reconstruction_loss: 1896.2596 - val_kl_loss: 99.5326 - val_false_loss: 12.1762 - val_true_loss: 1.1636\n",
      "Epoch 2052/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.3379 - reconstruction_loss: 1889.8633 - kl_loss: 99.0839 - false_loss: 0.0869 - true_loss: 1.1043 - val_loss: 5764.6543 - val_reconstruction_loss: 1896.2593 - val_kl_loss: 99.5328 - val_false_loss: 12.1751 - val_true_loss: 1.1636\n",
      "Epoch 2053/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0289 - reconstruction_loss: 1889.5983 - kl_loss: 99.3614 - false_loss: 0.0869 - true_loss: 1.1042 - val_loss: 5764.2959 - val_reconstruction_loss: 1896.2588 - val_kl_loss: 99.5333 - val_false_loss: 12.1739 - val_true_loss: 1.1635\n",
      "Epoch 2054/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.6541 - reconstruction_loss: 1889.7554 - kl_loss: 98.3506 - false_loss: 0.0869 - true_loss: 1.1042 - val_loss: 5763.9443 - val_reconstruction_loss: 1896.2583 - val_kl_loss: 99.5324 - val_false_loss: 12.1727 - val_true_loss: 1.1635\n",
      "Epoch 2055/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2260.5654 - reconstruction_loss: 1890.6595 - kl_loss: 98.6734 - false_loss: 0.0869 - true_loss: 1.1041 - val_loss: 5763.5923 - val_reconstruction_loss: 1896.2579 - val_kl_loss: 99.5317 - val_false_loss: 12.1715 - val_true_loss: 1.1635\n",
      "Epoch 2056/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2354 - reconstruction_loss: 1890.4800 - kl_loss: 96.9278 - false_loss: 0.0869 - true_loss: 1.1041 - val_loss: 5763.2354 - val_reconstruction_loss: 1896.2573 - val_kl_loss: 99.5314 - val_false_loss: 12.1704 - val_true_loss: 1.1634\n",
      "Epoch 2057/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.7906 - reconstruction_loss: 1890.2129 - kl_loss: 99.1295 - false_loss: 0.0869 - true_loss: 1.1040 - val_loss: 5762.8813 - val_reconstruction_loss: 1896.2570 - val_kl_loss: 99.5318 - val_false_loss: 12.1692 - val_true_loss: 1.1634\n",
      "Epoch 2058/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.5493 - reconstruction_loss: 1889.8063 - kl_loss: 100.6699 - false_loss: 0.0869 - true_loss: 1.1040 - val_loss: 5762.5303 - val_reconstruction_loss: 1896.2565 - val_kl_loss: 99.5322 - val_false_loss: 12.1681 - val_true_loss: 1.1633\n",
      "Epoch 2059/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.6639 - reconstruction_loss: 1889.6119 - kl_loss: 101.4563 - false_loss: 0.0869 - true_loss: 1.1039 - val_loss: 5762.1807 - val_reconstruction_loss: 1896.2561 - val_kl_loss: 99.5320 - val_false_loss: 12.1669 - val_true_loss: 1.1633\n",
      "Epoch 2060/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.1103 - reconstruction_loss: 1890.5514 - kl_loss: 100.8221 - false_loss: 0.0869 - true_loss: 1.1039 - val_loss: 5761.8267 - val_reconstruction_loss: 1896.2557 - val_kl_loss: 99.5320 - val_false_loss: 12.1657 - val_true_loss: 1.1633\n",
      "Epoch 2061/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.4084 - reconstruction_loss: 1890.3683 - kl_loss: 100.8254 - false_loss: 0.0869 - true_loss: 1.1038 - val_loss: 5761.4683 - val_reconstruction_loss: 1896.2552 - val_kl_loss: 99.5327 - val_false_loss: 12.1646 - val_true_loss: 1.1632\n",
      "Epoch 2062/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.3687 - reconstruction_loss: 1889.6787 - kl_loss: 101.0412 - false_loss: 0.0869 - true_loss: 1.1038 - val_loss: 5761.1226 - val_reconstruction_loss: 1896.2549 - val_kl_loss: 99.5339 - val_false_loss: 12.1634 - val_true_loss: 1.1632\n",
      "Epoch 2063/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3649 - reconstruction_loss: 1890.3229 - kl_loss: 101.0246 - false_loss: 0.0868 - true_loss: 1.1037 - val_loss: 5760.7690 - val_reconstruction_loss: 1896.2543 - val_kl_loss: 99.5342 - val_false_loss: 12.1623 - val_true_loss: 1.1631\n",
      "Epoch 2064/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.7050 - reconstruction_loss: 1890.0303 - kl_loss: 100.9903 - false_loss: 0.0868 - true_loss: 1.1037 - val_loss: 5760.4126 - val_reconstruction_loss: 1896.2538 - val_kl_loss: 99.5346 - val_false_loss: 12.1611 - val_true_loss: 1.1631\n",
      "Epoch 2065/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.4513 - reconstruction_loss: 1890.1371 - kl_loss: 102.1377 - false_loss: 0.0868 - true_loss: 1.1036 - val_loss: 5760.0591 - val_reconstruction_loss: 1896.2532 - val_kl_loss: 99.5349 - val_false_loss: 12.1599 - val_true_loss: 1.1630\n",
      "Epoch 2066/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.4712 - reconstruction_loss: 1889.6982 - kl_loss: 102.1034 - false_loss: 0.0868 - true_loss: 1.1036 - val_loss: 5759.7183 - val_reconstruction_loss: 1896.2529 - val_kl_loss: 99.5353 - val_false_loss: 12.1588 - val_true_loss: 1.1630\n",
      "Epoch 2067/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.0646 - reconstruction_loss: 1890.2574 - kl_loss: 102.0715 - false_loss: 0.0868 - true_loss: 1.1035 - val_loss: 5759.3584 - val_reconstruction_loss: 1896.2524 - val_kl_loss: 99.5357 - val_false_loss: 12.1576 - val_true_loss: 1.1629\n",
      "Epoch 2068/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.3960 - reconstruction_loss: 1889.5807 - kl_loss: 102.2291 - false_loss: 0.0868 - true_loss: 1.1035 - val_loss: 5759.0093 - val_reconstruction_loss: 1896.2520 - val_kl_loss: 99.5362 - val_false_loss: 12.1565 - val_true_loss: 1.1629\n",
      "Epoch 2069/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.3709 - reconstruction_loss: 1889.4180 - kl_loss: 102.8253 - false_loss: 0.0868 - true_loss: 1.1034 - val_loss: 5758.6514 - val_reconstruction_loss: 1896.2515 - val_kl_loss: 99.5372 - val_false_loss: 12.1553 - val_true_loss: 1.1628\n",
      "Epoch 2070/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.3451 - reconstruction_loss: 1890.2944 - kl_loss: 102.2648 - false_loss: 0.0868 - true_loss: 1.1034 - val_loss: 5758.2974 - val_reconstruction_loss: 1896.2510 - val_kl_loss: 99.5380 - val_false_loss: 12.1541 - val_true_loss: 1.1628\n",
      "Epoch 2071/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.4269 - reconstruction_loss: 1890.5609 - kl_loss: 102.8877 - false_loss: 0.0868 - true_loss: 1.1033 - val_loss: 5757.9429 - val_reconstruction_loss: 1896.2506 - val_kl_loss: 99.5392 - val_false_loss: 12.1530 - val_true_loss: 1.1627\n",
      "Epoch 2072/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.8345 - reconstruction_loss: 1889.7216 - kl_loss: 102.9317 - false_loss: 0.0868 - true_loss: 1.1033 - val_loss: 5757.5884 - val_reconstruction_loss: 1896.2500 - val_kl_loss: 99.5400 - val_false_loss: 12.1518 - val_true_loss: 1.1627\n",
      "Epoch 2073/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.3180 - reconstruction_loss: 1889.4623 - kl_loss: 102.3959 - false_loss: 0.0868 - true_loss: 1.1032 - val_loss: 5757.2412 - val_reconstruction_loss: 1896.2495 - val_kl_loss: 99.5412 - val_false_loss: 12.1507 - val_true_loss: 1.1626\n",
      "Epoch 2074/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.7187 - reconstruction_loss: 1890.1874 - kl_loss: 101.4379 - false_loss: 0.0868 - true_loss: 1.1032 - val_loss: 5756.8862 - val_reconstruction_loss: 1896.2491 - val_kl_loss: 99.5419 - val_false_loss: 12.1495 - val_true_loss: 1.1626\n",
      "Epoch 2075/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.5225 - reconstruction_loss: 1890.3828 - kl_loss: 102.6439 - false_loss: 0.0868 - true_loss: 1.1031 - val_loss: 5756.5317 - val_reconstruction_loss: 1896.2485 - val_kl_loss: 99.5420 - val_false_loss: 12.1483 - val_true_loss: 1.1626\n",
      "Epoch 2076/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.3880 - reconstruction_loss: 1890.0326 - kl_loss: 101.5277 - false_loss: 0.0867 - true_loss: 1.1031 - val_loss: 5756.1821 - val_reconstruction_loss: 1896.2483 - val_kl_loss: 99.5428 - val_false_loss: 12.1472 - val_true_loss: 1.1625\n",
      "Epoch 2077/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.1872 - reconstruction_loss: 1889.6519 - kl_loss: 101.5275 - false_loss: 0.0867 - true_loss: 1.1030 - val_loss: 5755.8262 - val_reconstruction_loss: 1896.2477 - val_kl_loss: 99.5439 - val_false_loss: 12.1460 - val_true_loss: 1.1625\n",
      "Epoch 2078/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9010 - reconstruction_loss: 1889.9980 - kl_loss: 102.2581 - false_loss: 0.0867 - true_loss: 1.1030 - val_loss: 5755.4849 - val_reconstruction_loss: 1896.2473 - val_kl_loss: 99.5452 - val_false_loss: 12.1449 - val_true_loss: 1.1624\n",
      "Epoch 2079/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.2086 - reconstruction_loss: 1889.9467 - kl_loss: 101.8450 - false_loss: 0.0867 - true_loss: 1.1029 - val_loss: 5755.1392 - val_reconstruction_loss: 1896.2468 - val_kl_loss: 99.5463 - val_false_loss: 12.1437 - val_true_loss: 1.1624\n",
      "Epoch 2080/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.6476 - reconstruction_loss: 1889.9398 - kl_loss: 101.0742 - false_loss: 0.0867 - true_loss: 1.1029 - val_loss: 5754.7812 - val_reconstruction_loss: 1896.2462 - val_kl_loss: 99.5468 - val_false_loss: 12.1425 - val_true_loss: 1.1623\n",
      "Epoch 2081/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2213.6873 - reconstruction_loss: 1890.1812 - kl_loss: 101.8432 - false_loss: 0.0867 - true_loss: 1.1028 - val_loss: 5754.4312 - val_reconstruction_loss: 1896.2458 - val_kl_loss: 99.5476 - val_false_loss: 12.1414 - val_true_loss: 1.1623\n",
      "Epoch 2082/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0271 - reconstruction_loss: 1889.8286 - kl_loss: 103.0178 - false_loss: 0.0867 - true_loss: 1.1028 - val_loss: 5754.0776 - val_reconstruction_loss: 1896.2454 - val_kl_loss: 99.5480 - val_false_loss: 12.1402 - val_true_loss: 1.1622\n",
      "Epoch 2083/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.2761 - reconstruction_loss: 1890.0131 - kl_loss: 101.3632 - false_loss: 0.0867 - true_loss: 1.1027 - val_loss: 5753.7222 - val_reconstruction_loss: 1896.2449 - val_kl_loss: 99.5477 - val_false_loss: 12.1391 - val_true_loss: 1.1622\n",
      "Epoch 2084/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.2752 - reconstruction_loss: 1889.5903 - kl_loss: 102.5629 - false_loss: 0.0867 - true_loss: 1.1027 - val_loss: 5753.3735 - val_reconstruction_loss: 1896.2444 - val_kl_loss: 99.5483 - val_false_loss: 12.1379 - val_true_loss: 1.1621\n",
      "Epoch 2085/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.1521 - reconstruction_loss: 1889.9600 - kl_loss: 102.7996 - false_loss: 0.0867 - true_loss: 1.1026 - val_loss: 5753.0278 - val_reconstruction_loss: 1896.2439 - val_kl_loss: 99.5489 - val_false_loss: 12.1368 - val_true_loss: 1.1621\n",
      "Epoch 2086/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0234 - reconstruction_loss: 1889.8965 - kl_loss: 102.5322 - false_loss: 0.0867 - true_loss: 1.1026 - val_loss: 5752.6807 - val_reconstruction_loss: 1896.2434 - val_kl_loss: 99.5493 - val_false_loss: 12.1356 - val_true_loss: 1.1621\n",
      "Epoch 2087/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.3371 - reconstruction_loss: 1890.1719 - kl_loss: 103.2641 - false_loss: 0.0867 - true_loss: 1.1025 - val_loss: 5752.3296 - val_reconstruction_loss: 1896.2429 - val_kl_loss: 99.5497 - val_false_loss: 12.1345 - val_true_loss: 1.1620\n",
      "Epoch 2088/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.5705 - reconstruction_loss: 1890.1812 - kl_loss: 102.8239 - false_loss: 0.0867 - true_loss: 1.1025 - val_loss: 5751.9829 - val_reconstruction_loss: 1896.2426 - val_kl_loss: 99.5497 - val_false_loss: 12.1333 - val_true_loss: 1.1620\n",
      "Epoch 2089/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9945 - reconstruction_loss: 1889.8781 - kl_loss: 102.2436 - false_loss: 0.0867 - true_loss: 1.1024 - val_loss: 5751.6372 - val_reconstruction_loss: 1896.2419 - val_kl_loss: 99.5495 - val_false_loss: 12.1322 - val_true_loss: 1.1620\n",
      "Epoch 2090/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8628 - reconstruction_loss: 1889.8322 - kl_loss: 100.0753 - false_loss: 0.0866 - true_loss: 1.1024 - val_loss: 5751.2949 - val_reconstruction_loss: 1896.2417 - val_kl_loss: 99.5505 - val_false_loss: 12.1311 - val_true_loss: 1.1619\n",
      "Epoch 2091/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4344 - reconstruction_loss: 1890.3888 - kl_loss: 100.5815 - false_loss: 0.0866 - true_loss: 1.1023 - val_loss: 5750.9438 - val_reconstruction_loss: 1896.2411 - val_kl_loss: 99.5515 - val_false_loss: 12.1299 - val_true_loss: 1.1619\n",
      "Epoch 2092/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.2206 - reconstruction_loss: 1890.3818 - kl_loss: 99.7451 - false_loss: 0.0866 - true_loss: 1.1023 - val_loss: 5750.5938 - val_reconstruction_loss: 1896.2408 - val_kl_loss: 99.5513 - val_false_loss: 12.1288 - val_true_loss: 1.1618\n",
      "Epoch 2093/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.9131 - reconstruction_loss: 1890.5190 - kl_loss: 99.5965 - false_loss: 0.0866 - true_loss: 1.1023 - val_loss: 5750.2549 - val_reconstruction_loss: 1896.2402 - val_kl_loss: 99.5517 - val_false_loss: 12.1276 - val_true_loss: 1.1618\n",
      "Epoch 2094/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.1960 - reconstruction_loss: 1890.4120 - kl_loss: 99.6662 - false_loss: 0.0866 - true_loss: 1.1022 - val_loss: 5749.9048 - val_reconstruction_loss: 1896.2396 - val_kl_loss: 99.5520 - val_false_loss: 12.1265 - val_true_loss: 1.1618\n",
      "Epoch 2095/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7175 - reconstruction_loss: 1889.9980 - kl_loss: 99.2250 - false_loss: 0.0866 - true_loss: 1.1022 - val_loss: 5749.5537 - val_reconstruction_loss: 1896.2394 - val_kl_loss: 99.5522 - val_false_loss: 12.1253 - val_true_loss: 1.1617\n",
      "Epoch 2096/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8425 - reconstruction_loss: 1890.0438 - kl_loss: 100.9183 - false_loss: 0.0866 - true_loss: 1.1021 - val_loss: 5749.2026 - val_reconstruction_loss: 1896.2388 - val_kl_loss: 99.5528 - val_false_loss: 12.1242 - val_true_loss: 1.1617\n",
      "Epoch 2097/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.8381 - reconstruction_loss: 1890.0114 - kl_loss: 101.6291 - false_loss: 0.0866 - true_loss: 1.1021 - val_loss: 5748.8550 - val_reconstruction_loss: 1896.2383 - val_kl_loss: 99.5537 - val_false_loss: 12.1230 - val_true_loss: 1.1616\n",
      "Epoch 2098/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.5952 - reconstruction_loss: 1889.4774 - kl_loss: 101.6628 - false_loss: 0.0866 - true_loss: 1.1020 - val_loss: 5748.5093 - val_reconstruction_loss: 1896.2377 - val_kl_loss: 99.5545 - val_false_loss: 12.1219 - val_true_loss: 1.1616\n",
      "Epoch 2099/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.7791 - reconstruction_loss: 1889.4703 - kl_loss: 100.8744 - false_loss: 0.0866 - true_loss: 1.1020 - val_loss: 5748.1577 - val_reconstruction_loss: 1896.2373 - val_kl_loss: 99.5554 - val_false_loss: 12.1207 - val_true_loss: 1.1616\n",
      "Epoch 2100/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.1880 - reconstruction_loss: 1890.0438 - kl_loss: 100.9350 - false_loss: 0.0866 - true_loss: 1.1019 - val_loss: 5747.8159 - val_reconstruction_loss: 1896.2368 - val_kl_loss: 99.5557 - val_false_loss: 12.1196 - val_true_loss: 1.1615\n",
      "Epoch 2101/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.1193 - reconstruction_loss: 1889.6617 - kl_loss: 101.9250 - false_loss: 0.0866 - true_loss: 1.1019 - val_loss: 5747.4751 - val_reconstruction_loss: 1896.2362 - val_kl_loss: 99.5556 - val_false_loss: 12.1185 - val_true_loss: 1.1615\n",
      "Epoch 2102/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.5273 - reconstruction_loss: 1889.7583 - kl_loss: 100.3564 - false_loss: 0.0866 - true_loss: 1.1018 - val_loss: 5747.1240 - val_reconstruction_loss: 1896.2361 - val_kl_loss: 99.5557 - val_false_loss: 12.1173 - val_true_loss: 1.1614\n",
      "Epoch 2103/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.5608 - reconstruction_loss: 1890.0751 - kl_loss: 101.6796 - false_loss: 0.0865 - true_loss: 1.1018 - val_loss: 5746.7886 - val_reconstruction_loss: 1896.2356 - val_kl_loss: 99.5560 - val_false_loss: 12.1162 - val_true_loss: 1.1614\n",
      "Epoch 2104/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.7875 - reconstruction_loss: 1889.6548 - kl_loss: 101.0901 - false_loss: 0.0865 - true_loss: 1.1018 - val_loss: 5746.4434 - val_reconstruction_loss: 1896.2351 - val_kl_loss: 99.5567 - val_false_loss: 12.1151 - val_true_loss: 1.1613\n",
      "Epoch 2105/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.1668 - reconstruction_loss: 1889.6937 - kl_loss: 101.7893 - false_loss: 0.0865 - true_loss: 1.1017 - val_loss: 5746.0903 - val_reconstruction_loss: 1896.2346 - val_kl_loss: 99.5573 - val_false_loss: 12.1139 - val_true_loss: 1.1613\n",
      "Epoch 2106/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.6635 - reconstruction_loss: 1889.8477 - kl_loss: 101.2185 - false_loss: 0.0865 - true_loss: 1.1017 - val_loss: 5745.7417 - val_reconstruction_loss: 1896.2343 - val_kl_loss: 99.5584 - val_false_loss: 12.1128 - val_true_loss: 1.1613\n",
      "Epoch 2107/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2756 - reconstruction_loss: 1890.5123 - kl_loss: 100.4593 - false_loss: 0.0865 - true_loss: 1.1016 - val_loss: 5745.4053 - val_reconstruction_loss: 1896.2338 - val_kl_loss: 99.5586 - val_false_loss: 12.1117 - val_true_loss: 1.1612\n",
      "Epoch 2108/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4608 - reconstruction_loss: 1890.2700 - kl_loss: 100.8473 - false_loss: 0.0865 - true_loss: 1.1016 - val_loss: 5745.0542 - val_reconstruction_loss: 1896.2333 - val_kl_loss: 99.5591 - val_false_loss: 12.1105 - val_true_loss: 1.1612\n",
      "Epoch 2109/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.5906 - reconstruction_loss: 1889.6466 - kl_loss: 100.9781 - false_loss: 0.0865 - true_loss: 1.1015 - val_loss: 5744.7075 - val_reconstruction_loss: 1896.2329 - val_kl_loss: 99.5591 - val_false_loss: 12.1094 - val_true_loss: 1.1611\n",
      "Epoch 2110/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4568 - reconstruction_loss: 1889.3907 - kl_loss: 101.0978 - false_loss: 0.0865 - true_loss: 1.1015 - val_loss: 5744.3682 - val_reconstruction_loss: 1896.2323 - val_kl_loss: 99.5597 - val_false_loss: 12.1083 - val_true_loss: 1.1611\n",
      "Epoch 2111/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6733 - reconstruction_loss: 1889.8170 - kl_loss: 98.4140 - false_loss: 0.0865 - true_loss: 1.1014 - val_loss: 5744.0225 - val_reconstruction_loss: 1896.2319 - val_kl_loss: 99.5602 - val_false_loss: 12.1071 - val_true_loss: 1.1611\n",
      "Epoch 2112/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.7541 - reconstruction_loss: 1890.1156 - kl_loss: 99.0870 - false_loss: 0.0865 - true_loss: 1.1014 - val_loss: 5743.6821 - val_reconstruction_loss: 1896.2314 - val_kl_loss: 99.5604 - val_false_loss: 12.1060 - val_true_loss: 1.1610\n",
      "Epoch 2113/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7984 - reconstruction_loss: 1889.7797 - kl_loss: 99.4747 - false_loss: 0.0865 - true_loss: 1.1014 - val_loss: 5743.3296 - val_reconstruction_loss: 1896.2310 - val_kl_loss: 99.5606 - val_false_loss: 12.1048 - val_true_loss: 1.1610\n",
      "Epoch 2114/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.5560 - reconstruction_loss: 1890.1548 - kl_loss: 100.0620 - false_loss: 0.0865 - true_loss: 1.1013 - val_loss: 5742.9976 - val_reconstruction_loss: 1896.2305 - val_kl_loss: 99.5609 - val_false_loss: 12.1037 - val_true_loss: 1.1610\n",
      "Epoch 2115/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.2657 - reconstruction_loss: 1889.5894 - kl_loss: 100.3216 - false_loss: 0.0865 - true_loss: 1.1013 - val_loss: 5742.6650 - val_reconstruction_loss: 1896.2301 - val_kl_loss: 99.5611 - val_false_loss: 12.1026 - val_true_loss: 1.1609\n",
      "Epoch 2116/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.5023 - reconstruction_loss: 1889.7682 - kl_loss: 99.7698 - false_loss: 0.0865 - true_loss: 1.1012 - val_loss: 5742.3213 - val_reconstruction_loss: 1896.2295 - val_kl_loss: 99.5606 - val_false_loss: 12.1015 - val_true_loss: 1.1609\n",
      "Epoch 2117/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.5010 - reconstruction_loss: 1889.9730 - kl_loss: 100.1895 - false_loss: 0.0864 - true_loss: 1.1012 - val_loss: 5741.9795 - val_reconstruction_loss: 1896.2292 - val_kl_loss: 99.5608 - val_false_loss: 12.1004 - val_true_loss: 1.1609\n",
      "Epoch 2118/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8099 - reconstruction_loss: 1891.0697 - kl_loss: 98.5792 - false_loss: 0.0864 - true_loss: 1.1011 - val_loss: 5741.6406 - val_reconstruction_loss: 1896.2286 - val_kl_loss: 99.5616 - val_false_loss: 12.0993 - val_true_loss: 1.1608\n",
      "Epoch 2119/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.2141 - reconstruction_loss: 1891.1830 - kl_loss: 99.2018 - false_loss: 0.0864 - true_loss: 1.1011 - val_loss: 5741.3115 - val_reconstruction_loss: 1896.2284 - val_kl_loss: 99.5617 - val_false_loss: 12.0982 - val_true_loss: 1.1608\n",
      "Epoch 2120/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7281 - reconstruction_loss: 1890.2836 - kl_loss: 100.1617 - false_loss: 0.0864 - true_loss: 1.1011 - val_loss: 5740.9697 - val_reconstruction_loss: 1896.2278 - val_kl_loss: 99.5621 - val_false_loss: 12.0970 - val_true_loss: 1.1607\n",
      "Epoch 2121/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.1101 - reconstruction_loss: 1889.7323 - kl_loss: 99.9209 - false_loss: 0.0864 - true_loss: 1.1010 - val_loss: 5740.6284 - val_reconstruction_loss: 1896.2274 - val_kl_loss: 99.5622 - val_false_loss: 12.0959 - val_true_loss: 1.1607\n",
      "Epoch 2122/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.8186 - reconstruction_loss: 1889.9298 - kl_loss: 99.9571 - false_loss: 0.0864 - true_loss: 1.1010 - val_loss: 5740.2891 - val_reconstruction_loss: 1896.2269 - val_kl_loss: 99.5625 - val_false_loss: 12.0948 - val_true_loss: 1.1607\n",
      "Epoch 2123/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.3748 - reconstruction_loss: 1890.2096 - kl_loss: 100.2881 - false_loss: 0.0864 - true_loss: 1.1009 - val_loss: 5739.9478 - val_reconstruction_loss: 1896.2266 - val_kl_loss: 99.5633 - val_false_loss: 12.0937 - val_true_loss: 1.1606\n",
      "Epoch 2124/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.1071 - reconstruction_loss: 1890.2274 - kl_loss: 98.1912 - false_loss: 0.0864 - true_loss: 1.1009 - val_loss: 5739.6050 - val_reconstruction_loss: 1896.2260 - val_kl_loss: 99.5637 - val_false_loss: 12.0926 - val_true_loss: 1.1606\n",
      "Epoch 2125/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.1322 - reconstruction_loss: 1889.9269 - kl_loss: 100.3869 - false_loss: 0.0864 - true_loss: 1.1008 - val_loss: 5739.2612 - val_reconstruction_loss: 1896.2255 - val_kl_loss: 99.5640 - val_false_loss: 12.0914 - val_true_loss: 1.1605\n",
      "Epoch 2126/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.3893 - reconstruction_loss: 1889.7852 - kl_loss: 98.5573 - false_loss: 0.0864 - true_loss: 1.1008 - val_loss: 5738.9175 - val_reconstruction_loss: 1896.2250 - val_kl_loss: 99.5642 - val_false_loss: 12.0903 - val_true_loss: 1.1605\n",
      "Epoch 2127/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0029 - reconstruction_loss: 1889.9741 - kl_loss: 99.3145 - false_loss: 0.0864 - true_loss: 1.1007 - val_loss: 5738.5640 - val_reconstruction_loss: 1896.2245 - val_kl_loss: 99.5643 - val_false_loss: 12.0891 - val_true_loss: 1.1605\n",
      "Epoch 2128/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6146 - reconstruction_loss: 1889.8258 - kl_loss: 99.5858 - false_loss: 0.0864 - true_loss: 1.1007 - val_loss: 5738.2251 - val_reconstruction_loss: 1896.2241 - val_kl_loss: 99.5648 - val_false_loss: 12.0880 - val_true_loss: 1.1604\n",
      "Epoch 2129/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.1509 - reconstruction_loss: 1889.4196 - kl_loss: 99.3282 - false_loss: 0.0864 - true_loss: 1.1007 - val_loss: 5737.8867 - val_reconstruction_loss: 1896.2236 - val_kl_loss: 99.5654 - val_false_loss: 12.0869 - val_true_loss: 1.1604\n",
      "Epoch 2130/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.2706 - reconstruction_loss: 1889.8389 - kl_loss: 97.8292 - false_loss: 0.0864 - true_loss: 1.1006 - val_loss: 5737.5391 - val_reconstruction_loss: 1896.2233 - val_kl_loss: 99.5661 - val_false_loss: 12.0857 - val_true_loss: 1.1604\n",
      "Epoch 2131/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.5835 - reconstruction_loss: 1890.6051 - kl_loss: 100.1181 - false_loss: 0.0863 - true_loss: 1.1006 - val_loss: 5737.1919 - val_reconstruction_loss: 1896.2227 - val_kl_loss: 99.5666 - val_false_loss: 12.0846 - val_true_loss: 1.1603\n",
      "Epoch 2132/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.6497 - reconstruction_loss: 1889.7318 - kl_loss: 99.2698 - false_loss: 0.0863 - true_loss: 1.1005 - val_loss: 5736.8481 - val_reconstruction_loss: 1896.2223 - val_kl_loss: 99.5670 - val_false_loss: 12.0835 - val_true_loss: 1.1603\n",
      "Epoch 2133/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2221.3866 - reconstruction_loss: 1889.6061 - kl_loss: 99.6106 - false_loss: 0.0863 - true_loss: 1.1005 - val_loss: 5736.5063 - val_reconstruction_loss: 1896.2219 - val_kl_loss: 99.5676 - val_false_loss: 12.0823 - val_true_loss: 1.1602\n",
      "Epoch 2134/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.1805 - reconstruction_loss: 1890.1781 - kl_loss: 99.4071 - false_loss: 0.0863 - true_loss: 1.1004 - val_loss: 5736.1582 - val_reconstruction_loss: 1896.2214 - val_kl_loss: 99.5679 - val_false_loss: 12.0812 - val_true_loss: 1.1602\n",
      "Epoch 2135/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7005 - reconstruction_loss: 1889.7953 - kl_loss: 99.5222 - false_loss: 0.0863 - true_loss: 1.1004 - val_loss: 5735.8125 - val_reconstruction_loss: 1896.2211 - val_kl_loss: 99.5683 - val_false_loss: 12.0801 - val_true_loss: 1.1602\n",
      "Epoch 2136/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.2818 - reconstruction_loss: 1890.0771 - kl_loss: 99.1076 - false_loss: 0.0863 - true_loss: 1.1004 - val_loss: 5735.4712 - val_reconstruction_loss: 1896.2208 - val_kl_loss: 99.5673 - val_false_loss: 12.0789 - val_true_loss: 1.1601\n",
      "Epoch 2137/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.0153 - reconstruction_loss: 1890.1505 - kl_loss: 95.9846 - false_loss: 0.0863 - true_loss: 1.1003 - val_loss: 5735.1260 - val_reconstruction_loss: 1896.2202 - val_kl_loss: 99.5683 - val_false_loss: 12.0778 - val_true_loss: 1.1601\n",
      "Epoch 2138/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.5291 - reconstruction_loss: 1890.2285 - kl_loss: 98.1464 - false_loss: 0.0863 - true_loss: 1.1003 - val_loss: 5734.7886 - val_reconstruction_loss: 1896.2200 - val_kl_loss: 99.5687 - val_false_loss: 12.0767 - val_true_loss: 1.1601\n",
      "Epoch 2139/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0733 - reconstruction_loss: 1890.3179 - kl_loss: 99.7164 - false_loss: 0.0863 - true_loss: 1.1002 - val_loss: 5734.4385 - val_reconstruction_loss: 1896.2194 - val_kl_loss: 99.5690 - val_false_loss: 12.0755 - val_true_loss: 1.1600\n",
      "Epoch 2140/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8050 - reconstruction_loss: 1889.7047 - kl_loss: 100.0150 - false_loss: 0.0863 - true_loss: 1.1002 - val_loss: 5734.0928 - val_reconstruction_loss: 1896.2190 - val_kl_loss: 99.5691 - val_false_loss: 12.0744 - val_true_loss: 1.1600\n",
      "Epoch 2141/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.4601 - reconstruction_loss: 1889.7699 - kl_loss: 99.1467 - false_loss: 0.0863 - true_loss: 1.1002 - val_loss: 5733.7539 - val_reconstruction_loss: 1896.2185 - val_kl_loss: 99.5698 - val_false_loss: 12.0733 - val_true_loss: 1.1600\n",
      "Epoch 2142/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1805 - reconstruction_loss: 1890.1802 - kl_loss: 97.9238 - false_loss: 0.0863 - true_loss: 1.1001 - val_loss: 5733.4287 - val_reconstruction_loss: 1896.2180 - val_kl_loss: 99.5704 - val_false_loss: 12.0722 - val_true_loss: 1.1599\n",
      "Epoch 2143/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.7094 - reconstruction_loss: 1890.1973 - kl_loss: 99.2154 - false_loss: 0.0863 - true_loss: 1.1001 - val_loss: 5733.0820 - val_reconstruction_loss: 1896.2177 - val_kl_loss: 99.5710 - val_false_loss: 12.0711 - val_true_loss: 1.1599\n",
      "Epoch 2144/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.8571 - reconstruction_loss: 1890.3246 - kl_loss: 100.3105 - false_loss: 0.0863 - true_loss: 1.1000 - val_loss: 5732.7383 - val_reconstruction_loss: 1896.2173 - val_kl_loss: 99.5715 - val_false_loss: 12.0699 - val_true_loss: 1.1598\n",
      "Epoch 2145/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3980 - reconstruction_loss: 1889.8031 - kl_loss: 99.8686 - false_loss: 0.0862 - true_loss: 1.1000 - val_loss: 5732.4009 - val_reconstruction_loss: 1896.2167 - val_kl_loss: 99.5720 - val_false_loss: 12.0688 - val_true_loss: 1.1598\n",
      "Epoch 2146/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.8885 - reconstruction_loss: 1889.7272 - kl_loss: 101.1109 - false_loss: 0.0862 - true_loss: 1.0999 - val_loss: 5732.0601 - val_reconstruction_loss: 1896.2163 - val_kl_loss: 99.5729 - val_false_loss: 12.0677 - val_true_loss: 1.1597\n",
      "Epoch 2147/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.9279 - reconstruction_loss: 1890.0114 - kl_loss: 101.3955 - false_loss: 0.0862 - true_loss: 1.0999 - val_loss: 5731.7124 - val_reconstruction_loss: 1896.2158 - val_kl_loss: 99.5737 - val_false_loss: 12.0665 - val_true_loss: 1.1597\n",
      "Epoch 2148/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.2186 - reconstruction_loss: 1889.6971 - kl_loss: 101.9150 - false_loss: 0.0862 - true_loss: 1.0998 - val_loss: 5731.3672 - val_reconstruction_loss: 1896.2155 - val_kl_loss: 99.5742 - val_false_loss: 12.0654 - val_true_loss: 1.1596\n",
      "Epoch 2149/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.8890 - reconstruction_loss: 1889.4698 - kl_loss: 102.9236 - false_loss: 0.0862 - true_loss: 1.0998 - val_loss: 5731.0220 - val_reconstruction_loss: 1896.2148 - val_kl_loss: 99.5747 - val_false_loss: 12.0643 - val_true_loss: 1.1596\n",
      "Epoch 2150/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.1202 - reconstruction_loss: 1889.9639 - kl_loss: 101.9142 - false_loss: 0.0862 - true_loss: 1.0997 - val_loss: 5730.6768 - val_reconstruction_loss: 1896.2145 - val_kl_loss: 99.5750 - val_false_loss: 12.0631 - val_true_loss: 1.1595\n",
      "Epoch 2151/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.8614 - reconstruction_loss: 1889.7123 - kl_loss: 100.8922 - false_loss: 0.0862 - true_loss: 1.0997 - val_loss: 5730.3394 - val_reconstruction_loss: 1896.2140 - val_kl_loss: 99.5752 - val_false_loss: 12.0620 - val_true_loss: 1.1595\n",
      "Epoch 2152/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.0319 - reconstruction_loss: 1889.7051 - kl_loss: 101.6018 - false_loss: 0.0862 - true_loss: 1.0996 - val_loss: 5729.9995 - val_reconstruction_loss: 1896.2137 - val_kl_loss: 99.5754 - val_false_loss: 12.0609 - val_true_loss: 1.1595\n",
      "Epoch 2153/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.0128 - reconstruction_loss: 1889.8480 - kl_loss: 102.0321 - false_loss: 0.0862 - true_loss: 1.0996 - val_loss: 5729.6504 - val_reconstruction_loss: 1896.2131 - val_kl_loss: 99.5759 - val_false_loss: 12.0598 - val_true_loss: 1.1594\n",
      "Epoch 2154/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.3701 - reconstruction_loss: 1889.7598 - kl_loss: 102.6595 - false_loss: 0.0862 - true_loss: 1.0995 - val_loss: 5729.3179 - val_reconstruction_loss: 1896.2128 - val_kl_loss: 99.5759 - val_false_loss: 12.0587 - val_true_loss: 1.1594\n",
      "Epoch 2155/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.8178 - reconstruction_loss: 1890.2076 - kl_loss: 102.0491 - false_loss: 0.0862 - true_loss: 1.0995 - val_loss: 5728.9800 - val_reconstruction_loss: 1896.2123 - val_kl_loss: 99.5762 - val_false_loss: 12.0576 - val_true_loss: 1.1593\n",
      "Epoch 2156/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.4633 - reconstruction_loss: 1889.5406 - kl_loss: 102.5385 - false_loss: 0.0862 - true_loss: 1.0994 - val_loss: 5728.6323 - val_reconstruction_loss: 1896.2118 - val_kl_loss: 99.5768 - val_false_loss: 12.0564 - val_true_loss: 1.1593\n",
      "Epoch 2157/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.6633 - reconstruction_loss: 1889.8906 - kl_loss: 103.0279 - false_loss: 0.0862 - true_loss: 1.0994 - val_loss: 5728.2910 - val_reconstruction_loss: 1896.2113 - val_kl_loss: 99.5774 - val_false_loss: 12.0553 - val_true_loss: 1.1592\n",
      "Epoch 2158/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.0767 - reconstruction_loss: 1889.4750 - kl_loss: 103.0978 - false_loss: 0.0861 - true_loss: 1.0993 - val_loss: 5727.9419 - val_reconstruction_loss: 1896.2109 - val_kl_loss: 99.5780 - val_false_loss: 12.0541 - val_true_loss: 1.1592\n",
      "Epoch 2159/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.0564 - reconstruction_loss: 1889.9330 - kl_loss: 102.9780 - false_loss: 0.0861 - true_loss: 1.0993 - val_loss: 5727.6055 - val_reconstruction_loss: 1896.2104 - val_kl_loss: 99.5781 - val_false_loss: 12.0530 - val_true_loss: 1.1591\n",
      "Epoch 2160/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.7206 - reconstruction_loss: 1890.0101 - kl_loss: 100.5588 - false_loss: 0.0861 - true_loss: 1.0992 - val_loss: 5727.2607 - val_reconstruction_loss: 1896.2100 - val_kl_loss: 99.5791 - val_false_loss: 12.0519 - val_true_loss: 1.1591\n",
      "Epoch 2161/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9193 - reconstruction_loss: 1890.4203 - kl_loss: 102.2132 - false_loss: 0.0861 - true_loss: 1.0992 - val_loss: 5726.9233 - val_reconstruction_loss: 1896.2095 - val_kl_loss: 99.5794 - val_false_loss: 12.0508 - val_true_loss: 1.1591\n",
      "Epoch 2162/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.5932 - reconstruction_loss: 1889.9965 - kl_loss: 100.6506 - false_loss: 0.0861 - true_loss: 1.0991 - val_loss: 5726.5791 - val_reconstruction_loss: 1896.2091 - val_kl_loss: 99.5801 - val_false_loss: 12.0497 - val_true_loss: 1.1590\n",
      "Epoch 2163/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2078 - reconstruction_loss: 1889.7408 - kl_loss: 100.2143 - false_loss: 0.0861 - true_loss: 1.0991 - val_loss: 5726.2437 - val_reconstruction_loss: 1896.2086 - val_kl_loss: 99.5811 - val_false_loss: 12.0486 - val_true_loss: 1.1590\n",
      "Epoch 2164/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6673 - reconstruction_loss: 1890.0065 - kl_loss: 99.1479 - false_loss: 0.0861 - true_loss: 1.0990 - val_loss: 5725.9038 - val_reconstruction_loss: 1896.2083 - val_kl_loss: 99.5816 - val_false_loss: 12.0474 - val_true_loss: 1.1589\n",
      "Epoch 2165/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3518 - reconstruction_loss: 1889.9921 - kl_loss: 100.9983 - false_loss: 0.0861 - true_loss: 1.0990 - val_loss: 5725.5698 - val_reconstruction_loss: 1896.2076 - val_kl_loss: 99.5819 - val_false_loss: 12.0463 - val_true_loss: 1.1589\n",
      "Epoch 2166/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2569 - reconstruction_loss: 1889.9047 - kl_loss: 99.4249 - false_loss: 0.0861 - true_loss: 1.0990 - val_loss: 5725.2266 - val_reconstruction_loss: 1896.2073 - val_kl_loss: 99.5826 - val_false_loss: 12.0452 - val_true_loss: 1.1589\n",
      "Epoch 2167/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2772 - reconstruction_loss: 1889.9365 - kl_loss: 99.8710 - false_loss: 0.0861 - true_loss: 1.0989 - val_loss: 5724.8877 - val_reconstruction_loss: 1896.2068 - val_kl_loss: 99.5833 - val_false_loss: 12.0441 - val_true_loss: 1.1588\n",
      "Epoch 2168/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.9715 - reconstruction_loss: 1890.3120 - kl_loss: 98.9112 - false_loss: 0.0861 - true_loss: 1.0989 - val_loss: 5724.5498 - val_reconstruction_loss: 1896.2064 - val_kl_loss: 99.5840 - val_false_loss: 12.0430 - val_true_loss: 1.1588\n",
      "Epoch 2169/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.9207 - reconstruction_loss: 1890.0800 - kl_loss: 101.3752 - false_loss: 0.0861 - true_loss: 1.0988 - val_loss: 5724.2056 - val_reconstruction_loss: 1896.2058 - val_kl_loss: 99.5846 - val_false_loss: 12.0418 - val_true_loss: 1.1587\n",
      "Epoch 2170/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.1848 - reconstruction_loss: 1889.6509 - kl_loss: 101.9438 - false_loss: 0.0861 - true_loss: 1.0988 - val_loss: 5723.8647 - val_reconstruction_loss: 1896.2056 - val_kl_loss: 99.5855 - val_false_loss: 12.0407 - val_true_loss: 1.1587\n",
      "Epoch 2171/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.1971 - reconstruction_loss: 1890.1456 - kl_loss: 102.5172 - false_loss: 0.0861 - true_loss: 1.0987 - val_loss: 5723.5249 - val_reconstruction_loss: 1896.2050 - val_kl_loss: 99.5861 - val_false_loss: 12.0396 - val_true_loss: 1.1586\n",
      "Epoch 2172/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.0641 - reconstruction_loss: 1889.9990 - kl_loss: 101.5366 - false_loss: 0.0860 - true_loss: 1.0987 - val_loss: 5723.1880 - val_reconstruction_loss: 1896.2047 - val_kl_loss: 99.5870 - val_false_loss: 12.0385 - val_true_loss: 1.1586\n",
      "Epoch 2173/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5742 - reconstruction_loss: 1890.0629 - kl_loss: 101.2908 - false_loss: 0.0860 - true_loss: 1.0986 - val_loss: 5722.8452 - val_reconstruction_loss: 1896.2041 - val_kl_loss: 99.5879 - val_false_loss: 12.0374 - val_true_loss: 1.1586\n",
      "Epoch 2174/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.2696 - reconstruction_loss: 1889.8195 - kl_loss: 101.3776 - false_loss: 0.0860 - true_loss: 1.0986 - val_loss: 5722.5073 - val_reconstruction_loss: 1896.2039 - val_kl_loss: 99.5881 - val_false_loss: 12.0362 - val_true_loss: 1.1585\n",
      "Epoch 2175/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.0479 - reconstruction_loss: 1889.9425 - kl_loss: 101.0458 - false_loss: 0.0860 - true_loss: 1.0985 - val_loss: 5722.1738 - val_reconstruction_loss: 1896.2032 - val_kl_loss: 99.5888 - val_false_loss: 12.0351 - val_true_loss: 1.1585\n",
      "Epoch 2176/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.0881 - reconstruction_loss: 1890.0298 - kl_loss: 101.9718 - false_loss: 0.0860 - true_loss: 1.0985 - val_loss: 5721.8330 - val_reconstruction_loss: 1896.2028 - val_kl_loss: 99.5897 - val_false_loss: 12.0340 - val_true_loss: 1.1584\n",
      "Epoch 2177/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.0000 - reconstruction_loss: 1890.0189 - kl_loss: 102.2258 - false_loss: 0.0860 - true_loss: 1.0984 - val_loss: 5721.5034 - val_reconstruction_loss: 1896.2025 - val_kl_loss: 99.5906 - val_false_loss: 12.0329 - val_true_loss: 1.1584\n",
      "Epoch 2178/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.5413 - reconstruction_loss: 1889.9076 - kl_loss: 101.2668 - false_loss: 0.0860 - true_loss: 1.0984 - val_loss: 5721.1719 - val_reconstruction_loss: 1896.2019 - val_kl_loss: 99.5908 - val_false_loss: 12.0318 - val_true_loss: 1.1584\n",
      "Epoch 2179/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.4289 - reconstruction_loss: 1890.3239 - kl_loss: 98.8770 - false_loss: 0.0860 - true_loss: 1.0983 - val_loss: 5720.8364 - val_reconstruction_loss: 1896.2017 - val_kl_loss: 99.5897 - val_false_loss: 12.0307 - val_true_loss: 1.1583\n",
      "Epoch 2180/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.6761 - reconstruction_loss: 1890.6444 - kl_loss: 100.4300 - false_loss: 0.0860 - true_loss: 1.0983 - val_loss: 5720.4966 - val_reconstruction_loss: 1896.2012 - val_kl_loss: 99.5901 - val_false_loss: 12.0296 - val_true_loss: 1.1583\n",
      "Epoch 2181/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3800 - reconstruction_loss: 1890.5951 - kl_loss: 99.9753 - false_loss: 0.0860 - true_loss: 1.0983 - val_loss: 5720.1514 - val_reconstruction_loss: 1896.2007 - val_kl_loss: 99.5905 - val_false_loss: 12.0285 - val_true_loss: 1.1583\n",
      "Epoch 2182/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4266 - reconstruction_loss: 1890.0762 - kl_loss: 99.7307 - false_loss: 0.0860 - true_loss: 1.0982 - val_loss: 5719.8213 - val_reconstruction_loss: 1896.2002 - val_kl_loss: 99.5913 - val_false_loss: 12.0274 - val_true_loss: 1.1582\n",
      "Epoch 2183/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.0514 - reconstruction_loss: 1890.0713 - kl_loss: 101.7632 - false_loss: 0.0860 - true_loss: 1.0982 - val_loss: 5719.4814 - val_reconstruction_loss: 1896.1997 - val_kl_loss: 99.5919 - val_false_loss: 12.0263 - val_true_loss: 1.1582\n",
      "Epoch 2184/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.4189 - reconstruction_loss: 1889.8281 - kl_loss: 100.5201 - false_loss: 0.0860 - true_loss: 1.0981 - val_loss: 5719.1484 - val_reconstruction_loss: 1896.1992 - val_kl_loss: 99.5922 - val_false_loss: 12.0252 - val_true_loss: 1.1581\n",
      "Epoch 2185/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2237.6178 - reconstruction_loss: 1889.6947 - kl_loss: 99.3528 - false_loss: 0.0860 - true_loss: 1.0981 - val_loss: 5718.8193 - val_reconstruction_loss: 1896.1989 - val_kl_loss: 99.5920 - val_false_loss: 12.0241 - val_true_loss: 1.1581\n",
      "Epoch 2186/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.1828 - reconstruction_loss: 1889.7054 - kl_loss: 99.6437 - false_loss: 0.0859 - true_loss: 1.0981 - val_loss: 5718.4897 - val_reconstruction_loss: 1896.1982 - val_kl_loss: 99.5921 - val_false_loss: 12.0230 - val_true_loss: 1.1581\n",
      "Epoch 2187/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.2201 - reconstruction_loss: 1889.5332 - kl_loss: 99.4059 - false_loss: 0.0859 - true_loss: 1.0980 - val_loss: 5718.1509 - val_reconstruction_loss: 1896.1979 - val_kl_loss: 99.5922 - val_false_loss: 12.0219 - val_true_loss: 1.1580\n",
      "Epoch 2188/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0737 - reconstruction_loss: 1889.8798 - kl_loss: 99.1506 - false_loss: 0.0859 - true_loss: 1.0980 - val_loss: 5717.8164 - val_reconstruction_loss: 1896.1974 - val_kl_loss: 99.5922 - val_false_loss: 12.0208 - val_true_loss: 1.1580\n",
      "Epoch 2189/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.8727 - reconstruction_loss: 1889.7758 - kl_loss: 97.9925 - false_loss: 0.0859 - true_loss: 1.0979 - val_loss: 5717.4810 - val_reconstruction_loss: 1896.1969 - val_kl_loss: 99.5923 - val_false_loss: 12.0197 - val_true_loss: 1.1580\n",
      "Epoch 2190/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.2183 - reconstruction_loss: 1890.0697 - kl_loss: 96.8663 - false_loss: 0.0859 - true_loss: 1.0979 - val_loss: 5717.1450 - val_reconstruction_loss: 1896.1964 - val_kl_loss: 99.5929 - val_false_loss: 12.0186 - val_true_loss: 1.1579\n",
      "Epoch 2191/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.7444 - reconstruction_loss: 1890.1298 - kl_loss: 98.8852 - false_loss: 0.0859 - true_loss: 1.0979 - val_loss: 5716.8042 - val_reconstruction_loss: 1896.1960 - val_kl_loss: 99.5930 - val_false_loss: 12.0175 - val_true_loss: 1.1579\n",
      "Epoch 2192/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7753 - reconstruction_loss: 1890.1158 - kl_loss: 98.9906 - false_loss: 0.0859 - true_loss: 1.0978 - val_loss: 5716.4771 - val_reconstruction_loss: 1896.1956 - val_kl_loss: 99.5935 - val_false_loss: 12.0164 - val_true_loss: 1.1579\n",
      "Epoch 2193/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.0633 - reconstruction_loss: 1890.1139 - kl_loss: 98.2940 - false_loss: 0.0859 - true_loss: 1.0978 - val_loss: 5716.1309 - val_reconstruction_loss: 1896.1952 - val_kl_loss: 99.5939 - val_false_loss: 12.0152 - val_true_loss: 1.1578\n",
      "Epoch 2194/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.5540 - reconstruction_loss: 1889.9689 - kl_loss: 99.8677 - false_loss: 0.0859 - true_loss: 1.0977 - val_loss: 5715.7983 - val_reconstruction_loss: 1896.1947 - val_kl_loss: 99.5941 - val_false_loss: 12.0141 - val_true_loss: 1.1578\n",
      "Epoch 2195/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.1739 - reconstruction_loss: 1889.4896 - kl_loss: 100.3817 - false_loss: 0.0859 - true_loss: 1.0977 - val_loss: 5715.4585 - val_reconstruction_loss: 1896.1942 - val_kl_loss: 99.5947 - val_false_loss: 12.0130 - val_true_loss: 1.1577\n",
      "Epoch 2196/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.8462 - reconstruction_loss: 1889.6293 - kl_loss: 101.4791 - false_loss: 0.0859 - true_loss: 1.0976 - val_loss: 5715.1289 - val_reconstruction_loss: 1896.1937 - val_kl_loss: 99.5954 - val_false_loss: 12.0119 - val_true_loss: 1.1577\n",
      "Epoch 2197/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.6868 - reconstruction_loss: 1890.0480 - kl_loss: 102.3046 - false_loss: 0.0859 - true_loss: 1.0976 - val_loss: 5714.7988 - val_reconstruction_loss: 1896.1934 - val_kl_loss: 99.5960 - val_false_loss: 12.0109 - val_true_loss: 1.1576\n",
      "Epoch 2198/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.9092 - reconstruction_loss: 1889.6354 - kl_loss: 100.9695 - false_loss: 0.0859 - true_loss: 1.0975 - val_loss: 5714.4556 - val_reconstruction_loss: 1896.1929 - val_kl_loss: 99.5967 - val_false_loss: 12.0097 - val_true_loss: 1.1576\n",
      "Epoch 2199/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.7516 - reconstruction_loss: 1890.1766 - kl_loss: 102.6612 - false_loss: 0.0859 - true_loss: 1.0975 - val_loss: 5714.1226 - val_reconstruction_loss: 1896.1924 - val_kl_loss: 99.5978 - val_false_loss: 12.0086 - val_true_loss: 1.1575\n",
      "Epoch 2200/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.3046 - reconstruction_loss: 1889.4961 - kl_loss: 103.0204 - false_loss: 0.0858 - true_loss: 1.0974 - val_loss: 5713.7837 - val_reconstruction_loss: 1896.1920 - val_kl_loss: 99.5985 - val_false_loss: 12.0075 - val_true_loss: 1.1575\n",
      "Epoch 2201/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.2099 - reconstruction_loss: 1889.8080 - kl_loss: 103.0585 - false_loss: 0.0858 - true_loss: 1.0974 - val_loss: 5713.4487 - val_reconstruction_loss: 1896.1914 - val_kl_loss: 99.5986 - val_false_loss: 12.0064 - val_true_loss: 1.1575\n",
      "Epoch 2202/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.1534 - reconstruction_loss: 1889.8287 - kl_loss: 103.0395 - false_loss: 0.0858 - true_loss: 1.0973 - val_loss: 5713.1123 - val_reconstruction_loss: 1896.1910 - val_kl_loss: 99.5991 - val_false_loss: 12.0053 - val_true_loss: 1.1574\n",
      "Epoch 2203/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.6642 - reconstruction_loss: 1889.9053 - kl_loss: 102.4609 - false_loss: 0.0858 - true_loss: 1.0973 - val_loss: 5712.7715 - val_reconstruction_loss: 1896.1907 - val_kl_loss: 99.5997 - val_false_loss: 12.0042 - val_true_loss: 1.1574\n",
      "Epoch 2204/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0051 - reconstruction_loss: 1890.1925 - kl_loss: 102.7093 - false_loss: 0.0858 - true_loss: 1.0972 - val_loss: 5712.4326 - val_reconstruction_loss: 1896.1904 - val_kl_loss: 99.6001 - val_false_loss: 12.0031 - val_true_loss: 1.1573\n",
      "Epoch 2205/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.4988 - reconstruction_loss: 1890.1671 - kl_loss: 102.6887 - false_loss: 0.0858 - true_loss: 1.0972 - val_loss: 5712.0952 - val_reconstruction_loss: 1896.1901 - val_kl_loss: 99.6007 - val_false_loss: 12.0020 - val_true_loss: 1.1573\n",
      "Epoch 2206/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.5523 - reconstruction_loss: 1889.5253 - kl_loss: 102.8842 - false_loss: 0.0858 - true_loss: 1.0971 - val_loss: 5711.7554 - val_reconstruction_loss: 1896.1895 - val_kl_loss: 99.6017 - val_false_loss: 12.0008 - val_true_loss: 1.1572\n",
      "Epoch 2207/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.1456 - reconstruction_loss: 1890.1156 - kl_loss: 102.6331 - false_loss: 0.0858 - true_loss: 1.0971 - val_loss: 5711.4321 - val_reconstruction_loss: 1896.1892 - val_kl_loss: 99.6022 - val_false_loss: 11.9998 - val_true_loss: 1.1572\n",
      "Epoch 2208/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.0106 - reconstruction_loss: 1889.8900 - kl_loss: 102.6901 - false_loss: 0.0858 - true_loss: 1.0970 - val_loss: 5711.0942 - val_reconstruction_loss: 1896.1886 - val_kl_loss: 99.6027 - val_false_loss: 11.9987 - val_true_loss: 1.1571\n",
      "Epoch 2209/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.1289 - reconstruction_loss: 1889.6930 - kl_loss: 102.1438 - false_loss: 0.0858 - true_loss: 1.0970 - val_loss: 5710.7632 - val_reconstruction_loss: 1896.1882 - val_kl_loss: 99.6036 - val_false_loss: 11.9976 - val_true_loss: 1.1571\n",
      "Epoch 2210/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.1169 - reconstruction_loss: 1890.0626 - kl_loss: 103.0486 - false_loss: 0.0858 - true_loss: 1.0969 - val_loss: 5710.4360 - val_reconstruction_loss: 1896.1877 - val_kl_loss: 99.6046 - val_false_loss: 11.9965 - val_true_loss: 1.1570\n",
      "Epoch 2211/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.3165 - reconstruction_loss: 1890.0928 - kl_loss: 103.2200 - false_loss: 0.0858 - true_loss: 1.0969 - val_loss: 5710.1016 - val_reconstruction_loss: 1896.1873 - val_kl_loss: 99.6052 - val_false_loss: 11.9954 - val_true_loss: 1.1570\n",
      "Epoch 2212/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.3734 - reconstruction_loss: 1889.8414 - kl_loss: 102.3525 - false_loss: 0.0858 - true_loss: 1.0968 - val_loss: 5709.7686 - val_reconstruction_loss: 1896.1868 - val_kl_loss: 99.6050 - val_false_loss: 11.9943 - val_true_loss: 1.1569\n",
      "Epoch 2213/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.2884 - reconstruction_loss: 1889.7904 - kl_loss: 101.3186 - false_loss: 0.0857 - true_loss: 1.0968 - val_loss: 5709.4341 - val_reconstruction_loss: 1896.1864 - val_kl_loss: 99.6056 - val_false_loss: 11.9932 - val_true_loss: 1.1569\n",
      "Epoch 2214/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.7916 - reconstruction_loss: 1889.9576 - kl_loss: 103.2049 - false_loss: 0.0857 - true_loss: 1.0967 - val_loss: 5709.1216 - val_reconstruction_loss: 1896.1858 - val_kl_loss: 99.6060 - val_false_loss: 11.9922 - val_true_loss: 1.1569\n",
      "Epoch 2215/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.1351 - reconstruction_loss: 1889.7412 - kl_loss: 102.9849 - false_loss: 0.0857 - true_loss: 1.0967 - val_loss: 5708.7871 - val_reconstruction_loss: 1896.1855 - val_kl_loss: 99.6067 - val_false_loss: 11.9911 - val_true_loss: 1.1568\n",
      "Epoch 2216/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.7511 - reconstruction_loss: 1889.9263 - kl_loss: 103.5391 - false_loss: 0.0857 - true_loss: 1.0966 - val_loss: 5708.4546 - val_reconstruction_loss: 1896.1852 - val_kl_loss: 99.6079 - val_false_loss: 11.9900 - val_true_loss: 1.1568\n",
      "Epoch 2217/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.3560 - reconstruction_loss: 1889.6625 - kl_loss: 103.0346 - false_loss: 0.0857 - true_loss: 1.0966 - val_loss: 5708.1304 - val_reconstruction_loss: 1896.1846 - val_kl_loss: 99.6082 - val_false_loss: 11.9889 - val_true_loss: 1.1567\n",
      "Epoch 2218/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.2270 - reconstruction_loss: 1889.5450 - kl_loss: 101.4060 - false_loss: 0.0857 - true_loss: 1.0965 - val_loss: 5707.7979 - val_reconstruction_loss: 1896.1842 - val_kl_loss: 99.6081 - val_false_loss: 11.9878 - val_true_loss: 1.1567\n",
      "Epoch 2219/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.9922 - reconstruction_loss: 1890.2822 - kl_loss: 101.5185 - false_loss: 0.0857 - true_loss: 1.0965 - val_loss: 5707.4780 - val_reconstruction_loss: 1896.1836 - val_kl_loss: 99.6087 - val_false_loss: 11.9868 - val_true_loss: 1.1566\n",
      "Epoch 2220/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.2215 - reconstruction_loss: 1890.2267 - kl_loss: 102.4137 - false_loss: 0.0857 - true_loss: 1.0964 - val_loss: 5707.1465 - val_reconstruction_loss: 1896.1832 - val_kl_loss: 99.6095 - val_false_loss: 11.9857 - val_true_loss: 1.1566\n",
      "Epoch 2221/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.3541 - reconstruction_loss: 1890.2291 - kl_loss: 102.0961 - false_loss: 0.0857 - true_loss: 1.0964 - val_loss: 5706.8345 - val_reconstruction_loss: 1896.1827 - val_kl_loss: 99.6104 - val_false_loss: 11.9847 - val_true_loss: 1.1565\n",
      "Epoch 2222/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.2290 - reconstruction_loss: 1890.0885 - kl_loss: 101.3219 - false_loss: 0.0857 - true_loss: 1.0963 - val_loss: 5706.5220 - val_reconstruction_loss: 1896.1824 - val_kl_loss: 99.6115 - val_false_loss: 11.9836 - val_true_loss: 1.1565\n",
      "Epoch 2223/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.3086 - reconstruction_loss: 1889.6122 - kl_loss: 102.9221 - false_loss: 0.0857 - true_loss: 1.0963 - val_loss: 5706.1943 - val_reconstruction_loss: 1896.1820 - val_kl_loss: 99.6123 - val_false_loss: 11.9825 - val_true_loss: 1.1564\n",
      "Epoch 2224/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.4249 - reconstruction_loss: 1889.7740 - kl_loss: 102.8326 - false_loss: 0.0857 - true_loss: 1.0962 - val_loss: 5705.8774 - val_reconstruction_loss: 1896.1815 - val_kl_loss: 99.6124 - val_false_loss: 11.9815 - val_true_loss: 1.1564\n",
      "Epoch 2225/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.4605 - reconstruction_loss: 1889.8741 - kl_loss: 102.6322 - false_loss: 0.0857 - true_loss: 1.0962 - val_loss: 5705.5493 - val_reconstruction_loss: 1896.1810 - val_kl_loss: 99.6132 - val_false_loss: 11.9804 - val_true_loss: 1.1564\n",
      "Epoch 2226/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.2975 - reconstruction_loss: 1889.8400 - kl_loss: 101.5291 - false_loss: 0.0857 - true_loss: 1.0961 - val_loss: 5705.2339 - val_reconstruction_loss: 1896.1805 - val_kl_loss: 99.6141 - val_false_loss: 11.9794 - val_true_loss: 1.1563\n",
      "Epoch 2227/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.9953 - reconstruction_loss: 1890.0739 - kl_loss: 101.2569 - false_loss: 0.0856 - true_loss: 1.0961 - val_loss: 5704.9038 - val_reconstruction_loss: 1896.1801 - val_kl_loss: 99.6154 - val_false_loss: 11.9783 - val_true_loss: 1.1563\n",
      "Epoch 2228/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.6461 - reconstruction_loss: 1889.7231 - kl_loss: 101.2738 - false_loss: 0.0856 - true_loss: 1.0960 - val_loss: 5704.5693 - val_reconstruction_loss: 1896.1796 - val_kl_loss: 99.6159 - val_false_loss: 11.9772 - val_true_loss: 1.1562\n",
      "Epoch 2229/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.6177 - reconstruction_loss: 1889.7347 - kl_loss: 102.7527 - false_loss: 0.0856 - true_loss: 1.0960 - val_loss: 5704.2368 - val_reconstruction_loss: 1896.1792 - val_kl_loss: 99.6168 - val_false_loss: 11.9761 - val_true_loss: 1.1562\n",
      "Epoch 2230/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.4095 - reconstruction_loss: 1889.8134 - kl_loss: 103.7962 - false_loss: 0.0856 - true_loss: 1.0959 - val_loss: 5703.9023 - val_reconstruction_loss: 1896.1786 - val_kl_loss: 99.6170 - val_false_loss: 11.9750 - val_true_loss: 1.1561\n",
      "Epoch 2231/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.6086 - reconstruction_loss: 1889.8466 - kl_loss: 103.1641 - false_loss: 0.0856 - true_loss: 1.0959 - val_loss: 5703.5742 - val_reconstruction_loss: 1896.1783 - val_kl_loss: 99.6174 - val_false_loss: 11.9739 - val_true_loss: 1.1561\n",
      "Epoch 2232/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.3403 - reconstruction_loss: 1889.5840 - kl_loss: 103.4297 - false_loss: 0.0856 - true_loss: 1.0958 - val_loss: 5703.2461 - val_reconstruction_loss: 1896.1779 - val_kl_loss: 99.6177 - val_false_loss: 11.9729 - val_true_loss: 1.1560\n",
      "Epoch 2233/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.4913 - reconstruction_loss: 1890.1927 - kl_loss: 102.2175 - false_loss: 0.0856 - true_loss: 1.0958 - val_loss: 5702.9297 - val_reconstruction_loss: 1896.1774 - val_kl_loss: 99.6184 - val_false_loss: 11.9718 - val_true_loss: 1.1560\n",
      "Epoch 2234/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.8132 - reconstruction_loss: 1890.0073 - kl_loss: 102.0861 - false_loss: 0.0856 - true_loss: 1.0957 - val_loss: 5702.6108 - val_reconstruction_loss: 1896.1770 - val_kl_loss: 99.6183 - val_false_loss: 11.9708 - val_true_loss: 1.1559\n",
      "Epoch 2235/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.8109 - reconstruction_loss: 1890.0791 - kl_loss: 101.6354 - false_loss: 0.0856 - true_loss: 1.0957 - val_loss: 5702.2812 - val_reconstruction_loss: 1896.1765 - val_kl_loss: 99.6180 - val_false_loss: 11.9697 - val_true_loss: 1.1559\n",
      "Epoch 2236/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.7864 - reconstruction_loss: 1890.4810 - kl_loss: 100.8393 - false_loss: 0.0856 - true_loss: 1.0956 - val_loss: 5701.9570 - val_reconstruction_loss: 1896.1760 - val_kl_loss: 99.6182 - val_false_loss: 11.9686 - val_true_loss: 1.1559\n",
      "Epoch 2237/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2211.1145 - reconstruction_loss: 1889.9038 - kl_loss: 102.8113 - false_loss: 0.0856 - true_loss: 1.0956 - val_loss: 5701.6279 - val_reconstruction_loss: 1896.1755 - val_kl_loss: 99.6185 - val_false_loss: 11.9675 - val_true_loss: 1.1558\n",
      "Epoch 2238/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.2739 - reconstruction_loss: 1889.9554 - kl_loss: 103.2058 - false_loss: 0.0856 - true_loss: 1.0955 - val_loss: 5701.2954 - val_reconstruction_loss: 1896.1753 - val_kl_loss: 99.6187 - val_false_loss: 11.9664 - val_true_loss: 1.1558\n",
      "Epoch 2239/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.3369 - reconstruction_loss: 1890.3478 - kl_loss: 101.8608 - false_loss: 0.0856 - true_loss: 1.0955 - val_loss: 5700.9600 - val_reconstruction_loss: 1896.1748 - val_kl_loss: 99.6187 - val_false_loss: 11.9653 - val_true_loss: 1.1557\n",
      "Epoch 2240/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5951 - reconstruction_loss: 1890.2716 - kl_loss: 102.1317 - false_loss: 0.0856 - true_loss: 1.0954 - val_loss: 5700.6348 - val_reconstruction_loss: 1896.1743 - val_kl_loss: 99.6192 - val_false_loss: 11.9643 - val_true_loss: 1.1557\n",
      "Epoch 2241/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.9366 - reconstruction_loss: 1890.0859 - kl_loss: 100.9473 - false_loss: 0.0855 - true_loss: 1.0954 - val_loss: 5700.3213 - val_reconstruction_loss: 1896.1740 - val_kl_loss: 99.6206 - val_false_loss: 11.9632 - val_true_loss: 1.1556\n",
      "Epoch 2242/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.0143 - reconstruction_loss: 1889.9574 - kl_loss: 101.5489 - false_loss: 0.0855 - true_loss: 1.0953 - val_loss: 5700.0059 - val_reconstruction_loss: 1896.1735 - val_kl_loss: 99.6215 - val_false_loss: 11.9622 - val_true_loss: 1.1556\n",
      "Epoch 2243/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.8573 - reconstruction_loss: 1889.8610 - kl_loss: 101.9856 - false_loss: 0.0855 - true_loss: 1.0953 - val_loss: 5699.6729 - val_reconstruction_loss: 1896.1730 - val_kl_loss: 99.6218 - val_false_loss: 11.9611 - val_true_loss: 1.1556\n",
      "Epoch 2244/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.7827 - reconstruction_loss: 1890.0292 - kl_loss: 104.0572 - false_loss: 0.0855 - true_loss: 1.0953 - val_loss: 5699.3452 - val_reconstruction_loss: 1896.1726 - val_kl_loss: 99.6222 - val_false_loss: 11.9600 - val_true_loss: 1.1555\n",
      "Epoch 2245/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.4775 - reconstruction_loss: 1889.6064 - kl_loss: 103.1670 - false_loss: 0.0855 - true_loss: 1.0952 - val_loss: 5699.0171 - val_reconstruction_loss: 1896.1721 - val_kl_loss: 99.6222 - val_false_loss: 11.9589 - val_true_loss: 1.1555\n",
      "Epoch 2246/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.5504 - reconstruction_loss: 1889.7206 - kl_loss: 101.1335 - false_loss: 0.0855 - true_loss: 1.0952 - val_loss: 5698.6831 - val_reconstruction_loss: 1896.1716 - val_kl_loss: 99.6234 - val_false_loss: 11.9578 - val_true_loss: 1.1554\n",
      "Epoch 2247/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.6036 - reconstruction_loss: 1889.9532 - kl_loss: 100.6874 - false_loss: 0.0855 - true_loss: 1.0951 - val_loss: 5698.3643 - val_reconstruction_loss: 1896.1711 - val_kl_loss: 99.6240 - val_false_loss: 11.9568 - val_true_loss: 1.1554\n",
      "Epoch 2248/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.8633 - reconstruction_loss: 1889.9398 - kl_loss: 101.7001 - false_loss: 0.0855 - true_loss: 1.0951 - val_loss: 5698.0396 - val_reconstruction_loss: 1896.1708 - val_kl_loss: 99.6248 - val_false_loss: 11.9557 - val_true_loss: 1.1554\n",
      "Epoch 2249/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4203 - reconstruction_loss: 1889.5980 - kl_loss: 100.7203 - false_loss: 0.0855 - true_loss: 1.0950 - val_loss: 5697.7080 - val_reconstruction_loss: 1896.1703 - val_kl_loss: 99.6256 - val_false_loss: 11.9546 - val_true_loss: 1.1553\n",
      "Epoch 2250/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.9082 - reconstruction_loss: 1889.5992 - kl_loss: 101.0628 - false_loss: 0.0855 - true_loss: 1.0950 - val_loss: 5697.3750 - val_reconstruction_loss: 1896.1698 - val_kl_loss: 99.6253 - val_false_loss: 11.9535 - val_true_loss: 1.1553\n",
      "Epoch 2251/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.7057 - reconstruction_loss: 1889.9171 - kl_loss: 101.0901 - false_loss: 0.0855 - true_loss: 1.0949 - val_loss: 5697.0454 - val_reconstruction_loss: 1896.1694 - val_kl_loss: 99.6257 - val_false_loss: 11.9524 - val_true_loss: 1.1553\n",
      "Epoch 2252/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9712 - reconstruction_loss: 1889.6180 - kl_loss: 100.5223 - false_loss: 0.0855 - true_loss: 1.0949 - val_loss: 5696.7261 - val_reconstruction_loss: 1896.1689 - val_kl_loss: 99.6257 - val_false_loss: 11.9514 - val_true_loss: 1.1552\n",
      "Epoch 2253/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8597 - reconstruction_loss: 1889.3785 - kl_loss: 99.4203 - false_loss: 0.0855 - true_loss: 1.0949 - val_loss: 5696.3955 - val_reconstruction_loss: 1896.1685 - val_kl_loss: 99.6255 - val_false_loss: 11.9503 - val_true_loss: 1.1552\n",
      "Epoch 2254/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.7554 - reconstruction_loss: 1889.9874 - kl_loss: 99.7361 - false_loss: 0.0855 - true_loss: 1.0948 - val_loss: 5696.0654 - val_reconstruction_loss: 1896.1680 - val_kl_loss: 99.6258 - val_false_loss: 11.9492 - val_true_loss: 1.1552\n",
      "Epoch 2255/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2798 - reconstruction_loss: 1890.4316 - kl_loss: 99.1859 - false_loss: 0.0854 - true_loss: 1.0948 - val_loss: 5695.7397 - val_reconstruction_loss: 1896.1677 - val_kl_loss: 99.6259 - val_false_loss: 11.9481 - val_true_loss: 1.1551\n",
      "Epoch 2256/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.4387 - reconstruction_loss: 1890.1913 - kl_loss: 97.9697 - false_loss: 0.0854 - true_loss: 1.0947 - val_loss: 5695.4180 - val_reconstruction_loss: 1896.1674 - val_kl_loss: 99.6265 - val_false_loss: 11.9471 - val_true_loss: 1.1551\n",
      "Epoch 2257/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2765 - reconstruction_loss: 1890.8182 - kl_loss: 100.1237 - false_loss: 0.0854 - true_loss: 1.0947 - val_loss: 5695.1030 - val_reconstruction_loss: 1896.1669 - val_kl_loss: 99.6260 - val_false_loss: 11.9460 - val_true_loss: 1.1550\n",
      "Epoch 2258/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.5272 - reconstruction_loss: 1891.1031 - kl_loss: 99.7727 - false_loss: 0.0854 - true_loss: 1.0947 - val_loss: 5694.7812 - val_reconstruction_loss: 1896.1664 - val_kl_loss: 99.6267 - val_false_loss: 11.9450 - val_true_loss: 1.1550\n",
      "Epoch 2259/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4966 - reconstruction_loss: 1890.0680 - kl_loss: 100.6624 - false_loss: 0.0854 - true_loss: 1.0946 - val_loss: 5694.4575 - val_reconstruction_loss: 1896.1659 - val_kl_loss: 99.6273 - val_false_loss: 11.9439 - val_true_loss: 1.1550\n",
      "Epoch 2260/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3266 - reconstruction_loss: 1889.6660 - kl_loss: 100.0229 - false_loss: 0.0854 - true_loss: 1.0946 - val_loss: 5694.1309 - val_reconstruction_loss: 1896.1655 - val_kl_loss: 99.6272 - val_false_loss: 11.9428 - val_true_loss: 1.1549\n",
      "Epoch 2261/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1055 - reconstruction_loss: 1889.7977 - kl_loss: 99.4442 - false_loss: 0.0854 - true_loss: 1.0945 - val_loss: 5693.8022 - val_reconstruction_loss: 1896.1652 - val_kl_loss: 99.6275 - val_false_loss: 11.9418 - val_true_loss: 1.1549\n",
      "Epoch 2262/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8454 - reconstruction_loss: 1889.9874 - kl_loss: 101.0018 - false_loss: 0.0854 - true_loss: 1.0945 - val_loss: 5693.4780 - val_reconstruction_loss: 1896.1647 - val_kl_loss: 99.6282 - val_false_loss: 11.9407 - val_true_loss: 1.1549\n",
      "Epoch 2263/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.5339 - reconstruction_loss: 1889.6660 - kl_loss: 100.5188 - false_loss: 0.0854 - true_loss: 1.0944 - val_loss: 5693.1631 - val_reconstruction_loss: 1896.1642 - val_kl_loss: 99.6284 - val_false_loss: 11.9397 - val_true_loss: 1.1548\n",
      "Epoch 2264/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.5139 - reconstruction_loss: 1889.7344 - kl_loss: 99.5157 - false_loss: 0.0854 - true_loss: 1.0944 - val_loss: 5692.8486 - val_reconstruction_loss: 1896.1637 - val_kl_loss: 99.6281 - val_false_loss: 11.9386 - val_true_loss: 1.1548\n",
      "Epoch 2265/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.1367 - reconstruction_loss: 1889.6201 - kl_loss: 98.6821 - false_loss: 0.0854 - true_loss: 1.0944 - val_loss: 5692.5420 - val_reconstruction_loss: 1896.1633 - val_kl_loss: 99.6273 - val_false_loss: 11.9376 - val_true_loss: 1.1548\n",
      "Epoch 2266/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6913 - reconstruction_loss: 1889.8120 - kl_loss: 99.6282 - false_loss: 0.0854 - true_loss: 1.0943 - val_loss: 5692.2192 - val_reconstruction_loss: 1896.1631 - val_kl_loss: 99.6281 - val_false_loss: 11.9366 - val_true_loss: 1.1547\n",
      "Epoch 2267/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3540 - reconstruction_loss: 1889.6473 - kl_loss: 99.9548 - false_loss: 0.0854 - true_loss: 1.0943 - val_loss: 5691.8945 - val_reconstruction_loss: 1896.1625 - val_kl_loss: 99.6288 - val_false_loss: 11.9355 - val_true_loss: 1.1547\n",
      "Epoch 2268/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.2707 - reconstruction_loss: 1889.5006 - kl_loss: 100.9184 - false_loss: 0.0854 - true_loss: 1.0942 - val_loss: 5691.5698 - val_reconstruction_loss: 1896.1622 - val_kl_loss: 99.6296 - val_false_loss: 11.9344 - val_true_loss: 1.1546\n",
      "Epoch 2269/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.0037 - reconstruction_loss: 1890.8395 - kl_loss: 101.0807 - false_loss: 0.0853 - true_loss: 1.0942 - val_loss: 5691.2363 - val_reconstruction_loss: 1896.1619 - val_kl_loss: 99.6303 - val_false_loss: 11.9333 - val_true_loss: 1.1546\n",
      "Epoch 2270/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.3401 - reconstruction_loss: 1889.8275 - kl_loss: 101.5536 - false_loss: 0.0853 - true_loss: 1.0941 - val_loss: 5690.8970 - val_reconstruction_loss: 1896.1613 - val_kl_loss: 99.6307 - val_false_loss: 11.9322 - val_true_loss: 1.1545\n",
      "Epoch 2271/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.9972 - reconstruction_loss: 1889.9932 - kl_loss: 101.3722 - false_loss: 0.0853 - true_loss: 1.0941 - val_loss: 5690.5791 - val_reconstruction_loss: 1896.1609 - val_kl_loss: 99.6309 - val_false_loss: 11.9312 - val_true_loss: 1.1545\n",
      "Epoch 2272/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.7199 - reconstruction_loss: 1889.6779 - kl_loss: 102.4096 - false_loss: 0.0853 - true_loss: 1.0940 - val_loss: 5690.2617 - val_reconstruction_loss: 1896.1604 - val_kl_loss: 99.6312 - val_false_loss: 11.9301 - val_true_loss: 1.1544\n",
      "Epoch 2273/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.7906 - reconstruction_loss: 1889.3623 - kl_loss: 102.5628 - false_loss: 0.0853 - true_loss: 1.0940 - val_loss: 5689.9424 - val_reconstruction_loss: 1896.1602 - val_kl_loss: 99.6321 - val_false_loss: 11.9291 - val_true_loss: 1.1544\n",
      "Epoch 2274/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.9580 - reconstruction_loss: 1889.4913 - kl_loss: 102.9882 - false_loss: 0.0853 - true_loss: 1.0939 - val_loss: 5689.6191 - val_reconstruction_loss: 1896.1597 - val_kl_loss: 99.6326 - val_false_loss: 11.9280 - val_true_loss: 1.1543\n",
      "Epoch 2275/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.6632 - reconstruction_loss: 1890.1049 - kl_loss: 102.8426 - false_loss: 0.0853 - true_loss: 1.0939 - val_loss: 5689.2983 - val_reconstruction_loss: 1896.1592 - val_kl_loss: 99.6331 - val_false_loss: 11.9269 - val_true_loss: 1.1543\n",
      "Epoch 2276/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.6309 - reconstruction_loss: 1889.8607 - kl_loss: 103.2183 - false_loss: 0.0853 - true_loss: 1.0938 - val_loss: 5688.9756 - val_reconstruction_loss: 1896.1588 - val_kl_loss: 99.6334 - val_false_loss: 11.9259 - val_true_loss: 1.1543\n",
      "Epoch 2277/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6489 - reconstruction_loss: 1889.9037 - kl_loss: 102.7826 - false_loss: 0.0853 - true_loss: 1.0938 - val_loss: 5688.6523 - val_reconstruction_loss: 1896.1584 - val_kl_loss: 99.6343 - val_false_loss: 11.9248 - val_true_loss: 1.1542\n",
      "Epoch 2278/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.5357 - reconstruction_loss: 1889.8969 - kl_loss: 100.7840 - false_loss: 0.0853 - true_loss: 1.0937 - val_loss: 5688.3311 - val_reconstruction_loss: 1896.1578 - val_kl_loss: 99.6346 - val_false_loss: 11.9238 - val_true_loss: 1.1542\n",
      "Epoch 2279/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.3422 - reconstruction_loss: 1889.7579 - kl_loss: 99.7984 - false_loss: 0.0853 - true_loss: 1.0937 - val_loss: 5688.0093 - val_reconstruction_loss: 1896.1575 - val_kl_loss: 99.6349 - val_false_loss: 11.9227 - val_true_loss: 1.1542\n",
      "Epoch 2280/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.2736 - reconstruction_loss: 1889.6162 - kl_loss: 99.6660 - false_loss: 0.0853 - true_loss: 1.0937 - val_loss: 5687.6875 - val_reconstruction_loss: 1896.1570 - val_kl_loss: 99.6352 - val_false_loss: 11.9216 - val_true_loss: 1.1541\n",
      "Epoch 2281/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.6521 - reconstruction_loss: 1889.7130 - kl_loss: 99.6639 - false_loss: 0.0853 - true_loss: 1.0936 - val_loss: 5687.3799 - val_reconstruction_loss: 1896.1566 - val_kl_loss: 99.6359 - val_false_loss: 11.9206 - val_true_loss: 1.1541\n",
      "Epoch 2282/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.0499 - reconstruction_loss: 1889.5194 - kl_loss: 97.3538 - false_loss: 0.0853 - true_loss: 1.0936 - val_loss: 5687.0698 - val_reconstruction_loss: 1896.1562 - val_kl_loss: 99.6361 - val_false_loss: 11.9196 - val_true_loss: 1.1541\n",
      "Epoch 2283/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.4418 - reconstruction_loss: 1889.5791 - kl_loss: 98.7243 - false_loss: 0.0852 - true_loss: 1.0936 - val_loss: 5686.7563 - val_reconstruction_loss: 1896.1556 - val_kl_loss: 99.6363 - val_false_loss: 11.9186 - val_true_loss: 1.1540\n",
      "Epoch 2284/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.8276 - reconstruction_loss: 1889.6689 - kl_loss: 98.3385 - false_loss: 0.0852 - true_loss: 1.0935 - val_loss: 5686.4434 - val_reconstruction_loss: 1896.1554 - val_kl_loss: 99.6362 - val_false_loss: 11.9175 - val_true_loss: 1.1540\n",
      "Epoch 2285/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.7657 - reconstruction_loss: 1889.9814 - kl_loss: 96.9086 - false_loss: 0.0852 - true_loss: 1.0935 - val_loss: 5686.1279 - val_reconstruction_loss: 1896.1549 - val_kl_loss: 99.6363 - val_false_loss: 11.9165 - val_true_loss: 1.1540\n",
      "Epoch 2286/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.9040 - reconstruction_loss: 1889.9037 - kl_loss: 99.5763 - false_loss: 0.0852 - true_loss: 1.0934 - val_loss: 5685.8101 - val_reconstruction_loss: 1896.1544 - val_kl_loss: 99.6360 - val_false_loss: 11.9154 - val_true_loss: 1.1539\n",
      "Epoch 2287/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.9649 - reconstruction_loss: 1889.8798 - kl_loss: 98.5484 - false_loss: 0.0852 - true_loss: 1.0934 - val_loss: 5685.4922 - val_reconstruction_loss: 1896.1541 - val_kl_loss: 99.6359 - val_false_loss: 11.9144 - val_true_loss: 1.1539\n",
      "Epoch 2288/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.2699 - reconstruction_loss: 1889.8981 - kl_loss: 98.3818 - false_loss: 0.0852 - true_loss: 1.0934 - val_loss: 5685.1719 - val_reconstruction_loss: 1896.1534 - val_kl_loss: 99.6357 - val_false_loss: 11.9133 - val_true_loss: 1.1539\n",
      "Epoch 2289/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4442 - reconstruction_loss: 1889.9557 - kl_loss: 98.2184 - false_loss: 0.0852 - true_loss: 1.0933 - val_loss: 5684.8506 - val_reconstruction_loss: 1896.1532 - val_kl_loss: 99.6356 - val_false_loss: 11.9123 - val_true_loss: 1.1538\n",
      "Epoch 2290/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.3708 - reconstruction_loss: 1889.8628 - kl_loss: 98.3496 - false_loss: 0.0852 - true_loss: 1.0933 - val_loss: 5684.5234 - val_reconstruction_loss: 1896.1528 - val_kl_loss: 99.6357 - val_false_loss: 11.9112 - val_true_loss: 1.1538\n",
      "Epoch 2291/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.0234 - reconstruction_loss: 1889.7633 - kl_loss: 99.3942 - false_loss: 0.0852 - true_loss: 1.0932 - val_loss: 5684.2100 - val_reconstruction_loss: 1896.1522 - val_kl_loss: 99.6360 - val_false_loss: 11.9102 - val_true_loss: 1.1537\n",
      "Epoch 2292/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.6837 - reconstruction_loss: 1889.8844 - kl_loss: 100.8042 - false_loss: 0.0852 - true_loss: 1.0932 - val_loss: 5683.8804 - val_reconstruction_loss: 1896.1519 - val_kl_loss: 99.6363 - val_false_loss: 11.9091 - val_true_loss: 1.1537\n",
      "Epoch 2293/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.5699 - reconstruction_loss: 1890.1205 - kl_loss: 101.2354 - false_loss: 0.0852 - true_loss: 1.0931 - val_loss: 5683.5596 - val_reconstruction_loss: 1896.1515 - val_kl_loss: 99.6364 - val_false_loss: 11.9080 - val_true_loss: 1.1537\n",
      "Epoch 2294/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.0094 - reconstruction_loss: 1889.7531 - kl_loss: 100.9509 - false_loss: 0.0852 - true_loss: 1.0931 - val_loss: 5683.2363 - val_reconstruction_loss: 1896.1510 - val_kl_loss: 99.6368 - val_false_loss: 11.9070 - val_true_loss: 1.1536\n",
      "Epoch 2295/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7268 - reconstruction_loss: 1889.4772 - kl_loss: 102.6538 - false_loss: 0.0852 - true_loss: 1.0930 - val_loss: 5682.9126 - val_reconstruction_loss: 1896.1505 - val_kl_loss: 99.6372 - val_false_loss: 11.9059 - val_true_loss: 1.1536\n",
      "Epoch 2296/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.9748 - reconstruction_loss: 1889.9684 - kl_loss: 101.3943 - false_loss: 0.0852 - true_loss: 1.0930 - val_loss: 5682.5879 - val_reconstruction_loss: 1896.1500 - val_kl_loss: 99.6376 - val_false_loss: 11.9048 - val_true_loss: 1.1535\n",
      "Epoch 2297/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2607 - reconstruction_loss: 1889.5338 - kl_loss: 100.6795 - false_loss: 0.0851 - true_loss: 1.0930 - val_loss: 5682.2700 - val_reconstruction_loss: 1896.1497 - val_kl_loss: 99.6379 - val_false_loss: 11.9038 - val_true_loss: 1.1535\n",
      "Epoch 2298/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.7570 - reconstruction_loss: 1890.0054 - kl_loss: 100.5016 - false_loss: 0.0851 - true_loss: 1.0929 - val_loss: 5681.9492 - val_reconstruction_loss: 1896.1494 - val_kl_loss: 99.6387 - val_false_loss: 11.9027 - val_true_loss: 1.1535\n",
      "Epoch 2299/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6084 - reconstruction_loss: 1889.5524 - kl_loss: 98.1905 - false_loss: 0.0851 - true_loss: 1.0929 - val_loss: 5681.6196 - val_reconstruction_loss: 1896.1492 - val_kl_loss: 99.6390 - val_false_loss: 11.9017 - val_true_loss: 1.1534\n",
      "Epoch 2300/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0080 - reconstruction_loss: 1890.1831 - kl_loss: 99.9314 - false_loss: 0.0851 - true_loss: 1.0928 - val_loss: 5681.2998 - val_reconstruction_loss: 1896.1487 - val_kl_loss: 99.6394 - val_false_loss: 11.9006 - val_true_loss: 1.1534\n",
      "Epoch 2301/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.8567 - reconstruction_loss: 1889.8975 - kl_loss: 99.4895 - false_loss: 0.0851 - true_loss: 1.0928 - val_loss: 5680.9819 - val_reconstruction_loss: 1896.1482 - val_kl_loss: 99.6394 - val_false_loss: 11.8996 - val_true_loss: 1.1534\n",
      "Epoch 2302/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.7298 - reconstruction_loss: 1890.7578 - kl_loss: 97.3714 - false_loss: 0.0851 - true_loss: 1.0928 - val_loss: 5680.6738 - val_reconstruction_loss: 1896.1478 - val_kl_loss: 99.6396 - val_false_loss: 11.8985 - val_true_loss: 1.1533\n",
      "Epoch 2303/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1417 - reconstruction_loss: 1890.8595 - kl_loss: 98.8043 - false_loss: 0.0851 - true_loss: 1.0927 - val_loss: 5680.3633 - val_reconstruction_loss: 1896.1475 - val_kl_loss: 99.6389 - val_false_loss: 11.8975 - val_true_loss: 1.1533\n",
      "Epoch 2304/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.5537 - reconstruction_loss: 1890.9994 - kl_loss: 93.6737 - false_loss: 0.0851 - true_loss: 1.0927 - val_loss: 5680.0630 - val_reconstruction_loss: 1896.1471 - val_kl_loss: 99.6395 - val_false_loss: 11.8965 - val_true_loss: 1.1533\n",
      "Epoch 2305/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.1452 - reconstruction_loss: 1890.3812 - kl_loss: 94.9550 - false_loss: 0.0851 - true_loss: 1.0927 - val_loss: 5679.7383 - val_reconstruction_loss: 1896.1465 - val_kl_loss: 99.6393 - val_false_loss: 11.8955 - val_true_loss: 1.1532\n",
      "Epoch 2306/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.2270 - reconstruction_loss: 1890.2910 - kl_loss: 97.2591 - false_loss: 0.0851 - true_loss: 1.0926 - val_loss: 5679.3999 - val_reconstruction_loss: 1896.1461 - val_kl_loss: 99.6395 - val_false_loss: 11.8944 - val_true_loss: 1.1532\n",
      "Epoch 2307/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.7947 - reconstruction_loss: 1890.0426 - kl_loss: 100.5691 - false_loss: 0.0851 - true_loss: 1.0926 - val_loss: 5679.0688 - val_reconstruction_loss: 1896.1458 - val_kl_loss: 99.6397 - val_false_loss: 11.8933 - val_true_loss: 1.1531\n",
      "Epoch 2308/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.5960 - reconstruction_loss: 1889.5103 - kl_loss: 101.5818 - false_loss: 0.0851 - true_loss: 1.0925 - val_loss: 5678.7524 - val_reconstruction_loss: 1896.1453 - val_kl_loss: 99.6399 - val_false_loss: 11.8922 - val_true_loss: 1.1531\n",
      "Epoch 2309/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6865 - reconstruction_loss: 1889.9414 - kl_loss: 101.7388 - false_loss: 0.0851 - true_loss: 1.0925 - val_loss: 5678.4199 - val_reconstruction_loss: 1896.1448 - val_kl_loss: 99.6405 - val_false_loss: 11.8911 - val_true_loss: 1.1530\n",
      "Epoch 2310/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.2148 - reconstruction_loss: 1889.3737 - kl_loss: 100.9524 - false_loss: 0.0851 - true_loss: 1.0924 - val_loss: 5678.0918 - val_reconstruction_loss: 1896.1444 - val_kl_loss: 99.6412 - val_false_loss: 11.8900 - val_true_loss: 1.1530\n",
      "Epoch 2311/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4310 - reconstruction_loss: 1889.4427 - kl_loss: 101.4173 - false_loss: 0.0851 - true_loss: 1.0924 - val_loss: 5677.7651 - val_reconstruction_loss: 1896.1438 - val_kl_loss: 99.6415 - val_false_loss: 11.8890 - val_true_loss: 1.1530\n",
      "Epoch 2312/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4001 - reconstruction_loss: 1889.3153 - kl_loss: 101.4468 - false_loss: 0.0850 - true_loss: 1.0923 - val_loss: 5677.4492 - val_reconstruction_loss: 1896.1434 - val_kl_loss: 99.6422 - val_false_loss: 11.8879 - val_true_loss: 1.1529\n",
      "Epoch 2313/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1102 - reconstruction_loss: 1889.6696 - kl_loss: 100.7008 - false_loss: 0.0850 - true_loss: 1.0923 - val_loss: 5677.1187 - val_reconstruction_loss: 1896.1429 - val_kl_loss: 99.6424 - val_false_loss: 11.8868 - val_true_loss: 1.1529\n",
      "Epoch 2314/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.6966 - reconstruction_loss: 1890.0951 - kl_loss: 100.4823 - false_loss: 0.0850 - true_loss: 1.0923 - val_loss: 5676.8027 - val_reconstruction_loss: 1896.1426 - val_kl_loss: 99.6428 - val_false_loss: 11.8858 - val_true_loss: 1.1528\n",
      "Epoch 2315/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.3267 - reconstruction_loss: 1889.6676 - kl_loss: 99.9598 - false_loss: 0.0850 - true_loss: 1.0922 - val_loss: 5676.4805 - val_reconstruction_loss: 1896.1422 - val_kl_loss: 99.6433 - val_false_loss: 11.8847 - val_true_loss: 1.1528\n",
      "Epoch 2316/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9397 - reconstruction_loss: 1889.6270 - kl_loss: 99.6127 - false_loss: 0.0850 - true_loss: 1.0922 - val_loss: 5676.1719 - val_reconstruction_loss: 1896.1417 - val_kl_loss: 99.6437 - val_false_loss: 11.8837 - val_true_loss: 1.1528\n",
      "Epoch 2317/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.5020 - reconstruction_loss: 1889.5348 - kl_loss: 99.6928 - false_loss: 0.0850 - true_loss: 1.0921 - val_loss: 5675.8398 - val_reconstruction_loss: 1896.1414 - val_kl_loss: 99.6438 - val_false_loss: 11.8826 - val_true_loss: 1.1527\n",
      "Epoch 2318/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.2332 - reconstruction_loss: 1889.6183 - kl_loss: 99.5455 - false_loss: 0.0850 - true_loss: 1.0921 - val_loss: 5675.5078 - val_reconstruction_loss: 1896.1409 - val_kl_loss: 99.6437 - val_false_loss: 11.8815 - val_true_loss: 1.1527\n",
      "Epoch 2319/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.1652 - reconstruction_loss: 1889.8822 - kl_loss: 99.6915 - false_loss: 0.0850 - true_loss: 1.0920 - val_loss: 5675.1763 - val_reconstruction_loss: 1896.1405 - val_kl_loss: 99.6437 - val_false_loss: 11.8804 - val_true_loss: 1.1527\n",
      "Epoch 2320/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3429 - reconstruction_loss: 1889.7855 - kl_loss: 100.1348 - false_loss: 0.0850 - true_loss: 1.0920 - val_loss: 5674.8438 - val_reconstruction_loss: 1896.1401 - val_kl_loss: 99.6433 - val_false_loss: 11.8794 - val_true_loss: 1.1526\n",
      "Epoch 2321/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.7949 - reconstruction_loss: 1890.1356 - kl_loss: 99.3378 - false_loss: 0.0850 - true_loss: 1.0920 - val_loss: 5674.5093 - val_reconstruction_loss: 1896.1399 - val_kl_loss: 99.6437 - val_false_loss: 11.8783 - val_true_loss: 1.1526\n",
      "Epoch 2322/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.8824 - reconstruction_loss: 1889.9692 - kl_loss: 101.0847 - false_loss: 0.0850 - true_loss: 1.0919 - val_loss: 5674.1860 - val_reconstruction_loss: 1896.1393 - val_kl_loss: 99.6442 - val_false_loss: 11.8772 - val_true_loss: 1.1525\n",
      "Epoch 2323/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.5996 - reconstruction_loss: 1889.9015 - kl_loss: 101.3250 - false_loss: 0.0850 - true_loss: 1.0919 - val_loss: 5673.8535 - val_reconstruction_loss: 1896.1389 - val_kl_loss: 99.6452 - val_false_loss: 11.8761 - val_true_loss: 1.1525\n",
      "Epoch 2324/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.3539 - reconstruction_loss: 1889.6436 - kl_loss: 102.5054 - false_loss: 0.0850 - true_loss: 1.0918 - val_loss: 5673.5205 - val_reconstruction_loss: 1896.1385 - val_kl_loss: 99.6459 - val_false_loss: 11.8750 - val_true_loss: 1.1524\n",
      "Epoch 2325/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.3848 - reconstruction_loss: 1889.8624 - kl_loss: 101.9988 - false_loss: 0.0850 - true_loss: 1.0918 - val_loss: 5673.1982 - val_reconstruction_loss: 1896.1379 - val_kl_loss: 99.6465 - val_false_loss: 11.8739 - val_true_loss: 1.1524\n",
      "Epoch 2326/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.1205 - reconstruction_loss: 1889.7705 - kl_loss: 101.2548 - false_loss: 0.0849 - true_loss: 1.0917 - val_loss: 5672.8804 - val_reconstruction_loss: 1896.1376 - val_kl_loss: 99.6470 - val_false_loss: 11.8729 - val_true_loss: 1.1523\n",
      "Epoch 2327/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.9604 - reconstruction_loss: 1889.5306 - kl_loss: 102.7299 - false_loss: 0.0849 - true_loss: 1.0917 - val_loss: 5672.5605 - val_reconstruction_loss: 1896.1372 - val_kl_loss: 99.6473 - val_false_loss: 11.8718 - val_true_loss: 1.1523\n",
      "Epoch 2328/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.3645 - reconstruction_loss: 1889.4225 - kl_loss: 102.1216 - false_loss: 0.0849 - true_loss: 1.0916 - val_loss: 5672.2495 - val_reconstruction_loss: 1896.1366 - val_kl_loss: 99.6477 - val_false_loss: 11.8708 - val_true_loss: 1.1523\n",
      "Epoch 2329/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.9315 - reconstruction_loss: 1889.8866 - kl_loss: 102.7473 - false_loss: 0.0849 - true_loss: 1.0916 - val_loss: 5671.9233 - val_reconstruction_loss: 1896.1364 - val_kl_loss: 99.6477 - val_false_loss: 11.8698 - val_true_loss: 1.1522\n",
      "Epoch 2330/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.2224 - reconstruction_loss: 1889.8750 - kl_loss: 100.6774 - false_loss: 0.0849 - true_loss: 1.0915 - val_loss: 5671.6079 - val_reconstruction_loss: 1896.1359 - val_kl_loss: 99.6478 - val_false_loss: 11.8687 - val_true_loss: 1.1522\n",
      "Epoch 2331/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.7417 - reconstruction_loss: 1889.8525 - kl_loss: 102.3043 - false_loss: 0.0849 - true_loss: 1.0915 - val_loss: 5671.2871 - val_reconstruction_loss: 1896.1354 - val_kl_loss: 99.6481 - val_false_loss: 11.8677 - val_true_loss: 1.1521\n",
      "Epoch 2332/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5702 - reconstruction_loss: 1889.8154 - kl_loss: 102.3004 - false_loss: 0.0849 - true_loss: 1.0914 - val_loss: 5670.9619 - val_reconstruction_loss: 1896.1350 - val_kl_loss: 99.6489 - val_false_loss: 11.8666 - val_true_loss: 1.1521\n",
      "Epoch 2333/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.6314 - reconstruction_loss: 1889.6339 - kl_loss: 99.6677 - false_loss: 0.0849 - true_loss: 1.0914 - val_loss: 5670.6426 - val_reconstruction_loss: 1896.1348 - val_kl_loss: 99.6491 - val_false_loss: 11.8655 - val_true_loss: 1.1521\n",
      "Epoch 2334/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.5981 - reconstruction_loss: 1889.5742 - kl_loss: 99.6744 - false_loss: 0.0849 - true_loss: 1.0913 - val_loss: 5670.3159 - val_reconstruction_loss: 1896.1342 - val_kl_loss: 99.6491 - val_false_loss: 11.8645 - val_true_loss: 1.1520\n",
      "Epoch 2335/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8358 - reconstruction_loss: 1889.7881 - kl_loss: 99.1922 - false_loss: 0.0849 - true_loss: 1.0913 - val_loss: 5669.9883 - val_reconstruction_loss: 1896.1339 - val_kl_loss: 99.6489 - val_false_loss: 11.8634 - val_true_loss: 1.1520\n",
      "Epoch 2336/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.7308 - reconstruction_loss: 1890.4801 - kl_loss: 97.9677 - false_loss: 0.0849 - true_loss: 1.0913 - val_loss: 5669.6714 - val_reconstruction_loss: 1896.1334 - val_kl_loss: 99.6482 - val_false_loss: 11.8623 - val_true_loss: 1.1520\n",
      "Epoch 2337/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1135 - reconstruction_loss: 1890.5555 - kl_loss: 98.1955 - false_loss: 0.0849 - true_loss: 1.0912 - val_loss: 5669.3472 - val_reconstruction_loss: 1896.1331 - val_kl_loss: 99.6480 - val_false_loss: 11.8613 - val_true_loss: 1.1519\n",
      "Epoch 2338/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.6533 - reconstruction_loss: 1890.1700 - kl_loss: 98.1408 - false_loss: 0.0849 - true_loss: 1.0912 - val_loss: 5669.0249 - val_reconstruction_loss: 1896.1327 - val_kl_loss: 99.6481 - val_false_loss: 11.8602 - val_true_loss: 1.1519\n",
      "Epoch 2339/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.0057 - reconstruction_loss: 1890.0347 - kl_loss: 100.1105 - false_loss: 0.0849 - true_loss: 1.0912 - val_loss: 5668.7061 - val_reconstruction_loss: 1896.1323 - val_kl_loss: 99.6483 - val_false_loss: 11.8592 - val_true_loss: 1.1519\n",
      "Epoch 2340/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.4523 - reconstruction_loss: 1889.8461 - kl_loss: 99.8241 - false_loss: 0.0848 - true_loss: 1.0911 - val_loss: 5668.3892 - val_reconstruction_loss: 1896.1318 - val_kl_loss: 99.6487 - val_false_loss: 11.8581 - val_true_loss: 1.1518\n",
      "Epoch 2341/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2226.3670 - reconstruction_loss: 1889.6562 - kl_loss: 100.5055 - false_loss: 0.0848 - true_loss: 1.0911 - val_loss: 5668.0669 - val_reconstruction_loss: 1896.1313 - val_kl_loss: 99.6493 - val_false_loss: 11.8571 - val_true_loss: 1.1518\n",
      "Epoch 2342/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.6209 - reconstruction_loss: 1889.7148 - kl_loss: 98.6152 - false_loss: 0.0848 - true_loss: 1.0910 - val_loss: 5667.7432 - val_reconstruction_loss: 1896.1311 - val_kl_loss: 99.6499 - val_false_loss: 11.8560 - val_true_loss: 1.1517\n",
      "Epoch 2343/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.3930 - reconstruction_loss: 1890.3129 - kl_loss: 97.2246 - false_loss: 0.0848 - true_loss: 1.0910 - val_loss: 5667.4243 - val_reconstruction_loss: 1896.1306 - val_kl_loss: 99.6495 - val_false_loss: 11.8549 - val_true_loss: 1.1517\n",
      "Epoch 2344/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.8500 - reconstruction_loss: 1890.4359 - kl_loss: 97.9105 - false_loss: 0.0848 - true_loss: 1.0910 - val_loss: 5667.1011 - val_reconstruction_loss: 1896.1301 - val_kl_loss: 99.6493 - val_false_loss: 11.8539 - val_true_loss: 1.1517\n",
      "Epoch 2345/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.6919 - reconstruction_loss: 1890.0664 - kl_loss: 98.9834 - false_loss: 0.0848 - true_loss: 1.0909 - val_loss: 5666.7832 - val_reconstruction_loss: 1896.1299 - val_kl_loss: 99.6497 - val_false_loss: 11.8528 - val_true_loss: 1.1516\n",
      "Epoch 2346/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1219 - reconstruction_loss: 1889.6357 - kl_loss: 98.4407 - false_loss: 0.0848 - true_loss: 1.0909 - val_loss: 5666.4731 - val_reconstruction_loss: 1896.1294 - val_kl_loss: 99.6498 - val_false_loss: 11.8518 - val_true_loss: 1.1516\n",
      "Epoch 2347/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.0779 - reconstruction_loss: 1889.5509 - kl_loss: 99.7838 - false_loss: 0.0848 - true_loss: 1.0908 - val_loss: 5666.1509 - val_reconstruction_loss: 1896.1288 - val_kl_loss: 99.6499 - val_false_loss: 11.8507 - val_true_loss: 1.1516\n",
      "Epoch 2348/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.1513 - reconstruction_loss: 1889.4238 - kl_loss: 100.4197 - false_loss: 0.0848 - true_loss: 1.0908 - val_loss: 5665.8398 - val_reconstruction_loss: 1896.1285 - val_kl_loss: 99.6501 - val_false_loss: 11.8497 - val_true_loss: 1.1515\n",
      "Epoch 2349/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.6684 - reconstruction_loss: 1889.5836 - kl_loss: 99.9836 - false_loss: 0.0848 - true_loss: 1.0908 - val_loss: 5665.5195 - val_reconstruction_loss: 1896.1283 - val_kl_loss: 99.6507 - val_false_loss: 11.8487 - val_true_loss: 1.1515\n",
      "Epoch 2350/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9353 - reconstruction_loss: 1889.5824 - kl_loss: 100.7358 - false_loss: 0.0848 - true_loss: 1.0907 - val_loss: 5665.2046 - val_reconstruction_loss: 1896.1277 - val_kl_loss: 99.6512 - val_false_loss: 11.8476 - val_true_loss: 1.1514\n",
      "Epoch 2351/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.6531 - reconstruction_loss: 1889.3862 - kl_loss: 99.8692 - false_loss: 0.0848 - true_loss: 1.0907 - val_loss: 5664.8789 - val_reconstruction_loss: 1896.1272 - val_kl_loss: 99.6520 - val_false_loss: 11.8466 - val_true_loss: 1.1514\n",
      "Epoch 2352/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.7103 - reconstruction_loss: 1889.7230 - kl_loss: 98.7908 - false_loss: 0.0848 - true_loss: 1.0906 - val_loss: 5664.5659 - val_reconstruction_loss: 1896.1270 - val_kl_loss: 99.6520 - val_false_loss: 11.8455 - val_true_loss: 1.1514\n",
      "Epoch 2353/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.7268 - reconstruction_loss: 1889.9967 - kl_loss: 100.3431 - false_loss: 0.0848 - true_loss: 1.0906 - val_loss: 5664.2539 - val_reconstruction_loss: 1896.1266 - val_kl_loss: 99.6517 - val_false_loss: 11.8445 - val_true_loss: 1.1513\n",
      "Epoch 2354/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.6503 - reconstruction_loss: 1889.9102 - kl_loss: 98.4919 - false_loss: 0.0848 - true_loss: 1.0905 - val_loss: 5663.9409 - val_reconstruction_loss: 1896.1261 - val_kl_loss: 99.6517 - val_false_loss: 11.8435 - val_true_loss: 1.1513\n",
      "Epoch 2355/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3943 - reconstruction_loss: 1889.8666 - kl_loss: 100.0432 - false_loss: 0.0847 - true_loss: 1.0905 - val_loss: 5663.6348 - val_reconstruction_loss: 1896.1256 - val_kl_loss: 99.6520 - val_false_loss: 11.8425 - val_true_loss: 1.1512\n",
      "Epoch 2356/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.3801 - reconstruction_loss: 1890.0024 - kl_loss: 100.3223 - false_loss: 0.0847 - true_loss: 1.0905 - val_loss: 5663.3198 - val_reconstruction_loss: 1896.1252 - val_kl_loss: 99.6522 - val_false_loss: 11.8414 - val_true_loss: 1.1512\n",
      "Epoch 2357/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.2101 - reconstruction_loss: 1890.1193 - kl_loss: 100.1463 - false_loss: 0.0847 - true_loss: 1.0904 - val_loss: 5663.0054 - val_reconstruction_loss: 1896.1248 - val_kl_loss: 99.6525 - val_false_loss: 11.8404 - val_true_loss: 1.1512\n",
      "Epoch 2358/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.0869 - reconstruction_loss: 1889.5697 - kl_loss: 99.9300 - false_loss: 0.0847 - true_loss: 1.0904 - val_loss: 5662.6914 - val_reconstruction_loss: 1896.1244 - val_kl_loss: 99.6530 - val_false_loss: 11.8394 - val_true_loss: 1.1511\n",
      "Epoch 2359/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.3589 - reconstruction_loss: 1889.7296 - kl_loss: 100.4872 - false_loss: 0.0847 - true_loss: 1.0903 - val_loss: 5662.3765 - val_reconstruction_loss: 1896.1240 - val_kl_loss: 99.6534 - val_false_loss: 11.8383 - val_true_loss: 1.1511\n",
      "Epoch 2360/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.4280 - reconstruction_loss: 1889.5674 - kl_loss: 101.4264 - false_loss: 0.0847 - true_loss: 1.0903 - val_loss: 5662.0669 - val_reconstruction_loss: 1896.1234 - val_kl_loss: 99.6536 - val_false_loss: 11.8373 - val_true_loss: 1.1510\n",
      "Epoch 2361/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0965 - reconstruction_loss: 1889.5358 - kl_loss: 101.5998 - false_loss: 0.0847 - true_loss: 1.0902 - val_loss: 5661.7500 - val_reconstruction_loss: 1896.1232 - val_kl_loss: 99.6536 - val_false_loss: 11.8363 - val_true_loss: 1.1510\n",
      "Epoch 2362/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.2418 - reconstruction_loss: 1889.6412 - kl_loss: 100.8814 - false_loss: 0.0847 - true_loss: 1.0902 - val_loss: 5661.4331 - val_reconstruction_loss: 1896.1229 - val_kl_loss: 99.6536 - val_false_loss: 11.8352 - val_true_loss: 1.1509\n",
      "Epoch 2363/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.1900 - reconstruction_loss: 1889.9071 - kl_loss: 101.2849 - false_loss: 0.0847 - true_loss: 1.0901 - val_loss: 5661.1167 - val_reconstruction_loss: 1896.1223 - val_kl_loss: 99.6539 - val_false_loss: 11.8342 - val_true_loss: 1.1509\n",
      "Epoch 2364/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.0282 - reconstruction_loss: 1890.1821 - kl_loss: 102.1910 - false_loss: 0.0847 - true_loss: 1.0901 - val_loss: 5660.7969 - val_reconstruction_loss: 1896.1221 - val_kl_loss: 99.6544 - val_false_loss: 11.8331 - val_true_loss: 1.1509\n",
      "Epoch 2365/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.3213 - reconstruction_loss: 1889.9615 - kl_loss: 102.2500 - false_loss: 0.0847 - true_loss: 1.0900 - val_loss: 5660.4868 - val_reconstruction_loss: 1896.1217 - val_kl_loss: 99.6552 - val_false_loss: 11.8321 - val_true_loss: 1.1508\n",
      "Epoch 2366/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0685 - reconstruction_loss: 1889.7213 - kl_loss: 102.4394 - false_loss: 0.0847 - true_loss: 1.0900 - val_loss: 5660.1724 - val_reconstruction_loss: 1896.1212 - val_kl_loss: 99.6557 - val_false_loss: 11.8311 - val_true_loss: 1.1508\n",
      "Epoch 2367/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.0636 - reconstruction_loss: 1889.4948 - kl_loss: 102.5831 - false_loss: 0.0847 - true_loss: 1.0899 - val_loss: 5659.8706 - val_reconstruction_loss: 1896.1207 - val_kl_loss: 99.6562 - val_false_loss: 11.8301 - val_true_loss: 1.1507\n",
      "Epoch 2368/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7870 - reconstruction_loss: 1889.4506 - kl_loss: 101.4711 - false_loss: 0.0847 - true_loss: 1.0899 - val_loss: 5659.5576 - val_reconstruction_loss: 1896.1204 - val_kl_loss: 99.6565 - val_false_loss: 11.8291 - val_true_loss: 1.1507\n",
      "Epoch 2369/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.3343 - reconstruction_loss: 1889.3291 - kl_loss: 100.9580 - false_loss: 0.0846 - true_loss: 1.0898 - val_loss: 5659.2534 - val_reconstruction_loss: 1896.1199 - val_kl_loss: 99.6567 - val_false_loss: 11.8281 - val_true_loss: 1.1506\n",
      "Epoch 2370/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.7679 - reconstruction_loss: 1889.6730 - kl_loss: 101.1212 - false_loss: 0.0846 - true_loss: 1.0898 - val_loss: 5658.9473 - val_reconstruction_loss: 1896.1194 - val_kl_loss: 99.6570 - val_false_loss: 11.8271 - val_true_loss: 1.1506\n",
      "Epoch 2371/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1510 - reconstruction_loss: 1889.5004 - kl_loss: 99.1145 - false_loss: 0.0846 - true_loss: 1.0898 - val_loss: 5658.6470 - val_reconstruction_loss: 1896.1190 - val_kl_loss: 99.6557 - val_false_loss: 11.8261 - val_true_loss: 1.1506\n",
      "Epoch 2372/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5972 - reconstruction_loss: 1889.6567 - kl_loss: 98.2914 - false_loss: 0.0846 - true_loss: 1.0897 - val_loss: 5658.3359 - val_reconstruction_loss: 1896.1187 - val_kl_loss: 99.6564 - val_false_loss: 11.8250 - val_true_loss: 1.1506\n",
      "Epoch 2373/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.4547 - reconstruction_loss: 1889.5677 - kl_loss: 99.0058 - false_loss: 0.0846 - true_loss: 1.0897 - val_loss: 5658.0181 - val_reconstruction_loss: 1896.1183 - val_kl_loss: 99.6564 - val_false_loss: 11.8240 - val_true_loss: 1.1505\n",
      "Epoch 2374/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.4120 - reconstruction_loss: 1889.4286 - kl_loss: 100.0999 - false_loss: 0.0846 - true_loss: 1.0897 - val_loss: 5657.7021 - val_reconstruction_loss: 1896.1178 - val_kl_loss: 99.6566 - val_false_loss: 11.8230 - val_true_loss: 1.1505\n",
      "Epoch 2375/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.2073 - reconstruction_loss: 1889.6576 - kl_loss: 98.1632 - false_loss: 0.0846 - true_loss: 1.0896 - val_loss: 5657.3940 - val_reconstruction_loss: 1896.1174 - val_kl_loss: 99.6567 - val_false_loss: 11.8219 - val_true_loss: 1.1505\n",
      "Epoch 2376/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.1152 - reconstruction_loss: 1890.5096 - kl_loss: 98.5108 - false_loss: 0.0846 - true_loss: 1.0896 - val_loss: 5657.0933 - val_reconstruction_loss: 1896.1172 - val_kl_loss: 99.6564 - val_false_loss: 11.8209 - val_true_loss: 1.1504\n",
      "Epoch 2377/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.0514 - reconstruction_loss: 1890.2572 - kl_loss: 99.2077 - false_loss: 0.0846 - true_loss: 1.0895 - val_loss: 5656.7725 - val_reconstruction_loss: 1896.1167 - val_kl_loss: 99.6567 - val_false_loss: 11.8199 - val_true_loss: 1.1504\n",
      "Epoch 2378/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.7018 - reconstruction_loss: 1890.0088 - kl_loss: 100.9657 - false_loss: 0.0846 - true_loss: 1.0895 - val_loss: 5656.4629 - val_reconstruction_loss: 1896.1162 - val_kl_loss: 99.6573 - val_false_loss: 11.8189 - val_true_loss: 1.1503\n",
      "Epoch 2379/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.7438 - reconstruction_loss: 1889.6387 - kl_loss: 101.3024 - false_loss: 0.0846 - true_loss: 1.0894 - val_loss: 5656.1538 - val_reconstruction_loss: 1896.1158 - val_kl_loss: 99.6579 - val_false_loss: 11.8179 - val_true_loss: 1.1503\n",
      "Epoch 2380/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.7373 - reconstruction_loss: 1889.4635 - kl_loss: 101.8276 - false_loss: 0.0846 - true_loss: 1.0894 - val_loss: 5655.8472 - val_reconstruction_loss: 1896.1155 - val_kl_loss: 99.6586 - val_false_loss: 11.8169 - val_true_loss: 1.1502\n",
      "Epoch 2381/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.1479 - reconstruction_loss: 1889.5353 - kl_loss: 102.0307 - false_loss: 0.0846 - true_loss: 1.0893 - val_loss: 5655.5430 - val_reconstruction_loss: 1896.1151 - val_kl_loss: 99.6588 - val_false_loss: 11.8159 - val_true_loss: 1.1502\n",
      "Epoch 2382/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.5912 - reconstruction_loss: 1889.8143 - kl_loss: 102.6297 - false_loss: 0.0846 - true_loss: 1.0893 - val_loss: 5655.2295 - val_reconstruction_loss: 1896.1146 - val_kl_loss: 99.6595 - val_false_loss: 11.8148 - val_true_loss: 1.1501\n",
      "Epoch 2383/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.3339 - reconstruction_loss: 1889.6815 - kl_loss: 102.8354 - false_loss: 0.0845 - true_loss: 1.0892 - val_loss: 5654.9180 - val_reconstruction_loss: 1896.1141 - val_kl_loss: 99.6600 - val_false_loss: 11.8138 - val_true_loss: 1.1501\n",
      "Epoch 2384/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.1688 - reconstruction_loss: 1890.1377 - kl_loss: 102.7084 - false_loss: 0.0845 - true_loss: 1.0892 - val_loss: 5654.6035 - val_reconstruction_loss: 1896.1135 - val_kl_loss: 99.6610 - val_false_loss: 11.8128 - val_true_loss: 1.1500\n",
      "Epoch 2385/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.5137 - reconstruction_loss: 1889.6680 - kl_loss: 103.0195 - false_loss: 0.0845 - true_loss: 1.0891 - val_loss: 5654.3091 - val_reconstruction_loss: 1896.1133 - val_kl_loss: 99.6618 - val_false_loss: 11.8118 - val_true_loss: 1.1500\n",
      "Epoch 2386/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.9470 - reconstruction_loss: 1889.5059 - kl_loss: 101.7564 - false_loss: 0.0845 - true_loss: 1.0891 - val_loss: 5654.0034 - val_reconstruction_loss: 1896.1128 - val_kl_loss: 99.6623 - val_false_loss: 11.8108 - val_true_loss: 1.1500\n",
      "Epoch 2387/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.0531 - reconstruction_loss: 1890.0562 - kl_loss: 102.7706 - false_loss: 0.0845 - true_loss: 1.0890 - val_loss: 5653.7065 - val_reconstruction_loss: 1896.1125 - val_kl_loss: 99.6625 - val_false_loss: 11.8098 - val_true_loss: 1.1499\n",
      "Epoch 2388/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.3492 - reconstruction_loss: 1889.6693 - kl_loss: 102.1012 - false_loss: 0.0845 - true_loss: 1.0890 - val_loss: 5653.3975 - val_reconstruction_loss: 1896.1121 - val_kl_loss: 99.6629 - val_false_loss: 11.8088 - val_true_loss: 1.1499\n",
      "Epoch 2389/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.2253 - reconstruction_loss: 1889.5184 - kl_loss: 103.6674 - false_loss: 0.0845 - true_loss: 1.0889 - val_loss: 5653.0884 - val_reconstruction_loss: 1896.1117 - val_kl_loss: 99.6637 - val_false_loss: 11.8078 - val_true_loss: 1.1498\n",
      "Epoch 2390/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.0069 - reconstruction_loss: 1889.6107 - kl_loss: 102.8320 - false_loss: 0.0845 - true_loss: 1.0889 - val_loss: 5652.7788 - val_reconstruction_loss: 1896.1112 - val_kl_loss: 99.6647 - val_false_loss: 11.8068 - val_true_loss: 1.1498\n",
      "Epoch 2391/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.7390 - reconstruction_loss: 1889.7728 - kl_loss: 103.1234 - false_loss: 0.0845 - true_loss: 1.0888 - val_loss: 5652.4614 - val_reconstruction_loss: 1896.1108 - val_kl_loss: 99.6657 - val_false_loss: 11.8057 - val_true_loss: 1.1497\n",
      "Epoch 2392/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.4895 - reconstruction_loss: 1890.0963 - kl_loss: 102.8264 - false_loss: 0.0845 - true_loss: 1.0888 - val_loss: 5652.1523 - val_reconstruction_loss: 1896.1104 - val_kl_loss: 99.6661 - val_false_loss: 11.8047 - val_true_loss: 1.1497\n",
      "Epoch 2393/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2204.9894 - reconstruction_loss: 1889.2816 - kl_loss: 102.8184 - false_loss: 0.0845 - true_loss: 1.0887 - val_loss: 5651.8379 - val_reconstruction_loss: 1896.1100 - val_kl_loss: 99.6666 - val_false_loss: 11.8037 - val_true_loss: 1.1496\n",
      "Epoch 2394/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.0543 - reconstruction_loss: 1889.8492 - kl_loss: 103.3607 - false_loss: 0.0845 - true_loss: 1.0887 - val_loss: 5651.5396 - val_reconstruction_loss: 1896.1095 - val_kl_loss: 99.6673 - val_false_loss: 11.8027 - val_true_loss: 1.1496\n",
      "Epoch 2395/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.1637 - reconstruction_loss: 1889.2904 - kl_loss: 103.1337 - false_loss: 0.0845 - true_loss: 1.0886 - val_loss: 5651.2275 - val_reconstruction_loss: 1896.1090 - val_kl_loss: 99.6682 - val_false_loss: 11.8017 - val_true_loss: 1.1495\n",
      "Epoch 2396/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.5582 - reconstruction_loss: 1890.0055 - kl_loss: 103.3359 - false_loss: 0.0844 - true_loss: 1.0886 - val_loss: 5650.9102 - val_reconstruction_loss: 1896.1086 - val_kl_loss: 99.6693 - val_false_loss: 11.8006 - val_true_loss: 1.1495\n",
      "Epoch 2397/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.8750 - reconstruction_loss: 1889.4838 - kl_loss: 103.9448 - false_loss: 0.0844 - true_loss: 1.0885 - val_loss: 5650.5996 - val_reconstruction_loss: 1896.1083 - val_kl_loss: 99.6705 - val_false_loss: 11.7996 - val_true_loss: 1.1495\n",
      "Epoch 2398/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.5016 - reconstruction_loss: 1889.6263 - kl_loss: 102.3272 - false_loss: 0.0844 - true_loss: 1.0885 - val_loss: 5650.2915 - val_reconstruction_loss: 1896.1080 - val_kl_loss: 99.6715 - val_false_loss: 11.7986 - val_true_loss: 1.1494\n",
      "Epoch 2399/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.3315 - reconstruction_loss: 1890.6986 - kl_loss: 101.7004 - false_loss: 0.0844 - true_loss: 1.0884 - val_loss: 5649.9858 - val_reconstruction_loss: 1896.1074 - val_kl_loss: 99.6730 - val_false_loss: 11.7976 - val_true_loss: 1.1494\n",
      "Epoch 2400/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.8762 - reconstruction_loss: 1890.0660 - kl_loss: 102.2352 - false_loss: 0.0844 - true_loss: 1.0884 - val_loss: 5649.6851 - val_reconstruction_loss: 1896.1071 - val_kl_loss: 99.6735 - val_false_loss: 11.7966 - val_true_loss: 1.1493\n",
      "Epoch 2401/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.6551 - reconstruction_loss: 1890.3390 - kl_loss: 101.3897 - false_loss: 0.0844 - true_loss: 1.0884 - val_loss: 5649.3604 - val_reconstruction_loss: 1896.1066 - val_kl_loss: 99.6741 - val_false_loss: 11.7955 - val_true_loss: 1.1493\n",
      "Epoch 2402/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.0956 - reconstruction_loss: 1890.2955 - kl_loss: 103.1667 - false_loss: 0.0844 - true_loss: 1.0883 - val_loss: 5649.0605 - val_reconstruction_loss: 1896.1061 - val_kl_loss: 99.6746 - val_false_loss: 11.7945 - val_true_loss: 1.1492\n",
      "Epoch 2403/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.7569 - reconstruction_loss: 1890.4409 - kl_loss: 102.7362 - false_loss: 0.0844 - true_loss: 1.0883 - val_loss: 5648.7607 - val_reconstruction_loss: 1896.1060 - val_kl_loss: 99.6751 - val_false_loss: 11.7936 - val_true_loss: 1.1492\n",
      "Epoch 2404/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.3306 - reconstruction_loss: 1890.1234 - kl_loss: 102.6776 - false_loss: 0.0844 - true_loss: 1.0882 - val_loss: 5648.4624 - val_reconstruction_loss: 1896.1056 - val_kl_loss: 99.6756 - val_false_loss: 11.7926 - val_true_loss: 1.1492\n",
      "Epoch 2405/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.6433 - reconstruction_loss: 1889.9961 - kl_loss: 101.8402 - false_loss: 0.0844 - true_loss: 1.0882 - val_loss: 5648.1636 - val_reconstruction_loss: 1896.1052 - val_kl_loss: 99.6760 - val_false_loss: 11.7916 - val_true_loss: 1.1491\n",
      "Epoch 2406/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.4880 - reconstruction_loss: 1889.8470 - kl_loss: 101.5118 - false_loss: 0.0844 - true_loss: 1.0881 - val_loss: 5647.8823 - val_reconstruction_loss: 1896.1046 - val_kl_loss: 99.6763 - val_false_loss: 11.7907 - val_true_loss: 1.1491\n",
      "Epoch 2407/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.4020 - reconstruction_loss: 1889.3558 - kl_loss: 101.5036 - false_loss: 0.0844 - true_loss: 1.0881 - val_loss: 5647.5757 - val_reconstruction_loss: 1896.1042 - val_kl_loss: 99.6768 - val_false_loss: 11.7897 - val_true_loss: 1.1490\n",
      "Epoch 2408/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.8236 - reconstruction_loss: 1889.6852 - kl_loss: 100.8882 - false_loss: 0.0844 - true_loss: 1.0880 - val_loss: 5647.2686 - val_reconstruction_loss: 1896.1039 - val_kl_loss: 99.6771 - val_false_loss: 11.7886 - val_true_loss: 1.1490\n",
      "Epoch 2409/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.1217 - reconstruction_loss: 1889.7227 - kl_loss: 99.3536 - false_loss: 0.0844 - true_loss: 1.0880 - val_loss: 5646.9648 - val_reconstruction_loss: 1896.1034 - val_kl_loss: 99.6771 - val_false_loss: 11.7876 - val_true_loss: 1.1490\n",
      "Epoch 2410/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.0044 - reconstruction_loss: 1889.7748 - kl_loss: 98.8482 - false_loss: 0.0844 - true_loss: 1.0880 - val_loss: 5646.6641 - val_reconstruction_loss: 1896.1029 - val_kl_loss: 99.6765 - val_false_loss: 11.7867 - val_true_loss: 1.1489\n",
      "Epoch 2411/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.1358 - reconstruction_loss: 1889.5946 - kl_loss: 99.8734 - false_loss: 0.0843 - true_loss: 1.0879 - val_loss: 5646.3540 - val_reconstruction_loss: 1896.1025 - val_kl_loss: 99.6770 - val_false_loss: 11.7856 - val_true_loss: 1.1489\n",
      "Epoch 2412/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.6837 - reconstruction_loss: 1889.8854 - kl_loss: 99.8910 - false_loss: 0.0843 - true_loss: 1.0879 - val_loss: 5646.0571 - val_reconstruction_loss: 1896.1023 - val_kl_loss: 99.6772 - val_false_loss: 11.7847 - val_true_loss: 1.1489\n",
      "Epoch 2413/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.1938 - reconstruction_loss: 1890.3119 - kl_loss: 97.6721 - false_loss: 0.0843 - true_loss: 1.0878 - val_loss: 5645.7402 - val_reconstruction_loss: 1896.1018 - val_kl_loss: 99.6772 - val_false_loss: 11.7836 - val_true_loss: 1.1488\n",
      "Epoch 2414/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.8833 - reconstruction_loss: 1890.3550 - kl_loss: 97.1690 - false_loss: 0.0843 - true_loss: 1.0878 - val_loss: 5645.4224 - val_reconstruction_loss: 1896.1012 - val_kl_loss: 99.6776 - val_false_loss: 11.7826 - val_true_loss: 1.1488\n",
      "Epoch 2415/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.8022 - reconstruction_loss: 1889.8506 - kl_loss: 100.6849 - false_loss: 0.0843 - true_loss: 1.0878 - val_loss: 5645.1167 - val_reconstruction_loss: 1896.1011 - val_kl_loss: 99.6782 - val_false_loss: 11.7816 - val_true_loss: 1.1487\n",
      "Epoch 2416/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.2277 - reconstruction_loss: 1889.9209 - kl_loss: 100.5867 - false_loss: 0.0843 - true_loss: 1.0877 - val_loss: 5644.8203 - val_reconstruction_loss: 1896.1006 - val_kl_loss: 99.6790 - val_false_loss: 11.7806 - val_true_loss: 1.1487\n",
      "Epoch 2417/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.0458 - reconstruction_loss: 1889.6215 - kl_loss: 99.9400 - false_loss: 0.0843 - true_loss: 1.0877 - val_loss: 5644.5020 - val_reconstruction_loss: 1896.1003 - val_kl_loss: 99.6801 - val_false_loss: 11.7795 - val_true_loss: 1.1487\n",
      "Epoch 2418/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.2854 - reconstruction_loss: 1889.7272 - kl_loss: 102.0792 - false_loss: 0.0843 - true_loss: 1.0876 - val_loss: 5644.1982 - val_reconstruction_loss: 1896.0997 - val_kl_loss: 99.6812 - val_false_loss: 11.7785 - val_true_loss: 1.1486\n",
      "Epoch 2419/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.8638 - reconstruction_loss: 1889.9967 - kl_loss: 102.0023 - false_loss: 0.0843 - true_loss: 1.0876 - val_loss: 5643.8877 - val_reconstruction_loss: 1896.0995 - val_kl_loss: 99.6817 - val_false_loss: 11.7775 - val_true_loss: 1.1486\n",
      "Epoch 2420/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.1812 - reconstruction_loss: 1890.2396 - kl_loss: 99.9521 - false_loss: 0.0843 - true_loss: 1.0875 - val_loss: 5643.5801 - val_reconstruction_loss: 1896.0990 - val_kl_loss: 99.6817 - val_false_loss: 11.7765 - val_true_loss: 1.1485\n",
      "Epoch 2421/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.9997 - reconstruction_loss: 1889.8359 - kl_loss: 101.3926 - false_loss: 0.0843 - true_loss: 1.0875 - val_loss: 5643.2749 - val_reconstruction_loss: 1896.0986 - val_kl_loss: 99.6814 - val_false_loss: 11.7755 - val_true_loss: 1.1485\n",
      "Epoch 2422/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.5051 - reconstruction_loss: 1889.4703 - kl_loss: 100.5180 - false_loss: 0.0843 - true_loss: 1.0875 - val_loss: 5642.9741 - val_reconstruction_loss: 1896.0981 - val_kl_loss: 99.6815 - val_false_loss: 11.7745 - val_true_loss: 1.1485\n",
      "Epoch 2423/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.4774 - reconstruction_loss: 1890.0599 - kl_loss: 99.2499 - false_loss: 0.0843 - true_loss: 1.0874 - val_loss: 5642.6641 - val_reconstruction_loss: 1896.0979 - val_kl_loss: 99.6825 - val_false_loss: 11.7735 - val_true_loss: 1.1484\n",
      "Epoch 2424/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.7907 - reconstruction_loss: 1889.9176 - kl_loss: 100.0586 - false_loss: 0.0843 - true_loss: 1.0874 - val_loss: 5642.3638 - val_reconstruction_loss: 1896.0974 - val_kl_loss: 99.6826 - val_false_loss: 11.7725 - val_true_loss: 1.1484\n",
      "Epoch 2425/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4099 - reconstruction_loss: 1890.5840 - kl_loss: 99.9322 - false_loss: 0.0842 - true_loss: 1.0873 - val_loss: 5642.0649 - val_reconstruction_loss: 1896.0970 - val_kl_loss: 99.6826 - val_false_loss: 11.7715 - val_true_loss: 1.1483\n",
      "Epoch 2426/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.1430 - reconstruction_loss: 1889.8815 - kl_loss: 99.5488 - false_loss: 0.0842 - true_loss: 1.0873 - val_loss: 5641.7710 - val_reconstruction_loss: 1896.0966 - val_kl_loss: 99.6831 - val_false_loss: 11.7706 - val_true_loss: 1.1483\n",
      "Epoch 2427/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.5201 - reconstruction_loss: 1889.8068 - kl_loss: 100.7328 - false_loss: 0.0842 - true_loss: 1.0872 - val_loss: 5641.4717 - val_reconstruction_loss: 1896.0961 - val_kl_loss: 99.6836 - val_false_loss: 11.7696 - val_true_loss: 1.1483\n",
      "Epoch 2428/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.0756 - reconstruction_loss: 1889.3115 - kl_loss: 101.8874 - false_loss: 0.0842 - true_loss: 1.0872 - val_loss: 5641.1631 - val_reconstruction_loss: 1896.0957 - val_kl_loss: 99.6839 - val_false_loss: 11.7686 - val_true_loss: 1.1482\n",
      "Epoch 2429/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.1649 - reconstruction_loss: 1889.5597 - kl_loss: 101.6205 - false_loss: 0.0842 - true_loss: 1.0872 - val_loss: 5640.8555 - val_reconstruction_loss: 1896.0953 - val_kl_loss: 99.6843 - val_false_loss: 11.7676 - val_true_loss: 1.1482\n",
      "Epoch 2430/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.9969 - reconstruction_loss: 1889.7408 - kl_loss: 101.5830 - false_loss: 0.0842 - true_loss: 1.0871 - val_loss: 5640.5532 - val_reconstruction_loss: 1896.0947 - val_kl_loss: 99.6853 - val_false_loss: 11.7666 - val_true_loss: 1.1481\n",
      "Epoch 2431/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8844 - reconstruction_loss: 1889.8809 - kl_loss: 99.5192 - false_loss: 0.0842 - true_loss: 1.0871 - val_loss: 5640.2505 - val_reconstruction_loss: 1896.0942 - val_kl_loss: 99.6860 - val_false_loss: 11.7656 - val_true_loss: 1.1481\n",
      "Epoch 2432/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.8135 - reconstruction_loss: 1889.7787 - kl_loss: 99.4791 - false_loss: 0.0842 - true_loss: 1.0870 - val_loss: 5639.9429 - val_reconstruction_loss: 1896.0939 - val_kl_loss: 99.6864 - val_false_loss: 11.7645 - val_true_loss: 1.1481\n",
      "Epoch 2433/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1456 - reconstruction_loss: 1889.8179 - kl_loss: 100.8924 - false_loss: 0.0842 - true_loss: 1.0870 - val_loss: 5639.6382 - val_reconstruction_loss: 1896.0935 - val_kl_loss: 99.6869 - val_false_loss: 11.7635 - val_true_loss: 1.1480\n",
      "Epoch 2434/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.0265 - reconstruction_loss: 1889.6429 - kl_loss: 101.6970 - false_loss: 0.0842 - true_loss: 1.0869 - val_loss: 5639.3320 - val_reconstruction_loss: 1896.0931 - val_kl_loss: 99.6873 - val_false_loss: 11.7625 - val_true_loss: 1.1480\n",
      "Epoch 2435/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7489 - reconstruction_loss: 1889.8472 - kl_loss: 101.6322 - false_loss: 0.0842 - true_loss: 1.0869 - val_loss: 5639.0332 - val_reconstruction_loss: 1896.0927 - val_kl_loss: 99.6874 - val_false_loss: 11.7616 - val_true_loss: 1.1479\n",
      "Epoch 2436/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.6012 - reconstruction_loss: 1889.5967 - kl_loss: 100.6086 - false_loss: 0.0842 - true_loss: 1.0869 - val_loss: 5638.7373 - val_reconstruction_loss: 1896.0924 - val_kl_loss: 99.6874 - val_false_loss: 11.7606 - val_true_loss: 1.1479\n",
      "Epoch 2437/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.7979 - reconstruction_loss: 1889.8678 - kl_loss: 98.4010 - false_loss: 0.0842 - true_loss: 1.0868 - val_loss: 5638.4277 - val_reconstruction_loss: 1896.0920 - val_kl_loss: 99.6879 - val_false_loss: 11.7596 - val_true_loss: 1.1479\n",
      "Epoch 2438/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.5629 - reconstruction_loss: 1889.4955 - kl_loss: 100.4947 - false_loss: 0.0842 - true_loss: 1.0868 - val_loss: 5638.1333 - val_reconstruction_loss: 1896.0914 - val_kl_loss: 99.6883 - val_false_loss: 11.7586 - val_true_loss: 1.1478\n",
      "Epoch 2439/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.1304 - reconstruction_loss: 1889.3615 - kl_loss: 100.7835 - false_loss: 0.0842 - true_loss: 1.0867 - val_loss: 5637.8291 - val_reconstruction_loss: 1896.0911 - val_kl_loss: 99.6889 - val_false_loss: 11.7576 - val_true_loss: 1.1478\n",
      "Epoch 2440/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.0465 - reconstruction_loss: 1889.8778 - kl_loss: 100.2392 - false_loss: 0.0841 - true_loss: 1.0867 - val_loss: 5637.5225 - val_reconstruction_loss: 1896.0907 - val_kl_loss: 99.6894 - val_false_loss: 11.7566 - val_true_loss: 1.1477\n",
      "Epoch 2441/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.3054 - reconstruction_loss: 1889.6709 - kl_loss: 102.0880 - false_loss: 0.0841 - true_loss: 1.0866 - val_loss: 5637.2280 - val_reconstruction_loss: 1896.0902 - val_kl_loss: 99.6900 - val_false_loss: 11.7556 - val_true_loss: 1.1477\n",
      "Epoch 2442/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.5050 - reconstruction_loss: 1889.3976 - kl_loss: 102.1970 - false_loss: 0.0841 - true_loss: 1.0866 - val_loss: 5636.9302 - val_reconstruction_loss: 1896.0898 - val_kl_loss: 99.6907 - val_false_loss: 11.7546 - val_true_loss: 1.1476\n",
      "Epoch 2443/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.2353 - reconstruction_loss: 1890.0674 - kl_loss: 102.9369 - false_loss: 0.0841 - true_loss: 1.0865 - val_loss: 5636.6274 - val_reconstruction_loss: 1896.0895 - val_kl_loss: 99.6916 - val_false_loss: 11.7536 - val_true_loss: 1.1476\n",
      "Epoch 2444/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.9636 - reconstruction_loss: 1889.4946 - kl_loss: 102.6475 - false_loss: 0.0841 - true_loss: 1.0865 - val_loss: 5636.3325 - val_reconstruction_loss: 1896.0892 - val_kl_loss: 99.6919 - val_false_loss: 11.7527 - val_true_loss: 1.1476\n",
      "Epoch 2445/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2202.7692 - reconstruction_loss: 1889.4293 - kl_loss: 102.7086 - false_loss: 0.0841 - true_loss: 1.0864 - val_loss: 5636.0327 - val_reconstruction_loss: 1896.0889 - val_kl_loss: 99.6923 - val_false_loss: 11.7517 - val_true_loss: 1.1475\n",
      "Epoch 2446/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.2210 - reconstruction_loss: 1889.9023 - kl_loss: 102.9246 - false_loss: 0.0841 - true_loss: 1.0864 - val_loss: 5635.7422 - val_reconstruction_loss: 1896.0885 - val_kl_loss: 99.6932 - val_false_loss: 11.7507 - val_true_loss: 1.1475\n",
      "Epoch 2447/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.3629 - reconstruction_loss: 1889.5552 - kl_loss: 103.5489 - false_loss: 0.0841 - true_loss: 1.0863 - val_loss: 5635.4414 - val_reconstruction_loss: 1896.0880 - val_kl_loss: 99.6938 - val_false_loss: 11.7498 - val_true_loss: 1.1474\n",
      "Epoch 2448/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.2859 - reconstruction_loss: 1889.7455 - kl_loss: 103.0230 - false_loss: 0.0841 - true_loss: 1.0863 - val_loss: 5635.1367 - val_reconstruction_loss: 1896.0878 - val_kl_loss: 99.6944 - val_false_loss: 11.7487 - val_true_loss: 1.1474\n",
      "Epoch 2449/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.1599 - reconstruction_loss: 1889.8756 - kl_loss: 103.8547 - false_loss: 0.0841 - true_loss: 1.0862 - val_loss: 5634.8428 - val_reconstruction_loss: 1896.0873 - val_kl_loss: 99.6950 - val_false_loss: 11.7478 - val_true_loss: 1.1473\n",
      "Epoch 2450/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.8910 - reconstruction_loss: 1889.4894 - kl_loss: 103.3539 - false_loss: 0.0841 - true_loss: 1.0862 - val_loss: 5634.5400 - val_reconstruction_loss: 1896.0869 - val_kl_loss: 99.6956 - val_false_loss: 11.7468 - val_true_loss: 1.1473\n",
      "Epoch 2451/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.5119 - reconstruction_loss: 1889.4879 - kl_loss: 103.8497 - false_loss: 0.0841 - true_loss: 1.0861 - val_loss: 5634.2446 - val_reconstruction_loss: 1896.0867 - val_kl_loss: 99.6959 - val_false_loss: 11.7458 - val_true_loss: 1.1472\n",
      "Epoch 2452/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.7689 - reconstruction_loss: 1889.7670 - kl_loss: 101.3989 - false_loss: 0.0841 - true_loss: 1.0861 - val_loss: 5633.9375 - val_reconstruction_loss: 1896.0862 - val_kl_loss: 99.6954 - val_false_loss: 11.7448 - val_true_loss: 1.1472\n",
      "Epoch 2453/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.6688 - reconstruction_loss: 1891.0062 - kl_loss: 99.4678 - false_loss: 0.0841 - true_loss: 1.0860 - val_loss: 5633.6240 - val_reconstruction_loss: 1896.0859 - val_kl_loss: 99.6956 - val_false_loss: 11.7438 - val_true_loss: 1.1472\n",
      "Epoch 2454/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.5667 - reconstruction_loss: 1891.1656 - kl_loss: 101.4412 - false_loss: 0.0840 - true_loss: 1.0860 - val_loss: 5633.3320 - val_reconstruction_loss: 1896.0854 - val_kl_loss: 99.6965 - val_false_loss: 11.7428 - val_true_loss: 1.1471\n",
      "Epoch 2455/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.4536 - reconstruction_loss: 1890.2793 - kl_loss: 101.6253 - false_loss: 0.0840 - true_loss: 1.0860 - val_loss: 5633.0464 - val_reconstruction_loss: 1896.0851 - val_kl_loss: 99.6969 - val_false_loss: 11.7419 - val_true_loss: 1.1471\n",
      "Epoch 2456/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.8261 - reconstruction_loss: 1889.8422 - kl_loss: 101.0361 - false_loss: 0.0840 - true_loss: 1.0859 - val_loss: 5632.7544 - val_reconstruction_loss: 1896.0847 - val_kl_loss: 99.6972 - val_false_loss: 11.7409 - val_true_loss: 1.1470\n",
      "Epoch 2457/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4922 - reconstruction_loss: 1889.4789 - kl_loss: 101.5576 - false_loss: 0.0840 - true_loss: 1.0859 - val_loss: 5632.4575 - val_reconstruction_loss: 1896.0845 - val_kl_loss: 99.6973 - val_false_loss: 11.7399 - val_true_loss: 1.1470\n",
      "Epoch 2458/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.3271 - reconstruction_loss: 1889.9259 - kl_loss: 101.2535 - false_loss: 0.0840 - true_loss: 1.0858 - val_loss: 5632.1636 - val_reconstruction_loss: 1896.0840 - val_kl_loss: 99.6978 - val_false_loss: 11.7390 - val_true_loss: 1.1470\n",
      "Epoch 2459/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6898 - reconstruction_loss: 1889.4404 - kl_loss: 101.9807 - false_loss: 0.0840 - true_loss: 1.0858 - val_loss: 5631.8770 - val_reconstruction_loss: 1896.0836 - val_kl_loss: 99.6982 - val_false_loss: 11.7380 - val_true_loss: 1.1469\n",
      "Epoch 2460/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.9505 - reconstruction_loss: 1889.3057 - kl_loss: 100.0920 - false_loss: 0.0840 - true_loss: 1.0858 - val_loss: 5631.5864 - val_reconstruction_loss: 1896.0833 - val_kl_loss: 99.6985 - val_false_loss: 11.7371 - val_true_loss: 1.1469\n",
      "Epoch 2461/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.9248 - reconstruction_loss: 1889.7809 - kl_loss: 99.5379 - false_loss: 0.0840 - true_loss: 1.0857 - val_loss: 5631.2959 - val_reconstruction_loss: 1896.0828 - val_kl_loss: 99.6989 - val_false_loss: 11.7361 - val_true_loss: 1.1469\n",
      "Epoch 2462/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.6423 - reconstruction_loss: 1889.3638 - kl_loss: 99.7226 - false_loss: 0.0840 - true_loss: 1.0857 - val_loss: 5630.9922 - val_reconstruction_loss: 1896.0824 - val_kl_loss: 99.6994 - val_false_loss: 11.7351 - val_true_loss: 1.1468\n",
      "Epoch 2463/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3171 - reconstruction_loss: 1889.8867 - kl_loss: 96.3664 - false_loss: 0.0840 - true_loss: 1.0856 - val_loss: 5630.6948 - val_reconstruction_loss: 1896.0819 - val_kl_loss: 99.6994 - val_false_loss: 11.7341 - val_true_loss: 1.1468\n",
      "Epoch 2464/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.6620 - reconstruction_loss: 1890.1016 - kl_loss: 99.5288 - false_loss: 0.0840 - true_loss: 1.0856 - val_loss: 5630.4092 - val_reconstruction_loss: 1896.0815 - val_kl_loss: 99.6999 - val_false_loss: 11.7332 - val_true_loss: 1.1467\n",
      "Epoch 2465/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0072 - reconstruction_loss: 1889.6744 - kl_loss: 100.4297 - false_loss: 0.0840 - true_loss: 1.0856 - val_loss: 5630.1089 - val_reconstruction_loss: 1896.0812 - val_kl_loss: 99.7003 - val_false_loss: 11.7322 - val_true_loss: 1.1467\n",
      "Epoch 2466/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.8538 - reconstruction_loss: 1889.9081 - kl_loss: 100.9938 - false_loss: 0.0840 - true_loss: 1.0855 - val_loss: 5629.8018 - val_reconstruction_loss: 1896.0807 - val_kl_loss: 99.7005 - val_false_loss: 11.7312 - val_true_loss: 1.1467\n",
      "Epoch 2467/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.8349 - reconstruction_loss: 1889.4896 - kl_loss: 100.8292 - false_loss: 0.0840 - true_loss: 1.0855 - val_loss: 5629.4995 - val_reconstruction_loss: 1896.0803 - val_kl_loss: 99.7002 - val_false_loss: 11.7302 - val_true_loss: 1.1466\n",
      "Epoch 2468/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.3774 - reconstruction_loss: 1889.2992 - kl_loss: 99.3984 - false_loss: 0.0839 - true_loss: 1.0854 - val_loss: 5629.1904 - val_reconstruction_loss: 1896.0800 - val_kl_loss: 99.7001 - val_false_loss: 11.7292 - val_true_loss: 1.1466\n",
      "Epoch 2469/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.3385 - reconstruction_loss: 1889.5103 - kl_loss: 102.5763 - false_loss: 0.0839 - true_loss: 1.0854 - val_loss: 5628.8921 - val_reconstruction_loss: 1896.0796 - val_kl_loss: 99.7003 - val_false_loss: 11.7282 - val_true_loss: 1.1465\n",
      "Epoch 2470/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.9651 - reconstruction_loss: 1889.8976 - kl_loss: 102.4960 - false_loss: 0.0839 - true_loss: 1.0853 - val_loss: 5628.5874 - val_reconstruction_loss: 1896.0793 - val_kl_loss: 99.7006 - val_false_loss: 11.7272 - val_true_loss: 1.1465\n",
      "Epoch 2471/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8154 - reconstruction_loss: 1889.4590 - kl_loss: 102.2533 - false_loss: 0.0839 - true_loss: 1.0853 - val_loss: 5628.2891 - val_reconstruction_loss: 1896.0787 - val_kl_loss: 99.7008 - val_false_loss: 11.7262 - val_true_loss: 1.1465\n",
      "Epoch 2472/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9264 - reconstruction_loss: 1889.4601 - kl_loss: 101.1475 - false_loss: 0.0839 - true_loss: 1.0852 - val_loss: 5627.9897 - val_reconstruction_loss: 1896.0782 - val_kl_loss: 99.7011 - val_false_loss: 11.7253 - val_true_loss: 1.1464\n",
      "Epoch 2473/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5772 - reconstruction_loss: 1889.4414 - kl_loss: 101.2213 - false_loss: 0.0839 - true_loss: 1.0852 - val_loss: 5627.6851 - val_reconstruction_loss: 1896.0780 - val_kl_loss: 99.7014 - val_false_loss: 11.7242 - val_true_loss: 1.1464\n",
      "Epoch 2474/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.7079 - reconstruction_loss: 1889.6642 - kl_loss: 101.6097 - false_loss: 0.0839 - true_loss: 1.0851 - val_loss: 5627.3838 - val_reconstruction_loss: 1896.0775 - val_kl_loss: 99.7021 - val_false_loss: 11.7233 - val_true_loss: 1.1463\n",
      "Epoch 2475/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8007 - reconstruction_loss: 1889.8427 - kl_loss: 101.4928 - false_loss: 0.0839 - true_loss: 1.0851 - val_loss: 5627.0928 - val_reconstruction_loss: 1896.0771 - val_kl_loss: 99.7020 - val_false_loss: 11.7223 - val_true_loss: 1.1463\n",
      "Epoch 2476/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.7246 - reconstruction_loss: 1889.8046 - kl_loss: 100.4710 - false_loss: 0.0839 - true_loss: 1.0851 - val_loss: 5626.8125 - val_reconstruction_loss: 1896.0768 - val_kl_loss: 99.7023 - val_false_loss: 11.7214 - val_true_loss: 1.1463\n",
      "Epoch 2477/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.9828 - reconstruction_loss: 1889.6989 - kl_loss: 101.2762 - false_loss: 0.0839 - true_loss: 1.0850 - val_loss: 5626.5264 - val_reconstruction_loss: 1896.0764 - val_kl_loss: 99.7024 - val_false_loss: 11.7204 - val_true_loss: 1.1462\n",
      "Epoch 2478/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.0783 - reconstruction_loss: 1889.3408 - kl_loss: 100.6219 - false_loss: 0.0839 - true_loss: 1.0850 - val_loss: 5626.2388 - val_reconstruction_loss: 1896.0760 - val_kl_loss: 99.7029 - val_false_loss: 11.7195 - val_true_loss: 1.1462\n",
      "Epoch 2479/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.3870 - reconstruction_loss: 1889.2617 - kl_loss: 100.8301 - false_loss: 0.0839 - true_loss: 1.0849 - val_loss: 5625.9507 - val_reconstruction_loss: 1896.0756 - val_kl_loss: 99.7030 - val_false_loss: 11.7185 - val_true_loss: 1.1461\n",
      "Epoch 2480/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.0234 - reconstruction_loss: 1889.4619 - kl_loss: 99.8371 - false_loss: 0.0839 - true_loss: 1.0849 - val_loss: 5625.6592 - val_reconstruction_loss: 1896.0751 - val_kl_loss: 99.7037 - val_false_loss: 11.7176 - val_true_loss: 1.1461\n",
      "Epoch 2481/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2154 - reconstruction_loss: 1889.3409 - kl_loss: 100.8336 - false_loss: 0.0839 - true_loss: 1.0849 - val_loss: 5625.3662 - val_reconstruction_loss: 1896.0747 - val_kl_loss: 99.7040 - val_false_loss: 11.7166 - val_true_loss: 1.1461\n",
      "Epoch 2482/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.9977 - reconstruction_loss: 1889.5536 - kl_loss: 99.6322 - false_loss: 0.0838 - true_loss: 1.0848 - val_loss: 5625.0688 - val_reconstruction_loss: 1896.0742 - val_kl_loss: 99.7044 - val_false_loss: 11.7156 - val_true_loss: 1.1460\n",
      "Epoch 2483/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8675 - reconstruction_loss: 1889.6191 - kl_loss: 99.3314 - false_loss: 0.0838 - true_loss: 1.0848 - val_loss: 5624.7778 - val_reconstruction_loss: 1896.0739 - val_kl_loss: 99.7044 - val_false_loss: 11.7147 - val_true_loss: 1.1460\n",
      "Epoch 2484/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.8818 - reconstruction_loss: 1889.7438 - kl_loss: 97.7822 - false_loss: 0.0838 - true_loss: 1.0847 - val_loss: 5624.4873 - val_reconstruction_loss: 1896.0735 - val_kl_loss: 99.7032 - val_false_loss: 11.7137 - val_true_loss: 1.1460\n",
      "Epoch 2485/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1753 - reconstruction_loss: 1890.0853 - kl_loss: 98.2464 - false_loss: 0.0838 - true_loss: 1.0847 - val_loss: 5624.1851 - val_reconstruction_loss: 1896.0731 - val_kl_loss: 99.7029 - val_false_loss: 11.7127 - val_true_loss: 1.1460\n",
      "Epoch 2486/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.3355 - reconstruction_loss: 1890.3438 - kl_loss: 98.4608 - false_loss: 0.0838 - true_loss: 1.0847 - val_loss: 5623.8818 - val_reconstruction_loss: 1896.0726 - val_kl_loss: 99.7024 - val_false_loss: 11.7117 - val_true_loss: 1.1459\n",
      "Epoch 2487/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.4850 - reconstruction_loss: 1890.6997 - kl_loss: 96.0672 - false_loss: 0.0838 - true_loss: 1.0846 - val_loss: 5623.5742 - val_reconstruction_loss: 1896.0725 - val_kl_loss: 99.7000 - val_false_loss: 11.7107 - val_true_loss: 1.1459\n",
      "Epoch 2488/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2276.3740 - reconstruction_loss: 1894.3004 - kl_loss: 93.6699 - false_loss: 0.0838 - true_loss: 1.0846 - val_loss: 5623.2808 - val_reconstruction_loss: 1896.0721 - val_kl_loss: 99.7006 - val_false_loss: 11.7097 - val_true_loss: 1.1459\n",
      "Epoch 2489/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.6568 - reconstruction_loss: 1893.0475 - kl_loss: 97.5263 - false_loss: 0.0838 - true_loss: 1.0846 - val_loss: 5622.9805 - val_reconstruction_loss: 1896.0718 - val_kl_loss: 99.7006 - val_false_loss: 11.7088 - val_true_loss: 1.1459\n",
      "Epoch 2490/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3452 - reconstruction_loss: 1890.6581 - kl_loss: 100.1616 - false_loss: 0.0838 - true_loss: 1.0845 - val_loss: 5622.6621 - val_reconstruction_loss: 1896.0715 - val_kl_loss: 99.7011 - val_false_loss: 11.7077 - val_true_loss: 1.1458\n",
      "Epoch 2491/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.1635 - reconstruction_loss: 1889.7191 - kl_loss: 100.2472 - false_loss: 0.0838 - true_loss: 1.0845 - val_loss: 5622.3535 - val_reconstruction_loss: 1896.0709 - val_kl_loss: 99.7011 - val_false_loss: 11.7067 - val_true_loss: 1.1458\n",
      "Epoch 2492/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.7971 - reconstruction_loss: 1889.4711 - kl_loss: 100.7541 - false_loss: 0.0838 - true_loss: 1.0844 - val_loss: 5622.0547 - val_reconstruction_loss: 1896.0704 - val_kl_loss: 99.7016 - val_false_loss: 11.7057 - val_true_loss: 1.1457\n",
      "Epoch 2493/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.3562 - reconstruction_loss: 1889.6216 - kl_loss: 99.5174 - false_loss: 0.0838 - true_loss: 1.0844 - val_loss: 5621.7568 - val_reconstruction_loss: 1896.0701 - val_kl_loss: 99.7015 - val_false_loss: 11.7047 - val_true_loss: 1.1457\n",
      "Epoch 2494/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7209 - reconstruction_loss: 1889.6761 - kl_loss: 100.8932 - false_loss: 0.0838 - true_loss: 1.0844 - val_loss: 5621.4639 - val_reconstruction_loss: 1896.0697 - val_kl_loss: 99.7018 - val_false_loss: 11.7038 - val_true_loss: 1.1457\n",
      "Epoch 2495/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.1957 - reconstruction_loss: 1889.6190 - kl_loss: 99.9344 - false_loss: 0.0838 - true_loss: 1.0843 - val_loss: 5621.1689 - val_reconstruction_loss: 1896.0692 - val_kl_loss: 99.7019 - val_false_loss: 11.7028 - val_true_loss: 1.1456\n",
      "Epoch 2496/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.9787 - reconstruction_loss: 1889.5620 - kl_loss: 99.5345 - false_loss: 0.0838 - true_loss: 1.0843 - val_loss: 5620.8672 - val_reconstruction_loss: 1896.0688 - val_kl_loss: 99.7022 - val_false_loss: 11.7018 - val_true_loss: 1.1456\n",
      "Epoch 2497/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2218.3145 - reconstruction_loss: 1889.5402 - kl_loss: 100.3944 - false_loss: 0.0837 - true_loss: 1.0842 - val_loss: 5620.5718 - val_reconstruction_loss: 1896.0684 - val_kl_loss: 99.7028 - val_false_loss: 11.7008 - val_true_loss: 1.1456\n",
      "Epoch 2498/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.2984 - reconstruction_loss: 1889.5531 - kl_loss: 99.1177 - false_loss: 0.0837 - true_loss: 1.0842 - val_loss: 5620.2764 - val_reconstruction_loss: 1896.0679 - val_kl_loss: 99.7023 - val_false_loss: 11.6999 - val_true_loss: 1.1455\n",
      "Epoch 2499/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1095 - reconstruction_loss: 1889.5562 - kl_loss: 98.6516 - false_loss: 0.0837 - true_loss: 1.0842 - val_loss: 5619.9751 - val_reconstruction_loss: 1896.0677 - val_kl_loss: 99.7026 - val_false_loss: 11.6989 - val_true_loss: 1.1455\n",
      "Epoch 2500/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.1102 - reconstruction_loss: 1889.8253 - kl_loss: 101.1965 - false_loss: 0.0837 - true_loss: 1.0841 - val_loss: 5619.6821 - val_reconstruction_loss: 1896.0673 - val_kl_loss: 99.7028 - val_false_loss: 11.6979 - val_true_loss: 1.1455\n",
      "Epoch 2501/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.6121 - reconstruction_loss: 1889.4745 - kl_loss: 100.4339 - false_loss: 0.0837 - true_loss: 1.0841 - val_loss: 5619.3838 - val_reconstruction_loss: 1896.0668 - val_kl_loss: 99.7030 - val_false_loss: 11.6969 - val_true_loss: 1.1454\n",
      "Epoch 2502/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.2560 - reconstruction_loss: 1889.6676 - kl_loss: 100.9526 - false_loss: 0.0837 - true_loss: 1.0840 - val_loss: 5619.0884 - val_reconstruction_loss: 1896.0664 - val_kl_loss: 99.7034 - val_false_loss: 11.6960 - val_true_loss: 1.1454\n",
      "Epoch 2503/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.6914 - reconstruction_loss: 1889.7285 - kl_loss: 100.9855 - false_loss: 0.0837 - true_loss: 1.0840 - val_loss: 5618.7930 - val_reconstruction_loss: 1896.0659 - val_kl_loss: 99.7036 - val_false_loss: 11.6950 - val_true_loss: 1.1453\n",
      "Epoch 2504/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.4103 - reconstruction_loss: 1889.4349 - kl_loss: 100.8785 - false_loss: 0.0837 - true_loss: 1.0839 - val_loss: 5618.5005 - val_reconstruction_loss: 1896.0657 - val_kl_loss: 99.7039 - val_false_loss: 11.6940 - val_true_loss: 1.1453\n",
      "Epoch 2505/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.3026 - reconstruction_loss: 1889.6929 - kl_loss: 100.7152 - false_loss: 0.0837 - true_loss: 1.0839 - val_loss: 5618.2017 - val_reconstruction_loss: 1896.0653 - val_kl_loss: 99.7043 - val_false_loss: 11.6930 - val_true_loss: 1.1453\n",
      "Epoch 2506/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4423 - reconstruction_loss: 1890.2959 - kl_loss: 96.8312 - false_loss: 0.0837 - true_loss: 1.0839 - val_loss: 5617.8994 - val_reconstruction_loss: 1896.0651 - val_kl_loss: 99.7047 - val_false_loss: 11.6920 - val_true_loss: 1.1452\n",
      "Epoch 2507/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2269.7807 - reconstruction_loss: 1892.7358 - kl_loss: 91.8077 - false_loss: 0.0837 - true_loss: 1.0838 - val_loss: 5617.6050 - val_reconstruction_loss: 1896.0647 - val_kl_loss: 99.7032 - val_false_loss: 11.6911 - val_true_loss: 1.1452\n",
      "Epoch 2508/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2291.2359 - reconstruction_loss: 1894.0348 - kl_loss: 89.6339 - false_loss: 0.0837 - true_loss: 1.0838 - val_loss: 5617.2949 - val_reconstruction_loss: 1896.0643 - val_kl_loss: 99.7015 - val_false_loss: 11.6901 - val_true_loss: 1.1452\n",
      "Epoch 2509/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5373 - reconstruction_loss: 1892.6163 - kl_loss: 93.0873 - false_loss: 0.0837 - true_loss: 1.0838 - val_loss: 5616.9810 - val_reconstruction_loss: 1896.0640 - val_kl_loss: 99.7011 - val_false_loss: 11.6890 - val_true_loss: 1.1452\n",
      "Epoch 2510/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0746 - reconstruction_loss: 1891.6543 - kl_loss: 96.6376 - false_loss: 0.0837 - true_loss: 1.0838 - val_loss: 5616.6636 - val_reconstruction_loss: 1896.0635 - val_kl_loss: 99.7015 - val_false_loss: 11.6880 - val_true_loss: 1.1451\n",
      "Epoch 2511/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.7175 - reconstruction_loss: 1890.8507 - kl_loss: 99.0276 - false_loss: 0.0837 - true_loss: 1.0837 - val_loss: 5616.3477 - val_reconstruction_loss: 1896.0631 - val_kl_loss: 99.7017 - val_false_loss: 11.6869 - val_true_loss: 1.1451\n",
      "Epoch 2512/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7731 - reconstruction_loss: 1889.6743 - kl_loss: 100.9484 - false_loss: 0.0837 - true_loss: 1.0837 - val_loss: 5616.0342 - val_reconstruction_loss: 1896.0627 - val_kl_loss: 99.7021 - val_false_loss: 11.6859 - val_true_loss: 1.1450\n",
      "Epoch 2513/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.6533 - reconstruction_loss: 1889.3228 - kl_loss: 101.3391 - false_loss: 0.0836 - true_loss: 1.0836 - val_loss: 5615.7192 - val_reconstruction_loss: 1896.0621 - val_kl_loss: 99.7027 - val_false_loss: 11.6849 - val_true_loss: 1.1450\n",
      "Epoch 2514/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.1275 - reconstruction_loss: 1889.5363 - kl_loss: 101.0008 - false_loss: 0.0836 - true_loss: 1.0836 - val_loss: 5615.4097 - val_reconstruction_loss: 1896.0618 - val_kl_loss: 99.7033 - val_false_loss: 11.6838 - val_true_loss: 1.1450\n",
      "Epoch 2515/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.6660 - reconstruction_loss: 1889.5146 - kl_loss: 100.6360 - false_loss: 0.0836 - true_loss: 1.0836 - val_loss: 5615.0923 - val_reconstruction_loss: 1896.0614 - val_kl_loss: 99.7039 - val_false_loss: 11.6828 - val_true_loss: 1.1449\n",
      "Epoch 2516/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9865 - reconstruction_loss: 1889.4459 - kl_loss: 101.3929 - false_loss: 0.0836 - true_loss: 1.0835 - val_loss: 5614.7749 - val_reconstruction_loss: 1896.0609 - val_kl_loss: 99.7041 - val_false_loss: 11.6818 - val_true_loss: 1.1449\n",
      "Epoch 2517/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.5942 - reconstruction_loss: 1889.4261 - kl_loss: 99.9166 - false_loss: 0.0836 - true_loss: 1.0835 - val_loss: 5614.4585 - val_reconstruction_loss: 1896.0605 - val_kl_loss: 99.7047 - val_false_loss: 11.6807 - val_true_loss: 1.1449\n",
      "Epoch 2518/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5468 - reconstruction_loss: 1889.5649 - kl_loss: 101.0644 - false_loss: 0.0836 - true_loss: 1.0834 - val_loss: 5614.1445 - val_reconstruction_loss: 1896.0599 - val_kl_loss: 99.7049 - val_false_loss: 11.6797 - val_true_loss: 1.1448\n",
      "Epoch 2519/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5618 - reconstruction_loss: 1889.6310 - kl_loss: 100.2755 - false_loss: 0.0836 - true_loss: 1.0834 - val_loss: 5613.8359 - val_reconstruction_loss: 1896.0596 - val_kl_loss: 99.7050 - val_false_loss: 11.6787 - val_true_loss: 1.1448\n",
      "Epoch 2520/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.3370 - reconstruction_loss: 1889.8131 - kl_loss: 100.8624 - false_loss: 0.0836 - true_loss: 1.0833 - val_loss: 5613.5283 - val_reconstruction_loss: 1896.0592 - val_kl_loss: 99.7055 - val_false_loss: 11.6776 - val_true_loss: 1.1447\n",
      "Epoch 2521/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.6774 - reconstruction_loss: 1889.3809 - kl_loss: 101.4790 - false_loss: 0.0836 - true_loss: 1.0833 - val_loss: 5613.2236 - val_reconstruction_loss: 1896.0588 - val_kl_loss: 99.7058 - val_false_loss: 11.6766 - val_true_loss: 1.1447\n",
      "Epoch 2522/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.8312 - reconstruction_loss: 1889.4507 - kl_loss: 102.0606 - false_loss: 0.0836 - true_loss: 1.0832 - val_loss: 5612.9131 - val_reconstruction_loss: 1896.0583 - val_kl_loss: 99.7064 - val_false_loss: 11.6756 - val_true_loss: 1.1447\n",
      "Epoch 2523/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.5343 - reconstruction_loss: 1889.9076 - kl_loss: 102.0202 - false_loss: 0.0836 - true_loss: 1.0832 - val_loss: 5612.6084 - val_reconstruction_loss: 1896.0581 - val_kl_loss: 99.7069 - val_false_loss: 11.6746 - val_true_loss: 1.1446\n",
      "Epoch 2524/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.2987 - reconstruction_loss: 1889.4800 - kl_loss: 101.3267 - false_loss: 0.0836 - true_loss: 1.0831 - val_loss: 5612.3008 - val_reconstruction_loss: 1896.0575 - val_kl_loss: 99.7077 - val_false_loss: 11.6736 - val_true_loss: 1.1446\n",
      "Epoch 2525/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.2944 - reconstruction_loss: 1889.7198 - kl_loss: 103.0810 - false_loss: 0.0836 - true_loss: 1.0831 - val_loss: 5611.9956 - val_reconstruction_loss: 1896.0571 - val_kl_loss: 99.7085 - val_false_loss: 11.6726 - val_true_loss: 1.1445\n",
      "Epoch 2526/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.2535 - reconstruction_loss: 1889.3502 - kl_loss: 102.6854 - false_loss: 0.0836 - true_loss: 1.0831 - val_loss: 5611.6870 - val_reconstruction_loss: 1896.0568 - val_kl_loss: 99.7089 - val_false_loss: 11.6716 - val_true_loss: 1.1445\n",
      "Epoch 2527/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.8431 - reconstruction_loss: 1889.6332 - kl_loss: 103.0000 - false_loss: 0.0835 - true_loss: 1.0830 - val_loss: 5611.3892 - val_reconstruction_loss: 1896.0563 - val_kl_loss: 99.7091 - val_false_loss: 11.6706 - val_true_loss: 1.1445\n",
      "Epoch 2528/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.4258 - reconstruction_loss: 1889.6415 - kl_loss: 103.1277 - false_loss: 0.0835 - true_loss: 1.0830 - val_loss: 5611.0918 - val_reconstruction_loss: 1896.0559 - val_kl_loss: 99.7101 - val_false_loss: 11.6696 - val_true_loss: 1.1444\n",
      "Epoch 2529/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.1586 - reconstruction_loss: 1889.2251 - kl_loss: 103.4284 - false_loss: 0.0835 - true_loss: 1.0829 - val_loss: 5610.7925 - val_reconstruction_loss: 1896.0555 - val_kl_loss: 99.7109 - val_false_loss: 11.6686 - val_true_loss: 1.1444\n",
      "Epoch 2530/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.0048 - reconstruction_loss: 1889.5299 - kl_loss: 103.0127 - false_loss: 0.0835 - true_loss: 1.0829 - val_loss: 5610.4927 - val_reconstruction_loss: 1896.0551 - val_kl_loss: 99.7118 - val_false_loss: 11.6677 - val_true_loss: 1.1443\n",
      "Epoch 2531/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.5987 - reconstruction_loss: 1889.2677 - kl_loss: 103.1476 - false_loss: 0.0835 - true_loss: 1.0828 - val_loss: 5610.1968 - val_reconstruction_loss: 1896.0546 - val_kl_loss: 99.7128 - val_false_loss: 11.6667 - val_true_loss: 1.1443\n",
      "Epoch 2532/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.9552 - reconstruction_loss: 1889.5304 - kl_loss: 104.0618 - false_loss: 0.0835 - true_loss: 1.0828 - val_loss: 5609.8989 - val_reconstruction_loss: 1896.0542 - val_kl_loss: 99.7137 - val_false_loss: 11.6657 - val_true_loss: 1.1442\n",
      "Epoch 2533/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.5659 - reconstruction_loss: 1889.9307 - kl_loss: 103.0758 - false_loss: 0.0835 - true_loss: 1.0827 - val_loss: 5609.6094 - val_reconstruction_loss: 1896.0538 - val_kl_loss: 99.7147 - val_false_loss: 11.6648 - val_true_loss: 1.1442\n",
      "Epoch 2534/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.0999 - reconstruction_loss: 1889.7552 - kl_loss: 103.2504 - false_loss: 0.0835 - true_loss: 1.0827 - val_loss: 5609.3184 - val_reconstruction_loss: 1896.0535 - val_kl_loss: 99.7152 - val_false_loss: 11.6638 - val_true_loss: 1.1441\n",
      "Epoch 2535/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.2969 - reconstruction_loss: 1889.3208 - kl_loss: 103.3355 - false_loss: 0.0835 - true_loss: 1.0826 - val_loss: 5609.0220 - val_reconstruction_loss: 1896.0530 - val_kl_loss: 99.7160 - val_false_loss: 11.6628 - val_true_loss: 1.1441\n",
      "Epoch 2536/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.3136 - reconstruction_loss: 1889.6825 - kl_loss: 102.8887 - false_loss: 0.0835 - true_loss: 1.0826 - val_loss: 5608.7280 - val_reconstruction_loss: 1896.0525 - val_kl_loss: 99.7166 - val_false_loss: 11.6619 - val_true_loss: 1.1441\n",
      "Epoch 2537/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.3108 - reconstruction_loss: 1889.5319 - kl_loss: 102.9852 - false_loss: 0.0835 - true_loss: 1.0825 - val_loss: 5608.4370 - val_reconstruction_loss: 1896.0521 - val_kl_loss: 99.7171 - val_false_loss: 11.6609 - val_true_loss: 1.1440\n",
      "Epoch 2538/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.4726 - reconstruction_loss: 1889.3286 - kl_loss: 101.8034 - false_loss: 0.0835 - true_loss: 1.0825 - val_loss: 5608.1523 - val_reconstruction_loss: 1896.0516 - val_kl_loss: 99.7175 - val_false_loss: 11.6600 - val_true_loss: 1.1440\n",
      "Epoch 2539/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.8466 - reconstruction_loss: 1889.4713 - kl_loss: 102.1777 - false_loss: 0.0835 - true_loss: 1.0824 - val_loss: 5607.8550 - val_reconstruction_loss: 1896.0511 - val_kl_loss: 99.7180 - val_false_loss: 11.6590 - val_true_loss: 1.1439\n",
      "Epoch 2540/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.2224 - reconstruction_loss: 1889.8535 - kl_loss: 104.2085 - false_loss: 0.0835 - true_loss: 1.0824 - val_loss: 5607.5527 - val_reconstruction_loss: 1896.0509 - val_kl_loss: 99.7184 - val_false_loss: 11.6580 - val_true_loss: 1.1439\n",
      "Epoch 2541/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.4557 - reconstruction_loss: 1889.5079 - kl_loss: 103.1626 - false_loss: 0.0834 - true_loss: 1.0823 - val_loss: 5607.2485 - val_reconstruction_loss: 1896.0504 - val_kl_loss: 99.7190 - val_false_loss: 11.6570 - val_true_loss: 1.1438\n",
      "Epoch 2542/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.8914 - reconstruction_loss: 1889.5321 - kl_loss: 104.0134 - false_loss: 0.0834 - true_loss: 1.0823 - val_loss: 5606.9502 - val_reconstruction_loss: 1896.0498 - val_kl_loss: 99.7191 - val_false_loss: 11.6560 - val_true_loss: 1.1438\n",
      "Epoch 2543/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.1753 - reconstruction_loss: 1889.3573 - kl_loss: 103.2338 - false_loss: 0.0834 - true_loss: 1.0822 - val_loss: 5606.6528 - val_reconstruction_loss: 1896.0496 - val_kl_loss: 99.7197 - val_false_loss: 11.6550 - val_true_loss: 1.1437\n",
      "Epoch 2544/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.1448 - reconstruction_loss: 1889.4833 - kl_loss: 103.7227 - false_loss: 0.0834 - true_loss: 1.0822 - val_loss: 5606.3584 - val_reconstruction_loss: 1896.0492 - val_kl_loss: 99.7204 - val_false_loss: 11.6541 - val_true_loss: 1.1437\n",
      "Epoch 2545/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.9725 - reconstruction_loss: 1889.2582 - kl_loss: 104.2855 - false_loss: 0.0834 - true_loss: 1.0821 - val_loss: 5606.0601 - val_reconstruction_loss: 1896.0487 - val_kl_loss: 99.7211 - val_false_loss: 11.6531 - val_true_loss: 1.1437\n",
      "Epoch 2546/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.9688 - reconstruction_loss: 1889.7515 - kl_loss: 103.8379 - false_loss: 0.0834 - true_loss: 1.0821 - val_loss: 5605.7651 - val_reconstruction_loss: 1896.0483 - val_kl_loss: 99.7221 - val_false_loss: 11.6521 - val_true_loss: 1.1436\n",
      "Epoch 2547/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.1049 - reconstruction_loss: 1889.8754 - kl_loss: 103.2504 - false_loss: 0.0834 - true_loss: 1.0820 - val_loss: 5605.4741 - val_reconstruction_loss: 1896.0481 - val_kl_loss: 99.7230 - val_false_loss: 11.6512 - val_true_loss: 1.1436\n",
      "Epoch 2548/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.7143 - reconstruction_loss: 1889.9468 - kl_loss: 104.0520 - false_loss: 0.0834 - true_loss: 1.0820 - val_loss: 5605.1807 - val_reconstruction_loss: 1896.0476 - val_kl_loss: 99.7238 - val_false_loss: 11.6502 - val_true_loss: 1.1435\n",
      "Epoch 2549/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2200.7551 - reconstruction_loss: 1889.5697 - kl_loss: 103.8126 - false_loss: 0.0834 - true_loss: 1.0819 - val_loss: 5604.8887 - val_reconstruction_loss: 1896.0472 - val_kl_loss: 99.7248 - val_false_loss: 11.6492 - val_true_loss: 1.1435\n",
      "Epoch 2550/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.6829 - reconstruction_loss: 1889.3531 - kl_loss: 104.4004 - false_loss: 0.0834 - true_loss: 1.0819 - val_loss: 5604.5898 - val_reconstruction_loss: 1896.0469 - val_kl_loss: 99.7257 - val_false_loss: 11.6483 - val_true_loss: 1.1434\n",
      "Epoch 2551/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.4969 - reconstruction_loss: 1889.2915 - kl_loss: 104.0484 - false_loss: 0.0834 - true_loss: 1.0818 - val_loss: 5604.2979 - val_reconstruction_loss: 1896.0464 - val_kl_loss: 99.7266 - val_false_loss: 11.6473 - val_true_loss: 1.1434\n",
      "Epoch 2552/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.8409 - reconstruction_loss: 1889.9443 - kl_loss: 103.8561 - false_loss: 0.0834 - true_loss: 1.0818 - val_loss: 5603.9966 - val_reconstruction_loss: 1896.0461 - val_kl_loss: 99.7277 - val_false_loss: 11.6463 - val_true_loss: 1.1433\n",
      "Epoch 2553/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.8371 - reconstruction_loss: 1889.8466 - kl_loss: 103.5910 - false_loss: 0.0834 - true_loss: 1.0817 - val_loss: 5603.7007 - val_reconstruction_loss: 1896.0457 - val_kl_loss: 99.7285 - val_false_loss: 11.6453 - val_true_loss: 1.1433\n",
      "Epoch 2554/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.7323 - reconstruction_loss: 1889.5238 - kl_loss: 104.0488 - false_loss: 0.0834 - true_loss: 1.0817 - val_loss: 5603.4058 - val_reconstruction_loss: 1896.0453 - val_kl_loss: 99.7293 - val_false_loss: 11.6444 - val_true_loss: 1.1433\n",
      "Epoch 2555/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.6743 - reconstruction_loss: 1889.5026 - kl_loss: 104.0761 - false_loss: 0.0833 - true_loss: 1.0816 - val_loss: 5603.1060 - val_reconstruction_loss: 1896.0449 - val_kl_loss: 99.7299 - val_false_loss: 11.6434 - val_true_loss: 1.1432\n",
      "Epoch 2556/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.4630 - reconstruction_loss: 1889.5924 - kl_loss: 103.2666 - false_loss: 0.0833 - true_loss: 1.0816 - val_loss: 5602.8076 - val_reconstruction_loss: 1896.0446 - val_kl_loss: 99.7302 - val_false_loss: 11.6424 - val_true_loss: 1.1432\n",
      "Epoch 2557/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.4384 - reconstruction_loss: 1889.7783 - kl_loss: 103.1564 - false_loss: 0.0833 - true_loss: 1.0815 - val_loss: 5602.5186 - val_reconstruction_loss: 1896.0441 - val_kl_loss: 99.7304 - val_false_loss: 11.6415 - val_true_loss: 1.1431\n",
      "Epoch 2558/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.8173 - reconstruction_loss: 1889.8666 - kl_loss: 103.1864 - false_loss: 0.0833 - true_loss: 1.0815 - val_loss: 5602.2231 - val_reconstruction_loss: 1896.0437 - val_kl_loss: 99.7312 - val_false_loss: 11.6405 - val_true_loss: 1.1431\n",
      "Epoch 2559/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.6001 - reconstruction_loss: 1889.4194 - kl_loss: 102.4405 - false_loss: 0.0833 - true_loss: 1.0814 - val_loss: 5601.9248 - val_reconstruction_loss: 1896.0433 - val_kl_loss: 99.7317 - val_false_loss: 11.6395 - val_true_loss: 1.1430\n",
      "Epoch 2560/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.1213 - reconstruction_loss: 1889.8770 - kl_loss: 103.0657 - false_loss: 0.0833 - true_loss: 1.0814 - val_loss: 5601.6191 - val_reconstruction_loss: 1896.0428 - val_kl_loss: 99.7325 - val_false_loss: 11.6385 - val_true_loss: 1.1430\n",
      "Epoch 2561/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.6092 - reconstruction_loss: 1889.6743 - kl_loss: 103.2582 - false_loss: 0.0833 - true_loss: 1.0813 - val_loss: 5601.3232 - val_reconstruction_loss: 1896.0425 - val_kl_loss: 99.7330 - val_false_loss: 11.6375 - val_true_loss: 1.1429\n",
      "Epoch 2562/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.9352 - reconstruction_loss: 1889.3287 - kl_loss: 103.9338 - false_loss: 0.0833 - true_loss: 1.0813 - val_loss: 5601.0303 - val_reconstruction_loss: 1896.0420 - val_kl_loss: 99.7340 - val_false_loss: 11.6366 - val_true_loss: 1.1429\n",
      "Epoch 2563/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0827 - reconstruction_loss: 1889.5708 - kl_loss: 104.2996 - false_loss: 0.0833 - true_loss: 1.0812 - val_loss: 5600.7432 - val_reconstruction_loss: 1896.0416 - val_kl_loss: 99.7349 - val_false_loss: 11.6356 - val_true_loss: 1.1429\n",
      "Epoch 2564/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.5561 - reconstruction_loss: 1890.0332 - kl_loss: 102.9860 - false_loss: 0.0833 - true_loss: 1.0812 - val_loss: 5600.4512 - val_reconstruction_loss: 1896.0413 - val_kl_loss: 99.7355 - val_false_loss: 11.6347 - val_true_loss: 1.1428\n",
      "Epoch 2565/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.8441 - reconstruction_loss: 1889.9572 - kl_loss: 102.7154 - false_loss: 0.0833 - true_loss: 1.0811 - val_loss: 5600.1636 - val_reconstruction_loss: 1896.0408 - val_kl_loss: 99.7362 - val_false_loss: 11.6337 - val_true_loss: 1.1428\n",
      "Epoch 2566/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.3879 - reconstruction_loss: 1889.4401 - kl_loss: 103.0045 - false_loss: 0.0833 - true_loss: 1.0811 - val_loss: 5599.8735 - val_reconstruction_loss: 1896.0404 - val_kl_loss: 99.7369 - val_false_loss: 11.6328 - val_true_loss: 1.1427\n",
      "Epoch 2567/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.2963 - reconstruction_loss: 1889.8605 - kl_loss: 101.2342 - false_loss: 0.0833 - true_loss: 1.0811 - val_loss: 5599.5776 - val_reconstruction_loss: 1896.0402 - val_kl_loss: 99.7376 - val_false_loss: 11.6318 - val_true_loss: 1.1427\n",
      "Epoch 2568/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.5749 - reconstruction_loss: 1889.6494 - kl_loss: 101.4711 - false_loss: 0.0833 - true_loss: 1.0810 - val_loss: 5599.2910 - val_reconstruction_loss: 1896.0398 - val_kl_loss: 99.7379 - val_false_loss: 11.6308 - val_true_loss: 1.1427\n",
      "Epoch 2569/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.2646 - reconstruction_loss: 1890.4463 - kl_loss: 99.1768 - false_loss: 0.0832 - true_loss: 1.0810 - val_loss: 5599.0117 - val_reconstruction_loss: 1896.0394 - val_kl_loss: 99.7372 - val_false_loss: 11.6299 - val_true_loss: 1.1426\n",
      "Epoch 2570/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.4177 - reconstruction_loss: 1890.3656 - kl_loss: 98.6497 - false_loss: 0.0832 - true_loss: 1.0809 - val_loss: 5598.7207 - val_reconstruction_loss: 1896.0392 - val_kl_loss: 99.7366 - val_false_loss: 11.6290 - val_true_loss: 1.1426\n",
      "Epoch 2571/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.0869 - reconstruction_loss: 1890.3793 - kl_loss: 99.8901 - false_loss: 0.0832 - true_loss: 1.0809 - val_loss: 5598.4287 - val_reconstruction_loss: 1896.0387 - val_kl_loss: 99.7369 - val_false_loss: 11.6280 - val_true_loss: 1.1425\n",
      "Epoch 2572/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.7286 - reconstruction_loss: 1889.8154 - kl_loss: 102.3203 - false_loss: 0.0832 - true_loss: 1.0809 - val_loss: 5598.1372 - val_reconstruction_loss: 1896.0382 - val_kl_loss: 99.7377 - val_false_loss: 11.6271 - val_true_loss: 1.1425\n",
      "Epoch 2573/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.4161 - reconstruction_loss: 1889.2672 - kl_loss: 103.0027 - false_loss: 0.0832 - true_loss: 1.0808 - val_loss: 5597.8462 - val_reconstruction_loss: 1896.0378 - val_kl_loss: 99.7384 - val_false_loss: 11.6261 - val_true_loss: 1.1425\n",
      "Epoch 2574/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.1732 - reconstruction_loss: 1889.6533 - kl_loss: 103.1874 - false_loss: 0.0832 - true_loss: 1.0808 - val_loss: 5597.5537 - val_reconstruction_loss: 1896.0374 - val_kl_loss: 99.7392 - val_false_loss: 11.6251 - val_true_loss: 1.1424\n",
      "Epoch 2575/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.1625 - reconstruction_loss: 1889.6466 - kl_loss: 102.5346 - false_loss: 0.0832 - true_loss: 1.0807 - val_loss: 5597.2598 - val_reconstruction_loss: 1896.0370 - val_kl_loss: 99.7400 - val_false_loss: 11.6242 - val_true_loss: 1.1424\n",
      "Epoch 2576/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.0787 - reconstruction_loss: 1889.5098 - kl_loss: 103.6893 - false_loss: 0.0832 - true_loss: 1.0807 - val_loss: 5596.9692 - val_reconstruction_loss: 1896.0366 - val_kl_loss: 99.7408 - val_false_loss: 11.6232 - val_true_loss: 1.1423\n",
      "Epoch 2577/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.0303 - reconstruction_loss: 1889.8685 - kl_loss: 103.7440 - false_loss: 0.0832 - true_loss: 1.0806 - val_loss: 5596.6802 - val_reconstruction_loss: 1896.0363 - val_kl_loss: 99.7415 - val_false_loss: 11.6223 - val_true_loss: 1.1423\n",
      "Epoch 2578/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.0873 - reconstruction_loss: 1889.2245 - kl_loss: 104.3325 - false_loss: 0.0832 - true_loss: 1.0806 - val_loss: 5596.3979 - val_reconstruction_loss: 1896.0359 - val_kl_loss: 99.7422 - val_false_loss: 11.6213 - val_true_loss: 1.1422\n",
      "Epoch 2579/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.9184 - reconstruction_loss: 1889.3326 - kl_loss: 103.3808 - false_loss: 0.0832 - true_loss: 1.0805 - val_loss: 5596.1040 - val_reconstruction_loss: 1896.0354 - val_kl_loss: 99.7430 - val_false_loss: 11.6204 - val_true_loss: 1.1422\n",
      "Epoch 2580/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.2608 - reconstruction_loss: 1889.5043 - kl_loss: 103.7396 - false_loss: 0.0832 - true_loss: 1.0805 - val_loss: 5595.8115 - val_reconstruction_loss: 1896.0350 - val_kl_loss: 99.7436 - val_false_loss: 11.6194 - val_true_loss: 1.1421\n",
      "Epoch 2581/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.9626 - reconstruction_loss: 1889.9991 - kl_loss: 103.6087 - false_loss: 0.0832 - true_loss: 1.0804 - val_loss: 5595.5142 - val_reconstruction_loss: 1896.0348 - val_kl_loss: 99.7446 - val_false_loss: 11.6184 - val_true_loss: 1.1421\n",
      "Epoch 2582/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.1535 - reconstruction_loss: 1889.9491 - kl_loss: 103.3620 - false_loss: 0.0832 - true_loss: 1.0804 - val_loss: 5595.2290 - val_reconstruction_loss: 1896.0343 - val_kl_loss: 99.7449 - val_false_loss: 11.6175 - val_true_loss: 1.1421\n",
      "Epoch 2583/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.5864 - reconstruction_loss: 1889.4950 - kl_loss: 103.4648 - false_loss: 0.0832 - true_loss: 1.0803 - val_loss: 5594.9419 - val_reconstruction_loss: 1896.0338 - val_kl_loss: 99.7457 - val_false_loss: 11.6166 - val_true_loss: 1.1420\n",
      "Epoch 2584/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.3140 - reconstruction_loss: 1889.5493 - kl_loss: 103.5534 - false_loss: 0.0831 - true_loss: 1.0803 - val_loss: 5594.6528 - val_reconstruction_loss: 1896.0336 - val_kl_loss: 99.7465 - val_false_loss: 11.6156 - val_true_loss: 1.1420\n",
      "Epoch 2585/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.1765 - reconstruction_loss: 1889.7178 - kl_loss: 103.9732 - false_loss: 0.0831 - true_loss: 1.0802 - val_loss: 5594.3613 - val_reconstruction_loss: 1896.0331 - val_kl_loss: 99.7471 - val_false_loss: 11.6146 - val_true_loss: 1.1419\n",
      "Epoch 2586/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.8376 - reconstruction_loss: 1889.4781 - kl_loss: 103.3083 - false_loss: 0.0831 - true_loss: 1.0802 - val_loss: 5594.0786 - val_reconstruction_loss: 1896.0326 - val_kl_loss: 99.7476 - val_false_loss: 11.6137 - val_true_loss: 1.1419\n",
      "Epoch 2587/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.1042 - reconstruction_loss: 1889.5316 - kl_loss: 103.0589 - false_loss: 0.0831 - true_loss: 1.0801 - val_loss: 5593.7827 - val_reconstruction_loss: 1896.0323 - val_kl_loss: 99.7483 - val_false_loss: 11.6127 - val_true_loss: 1.1418\n",
      "Epoch 2588/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.2210 - reconstruction_loss: 1889.2764 - kl_loss: 104.2178 - false_loss: 0.0831 - true_loss: 1.0801 - val_loss: 5593.4849 - val_reconstruction_loss: 1896.0317 - val_kl_loss: 99.7490 - val_false_loss: 11.6118 - val_true_loss: 1.1418\n",
      "Epoch 2589/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.0178 - reconstruction_loss: 1889.6886 - kl_loss: 103.9749 - false_loss: 0.0831 - true_loss: 1.0800 - val_loss: 5593.1968 - val_reconstruction_loss: 1896.0312 - val_kl_loss: 99.7501 - val_false_loss: 11.6108 - val_true_loss: 1.1417\n",
      "Epoch 2590/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.2101 - reconstruction_loss: 1889.5802 - kl_loss: 102.8831 - false_loss: 0.0831 - true_loss: 1.0800 - val_loss: 5592.9053 - val_reconstruction_loss: 1896.0310 - val_kl_loss: 99.7509 - val_false_loss: 11.6099 - val_true_loss: 1.1417\n",
      "Epoch 2591/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.6266 - reconstruction_loss: 1889.6406 - kl_loss: 102.8028 - false_loss: 0.0831 - true_loss: 1.0799 - val_loss: 5592.6064 - val_reconstruction_loss: 1896.0305 - val_kl_loss: 99.7521 - val_false_loss: 11.6089 - val_true_loss: 1.1417\n",
      "Epoch 2592/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.3362 - reconstruction_loss: 1889.7445 - kl_loss: 102.3092 - false_loss: 0.0831 - true_loss: 1.0799 - val_loss: 5592.3179 - val_reconstruction_loss: 1896.0303 - val_kl_loss: 99.7530 - val_false_loss: 11.6079 - val_true_loss: 1.1416\n",
      "Epoch 2593/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.2878 - reconstruction_loss: 1889.4376 - kl_loss: 103.7437 - false_loss: 0.0831 - true_loss: 1.0798 - val_loss: 5592.0186 - val_reconstruction_loss: 1896.0298 - val_kl_loss: 99.7540 - val_false_loss: 11.6069 - val_true_loss: 1.1416\n",
      "Epoch 2594/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.1722 - reconstruction_loss: 1889.4106 - kl_loss: 103.9652 - false_loss: 0.0831 - true_loss: 1.0798 - val_loss: 5591.7290 - val_reconstruction_loss: 1896.0293 - val_kl_loss: 99.7550 - val_false_loss: 11.6060 - val_true_loss: 1.1415\n",
      "Epoch 2595/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.0253 - reconstruction_loss: 1889.3384 - kl_loss: 104.5774 - false_loss: 0.0831 - true_loss: 1.0797 - val_loss: 5591.4409 - val_reconstruction_loss: 1896.0291 - val_kl_loss: 99.7555 - val_false_loss: 11.6050 - val_true_loss: 1.1415\n",
      "Epoch 2596/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.7146 - reconstruction_loss: 1889.5509 - kl_loss: 103.5999 - false_loss: 0.0831 - true_loss: 1.0797 - val_loss: 5591.1489 - val_reconstruction_loss: 1896.0286 - val_kl_loss: 99.7561 - val_false_loss: 11.6041 - val_true_loss: 1.1414\n",
      "Epoch 2597/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.7702 - reconstruction_loss: 1889.8644 - kl_loss: 102.3683 - false_loss: 0.0831 - true_loss: 1.0796 - val_loss: 5590.8647 - val_reconstruction_loss: 1896.0283 - val_kl_loss: 99.7571 - val_false_loss: 11.6032 - val_true_loss: 1.1414\n",
      "Epoch 2598/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.0406 - reconstruction_loss: 1889.9283 - kl_loss: 103.3051 - false_loss: 0.0830 - true_loss: 1.0796 - val_loss: 5590.5898 - val_reconstruction_loss: 1896.0277 - val_kl_loss: 99.7576 - val_false_loss: 11.6023 - val_true_loss: 1.1413\n",
      "Epoch 2599/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.8985 - reconstruction_loss: 1889.8759 - kl_loss: 103.3302 - false_loss: 0.0830 - true_loss: 1.0795 - val_loss: 5590.3042 - val_reconstruction_loss: 1896.0272 - val_kl_loss: 99.7583 - val_false_loss: 11.6013 - val_true_loss: 1.1413\n",
      "Epoch 2600/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.7273 - reconstruction_loss: 1889.8379 - kl_loss: 103.4383 - false_loss: 0.0830 - true_loss: 1.0795 - val_loss: 5590.0122 - val_reconstruction_loss: 1896.0270 - val_kl_loss: 99.7593 - val_false_loss: 11.6004 - val_true_loss: 1.1413\n",
      "Epoch 2601/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2201.7126 - reconstruction_loss: 1889.8004 - kl_loss: 104.5974 - false_loss: 0.0830 - true_loss: 1.0794 - val_loss: 5589.7251 - val_reconstruction_loss: 1896.0265 - val_kl_loss: 99.7599 - val_false_loss: 11.5994 - val_true_loss: 1.1412\n",
      "Epoch 2602/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.6907 - reconstruction_loss: 1889.5889 - kl_loss: 104.5496 - false_loss: 0.0830 - true_loss: 1.0794 - val_loss: 5589.4395 - val_reconstruction_loss: 1896.0261 - val_kl_loss: 99.7606 - val_false_loss: 11.5985 - val_true_loss: 1.1412\n",
      "Epoch 2603/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.8867 - reconstruction_loss: 1889.3833 - kl_loss: 104.2843 - false_loss: 0.0830 - true_loss: 1.0793 - val_loss: 5589.1494 - val_reconstruction_loss: 1896.0258 - val_kl_loss: 99.7614 - val_false_loss: 11.5975 - val_true_loss: 1.1411\n",
      "Epoch 2604/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.1585 - reconstruction_loss: 1889.5006 - kl_loss: 103.2289 - false_loss: 0.0830 - true_loss: 1.0793 - val_loss: 5588.8613 - val_reconstruction_loss: 1896.0254 - val_kl_loss: 99.7623 - val_false_loss: 11.5966 - val_true_loss: 1.1411\n",
      "Epoch 2605/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.6730 - reconstruction_loss: 1889.6450 - kl_loss: 103.1446 - false_loss: 0.0830 - true_loss: 1.0793 - val_loss: 5588.5757 - val_reconstruction_loss: 1896.0251 - val_kl_loss: 99.7630 - val_false_loss: 11.5956 - val_true_loss: 1.1410\n",
      "Epoch 2606/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.7796 - reconstruction_loss: 1889.3539 - kl_loss: 103.9231 - false_loss: 0.0830 - true_loss: 1.0792 - val_loss: 5588.2886 - val_reconstruction_loss: 1896.0247 - val_kl_loss: 99.7636 - val_false_loss: 11.5947 - val_true_loss: 1.1410\n",
      "Epoch 2607/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.1687 - reconstruction_loss: 1889.7279 - kl_loss: 103.4401 - false_loss: 0.0830 - true_loss: 1.0792 - val_loss: 5588.0039 - val_reconstruction_loss: 1896.0242 - val_kl_loss: 99.7644 - val_false_loss: 11.5938 - val_true_loss: 1.1409\n",
      "Epoch 2608/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.9897 - reconstruction_loss: 1889.6636 - kl_loss: 104.1506 - false_loss: 0.0830 - true_loss: 1.0791 - val_loss: 5587.7148 - val_reconstruction_loss: 1896.0238 - val_kl_loss: 99.7652 - val_false_loss: 11.5928 - val_true_loss: 1.1409\n",
      "Epoch 2609/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.6709 - reconstruction_loss: 1889.7090 - kl_loss: 103.5778 - false_loss: 0.0830 - true_loss: 1.0791 - val_loss: 5587.4243 - val_reconstruction_loss: 1896.0233 - val_kl_loss: 99.7658 - val_false_loss: 11.5919 - val_true_loss: 1.1409\n",
      "Epoch 2610/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.2344 - reconstruction_loss: 1889.3846 - kl_loss: 101.9932 - false_loss: 0.0830 - true_loss: 1.0790 - val_loss: 5587.1323 - val_reconstruction_loss: 1896.0229 - val_kl_loss: 99.7665 - val_false_loss: 11.5909 - val_true_loss: 1.1408\n",
      "Epoch 2611/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0264 - reconstruction_loss: 1889.7333 - kl_loss: 102.2179 - false_loss: 0.0830 - true_loss: 1.0790 - val_loss: 5586.8457 - val_reconstruction_loss: 1896.0226 - val_kl_loss: 99.7673 - val_false_loss: 11.5900 - val_true_loss: 1.1408\n",
      "Epoch 2612/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.0697 - reconstruction_loss: 1890.1608 - kl_loss: 103.4378 - false_loss: 0.0829 - true_loss: 1.0789 - val_loss: 5586.5591 - val_reconstruction_loss: 1896.0223 - val_kl_loss: 99.7684 - val_false_loss: 11.5890 - val_true_loss: 1.1407\n",
      "Epoch 2613/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.1437 - reconstruction_loss: 1889.4918 - kl_loss: 104.2906 - false_loss: 0.0829 - true_loss: 1.0789 - val_loss: 5586.2690 - val_reconstruction_loss: 1896.0219 - val_kl_loss: 99.7689 - val_false_loss: 11.5881 - val_true_loss: 1.1407\n",
      "Epoch 2614/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.8436 - reconstruction_loss: 1889.2601 - kl_loss: 104.2472 - false_loss: 0.0829 - true_loss: 1.0788 - val_loss: 5585.9805 - val_reconstruction_loss: 1896.0215 - val_kl_loss: 99.7694 - val_false_loss: 11.5871 - val_true_loss: 1.1406\n",
      "Epoch 2615/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.3051 - reconstruction_loss: 1889.9209 - kl_loss: 104.2191 - false_loss: 0.0829 - true_loss: 1.0788 - val_loss: 5585.6938 - val_reconstruction_loss: 1896.0211 - val_kl_loss: 99.7696 - val_false_loss: 11.5862 - val_true_loss: 1.1406\n",
      "Epoch 2616/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0535 - reconstruction_loss: 1889.3324 - kl_loss: 102.7682 - false_loss: 0.0829 - true_loss: 1.0787 - val_loss: 5585.4082 - val_reconstruction_loss: 1896.0206 - val_kl_loss: 99.7703 - val_false_loss: 11.5852 - val_true_loss: 1.1405\n",
      "Epoch 2617/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.8973 - reconstruction_loss: 1889.8955 - kl_loss: 103.1682 - false_loss: 0.0829 - true_loss: 1.0787 - val_loss: 5585.1240 - val_reconstruction_loss: 1896.0203 - val_kl_loss: 99.7707 - val_false_loss: 11.5843 - val_true_loss: 1.1405\n",
      "Epoch 2618/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.1980 - reconstruction_loss: 1890.3439 - kl_loss: 102.6065 - false_loss: 0.0829 - true_loss: 1.0786 - val_loss: 5584.8364 - val_reconstruction_loss: 1896.0198 - val_kl_loss: 99.7713 - val_false_loss: 11.5833 - val_true_loss: 1.1405\n",
      "Epoch 2619/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.0250 - reconstruction_loss: 1889.8070 - kl_loss: 104.2961 - false_loss: 0.0829 - true_loss: 1.0786 - val_loss: 5584.5518 - val_reconstruction_loss: 1896.0193 - val_kl_loss: 99.7720 - val_false_loss: 11.5824 - val_true_loss: 1.1404\n",
      "Epoch 2620/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.0809 - reconstruction_loss: 1889.4561 - kl_loss: 103.5173 - false_loss: 0.0829 - true_loss: 1.0785 - val_loss: 5584.2700 - val_reconstruction_loss: 1896.0189 - val_kl_loss: 99.7729 - val_false_loss: 11.5815 - val_true_loss: 1.1404\n",
      "Epoch 2621/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.0643 - reconstruction_loss: 1890.0199 - kl_loss: 103.6664 - false_loss: 0.0829 - true_loss: 1.0785 - val_loss: 5583.9849 - val_reconstruction_loss: 1896.0186 - val_kl_loss: 99.7739 - val_false_loss: 11.5806 - val_true_loss: 1.1403\n",
      "Epoch 2622/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.6308 - reconstruction_loss: 1890.1234 - kl_loss: 104.2987 - false_loss: 0.0829 - true_loss: 1.0784 - val_loss: 5583.6929 - val_reconstruction_loss: 1896.0182 - val_kl_loss: 99.7750 - val_false_loss: 11.5796 - val_true_loss: 1.1403\n",
      "Epoch 2623/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.8037 - reconstruction_loss: 1889.9458 - kl_loss: 101.8970 - false_loss: 0.0829 - true_loss: 1.0784 - val_loss: 5583.4155 - val_reconstruction_loss: 1896.0178 - val_kl_loss: 99.7758 - val_false_loss: 11.5787 - val_true_loss: 1.1402\n",
      "Epoch 2624/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.5915 - reconstruction_loss: 1889.5541 - kl_loss: 104.0535 - false_loss: 0.0829 - true_loss: 1.0783 - val_loss: 5583.1343 - val_reconstruction_loss: 1896.0173 - val_kl_loss: 99.7766 - val_false_loss: 11.5778 - val_true_loss: 1.1402\n",
      "Epoch 2625/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.2659 - reconstruction_loss: 1889.0566 - kl_loss: 103.7135 - false_loss: 0.0829 - true_loss: 1.0783 - val_loss: 5582.8579 - val_reconstruction_loss: 1896.0168 - val_kl_loss: 99.7772 - val_false_loss: 11.5768 - val_true_loss: 1.1402\n",
      "Epoch 2626/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.4013 - reconstruction_loss: 1889.2900 - kl_loss: 103.8239 - false_loss: 0.0828 - true_loss: 1.0783 - val_loss: 5582.5669 - val_reconstruction_loss: 1896.0167 - val_kl_loss: 99.7774 - val_false_loss: 11.5759 - val_true_loss: 1.1401\n",
      "Epoch 2627/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.6593 - reconstruction_loss: 1889.8715 - kl_loss: 104.1205 - false_loss: 0.0828 - true_loss: 1.0782 - val_loss: 5582.2778 - val_reconstruction_loss: 1896.0162 - val_kl_loss: 99.7786 - val_false_loss: 11.5749 - val_true_loss: 1.1401\n",
      "Epoch 2628/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4138 - reconstruction_loss: 1889.4736 - kl_loss: 101.6136 - false_loss: 0.0828 - true_loss: 1.0782 - val_loss: 5581.9976 - val_reconstruction_loss: 1896.0160 - val_kl_loss: 99.7793 - val_false_loss: 11.5740 - val_true_loss: 1.1401\n",
      "Epoch 2629/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.9647 - reconstruction_loss: 1889.6969 - kl_loss: 99.2469 - false_loss: 0.0828 - true_loss: 1.0781 - val_loss: 5581.7114 - val_reconstruction_loss: 1896.0155 - val_kl_loss: 99.7794 - val_false_loss: 11.5731 - val_true_loss: 1.1400\n",
      "Epoch 2630/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7539 - reconstruction_loss: 1889.8470 - kl_loss: 100.4029 - false_loss: 0.0828 - true_loss: 1.0781 - val_loss: 5581.4282 - val_reconstruction_loss: 1896.0149 - val_kl_loss: 99.7799 - val_false_loss: 11.5721 - val_true_loss: 1.1400\n",
      "Epoch 2631/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.5701 - reconstruction_loss: 1889.4122 - kl_loss: 99.1811 - false_loss: 0.0828 - true_loss: 1.0781 - val_loss: 5581.1396 - val_reconstruction_loss: 1896.0144 - val_kl_loss: 99.7806 - val_false_loss: 11.5712 - val_true_loss: 1.1400\n",
      "Epoch 2632/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.9918 - reconstruction_loss: 1889.9506 - kl_loss: 96.3423 - false_loss: 0.0828 - true_loss: 1.0780 - val_loss: 5580.8345 - val_reconstruction_loss: 1896.0142 - val_kl_loss: 99.7809 - val_false_loss: 11.5702 - val_true_loss: 1.1399\n",
      "Epoch 2633/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2263.5441 - reconstruction_loss: 1891.0524 - kl_loss: 93.3928 - false_loss: 0.0828 - true_loss: 1.0780 - val_loss: 5580.5581 - val_reconstruction_loss: 1896.0139 - val_kl_loss: 99.7807 - val_false_loss: 11.5693 - val_true_loss: 1.1399\n",
      "Epoch 2634/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.3880 - reconstruction_loss: 1890.1324 - kl_loss: 97.3693 - false_loss: 0.0828 - true_loss: 1.0780 - val_loss: 5580.2681 - val_reconstruction_loss: 1896.0134 - val_kl_loss: 99.7808 - val_false_loss: 11.5683 - val_true_loss: 1.1399\n",
      "Epoch 2635/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7248 - reconstruction_loss: 1889.5294 - kl_loss: 100.4589 - false_loss: 0.0828 - true_loss: 1.0779 - val_loss: 5579.9736 - val_reconstruction_loss: 1896.0131 - val_kl_loss: 99.7809 - val_false_loss: 11.5673 - val_true_loss: 1.1398\n",
      "Epoch 2636/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.6148 - reconstruction_loss: 1889.6613 - kl_loss: 99.7079 - false_loss: 0.0828 - true_loss: 1.0779 - val_loss: 5579.6875 - val_reconstruction_loss: 1896.0127 - val_kl_loss: 99.7812 - val_false_loss: 11.5664 - val_true_loss: 1.1398\n",
      "Epoch 2637/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.9065 - reconstruction_loss: 1889.6465 - kl_loss: 100.7046 - false_loss: 0.0828 - true_loss: 1.0779 - val_loss: 5579.4077 - val_reconstruction_loss: 1896.0123 - val_kl_loss: 99.7815 - val_false_loss: 11.5655 - val_true_loss: 1.1398\n",
      "Epoch 2638/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1032 - reconstruction_loss: 1889.7208 - kl_loss: 100.7654 - false_loss: 0.0828 - true_loss: 1.0778 - val_loss: 5579.1328 - val_reconstruction_loss: 1896.0120 - val_kl_loss: 99.7818 - val_false_loss: 11.5646 - val_true_loss: 1.1397\n",
      "Epoch 2639/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3257 - reconstruction_loss: 1889.6901 - kl_loss: 99.1845 - false_loss: 0.0828 - true_loss: 1.0778 - val_loss: 5578.8389 - val_reconstruction_loss: 1896.0115 - val_kl_loss: 99.7826 - val_false_loss: 11.5636 - val_true_loss: 1.1397\n",
      "Epoch 2640/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3853 - reconstruction_loss: 1889.4141 - kl_loss: 99.6618 - false_loss: 0.0828 - true_loss: 1.0777 - val_loss: 5578.5547 - val_reconstruction_loss: 1896.0112 - val_kl_loss: 99.7831 - val_false_loss: 11.5627 - val_true_loss: 1.1397\n",
      "Epoch 2641/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.0837 - reconstruction_loss: 1889.6455 - kl_loss: 100.1668 - false_loss: 0.0828 - true_loss: 1.0777 - val_loss: 5578.2686 - val_reconstruction_loss: 1896.0107 - val_kl_loss: 99.7836 - val_false_loss: 11.5617 - val_true_loss: 1.1396\n",
      "Epoch 2642/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.0325 - reconstruction_loss: 1889.5220 - kl_loss: 99.7432 - false_loss: 0.0827 - true_loss: 1.0777 - val_loss: 5577.9805 - val_reconstruction_loss: 1896.0103 - val_kl_loss: 99.7843 - val_false_loss: 11.5608 - val_true_loss: 1.1396\n",
      "Epoch 2643/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.9612 - reconstruction_loss: 1889.3190 - kl_loss: 101.2677 - false_loss: 0.0827 - true_loss: 1.0776 - val_loss: 5577.6958 - val_reconstruction_loss: 1896.0098 - val_kl_loss: 99.7848 - val_false_loss: 11.5598 - val_true_loss: 1.1395\n",
      "Epoch 2644/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.1852 - reconstruction_loss: 1889.5049 - kl_loss: 102.5642 - false_loss: 0.0827 - true_loss: 1.0776 - val_loss: 5577.4082 - val_reconstruction_loss: 1896.0094 - val_kl_loss: 99.7854 - val_false_loss: 11.5589 - val_true_loss: 1.1395\n",
      "Epoch 2645/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.7045 - reconstruction_loss: 1889.5983 - kl_loss: 101.9002 - false_loss: 0.0827 - true_loss: 1.0775 - val_loss: 5577.1196 - val_reconstruction_loss: 1896.0092 - val_kl_loss: 99.7857 - val_false_loss: 11.5580 - val_true_loss: 1.1394\n",
      "Epoch 2646/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.1749 - reconstruction_loss: 1889.4095 - kl_loss: 103.1795 - false_loss: 0.0827 - true_loss: 1.0775 - val_loss: 5576.8267 - val_reconstruction_loss: 1896.0087 - val_kl_loss: 99.7864 - val_false_loss: 11.5570 - val_true_loss: 1.1394\n",
      "Epoch 2647/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.1060 - reconstruction_loss: 1889.4619 - kl_loss: 103.5301 - false_loss: 0.0827 - true_loss: 1.0774 - val_loss: 5576.5327 - val_reconstruction_loss: 1896.0084 - val_kl_loss: 99.7875 - val_false_loss: 11.5560 - val_true_loss: 1.1394\n",
      "Epoch 2648/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.3813 - reconstruction_loss: 1889.5485 - kl_loss: 103.8868 - false_loss: 0.0827 - true_loss: 1.0774 - val_loss: 5576.2466 - val_reconstruction_loss: 1896.0079 - val_kl_loss: 99.7883 - val_false_loss: 11.5551 - val_true_loss: 1.1393\n",
      "Epoch 2649/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.1583 - reconstruction_loss: 1889.1451 - kl_loss: 104.3743 - false_loss: 0.0827 - true_loss: 1.0773 - val_loss: 5575.9609 - val_reconstruction_loss: 1896.0076 - val_kl_loss: 99.7886 - val_false_loss: 11.5541 - val_true_loss: 1.1393\n",
      "Epoch 2650/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.2315 - reconstruction_loss: 1889.6688 - kl_loss: 102.8115 - false_loss: 0.0827 - true_loss: 1.0773 - val_loss: 5575.6704 - val_reconstruction_loss: 1896.0073 - val_kl_loss: 99.7888 - val_false_loss: 11.5532 - val_true_loss: 1.1392\n",
      "Epoch 2651/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.3556 - reconstruction_loss: 1889.5273 - kl_loss: 102.3900 - false_loss: 0.0827 - true_loss: 1.0772 - val_loss: 5575.3770 - val_reconstruction_loss: 1896.0068 - val_kl_loss: 99.7883 - val_false_loss: 11.5522 - val_true_loss: 1.1392\n",
      "Epoch 2652/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.9483 - reconstruction_loss: 1890.0084 - kl_loss: 101.6106 - false_loss: 0.0827 - true_loss: 1.0772 - val_loss: 5575.0854 - val_reconstruction_loss: 1896.0067 - val_kl_loss: 99.7886 - val_false_loss: 11.5513 - val_true_loss: 1.1391\n",
      "Epoch 2653/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2209.7849 - reconstruction_loss: 1889.9423 - kl_loss: 103.6518 - false_loss: 0.0827 - true_loss: 1.0771 - val_loss: 5574.7905 - val_reconstruction_loss: 1896.0062 - val_kl_loss: 99.7894 - val_false_loss: 11.5503 - val_true_loss: 1.1391\n",
      "Epoch 2654/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.4480 - reconstruction_loss: 1889.7242 - kl_loss: 104.0628 - false_loss: 0.0827 - true_loss: 1.0771 - val_loss: 5574.4961 - val_reconstruction_loss: 1896.0057 - val_kl_loss: 99.7898 - val_false_loss: 11.5493 - val_true_loss: 1.1390\n",
      "Epoch 2655/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.9095 - reconstruction_loss: 1889.5244 - kl_loss: 104.1946 - false_loss: 0.0827 - true_loss: 1.0770 - val_loss: 5574.2095 - val_reconstruction_loss: 1896.0055 - val_kl_loss: 99.7905 - val_false_loss: 11.5484 - val_true_loss: 1.1390\n",
      "Epoch 2656/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.7978 - reconstruction_loss: 1889.2700 - kl_loss: 104.0647 - false_loss: 0.0826 - true_loss: 1.0770 - val_loss: 5573.9146 - val_reconstruction_loss: 1896.0050 - val_kl_loss: 99.7914 - val_false_loss: 11.5474 - val_true_loss: 1.1390\n",
      "Epoch 2657/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.3504 - reconstruction_loss: 1889.9658 - kl_loss: 104.0189 - false_loss: 0.0826 - true_loss: 1.0769 - val_loss: 5573.6245 - val_reconstruction_loss: 1896.0048 - val_kl_loss: 99.7924 - val_false_loss: 11.5465 - val_true_loss: 1.1389\n",
      "Epoch 2658/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.2240 - reconstruction_loss: 1889.5936 - kl_loss: 103.0947 - false_loss: 0.0826 - true_loss: 1.0769 - val_loss: 5573.3364 - val_reconstruction_loss: 1896.0043 - val_kl_loss: 99.7931 - val_false_loss: 11.5455 - val_true_loss: 1.1389\n",
      "Epoch 2659/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.0222 - reconstruction_loss: 1889.3907 - kl_loss: 103.4502 - false_loss: 0.0826 - true_loss: 1.0768 - val_loss: 5573.0474 - val_reconstruction_loss: 1896.0037 - val_kl_loss: 99.7937 - val_false_loss: 11.5446 - val_true_loss: 1.1388\n",
      "Epoch 2660/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.2745 - reconstruction_loss: 1890.0830 - kl_loss: 103.5833 - false_loss: 0.0826 - true_loss: 1.0768 - val_loss: 5572.7563 - val_reconstruction_loss: 1896.0032 - val_kl_loss: 99.7941 - val_false_loss: 11.5436 - val_true_loss: 1.1388\n",
      "Epoch 2661/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.5532 - reconstruction_loss: 1890.1117 - kl_loss: 102.6605 - false_loss: 0.0826 - true_loss: 1.0767 - val_loss: 5572.4814 - val_reconstruction_loss: 1896.0029 - val_kl_loss: 99.7947 - val_false_loss: 11.5427 - val_true_loss: 1.1387\n",
      "Epoch 2662/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.6846 - reconstruction_loss: 1889.8766 - kl_loss: 103.3021 - false_loss: 0.0826 - true_loss: 1.0767 - val_loss: 5572.2085 - val_reconstruction_loss: 1896.0024 - val_kl_loss: 99.7952 - val_false_loss: 11.5418 - val_true_loss: 1.1387\n",
      "Epoch 2663/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5224 - reconstruction_loss: 1889.2484 - kl_loss: 102.0651 - false_loss: 0.0826 - true_loss: 1.0767 - val_loss: 5571.9282 - val_reconstruction_loss: 1896.0020 - val_kl_loss: 99.7952 - val_false_loss: 11.5409 - val_true_loss: 1.1387\n",
      "Epoch 2664/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.6527 - reconstruction_loss: 1889.2129 - kl_loss: 101.4235 - false_loss: 0.0826 - true_loss: 1.0766 - val_loss: 5571.6450 - val_reconstruction_loss: 1896.0017 - val_kl_loss: 99.7950 - val_false_loss: 11.5400 - val_true_loss: 1.1386\n",
      "Epoch 2665/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.2261 - reconstruction_loss: 1889.4990 - kl_loss: 99.9681 - false_loss: 0.0826 - true_loss: 1.0766 - val_loss: 5571.3584 - val_reconstruction_loss: 1896.0012 - val_kl_loss: 99.7949 - val_false_loss: 11.5390 - val_true_loss: 1.1386\n",
      "Epoch 2666/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.5067 - reconstruction_loss: 1889.3392 - kl_loss: 100.1132 - false_loss: 0.0826 - true_loss: 1.0765 - val_loss: 5571.0806 - val_reconstruction_loss: 1896.0010 - val_kl_loss: 99.7946 - val_false_loss: 11.5381 - val_true_loss: 1.1385\n",
      "Epoch 2667/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0844 - reconstruction_loss: 1889.4010 - kl_loss: 98.9888 - false_loss: 0.0826 - true_loss: 1.0765 - val_loss: 5570.8018 - val_reconstruction_loss: 1896.0006 - val_kl_loss: 99.7952 - val_false_loss: 11.5372 - val_true_loss: 1.1385\n",
      "Epoch 2668/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.6905 - reconstruction_loss: 1889.4454 - kl_loss: 100.2572 - false_loss: 0.0826 - true_loss: 1.0765 - val_loss: 5570.5171 - val_reconstruction_loss: 1896.0002 - val_kl_loss: 99.7955 - val_false_loss: 11.5363 - val_true_loss: 1.1385\n",
      "Epoch 2669/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.5655 - reconstruction_loss: 1889.8038 - kl_loss: 99.0738 - false_loss: 0.0826 - true_loss: 1.0764 - val_loss: 5570.2437 - val_reconstruction_loss: 1895.9998 - val_kl_loss: 99.7964 - val_false_loss: 11.5354 - val_true_loss: 1.1384\n",
      "Epoch 2670/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.4409 - reconstruction_loss: 1890.1455 - kl_loss: 97.9902 - false_loss: 0.0826 - true_loss: 1.0764 - val_loss: 5569.9487 - val_reconstruction_loss: 1895.9994 - val_kl_loss: 99.7959 - val_false_loss: 11.5344 - val_true_loss: 1.1384\n",
      "Epoch 2671/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.2870 - reconstruction_loss: 1889.7383 - kl_loss: 101.1561 - false_loss: 0.0825 - true_loss: 1.0764 - val_loss: 5569.6675 - val_reconstruction_loss: 1895.9990 - val_kl_loss: 99.7965 - val_false_loss: 11.5335 - val_true_loss: 1.1384\n",
      "Epoch 2672/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.7418 - reconstruction_loss: 1889.5400 - kl_loss: 102.0840 - false_loss: 0.0825 - true_loss: 1.0763 - val_loss: 5569.3853 - val_reconstruction_loss: 1895.9985 - val_kl_loss: 99.7968 - val_false_loss: 11.5325 - val_true_loss: 1.1383\n",
      "Epoch 2673/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.1301 - reconstruction_loss: 1889.2272 - kl_loss: 101.6640 - false_loss: 0.0825 - true_loss: 1.0763 - val_loss: 5569.0981 - val_reconstruction_loss: 1895.9983 - val_kl_loss: 99.7969 - val_false_loss: 11.5316 - val_true_loss: 1.1383\n",
      "Epoch 2674/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.7523 - reconstruction_loss: 1889.7261 - kl_loss: 100.1169 - false_loss: 0.0825 - true_loss: 1.0762 - val_loss: 5568.8145 - val_reconstruction_loss: 1895.9978 - val_kl_loss: 99.7971 - val_false_loss: 11.5307 - val_true_loss: 1.1382\n",
      "Epoch 2675/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7053 - reconstruction_loss: 1889.2828 - kl_loss: 101.7091 - false_loss: 0.0825 - true_loss: 1.0762 - val_loss: 5568.5200 - val_reconstruction_loss: 1895.9973 - val_kl_loss: 99.7976 - val_false_loss: 11.5297 - val_true_loss: 1.1382\n",
      "Epoch 2676/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.4445 - reconstruction_loss: 1889.7622 - kl_loss: 101.5485 - false_loss: 0.0825 - true_loss: 1.0761 - val_loss: 5568.2407 - val_reconstruction_loss: 1895.9971 - val_kl_loss: 99.7985 - val_false_loss: 11.5288 - val_true_loss: 1.1382\n",
      "Epoch 2677/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.8053 - reconstruction_loss: 1889.7650 - kl_loss: 101.3593 - false_loss: 0.0825 - true_loss: 1.0761 - val_loss: 5567.9556 - val_reconstruction_loss: 1895.9968 - val_kl_loss: 99.7991 - val_false_loss: 11.5278 - val_true_loss: 1.1381\n",
      "Epoch 2678/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.6276 - reconstruction_loss: 1889.4349 - kl_loss: 101.0640 - false_loss: 0.0825 - true_loss: 1.0761 - val_loss: 5567.6743 - val_reconstruction_loss: 1895.9963 - val_kl_loss: 99.7997 - val_false_loss: 11.5269 - val_true_loss: 1.1381\n",
      "Epoch 2679/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4405 - reconstruction_loss: 1889.4525 - kl_loss: 99.7440 - false_loss: 0.0825 - true_loss: 1.0760 - val_loss: 5567.3867 - val_reconstruction_loss: 1895.9958 - val_kl_loss: 99.7996 - val_false_loss: 11.5260 - val_true_loss: 1.1380\n",
      "Epoch 2680/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.0270 - reconstruction_loss: 1889.6947 - kl_loss: 101.0466 - false_loss: 0.0825 - true_loss: 1.0760 - val_loss: 5567.0942 - val_reconstruction_loss: 1895.9956 - val_kl_loss: 99.7997 - val_false_loss: 11.5250 - val_true_loss: 1.1380\n",
      "Epoch 2681/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.5730 - reconstruction_loss: 1889.8693 - kl_loss: 101.2763 - false_loss: 0.0825 - true_loss: 1.0759 - val_loss: 5566.8057 - val_reconstruction_loss: 1895.9951 - val_kl_loss: 99.7996 - val_false_loss: 11.5241 - val_true_loss: 1.1380\n",
      "Epoch 2682/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.8656 - reconstruction_loss: 1889.9823 - kl_loss: 98.8380 - false_loss: 0.0825 - true_loss: 1.0759 - val_loss: 5566.5244 - val_reconstruction_loss: 1895.9949 - val_kl_loss: 99.7996 - val_false_loss: 11.5231 - val_true_loss: 1.1379\n",
      "Epoch 2683/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.5363 - reconstruction_loss: 1889.7740 - kl_loss: 100.7896 - false_loss: 0.0825 - true_loss: 1.0759 - val_loss: 5566.2363 - val_reconstruction_loss: 1895.9944 - val_kl_loss: 99.8001 - val_false_loss: 11.5222 - val_true_loss: 1.1379\n",
      "Epoch 2684/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.3605 - reconstruction_loss: 1890.0021 - kl_loss: 100.2049 - false_loss: 0.0825 - true_loss: 1.0758 - val_loss: 5565.9536 - val_reconstruction_loss: 1895.9940 - val_kl_loss: 99.8006 - val_false_loss: 11.5213 - val_true_loss: 1.1378\n",
      "Epoch 2685/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.0088 - reconstruction_loss: 1889.8373 - kl_loss: 99.0213 - false_loss: 0.0825 - true_loss: 1.0758 - val_loss: 5565.6606 - val_reconstruction_loss: 1895.9937 - val_kl_loss: 99.8011 - val_false_loss: 11.5203 - val_true_loss: 1.1378\n",
      "Epoch 2686/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3043 - reconstruction_loss: 1889.7207 - kl_loss: 100.8236 - false_loss: 0.0824 - true_loss: 1.0757 - val_loss: 5565.3770 - val_reconstruction_loss: 1895.9933 - val_kl_loss: 99.8015 - val_false_loss: 11.5194 - val_true_loss: 1.1378\n",
      "Epoch 2687/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.4179 - reconstruction_loss: 1889.2609 - kl_loss: 102.0628 - false_loss: 0.0824 - true_loss: 1.0757 - val_loss: 5565.1021 - val_reconstruction_loss: 1895.9928 - val_kl_loss: 99.8018 - val_false_loss: 11.5185 - val_true_loss: 1.1377\n",
      "Epoch 2688/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.6086 - reconstruction_loss: 1889.1221 - kl_loss: 102.1248 - false_loss: 0.0824 - true_loss: 1.0756 - val_loss: 5564.8228 - val_reconstruction_loss: 1895.9924 - val_kl_loss: 99.8021 - val_false_loss: 11.5175 - val_true_loss: 1.1377\n",
      "Epoch 2689/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.2999 - reconstruction_loss: 1889.2383 - kl_loss: 101.4429 - false_loss: 0.0824 - true_loss: 1.0756 - val_loss: 5564.5493 - val_reconstruction_loss: 1895.9921 - val_kl_loss: 99.8023 - val_false_loss: 11.5167 - val_true_loss: 1.1377\n",
      "Epoch 2690/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.7894 - reconstruction_loss: 1889.5127 - kl_loss: 101.4818 - false_loss: 0.0824 - true_loss: 1.0756 - val_loss: 5564.2690 - val_reconstruction_loss: 1895.9917 - val_kl_loss: 99.8023 - val_false_loss: 11.5157 - val_true_loss: 1.1376\n",
      "Epoch 2691/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.7399 - reconstruction_loss: 1889.5543 - kl_loss: 98.5766 - false_loss: 0.0824 - true_loss: 1.0755 - val_loss: 5563.9849 - val_reconstruction_loss: 1895.9912 - val_kl_loss: 99.8027 - val_false_loss: 11.5148 - val_true_loss: 1.1376\n",
      "Epoch 2692/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5088 - reconstruction_loss: 1890.3809 - kl_loss: 98.9451 - false_loss: 0.0824 - true_loss: 1.0755 - val_loss: 5563.6978 - val_reconstruction_loss: 1895.9908 - val_kl_loss: 99.8030 - val_false_loss: 11.5139 - val_true_loss: 1.1375\n",
      "Epoch 2693/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.3019 - reconstruction_loss: 1890.3822 - kl_loss: 99.9780 - false_loss: 0.0824 - true_loss: 1.0754 - val_loss: 5563.4204 - val_reconstruction_loss: 1895.9905 - val_kl_loss: 99.8038 - val_false_loss: 11.5129 - val_true_loss: 1.1375\n",
      "Epoch 2694/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.6099 - reconstruction_loss: 1890.5052 - kl_loss: 101.1684 - false_loss: 0.0824 - true_loss: 1.0754 - val_loss: 5563.1348 - val_reconstruction_loss: 1895.9901 - val_kl_loss: 99.8047 - val_false_loss: 11.5120 - val_true_loss: 1.1375\n",
      "Epoch 2695/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.4088 - reconstruction_loss: 1890.0439 - kl_loss: 101.6562 - false_loss: 0.0824 - true_loss: 1.0753 - val_loss: 5562.8481 - val_reconstruction_loss: 1895.9896 - val_kl_loss: 99.8059 - val_false_loss: 11.5111 - val_true_loss: 1.1374\n",
      "Epoch 2696/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.5149 - reconstruction_loss: 1889.9845 - kl_loss: 102.7867 - false_loss: 0.0824 - true_loss: 1.0753 - val_loss: 5562.5664 - val_reconstruction_loss: 1895.9894 - val_kl_loss: 99.8066 - val_false_loss: 11.5101 - val_true_loss: 1.1374\n",
      "Epoch 2697/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.1016 - reconstruction_loss: 1889.4945 - kl_loss: 102.4391 - false_loss: 0.0824 - true_loss: 1.0753 - val_loss: 5562.2876 - val_reconstruction_loss: 1895.9891 - val_kl_loss: 99.8077 - val_false_loss: 11.5092 - val_true_loss: 1.1373\n",
      "Epoch 2698/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2031 - reconstruction_loss: 1889.3271 - kl_loss: 101.5768 - false_loss: 0.0824 - true_loss: 1.0752 - val_loss: 5562.0015 - val_reconstruction_loss: 1895.9886 - val_kl_loss: 99.8081 - val_false_loss: 11.5083 - val_true_loss: 1.1373\n",
      "Epoch 2699/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.8776 - reconstruction_loss: 1889.2723 - kl_loss: 100.9265 - false_loss: 0.0824 - true_loss: 1.0752 - val_loss: 5561.7173 - val_reconstruction_loss: 1895.9882 - val_kl_loss: 99.8077 - val_false_loss: 11.5073 - val_true_loss: 1.1373\n",
      "Epoch 2700/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.0128 - reconstruction_loss: 1890.0267 - kl_loss: 97.4909 - false_loss: 0.0824 - true_loss: 1.0752 - val_loss: 5561.4370 - val_reconstruction_loss: 1895.9879 - val_kl_loss: 99.8078 - val_false_loss: 11.5064 - val_true_loss: 1.1372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fad94bf8eb8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"vae_best_model.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(x = [data,true_data,false_data ],y= data[:,:,:,:], epochs=2700, batch_size=5000, \n",
    "          validation_data=([data_test,true_data_test,false_data_test ], data_test),validation_batch_size=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2700\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2221.9847 - reconstruction_loss: 1889.7529 - kl_loss: 98.3611 - false_loss: 0.0823 - true_loss: 1.0751 - val_loss: 5561.1548 - val_reconstruction_loss: 1895.9874 - val_kl_loss: 99.8086 - val_false_loss: 11.5055 - val_true_loss: 1.1372\n",
      "Epoch 2/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.6500 - reconstruction_loss: 1889.7163 - kl_loss: 101.3758 - false_loss: 0.0823 - true_loss: 1.0751 - val_loss: 5560.8721 - val_reconstruction_loss: 1895.9871 - val_kl_loss: 99.8092 - val_false_loss: 11.5045 - val_true_loss: 1.1372\n",
      "Epoch 3/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3457 - reconstruction_loss: 1889.3164 - kl_loss: 99.6626 - false_loss: 0.0823 - true_loss: 1.0750 - val_loss: 5560.5854 - val_reconstruction_loss: 1895.9866 - val_kl_loss: 99.8093 - val_false_loss: 11.5036 - val_true_loss: 1.1371\n",
      "Epoch 4/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0940 - reconstruction_loss: 1889.4994 - kl_loss: 100.1620 - false_loss: 0.0823 - true_loss: 1.0750 - val_loss: 5560.3013 - val_reconstruction_loss: 1895.9862 - val_kl_loss: 99.8089 - val_false_loss: 11.5027 - val_true_loss: 1.1371\n",
      "Epoch 5/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2886 - reconstruction_loss: 1889.4750 - kl_loss: 97.9781 - false_loss: 0.0823 - true_loss: 1.0750 - val_loss: 5560.0312 - val_reconstruction_loss: 1895.9858 - val_kl_loss: 99.8092 - val_false_loss: 11.5018 - val_true_loss: 1.1371\n",
      "Epoch 6/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.5000 - reconstruction_loss: 1889.2607 - kl_loss: 98.9670 - false_loss: 0.0823 - true_loss: 1.0749 - val_loss: 5559.7534 - val_reconstruction_loss: 1895.9854 - val_kl_loss: 99.8093 - val_false_loss: 11.5009 - val_true_loss: 1.1370\n",
      "Epoch 7/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.2784 - reconstruction_loss: 1889.2535 - kl_loss: 99.7354 - false_loss: 0.0823 - true_loss: 1.0749 - val_loss: 5559.4780 - val_reconstruction_loss: 1895.9850 - val_kl_loss: 99.8096 - val_false_loss: 11.5000 - val_true_loss: 1.1370\n",
      "Epoch 8/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.8592 - reconstruction_loss: 1889.4263 - kl_loss: 99.1994 - false_loss: 0.0823 - true_loss: 1.0749 - val_loss: 5559.1987 - val_reconstruction_loss: 1895.9846 - val_kl_loss: 99.8095 - val_false_loss: 11.4990 - val_true_loss: 1.1370\n",
      "Epoch 9/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.4063 - reconstruction_loss: 1889.4244 - kl_loss: 99.1738 - false_loss: 0.0823 - true_loss: 1.0748 - val_loss: 5558.9067 - val_reconstruction_loss: 1895.9843 - val_kl_loss: 99.8100 - val_false_loss: 11.4981 - val_true_loss: 1.1369\n",
      "Epoch 10/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.3204 - reconstruction_loss: 1889.4160 - kl_loss: 99.9778 - false_loss: 0.0823 - true_loss: 1.0748 - val_loss: 5558.6216 - val_reconstruction_loss: 1895.9838 - val_kl_loss: 99.8106 - val_false_loss: 11.4971 - val_true_loss: 1.1369\n",
      "Epoch 11/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.9119 - reconstruction_loss: 1889.2296 - kl_loss: 101.7411 - false_loss: 0.0823 - true_loss: 1.0747 - val_loss: 5558.3374 - val_reconstruction_loss: 1895.9834 - val_kl_loss: 99.8111 - val_false_loss: 11.4962 - val_true_loss: 1.1368\n",
      "Epoch 12/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.4801 - reconstruction_loss: 1889.3180 - kl_loss: 100.5624 - false_loss: 0.0823 - true_loss: 1.0747 - val_loss: 5558.0454 - val_reconstruction_loss: 1895.9830 - val_kl_loss: 99.8119 - val_false_loss: 11.4952 - val_true_loss: 1.1368\n",
      "Epoch 13/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.4976 - reconstruction_loss: 1889.3833 - kl_loss: 102.7865 - false_loss: 0.0823 - true_loss: 1.0746 - val_loss: 5557.7612 - val_reconstruction_loss: 1895.9825 - val_kl_loss: 99.8127 - val_false_loss: 11.4943 - val_true_loss: 1.1368\n",
      "Epoch 14/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.3390 - reconstruction_loss: 1889.6146 - kl_loss: 101.7010 - false_loss: 0.0823 - true_loss: 1.0746 - val_loss: 5557.4790 - val_reconstruction_loss: 1895.9823 - val_kl_loss: 99.8135 - val_false_loss: 11.4934 - val_true_loss: 1.1367\n",
      "Epoch 15/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.6828 - reconstruction_loss: 1889.7584 - kl_loss: 101.8407 - false_loss: 0.0822 - true_loss: 1.0745 - val_loss: 5557.1953 - val_reconstruction_loss: 1895.9818 - val_kl_loss: 99.8143 - val_false_loss: 11.4925 - val_true_loss: 1.1367\n",
      "Epoch 16/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.4158 - reconstruction_loss: 1889.3271 - kl_loss: 100.5378 - false_loss: 0.0822 - true_loss: 1.0745 - val_loss: 5556.9150 - val_reconstruction_loss: 1895.9816 - val_kl_loss: 99.8150 - val_false_loss: 11.4915 - val_true_loss: 1.1366\n",
      "Epoch 17/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.1296 - reconstruction_loss: 1889.2662 - kl_loss: 101.8545 - false_loss: 0.0822 - true_loss: 1.0745 - val_loss: 5556.6304 - val_reconstruction_loss: 1895.9811 - val_kl_loss: 99.8158 - val_false_loss: 11.4906 - val_true_loss: 1.1366\n",
      "Epoch 18/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.2435 - reconstruction_loss: 1889.8248 - kl_loss: 103.1281 - false_loss: 0.0822 - true_loss: 1.0744 - val_loss: 5556.3545 - val_reconstruction_loss: 1895.9808 - val_kl_loss: 99.8165 - val_false_loss: 11.4897 - val_true_loss: 1.1365\n",
      "Epoch 19/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.5248 - reconstruction_loss: 1889.3390 - kl_loss: 103.8401 - false_loss: 0.0822 - true_loss: 1.0744 - val_loss: 5556.0684 - val_reconstruction_loss: 1895.9803 - val_kl_loss: 99.8171 - val_false_loss: 11.4888 - val_true_loss: 1.1365\n",
      "Epoch 20/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.4918 - reconstruction_loss: 1889.3086 - kl_loss: 103.0544 - false_loss: 0.0822 - true_loss: 1.0743 - val_loss: 5555.7900 - val_reconstruction_loss: 1895.9799 - val_kl_loss: 99.8179 - val_false_loss: 11.4878 - val_true_loss: 1.1365\n",
      "Epoch 21/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.2052 - reconstruction_loss: 1889.2164 - kl_loss: 103.4872 - false_loss: 0.0822 - true_loss: 1.0743 - val_loss: 5555.5088 - val_reconstruction_loss: 1895.9796 - val_kl_loss: 99.8189 - val_false_loss: 11.4869 - val_true_loss: 1.1364\n",
      "Epoch 22/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.4714 - reconstruction_loss: 1889.2393 - kl_loss: 104.5103 - false_loss: 0.0822 - true_loss: 1.0742 - val_loss: 5555.2275 - val_reconstruction_loss: 1895.9791 - val_kl_loss: 99.8198 - val_false_loss: 11.4860 - val_true_loss: 1.1364\n",
      "Epoch 23/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.7702 - reconstruction_loss: 1889.7045 - kl_loss: 103.1757 - false_loss: 0.0822 - true_loss: 1.0742 - val_loss: 5554.9487 - val_reconstruction_loss: 1895.9789 - val_kl_loss: 99.8208 - val_false_loss: 11.4851 - val_true_loss: 1.1363\n",
      "Epoch 24/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.7173 - reconstruction_loss: 1889.8676 - kl_loss: 104.4459 - false_loss: 0.0822 - true_loss: 1.0741 - val_loss: 5554.6602 - val_reconstruction_loss: 1895.9784 - val_kl_loss: 99.8215 - val_false_loss: 11.4841 - val_true_loss: 1.1363\n",
      "Epoch 25/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.4635 - reconstruction_loss: 1889.3910 - kl_loss: 103.5844 - false_loss: 0.0822 - true_loss: 1.0741 - val_loss: 5554.3789 - val_reconstruction_loss: 1895.9779 - val_kl_loss: 99.8224 - val_false_loss: 11.4832 - val_true_loss: 1.1362\n",
      "Epoch 26/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.2737 - reconstruction_loss: 1889.1156 - kl_loss: 104.0442 - false_loss: 0.0822 - true_loss: 1.0740 - val_loss: 5554.0859 - val_reconstruction_loss: 1895.9777 - val_kl_loss: 99.8232 - val_false_loss: 11.4822 - val_true_loss: 1.1362\n",
      "Epoch 27/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.3833 - reconstruction_loss: 1890.0250 - kl_loss: 104.6286 - false_loss: 0.0822 - true_loss: 1.0740 - val_loss: 5553.7998 - val_reconstruction_loss: 1895.9774 - val_kl_loss: 99.8239 - val_false_loss: 11.4813 - val_true_loss: 1.1361\n",
      "Epoch 28/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.9984 - reconstruction_loss: 1889.3497 - kl_loss: 104.2673 - false_loss: 0.0822 - true_loss: 1.0739 - val_loss: 5553.5186 - val_reconstruction_loss: 1895.9769 - val_kl_loss: 99.8247 - val_false_loss: 11.4804 - val_true_loss: 1.1361\n",
      "Epoch 29/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.8120 - reconstruction_loss: 1889.2954 - kl_loss: 104.0619 - false_loss: 0.0821 - true_loss: 1.0739 - val_loss: 5553.2344 - val_reconstruction_loss: 1895.9764 - val_kl_loss: 99.8255 - val_false_loss: 11.4794 - val_true_loss: 1.1361\n",
      "Epoch 30/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.7490 - reconstruction_loss: 1889.4305 - kl_loss: 104.7450 - false_loss: 0.0821 - true_loss: 1.0738 - val_loss: 5552.9497 - val_reconstruction_loss: 1895.9762 - val_kl_loss: 99.8264 - val_false_loss: 11.4785 - val_true_loss: 1.1360\n",
      "Epoch 31/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.3797 - reconstruction_loss: 1889.8949 - kl_loss: 103.6733 - false_loss: 0.0821 - true_loss: 1.0738 - val_loss: 5552.6646 - val_reconstruction_loss: 1895.9757 - val_kl_loss: 99.8270 - val_false_loss: 11.4776 - val_true_loss: 1.1360\n",
      "Epoch 32/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.0556 - reconstruction_loss: 1889.5287 - kl_loss: 103.6574 - false_loss: 0.0821 - true_loss: 1.0737 - val_loss: 5552.3848 - val_reconstruction_loss: 1895.9756 - val_kl_loss: 99.8275 - val_false_loss: 11.4766 - val_true_loss: 1.1359\n",
      "Epoch 33/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.3919 - reconstruction_loss: 1889.9398 - kl_loss: 104.3695 - false_loss: 0.0821 - true_loss: 1.0737 - val_loss: 5552.0967 - val_reconstruction_loss: 1895.9751 - val_kl_loss: 99.8284 - val_false_loss: 11.4757 - val_true_loss: 1.1359\n",
      "Epoch 34/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.2513 - reconstruction_loss: 1889.3851 - kl_loss: 102.0475 - false_loss: 0.0821 - true_loss: 1.0736 - val_loss: 5551.8105 - val_reconstruction_loss: 1895.9747 - val_kl_loss: 99.8294 - val_false_loss: 11.4748 - val_true_loss: 1.1358\n",
      "Epoch 35/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.1304 - reconstruction_loss: 1889.5905 - kl_loss: 103.6718 - false_loss: 0.0821 - true_loss: 1.0736 - val_loss: 5551.5371 - val_reconstruction_loss: 1895.9744 - val_kl_loss: 99.8305 - val_false_loss: 11.4739 - val_true_loss: 1.1358\n",
      "Epoch 36/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.4411 - reconstruction_loss: 1889.6027 - kl_loss: 103.6256 - false_loss: 0.0821 - true_loss: 1.0735 - val_loss: 5551.2524 - val_reconstruction_loss: 1895.9740 - val_kl_loss: 99.8310 - val_false_loss: 11.4729 - val_true_loss: 1.1357\n",
      "Epoch 37/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.0685 - reconstruction_loss: 1889.4287 - kl_loss: 103.5069 - false_loss: 0.0821 - true_loss: 1.0735 - val_loss: 5550.9697 - val_reconstruction_loss: 1895.9736 - val_kl_loss: 99.8320 - val_false_loss: 11.4720 - val_true_loss: 1.1357\n",
      "Epoch 38/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.1872 - reconstruction_loss: 1889.2065 - kl_loss: 103.5761 - false_loss: 0.0821 - true_loss: 1.0734 - val_loss: 5550.6870 - val_reconstruction_loss: 1895.9733 - val_kl_loss: 99.8326 - val_false_loss: 11.4711 - val_true_loss: 1.1357\n",
      "Epoch 39/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.4419 - reconstruction_loss: 1889.6044 - kl_loss: 105.1336 - false_loss: 0.0821 - true_loss: 1.0734 - val_loss: 5550.4038 - val_reconstruction_loss: 1895.9729 - val_kl_loss: 99.8334 - val_false_loss: 11.4701 - val_true_loss: 1.1356\n",
      "Epoch 40/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.6728 - reconstruction_loss: 1889.3275 - kl_loss: 104.9941 - false_loss: 0.0821 - true_loss: 1.0733 - val_loss: 5550.1318 - val_reconstruction_loss: 1895.9725 - val_kl_loss: 99.8341 - val_false_loss: 11.4692 - val_true_loss: 1.1356\n",
      "Epoch 41/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.0173 - reconstruction_loss: 1889.6694 - kl_loss: 103.3525 - false_loss: 0.0821 - true_loss: 1.0733 - val_loss: 5549.8599 - val_reconstruction_loss: 1895.9722 - val_kl_loss: 99.8345 - val_false_loss: 11.4684 - val_true_loss: 1.1355\n",
      "Epoch 42/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.2733 - reconstruction_loss: 1889.7852 - kl_loss: 103.3839 - false_loss: 0.0821 - true_loss: 1.0732 - val_loss: 5549.5786 - val_reconstruction_loss: 1895.9718 - val_kl_loss: 99.8351 - val_false_loss: 11.4674 - val_true_loss: 1.1355\n",
      "Epoch 43/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.5568 - reconstruction_loss: 1889.7944 - kl_loss: 103.8954 - false_loss: 0.0821 - true_loss: 1.0732 - val_loss: 5549.2969 - val_reconstruction_loss: 1895.9713 - val_kl_loss: 99.8357 - val_false_loss: 11.4665 - val_true_loss: 1.1354\n",
      "Epoch 44/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4111 - reconstruction_loss: 1889.5482 - kl_loss: 102.4019 - false_loss: 0.0820 - true_loss: 1.0732 - val_loss: 5549.0146 - val_reconstruction_loss: 1895.9709 - val_kl_loss: 99.8362 - val_false_loss: 11.4656 - val_true_loss: 1.1354\n",
      "Epoch 45/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.8247 - reconstruction_loss: 1889.5365 - kl_loss: 101.3254 - false_loss: 0.0820 - true_loss: 1.0731 - val_loss: 5548.7329 - val_reconstruction_loss: 1895.9706 - val_kl_loss: 99.8369 - val_false_loss: 11.4646 - val_true_loss: 1.1354\n",
      "Epoch 46/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.9909 - reconstruction_loss: 1889.7119 - kl_loss: 100.9864 - false_loss: 0.0820 - true_loss: 1.0731 - val_loss: 5548.4482 - val_reconstruction_loss: 1895.9702 - val_kl_loss: 99.8379 - val_false_loss: 11.4637 - val_true_loss: 1.1353\n",
      "Epoch 47/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.4607 - reconstruction_loss: 1889.9056 - kl_loss: 99.0434 - false_loss: 0.0820 - true_loss: 1.0730 - val_loss: 5548.1680 - val_reconstruction_loss: 1895.9697 - val_kl_loss: 99.8382 - val_false_loss: 11.4628 - val_true_loss: 1.1353\n",
      "Epoch 48/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.5869 - reconstruction_loss: 1889.8146 - kl_loss: 102.2525 - false_loss: 0.0820 - true_loss: 1.0730 - val_loss: 5547.8867 - val_reconstruction_loss: 1895.9694 - val_kl_loss: 99.8389 - val_false_loss: 11.4619 - val_true_loss: 1.1352\n",
      "Epoch 49/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.1160 - reconstruction_loss: 1889.3209 - kl_loss: 103.8080 - false_loss: 0.0820 - true_loss: 1.0730 - val_loss: 5547.5957 - val_reconstruction_loss: 1895.9690 - val_kl_loss: 99.8393 - val_false_loss: 11.4609 - val_true_loss: 1.1352\n",
      "Epoch 50/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.8437 - reconstruction_loss: 1889.2804 - kl_loss: 103.2211 - false_loss: 0.0820 - true_loss: 1.0729 - val_loss: 5547.3047 - val_reconstruction_loss: 1895.9686 - val_kl_loss: 99.8401 - val_false_loss: 11.4599 - val_true_loss: 1.1352\n",
      "Epoch 51/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.0096 - reconstruction_loss: 1889.7133 - kl_loss: 103.4101 - false_loss: 0.0820 - true_loss: 1.0729 - val_loss: 5547.0156 - val_reconstruction_loss: 1895.9683 - val_kl_loss: 99.8410 - val_false_loss: 11.4590 - val_true_loss: 1.1351\n",
      "Epoch 52/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.4302 - reconstruction_loss: 1889.4164 - kl_loss: 102.3710 - false_loss: 0.0820 - true_loss: 1.0728 - val_loss: 5546.7271 - val_reconstruction_loss: 1895.9679 - val_kl_loss: 99.8415 - val_false_loss: 11.4580 - val_true_loss: 1.1351\n",
      "Epoch 53/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2203.0691 - reconstruction_loss: 1889.5387 - kl_loss: 102.8094 - false_loss: 0.0820 - true_loss: 1.0728 - val_loss: 5546.4478 - val_reconstruction_loss: 1895.9674 - val_kl_loss: 99.8417 - val_false_loss: 11.4571 - val_true_loss: 1.1350\n",
      "Epoch 54/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.9646 - reconstruction_loss: 1889.5029 - kl_loss: 103.0408 - false_loss: 0.0820 - true_loss: 1.0727 - val_loss: 5546.1699 - val_reconstruction_loss: 1895.9672 - val_kl_loss: 99.8421 - val_false_loss: 11.4562 - val_true_loss: 1.1350\n",
      "Epoch 55/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.9247 - reconstruction_loss: 1889.2050 - kl_loss: 103.9138 - false_loss: 0.0820 - true_loss: 1.0727 - val_loss: 5545.8892 - val_reconstruction_loss: 1895.9668 - val_kl_loss: 99.8429 - val_false_loss: 11.4553 - val_true_loss: 1.1349\n",
      "Epoch 56/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.5944 - reconstruction_loss: 1890.0089 - kl_loss: 103.5140 - false_loss: 0.0820 - true_loss: 1.0726 - val_loss: 5545.6030 - val_reconstruction_loss: 1895.9664 - val_kl_loss: 99.8439 - val_false_loss: 11.4544 - val_true_loss: 1.1349\n",
      "Epoch 57/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.1870 - reconstruction_loss: 1889.4911 - kl_loss: 102.9148 - false_loss: 0.0820 - true_loss: 1.0726 - val_loss: 5545.3154 - val_reconstruction_loss: 1895.9661 - val_kl_loss: 99.8442 - val_false_loss: 11.4534 - val_true_loss: 1.1348\n",
      "Epoch 58/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.6246 - reconstruction_loss: 1890.0685 - kl_loss: 103.1181 - false_loss: 0.0819 - true_loss: 1.0725 - val_loss: 5545.0312 - val_reconstruction_loss: 1895.9657 - val_kl_loss: 99.8447 - val_false_loss: 11.4525 - val_true_loss: 1.1348\n",
      "Epoch 59/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.0756 - reconstruction_loss: 1890.2054 - kl_loss: 102.7606 - false_loss: 0.0819 - true_loss: 1.0725 - val_loss: 5544.7495 - val_reconstruction_loss: 1895.9655 - val_kl_loss: 99.8441 - val_false_loss: 11.4516 - val_true_loss: 1.1348\n",
      "Epoch 60/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.6757 - reconstruction_loss: 1890.3268 - kl_loss: 98.1726 - false_loss: 0.0819 - true_loss: 1.0724 - val_loss: 5544.4668 - val_reconstruction_loss: 1895.9650 - val_kl_loss: 99.8446 - val_false_loss: 11.4506 - val_true_loss: 1.1347\n",
      "Epoch 61/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.1418 - reconstruction_loss: 1890.9082 - kl_loss: 100.4618 - false_loss: 0.0819 - true_loss: 1.0724 - val_loss: 5544.1816 - val_reconstruction_loss: 1895.9647 - val_kl_loss: 99.8450 - val_false_loss: 11.4497 - val_true_loss: 1.1347\n",
      "Epoch 62/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.6507 - reconstruction_loss: 1889.9498 - kl_loss: 102.7567 - false_loss: 0.0819 - true_loss: 1.0724 - val_loss: 5543.8853 - val_reconstruction_loss: 1895.9642 - val_kl_loss: 99.8454 - val_false_loss: 11.4487 - val_true_loss: 1.1346\n",
      "Epoch 63/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.7047 - reconstruction_loss: 1889.8595 - kl_loss: 102.5499 - false_loss: 0.0819 - true_loss: 1.0723 - val_loss: 5543.5894 - val_reconstruction_loss: 1895.9637 - val_kl_loss: 99.8464 - val_false_loss: 11.4477 - val_true_loss: 1.1346\n",
      "Epoch 64/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.8924 - reconstruction_loss: 1890.4668 - kl_loss: 104.5267 - false_loss: 0.0819 - true_loss: 1.0723 - val_loss: 5543.3008 - val_reconstruction_loss: 1895.9636 - val_kl_loss: 99.8467 - val_false_loss: 11.4468 - val_true_loss: 1.1346\n",
      "Epoch 65/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.3917 - reconstruction_loss: 1889.7515 - kl_loss: 103.2084 - false_loss: 0.0819 - true_loss: 1.0722 - val_loss: 5543.0088 - val_reconstruction_loss: 1895.9631 - val_kl_loss: 99.8471 - val_false_loss: 11.4458 - val_true_loss: 1.1345\n",
      "Epoch 66/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.8603 - reconstruction_loss: 1889.3331 - kl_loss: 103.5685 - false_loss: 0.0819 - true_loss: 1.0722 - val_loss: 5542.7192 - val_reconstruction_loss: 1895.9626 - val_kl_loss: 99.8477 - val_false_loss: 11.4449 - val_true_loss: 1.1345\n",
      "Epoch 67/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.4030 - reconstruction_loss: 1889.3287 - kl_loss: 104.3567 - false_loss: 0.0819 - true_loss: 1.0721 - val_loss: 5542.4307 - val_reconstruction_loss: 1895.9623 - val_kl_loss: 99.8484 - val_false_loss: 11.4439 - val_true_loss: 1.1344\n",
      "Epoch 68/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.0182 - reconstruction_loss: 1889.3969 - kl_loss: 104.7426 - false_loss: 0.0819 - true_loss: 1.0721 - val_loss: 5542.1460 - val_reconstruction_loss: 1895.9619 - val_kl_loss: 99.8490 - val_false_loss: 11.4430 - val_true_loss: 1.1344\n",
      "Epoch 69/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.8234 - reconstruction_loss: 1889.1927 - kl_loss: 104.9386 - false_loss: 0.0819 - true_loss: 1.0720 - val_loss: 5541.8608 - val_reconstruction_loss: 1895.9615 - val_kl_loss: 99.8497 - val_false_loss: 11.4421 - val_true_loss: 1.1343\n",
      "Epoch 70/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.3737 - reconstruction_loss: 1889.3643 - kl_loss: 103.6394 - false_loss: 0.0819 - true_loss: 1.0720 - val_loss: 5541.5786 - val_reconstruction_loss: 1895.9612 - val_kl_loss: 99.8505 - val_false_loss: 11.4411 - val_true_loss: 1.1343\n",
      "Epoch 71/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.1411 - reconstruction_loss: 1889.5487 - kl_loss: 100.5751 - false_loss: 0.0819 - true_loss: 1.0719 - val_loss: 5541.3008 - val_reconstruction_loss: 1895.9607 - val_kl_loss: 99.8508 - val_false_loss: 11.4402 - val_true_loss: 1.1343\n",
      "Epoch 72/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.2231 - reconstruction_loss: 1890.3304 - kl_loss: 97.2108 - false_loss: 0.0819 - true_loss: 1.0719 - val_loss: 5541.0249 - val_reconstruction_loss: 1895.9603 - val_kl_loss: 99.8510 - val_false_loss: 11.4393 - val_true_loss: 1.1342\n",
      "Epoch 73/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7201 - reconstruction_loss: 1889.9662 - kl_loss: 101.2623 - false_loss: 0.0818 - true_loss: 1.0719 - val_loss: 5540.7290 - val_reconstruction_loss: 1895.9598 - val_kl_loss: 99.8514 - val_false_loss: 11.4383 - val_true_loss: 1.1342\n",
      "Epoch 74/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.6785 - reconstruction_loss: 1889.5082 - kl_loss: 101.7431 - false_loss: 0.0818 - true_loss: 1.0718 - val_loss: 5540.4414 - val_reconstruction_loss: 1895.9595 - val_kl_loss: 99.8518 - val_false_loss: 11.4374 - val_true_loss: 1.1341\n",
      "Epoch 75/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.2968 - reconstruction_loss: 1889.5297 - kl_loss: 102.6690 - false_loss: 0.0818 - true_loss: 1.0718 - val_loss: 5540.1533 - val_reconstruction_loss: 1895.9591 - val_kl_loss: 99.8517 - val_false_loss: 11.4364 - val_true_loss: 1.1341\n",
      "Epoch 76/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.7773 - reconstruction_loss: 1890.0118 - kl_loss: 98.7708 - false_loss: 0.0818 - true_loss: 1.0718 - val_loss: 5539.8745 - val_reconstruction_loss: 1895.9589 - val_kl_loss: 99.8521 - val_false_loss: 11.4355 - val_true_loss: 1.1341\n",
      "Epoch 77/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.9472 - reconstruction_loss: 1890.4332 - kl_loss: 100.0014 - false_loss: 0.0818 - true_loss: 1.0717 - val_loss: 5539.5879 - val_reconstruction_loss: 1895.9585 - val_kl_loss: 99.8523 - val_false_loss: 11.4346 - val_true_loss: 1.1340\n",
      "Epoch 78/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.8326 - reconstruction_loss: 1890.2549 - kl_loss: 101.1971 - false_loss: 0.0818 - true_loss: 1.0717 - val_loss: 5539.3071 - val_reconstruction_loss: 1895.9580 - val_kl_loss: 99.8522 - val_false_loss: 11.4337 - val_true_loss: 1.1340\n",
      "Epoch 79/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.3250 - reconstruction_loss: 1889.8666 - kl_loss: 102.4123 - false_loss: 0.0818 - true_loss: 1.0716 - val_loss: 5539.0156 - val_reconstruction_loss: 1895.9576 - val_kl_loss: 99.8528 - val_false_loss: 11.4327 - val_true_loss: 1.1340\n",
      "Epoch 80/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.1795 - reconstruction_loss: 1889.5302 - kl_loss: 102.8249 - false_loss: 0.0818 - true_loss: 1.0716 - val_loss: 5538.7305 - val_reconstruction_loss: 1895.9573 - val_kl_loss: 99.8532 - val_false_loss: 11.4318 - val_true_loss: 1.1339\n",
      "Epoch 81/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.2365 - reconstruction_loss: 1889.3394 - kl_loss: 102.1909 - false_loss: 0.0818 - true_loss: 1.0715 - val_loss: 5538.4512 - val_reconstruction_loss: 1895.9569 - val_kl_loss: 99.8533 - val_false_loss: 11.4309 - val_true_loss: 1.1339\n",
      "Epoch 82/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.7847 - reconstruction_loss: 1889.3965 - kl_loss: 100.5207 - false_loss: 0.0818 - true_loss: 1.0715 - val_loss: 5538.1729 - val_reconstruction_loss: 1895.9565 - val_kl_loss: 99.8540 - val_false_loss: 11.4299 - val_true_loss: 1.1339\n",
      "Epoch 83/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.2218 - reconstruction_loss: 1889.7316 - kl_loss: 102.8094 - false_loss: 0.0818 - true_loss: 1.0715 - val_loss: 5537.8892 - val_reconstruction_loss: 1895.9561 - val_kl_loss: 99.8547 - val_false_loss: 11.4290 - val_true_loss: 1.1338\n",
      "Epoch 84/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.3985 - reconstruction_loss: 1889.3955 - kl_loss: 102.1887 - false_loss: 0.0818 - true_loss: 1.0714 - val_loss: 5537.6128 - val_reconstruction_loss: 1895.9557 - val_kl_loss: 99.8554 - val_false_loss: 11.4281 - val_true_loss: 1.1338\n",
      "Epoch 85/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.7116 - reconstruction_loss: 1889.2574 - kl_loss: 99.7505 - false_loss: 0.0818 - true_loss: 1.0714 - val_loss: 5537.3213 - val_reconstruction_loss: 1895.9553 - val_kl_loss: 99.8556 - val_false_loss: 11.4271 - val_true_loss: 1.1338\n",
      "Epoch 86/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.4217 - reconstruction_loss: 1889.4448 - kl_loss: 99.3524 - false_loss: 0.0818 - true_loss: 1.0713 - val_loss: 5537.0347 - val_reconstruction_loss: 1895.9548 - val_kl_loss: 99.8559 - val_false_loss: 11.4262 - val_true_loss: 1.1337\n",
      "Epoch 87/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.6549 - reconstruction_loss: 1889.5161 - kl_loss: 101.4758 - false_loss: 0.0818 - true_loss: 1.0713 - val_loss: 5536.7500 - val_reconstruction_loss: 1895.9545 - val_kl_loss: 99.8560 - val_false_loss: 11.4253 - val_true_loss: 1.1337\n",
      "Epoch 88/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.5611 - reconstruction_loss: 1889.0713 - kl_loss: 101.8208 - false_loss: 0.0818 - true_loss: 1.0713 - val_loss: 5536.4678 - val_reconstruction_loss: 1895.9541 - val_kl_loss: 99.8564 - val_false_loss: 11.4243 - val_true_loss: 1.1336\n",
      "Epoch 89/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3372 - reconstruction_loss: 1889.5736 - kl_loss: 101.7281 - false_loss: 0.0817 - true_loss: 1.0712 - val_loss: 5536.1777 - val_reconstruction_loss: 1895.9537 - val_kl_loss: 99.8568 - val_false_loss: 11.4234 - val_true_loss: 1.1336\n",
      "Epoch 90/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3448 - reconstruction_loss: 1889.4532 - kl_loss: 101.1927 - false_loss: 0.0817 - true_loss: 1.0712 - val_loss: 5535.9023 - val_reconstruction_loss: 1895.9534 - val_kl_loss: 99.8569 - val_false_loss: 11.4225 - val_true_loss: 1.1336\n",
      "Epoch 91/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.4233 - reconstruction_loss: 1889.6431 - kl_loss: 98.0266 - false_loss: 0.0817 - true_loss: 1.0711 - val_loss: 5535.6113 - val_reconstruction_loss: 1895.9531 - val_kl_loss: 99.8570 - val_false_loss: 11.4215 - val_true_loss: 1.1335\n",
      "Epoch 92/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3847 - reconstruction_loss: 1889.3700 - kl_loss: 101.7312 - false_loss: 0.0817 - true_loss: 1.0711 - val_loss: 5535.3213 - val_reconstruction_loss: 1895.9526 - val_kl_loss: 99.8572 - val_false_loss: 11.4206 - val_true_loss: 1.1335\n",
      "Epoch 93/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.0570 - reconstruction_loss: 1889.4430 - kl_loss: 101.0172 - false_loss: 0.0817 - true_loss: 1.0711 - val_loss: 5535.0352 - val_reconstruction_loss: 1895.9521 - val_kl_loss: 99.8577 - val_false_loss: 11.4196 - val_true_loss: 1.1334\n",
      "Epoch 94/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.2665 - reconstruction_loss: 1889.3375 - kl_loss: 101.9739 - false_loss: 0.0817 - true_loss: 1.0710 - val_loss: 5534.7524 - val_reconstruction_loss: 1895.9519 - val_kl_loss: 99.8578 - val_false_loss: 11.4187 - val_true_loss: 1.1334\n",
      "Epoch 95/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.7415 - reconstruction_loss: 1889.2548 - kl_loss: 101.0418 - false_loss: 0.0817 - true_loss: 1.0710 - val_loss: 5534.4639 - val_reconstruction_loss: 1895.9514 - val_kl_loss: 99.8580 - val_false_loss: 11.4177 - val_true_loss: 1.1334\n",
      "Epoch 96/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.0199 - reconstruction_loss: 1889.5370 - kl_loss: 101.6096 - false_loss: 0.0817 - true_loss: 1.0709 - val_loss: 5534.1826 - val_reconstruction_loss: 1895.9512 - val_kl_loss: 99.8575 - val_false_loss: 11.4168 - val_true_loss: 1.1333\n",
      "Epoch 97/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.9863 - reconstruction_loss: 1889.7262 - kl_loss: 98.9917 - false_loss: 0.0817 - true_loss: 1.0709 - val_loss: 5533.8911 - val_reconstruction_loss: 1895.9509 - val_kl_loss: 99.8581 - val_false_loss: 11.4159 - val_true_loss: 1.1333\n",
      "Epoch 98/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.2446 - reconstruction_loss: 1889.6227 - kl_loss: 102.6569 - false_loss: 0.0817 - true_loss: 1.0708 - val_loss: 5533.6021 - val_reconstruction_loss: 1895.9504 - val_kl_loss: 99.8588 - val_false_loss: 11.4149 - val_true_loss: 1.1332\n",
      "Epoch 99/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.9930 - reconstruction_loss: 1889.4082 - kl_loss: 103.5010 - false_loss: 0.0817 - true_loss: 1.0708 - val_loss: 5533.3062 - val_reconstruction_loss: 1895.9501 - val_kl_loss: 99.8595 - val_false_loss: 11.4139 - val_true_loss: 1.1332\n",
      "Epoch 100/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1740 - reconstruction_loss: 1889.1548 - kl_loss: 102.8285 - false_loss: 0.0817 - true_loss: 1.0708 - val_loss: 5533.0137 - val_reconstruction_loss: 1895.9497 - val_kl_loss: 99.8600 - val_false_loss: 11.4130 - val_true_loss: 1.1332\n",
      "Epoch 101/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.1116 - reconstruction_loss: 1889.4575 - kl_loss: 101.9260 - false_loss: 0.0817 - true_loss: 1.0707 - val_loss: 5532.7251 - val_reconstruction_loss: 1895.9492 - val_kl_loss: 99.8603 - val_false_loss: 11.4120 - val_true_loss: 1.1331\n",
      "Epoch 102/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.6144 - reconstruction_loss: 1889.4664 - kl_loss: 99.6803 - false_loss: 0.0817 - true_loss: 1.0707 - val_loss: 5532.4404 - val_reconstruction_loss: 1895.9491 - val_kl_loss: 99.8599 - val_false_loss: 11.4111 - val_true_loss: 1.1331\n",
      "Epoch 103/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6156 - reconstruction_loss: 1889.6229 - kl_loss: 99.7227 - false_loss: 0.0817 - true_loss: 1.0706 - val_loss: 5532.1562 - val_reconstruction_loss: 1895.9487 - val_kl_loss: 99.8601 - val_false_loss: 11.4101 - val_true_loss: 1.1331\n",
      "Epoch 104/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.9072 - reconstruction_loss: 1889.6764 - kl_loss: 97.7571 - false_loss: 0.0816 - true_loss: 1.0706 - val_loss: 5531.8740 - val_reconstruction_loss: 1895.9484 - val_kl_loss: 99.8606 - val_false_loss: 11.4092 - val_true_loss: 1.1331\n",
      "Epoch 105/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2250.8030 - reconstruction_loss: 1889.7496 - kl_loss: 97.0699 - false_loss: 0.0816 - true_loss: 1.0706 - val_loss: 5531.5874 - val_reconstruction_loss: 1895.9480 - val_kl_loss: 99.8602 - val_false_loss: 11.4083 - val_true_loss: 1.1330\n",
      "Epoch 106/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6675 - reconstruction_loss: 1889.6898 - kl_loss: 97.9930 - false_loss: 0.0816 - true_loss: 1.0706 - val_loss: 5531.3066 - val_reconstruction_loss: 1895.9475 - val_kl_loss: 99.8602 - val_false_loss: 11.4073 - val_true_loss: 1.1330\n",
      "Epoch 107/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.2653 - reconstruction_loss: 1889.5565 - kl_loss: 99.2172 - false_loss: 0.0816 - true_loss: 1.0705 - val_loss: 5531.0254 - val_reconstruction_loss: 1895.9471 - val_kl_loss: 99.8602 - val_false_loss: 11.4064 - val_true_loss: 1.1330\n",
      "Epoch 108/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.2203 - reconstruction_loss: 1889.5420 - kl_loss: 99.2324 - false_loss: 0.0816 - true_loss: 1.0705 - val_loss: 5530.7407 - val_reconstruction_loss: 1895.9468 - val_kl_loss: 99.8595 - val_false_loss: 11.4055 - val_true_loss: 1.1329\n",
      "Epoch 109/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.5963 - reconstruction_loss: 1889.7689 - kl_loss: 98.9122 - false_loss: 0.0816 - true_loss: 1.0704 - val_loss: 5530.4565 - val_reconstruction_loss: 1895.9464 - val_kl_loss: 99.8592 - val_false_loss: 11.4046 - val_true_loss: 1.1329\n",
      "Epoch 110/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9308 - reconstruction_loss: 1889.5616 - kl_loss: 99.3366 - false_loss: 0.0816 - true_loss: 1.0704 - val_loss: 5530.1694 - val_reconstruction_loss: 1895.9460 - val_kl_loss: 99.8594 - val_false_loss: 11.4036 - val_true_loss: 1.1329\n",
      "Epoch 111/2700\n",
      "12/12 [==============================] - 17s 1s/step - loss: 2216.5292 - reconstruction_loss: 1889.5533 - kl_loss: 100.0157 - false_loss: 0.0816 - true_loss: 1.0704 - val_loss: 5529.8916 - val_reconstruction_loss: 1895.9456 - val_kl_loss: 99.8600 - val_false_loss: 11.4027 - val_true_loss: 1.1328\n",
      "Epoch 112/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.0785 - reconstruction_loss: 1889.6801 - kl_loss: 97.2238 - false_loss: 0.0816 - true_loss: 1.0703 - val_loss: 5529.6157 - val_reconstruction_loss: 1895.9452 - val_kl_loss: 99.8600 - val_false_loss: 11.4018 - val_true_loss: 1.1328\n",
      "Epoch 113/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8631 - reconstruction_loss: 1889.9247 - kl_loss: 99.7870 - false_loss: 0.0816 - true_loss: 1.0703 - val_loss: 5529.3354 - val_reconstruction_loss: 1895.9448 - val_kl_loss: 99.8601 - val_false_loss: 11.4009 - val_true_loss: 1.1327\n",
      "Epoch 114/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.0118 - reconstruction_loss: 1889.7129 - kl_loss: 101.2632 - false_loss: 0.0816 - true_loss: 1.0702 - val_loss: 5529.0503 - val_reconstruction_loss: 1895.9443 - val_kl_loss: 99.8604 - val_false_loss: 11.3999 - val_true_loss: 1.1327\n",
      "Epoch 115/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.5904 - reconstruction_loss: 1889.4971 - kl_loss: 102.3495 - false_loss: 0.0816 - true_loss: 1.0702 - val_loss: 5528.7656 - val_reconstruction_loss: 1895.9442 - val_kl_loss: 99.8612 - val_false_loss: 11.3990 - val_true_loss: 1.1327\n",
      "Epoch 116/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.0522 - reconstruction_loss: 1889.4298 - kl_loss: 103.1606 - false_loss: 0.0816 - true_loss: 1.0702 - val_loss: 5528.4790 - val_reconstruction_loss: 1895.9438 - val_kl_loss: 99.8619 - val_false_loss: 11.3981 - val_true_loss: 1.1326\n",
      "Epoch 117/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.3611 - reconstruction_loss: 1889.8939 - kl_loss: 103.1625 - false_loss: 0.0816 - true_loss: 1.0701 - val_loss: 5528.1953 - val_reconstruction_loss: 1895.9435 - val_kl_loss: 99.8625 - val_false_loss: 11.3971 - val_true_loss: 1.1326\n",
      "Epoch 118/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.3068 - reconstruction_loss: 1889.4313 - kl_loss: 101.9717 - false_loss: 0.0816 - true_loss: 1.0701 - val_loss: 5527.9131 - val_reconstruction_loss: 1895.9430 - val_kl_loss: 99.8633 - val_false_loss: 11.3962 - val_true_loss: 1.1325\n",
      "Epoch 119/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.5655 - reconstruction_loss: 1889.0966 - kl_loss: 102.2231 - false_loss: 0.0815 - true_loss: 1.0700 - val_loss: 5527.6279 - val_reconstruction_loss: 1895.9427 - val_kl_loss: 99.8643 - val_false_loss: 11.3953 - val_true_loss: 1.1325\n",
      "Epoch 120/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.9263 - reconstruction_loss: 1889.6123 - kl_loss: 101.6147 - false_loss: 0.0815 - true_loss: 1.0700 - val_loss: 5527.3350 - val_reconstruction_loss: 1895.9424 - val_kl_loss: 99.8647 - val_false_loss: 11.3943 - val_true_loss: 1.1324\n",
      "Epoch 121/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.7385 - reconstruction_loss: 1889.6488 - kl_loss: 102.2383 - false_loss: 0.0815 - true_loss: 1.0699 - val_loss: 5527.0474 - val_reconstruction_loss: 1895.9419 - val_kl_loss: 99.8648 - val_false_loss: 11.3933 - val_true_loss: 1.1324\n",
      "Epoch 122/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.0060 - reconstruction_loss: 1889.2465 - kl_loss: 104.2003 - false_loss: 0.0815 - true_loss: 1.0699 - val_loss: 5526.7563 - val_reconstruction_loss: 1895.9415 - val_kl_loss: 99.8654 - val_false_loss: 11.3924 - val_true_loss: 1.1324\n",
      "Epoch 123/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.0895 - reconstruction_loss: 1890.0326 - kl_loss: 103.4490 - false_loss: 0.0815 - true_loss: 1.0698 - val_loss: 5526.4712 - val_reconstruction_loss: 1895.9412 - val_kl_loss: 99.8657 - val_false_loss: 11.3915 - val_true_loss: 1.1323\n",
      "Epoch 124/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.9111 - reconstruction_loss: 1889.1664 - kl_loss: 103.3714 - false_loss: 0.0815 - true_loss: 1.0698 - val_loss: 5526.1870 - val_reconstruction_loss: 1895.9407 - val_kl_loss: 99.8663 - val_false_loss: 11.3905 - val_true_loss: 1.1323\n",
      "Epoch 125/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.2157 - reconstruction_loss: 1889.1376 - kl_loss: 104.6261 - false_loss: 0.0815 - true_loss: 1.0697 - val_loss: 5525.9102 - val_reconstruction_loss: 1895.9403 - val_kl_loss: 99.8672 - val_false_loss: 11.3896 - val_true_loss: 1.1322\n",
      "Epoch 126/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.7238 - reconstruction_loss: 1889.4257 - kl_loss: 105.1327 - false_loss: 0.0815 - true_loss: 1.0697 - val_loss: 5525.6255 - val_reconstruction_loss: 1895.9399 - val_kl_loss: 99.8683 - val_false_loss: 11.3887 - val_true_loss: 1.1322\n",
      "Epoch 127/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.7910 - reconstruction_loss: 1889.4943 - kl_loss: 105.0399 - false_loss: 0.0815 - true_loss: 1.0696 - val_loss: 5525.3389 - val_reconstruction_loss: 1895.9395 - val_kl_loss: 99.8693 - val_false_loss: 11.3877 - val_true_loss: 1.1321\n",
      "Epoch 128/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.5259 - reconstruction_loss: 1889.1591 - kl_loss: 104.0576 - false_loss: 0.0815 - true_loss: 1.0696 - val_loss: 5525.0498 - val_reconstruction_loss: 1895.9391 - val_kl_loss: 99.8702 - val_false_loss: 11.3868 - val_true_loss: 1.1321\n",
      "Epoch 129/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.1581 - reconstruction_loss: 1889.2203 - kl_loss: 103.5966 - false_loss: 0.0815 - true_loss: 1.0695 - val_loss: 5524.7612 - val_reconstruction_loss: 1895.9387 - val_kl_loss: 99.8707 - val_false_loss: 11.3858 - val_true_loss: 1.1320\n",
      "Epoch 130/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.7234 - reconstruction_loss: 1889.3248 - kl_loss: 105.0117 - false_loss: 0.0815 - true_loss: 1.0695 - val_loss: 5524.4746 - val_reconstruction_loss: 1895.9382 - val_kl_loss: 99.8717 - val_false_loss: 11.3849 - val_true_loss: 1.1320\n",
      "Epoch 131/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.1381 - reconstruction_loss: 1889.3607 - kl_loss: 103.4851 - false_loss: 0.0815 - true_loss: 1.0694 - val_loss: 5524.1870 - val_reconstruction_loss: 1895.9379 - val_kl_loss: 99.8726 - val_false_loss: 11.3839 - val_true_loss: 1.1320\n",
      "Epoch 132/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.0904 - reconstruction_loss: 1889.5762 - kl_loss: 101.9372 - false_loss: 0.0815 - true_loss: 1.0694 - val_loss: 5523.9004 - val_reconstruction_loss: 1895.9375 - val_kl_loss: 99.8733 - val_false_loss: 11.3830 - val_true_loss: 1.1319\n",
      "Epoch 133/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.8806 - reconstruction_loss: 1890.0406 - kl_loss: 102.9141 - false_loss: 0.0814 - true_loss: 1.0693 - val_loss: 5523.6123 - val_reconstruction_loss: 1895.9373 - val_kl_loss: 99.8740 - val_false_loss: 11.3821 - val_true_loss: 1.1319\n",
      "Epoch 134/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.8556 - reconstruction_loss: 1890.5909 - kl_loss: 100.8701 - false_loss: 0.0814 - true_loss: 1.0693 - val_loss: 5523.3296 - val_reconstruction_loss: 1895.9369 - val_kl_loss: 99.8747 - val_false_loss: 11.3811 - val_true_loss: 1.1318\n",
      "Epoch 135/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.9109 - reconstruction_loss: 1891.0781 - kl_loss: 99.7578 - false_loss: 0.0814 - true_loss: 1.0693 - val_loss: 5523.0352 - val_reconstruction_loss: 1895.9364 - val_kl_loss: 99.8753 - val_false_loss: 11.3802 - val_true_loss: 1.1318\n",
      "Epoch 136/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.5353 - reconstruction_loss: 1889.8151 - kl_loss: 102.9338 - false_loss: 0.0814 - true_loss: 1.0692 - val_loss: 5522.7500 - val_reconstruction_loss: 1895.9360 - val_kl_loss: 99.8759 - val_false_loss: 11.3792 - val_true_loss: 1.1318\n",
      "Epoch 137/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.9910 - reconstruction_loss: 1889.2943 - kl_loss: 103.6343 - false_loss: 0.0814 - true_loss: 1.0692 - val_loss: 5522.4575 - val_reconstruction_loss: 1895.9357 - val_kl_loss: 99.8768 - val_false_loss: 11.3783 - val_true_loss: 1.1317\n",
      "Epoch 138/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.8063 - reconstruction_loss: 1889.2593 - kl_loss: 104.8446 - false_loss: 0.0814 - true_loss: 1.0691 - val_loss: 5522.1772 - val_reconstruction_loss: 1895.9352 - val_kl_loss: 99.8780 - val_false_loss: 11.3773 - val_true_loss: 1.1317\n",
      "Epoch 139/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.7489 - reconstruction_loss: 1888.9962 - kl_loss: 105.6603 - false_loss: 0.0814 - true_loss: 1.0691 - val_loss: 5521.8926 - val_reconstruction_loss: 1895.9347 - val_kl_loss: 99.8792 - val_false_loss: 11.3764 - val_true_loss: 1.1316\n",
      "Epoch 140/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.1125 - reconstruction_loss: 1889.2802 - kl_loss: 105.3948 - false_loss: 0.0814 - true_loss: 1.0690 - val_loss: 5521.6128 - val_reconstruction_loss: 1895.9344 - val_kl_loss: 99.8798 - val_false_loss: 11.3755 - val_true_loss: 1.1316\n",
      "Epoch 141/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.8168 - reconstruction_loss: 1889.5997 - kl_loss: 103.2496 - false_loss: 0.0814 - true_loss: 1.0690 - val_loss: 5521.3267 - val_reconstruction_loss: 1895.9340 - val_kl_loss: 99.8804 - val_false_loss: 11.3745 - val_true_loss: 1.1315\n",
      "Epoch 142/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.8592 - reconstruction_loss: 1889.5195 - kl_loss: 104.0017 - false_loss: 0.0814 - true_loss: 1.0689 - val_loss: 5521.0391 - val_reconstruction_loss: 1895.9337 - val_kl_loss: 99.8812 - val_false_loss: 11.3736 - val_true_loss: 1.1315\n",
      "Epoch 143/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.6438 - reconstruction_loss: 1889.6748 - kl_loss: 105.8815 - false_loss: 0.0814 - true_loss: 1.0689 - val_loss: 5520.7622 - val_reconstruction_loss: 1895.9332 - val_kl_loss: 99.8821 - val_false_loss: 11.3727 - val_true_loss: 1.1314\n",
      "Epoch 144/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.4203 - reconstruction_loss: 1889.4691 - kl_loss: 104.7138 - false_loss: 0.0814 - true_loss: 1.0688 - val_loss: 5520.4795 - val_reconstruction_loss: 1895.9330 - val_kl_loss: 99.8830 - val_false_loss: 11.3718 - val_true_loss: 1.1314\n",
      "Epoch 145/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.9668 - reconstruction_loss: 1889.7202 - kl_loss: 103.8362 - false_loss: 0.0814 - true_loss: 1.0688 - val_loss: 5520.2021 - val_reconstruction_loss: 1895.9326 - val_kl_loss: 99.8838 - val_false_loss: 11.3708 - val_true_loss: 1.1314\n",
      "Epoch 146/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.3250 - reconstruction_loss: 1889.3247 - kl_loss: 103.8823 - false_loss: 0.0814 - true_loss: 1.0687 - val_loss: 5519.9141 - val_reconstruction_loss: 1895.9323 - val_kl_loss: 99.8847 - val_false_loss: 11.3699 - val_true_loss: 1.1313\n",
      "Epoch 147/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.6165 - reconstruction_loss: 1889.0804 - kl_loss: 105.1728 - false_loss: 0.0814 - true_loss: 1.0687 - val_loss: 5519.6318 - val_reconstruction_loss: 1895.9320 - val_kl_loss: 99.8855 - val_false_loss: 11.3690 - val_true_loss: 1.1313\n",
      "Epoch 148/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.6815 - reconstruction_loss: 1889.7184 - kl_loss: 104.5350 - false_loss: 0.0813 - true_loss: 1.0686 - val_loss: 5519.3438 - val_reconstruction_loss: 1895.9316 - val_kl_loss: 99.8861 - val_false_loss: 11.3680 - val_true_loss: 1.1312\n",
      "Epoch 149/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.1697 - reconstruction_loss: 1889.5858 - kl_loss: 104.7560 - false_loss: 0.0813 - true_loss: 1.0686 - val_loss: 5519.0576 - val_reconstruction_loss: 1895.9312 - val_kl_loss: 99.8866 - val_false_loss: 11.3671 - val_true_loss: 1.1312\n",
      "Epoch 150/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.6930 - reconstruction_loss: 1889.1260 - kl_loss: 104.8015 - false_loss: 0.0813 - true_loss: 1.0685 - val_loss: 5518.7812 - val_reconstruction_loss: 1895.9308 - val_kl_loss: 99.8872 - val_false_loss: 11.3662 - val_true_loss: 1.1311\n",
      "Epoch 151/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.6381 - reconstruction_loss: 1889.3256 - kl_loss: 104.9601 - false_loss: 0.0813 - true_loss: 1.0685 - val_loss: 5518.5054 - val_reconstruction_loss: 1895.9304 - val_kl_loss: 99.8878 - val_false_loss: 11.3653 - val_true_loss: 1.1311\n",
      "Epoch 152/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.4836 - reconstruction_loss: 1889.3453 - kl_loss: 103.7600 - false_loss: 0.0813 - true_loss: 1.0685 - val_loss: 5518.2290 - val_reconstruction_loss: 1895.9301 - val_kl_loss: 99.8882 - val_false_loss: 11.3644 - val_true_loss: 1.1310\n",
      "Epoch 153/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.4998 - reconstruction_loss: 1889.5289 - kl_loss: 103.3625 - false_loss: 0.0813 - true_loss: 1.0684 - val_loss: 5517.9570 - val_reconstruction_loss: 1895.9296 - val_kl_loss: 99.8887 - val_false_loss: 11.3635 - val_true_loss: 1.1310\n",
      "Epoch 154/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4069 - reconstruction_loss: 1889.4359 - kl_loss: 101.7680 - false_loss: 0.0813 - true_loss: 1.0684 - val_loss: 5517.6865 - val_reconstruction_loss: 1895.9294 - val_kl_loss: 99.8893 - val_false_loss: 11.3626 - val_true_loss: 1.1310\n",
      "Epoch 155/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.6329 - reconstruction_loss: 1889.4203 - kl_loss: 102.6563 - false_loss: 0.0813 - true_loss: 1.0683 - val_loss: 5517.4072 - val_reconstruction_loss: 1895.9291 - val_kl_loss: 99.8897 - val_false_loss: 11.3617 - val_true_loss: 1.1309\n",
      "Epoch 156/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.2893 - reconstruction_loss: 1889.2584 - kl_loss: 102.3394 - false_loss: 0.0813 - true_loss: 1.0683 - val_loss: 5517.1318 - val_reconstruction_loss: 1895.9287 - val_kl_loss: 99.8901 - val_false_loss: 11.3607 - val_true_loss: 1.1309\n",
      "Epoch 157/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2217.6805 - reconstruction_loss: 1889.0319 - kl_loss: 101.1832 - false_loss: 0.0813 - true_loss: 1.0683 - val_loss: 5516.8589 - val_reconstruction_loss: 1895.9283 - val_kl_loss: 99.8899 - val_false_loss: 11.3598 - val_true_loss: 1.1309\n",
      "Epoch 158/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8626 - reconstruction_loss: 1889.4935 - kl_loss: 98.0861 - false_loss: 0.0813 - true_loss: 1.0682 - val_loss: 5516.5884 - val_reconstruction_loss: 1895.9279 - val_kl_loss: 99.8891 - val_false_loss: 11.3590 - val_true_loss: 1.1309\n",
      "Epoch 159/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.5969 - reconstruction_loss: 1889.2998 - kl_loss: 100.3061 - false_loss: 0.0813 - true_loss: 1.0682 - val_loss: 5516.3135 - val_reconstruction_loss: 1895.9275 - val_kl_loss: 99.8900 - val_false_loss: 11.3581 - val_true_loss: 1.1308\n",
      "Epoch 160/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.3658 - reconstruction_loss: 1889.5797 - kl_loss: 101.3457 - false_loss: 0.0813 - true_loss: 1.0681 - val_loss: 5516.0308 - val_reconstruction_loss: 1895.9272 - val_kl_loss: 99.8908 - val_false_loss: 11.3571 - val_true_loss: 1.1308\n",
      "Epoch 161/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.7249 - reconstruction_loss: 1889.8690 - kl_loss: 102.7062 - false_loss: 0.0813 - true_loss: 1.0681 - val_loss: 5515.7593 - val_reconstruction_loss: 1895.9269 - val_kl_loss: 99.8914 - val_false_loss: 11.3562 - val_true_loss: 1.1307\n",
      "Epoch 162/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8932 - reconstruction_loss: 1889.6011 - kl_loss: 101.3240 - false_loss: 0.0813 - true_loss: 1.0681 - val_loss: 5515.4824 - val_reconstruction_loss: 1895.9264 - val_kl_loss: 99.8920 - val_false_loss: 11.3553 - val_true_loss: 1.1307\n",
      "Epoch 163/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.7422 - reconstruction_loss: 1889.6207 - kl_loss: 103.0541 - false_loss: 0.0812 - true_loss: 1.0680 - val_loss: 5515.2046 - val_reconstruction_loss: 1895.9261 - val_kl_loss: 99.8927 - val_false_loss: 11.3544 - val_true_loss: 1.1307\n",
      "Epoch 164/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7199 - reconstruction_loss: 1889.2426 - kl_loss: 101.9077 - false_loss: 0.0812 - true_loss: 1.0680 - val_loss: 5514.9312 - val_reconstruction_loss: 1895.9257 - val_kl_loss: 99.8932 - val_false_loss: 11.3535 - val_true_loss: 1.1306\n",
      "Epoch 165/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.8589 - reconstruction_loss: 1889.0215 - kl_loss: 100.8857 - false_loss: 0.0812 - true_loss: 1.0679 - val_loss: 5514.6606 - val_reconstruction_loss: 1895.9252 - val_kl_loss: 99.8933 - val_false_loss: 11.3526 - val_true_loss: 1.1306\n",
      "Epoch 166/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4572 - reconstruction_loss: 1889.2894 - kl_loss: 98.6388 - false_loss: 0.0812 - true_loss: 1.0679 - val_loss: 5514.3984 - val_reconstruction_loss: 1895.9250 - val_kl_loss: 99.8926 - val_false_loss: 11.3518 - val_true_loss: 1.1306\n",
      "Epoch 167/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.4050 - reconstruction_loss: 1889.5029 - kl_loss: 99.6164 - false_loss: 0.0812 - true_loss: 1.0679 - val_loss: 5514.1206 - val_reconstruction_loss: 1895.9247 - val_kl_loss: 99.8927 - val_false_loss: 11.3508 - val_true_loss: 1.1305\n",
      "Epoch 168/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.3896 - reconstruction_loss: 1889.6342 - kl_loss: 100.2965 - false_loss: 0.0812 - true_loss: 1.0678 - val_loss: 5513.8550 - val_reconstruction_loss: 1895.9243 - val_kl_loss: 99.8929 - val_false_loss: 11.3500 - val_true_loss: 1.1305\n",
      "Epoch 169/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9281 - reconstruction_loss: 1889.5731 - kl_loss: 99.1893 - false_loss: 0.0812 - true_loss: 1.0678 - val_loss: 5513.5952 - val_reconstruction_loss: 1895.9240 - val_kl_loss: 99.8927 - val_false_loss: 11.3491 - val_true_loss: 1.1305\n",
      "Epoch 170/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.4283 - reconstruction_loss: 1890.3583 - kl_loss: 96.3726 - false_loss: 0.0812 - true_loss: 1.0677 - val_loss: 5513.3223 - val_reconstruction_loss: 1895.9235 - val_kl_loss: 99.8926 - val_false_loss: 11.3482 - val_true_loss: 1.1304\n",
      "Epoch 171/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7567 - reconstruction_loss: 1891.0260 - kl_loss: 95.3909 - false_loss: 0.0812 - true_loss: 1.0677 - val_loss: 5513.0527 - val_reconstruction_loss: 1895.9231 - val_kl_loss: 99.8924 - val_false_loss: 11.3473 - val_true_loss: 1.1304\n",
      "Epoch 172/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.2463 - reconstruction_loss: 1890.0785 - kl_loss: 99.8831 - false_loss: 0.0812 - true_loss: 1.0677 - val_loss: 5512.7896 - val_reconstruction_loss: 1895.9227 - val_kl_loss: 99.8923 - val_false_loss: 11.3465 - val_true_loss: 1.1304\n",
      "Epoch 173/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.0934 - reconstruction_loss: 1889.5499 - kl_loss: 101.4174 - false_loss: 0.0812 - true_loss: 1.0676 - val_loss: 5512.5083 - val_reconstruction_loss: 1895.9222 - val_kl_loss: 99.8926 - val_false_loss: 11.3455 - val_true_loss: 1.1303\n",
      "Epoch 174/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.8327 - reconstruction_loss: 1889.4082 - kl_loss: 101.1158 - false_loss: 0.0812 - true_loss: 1.0676 - val_loss: 5512.2334 - val_reconstruction_loss: 1895.9219 - val_kl_loss: 99.8930 - val_false_loss: 11.3446 - val_true_loss: 1.1303\n",
      "Epoch 175/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.9807 - reconstruction_loss: 1889.2457 - kl_loss: 101.8203 - false_loss: 0.0812 - true_loss: 1.0676 - val_loss: 5511.9463 - val_reconstruction_loss: 1895.9216 - val_kl_loss: 99.8934 - val_false_loss: 11.3437 - val_true_loss: 1.1303\n",
      "Epoch 176/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.7661 - reconstruction_loss: 1889.7142 - kl_loss: 96.0941 - false_loss: 0.0812 - true_loss: 1.0675 - val_loss: 5511.6621 - val_reconstruction_loss: 1895.9211 - val_kl_loss: 99.8937 - val_false_loss: 11.3428 - val_true_loss: 1.1302\n",
      "Epoch 177/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4142 - reconstruction_loss: 1889.5765 - kl_loss: 101.4092 - false_loss: 0.0812 - true_loss: 1.0675 - val_loss: 5511.3828 - val_reconstruction_loss: 1895.9209 - val_kl_loss: 99.8938 - val_false_loss: 11.3418 - val_true_loss: 1.1302\n",
      "Epoch 178/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.6743 - reconstruction_loss: 1889.2133 - kl_loss: 102.6922 - false_loss: 0.0812 - true_loss: 1.0674 - val_loss: 5511.0991 - val_reconstruction_loss: 1895.9204 - val_kl_loss: 99.8945 - val_false_loss: 11.3409 - val_true_loss: 1.1301\n",
      "Epoch 179/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.0377 - reconstruction_loss: 1889.8041 - kl_loss: 102.9030 - false_loss: 0.0811 - true_loss: 1.0674 - val_loss: 5510.8125 - val_reconstruction_loss: 1895.9200 - val_kl_loss: 99.8950 - val_false_loss: 11.3400 - val_true_loss: 1.1301\n",
      "Epoch 180/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.0572 - reconstruction_loss: 1889.7100 - kl_loss: 103.3584 - false_loss: 0.0811 - true_loss: 1.0673 - val_loss: 5510.5337 - val_reconstruction_loss: 1895.9198 - val_kl_loss: 99.8953 - val_false_loss: 11.3391 - val_true_loss: 1.1301\n",
      "Epoch 181/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.8202 - reconstruction_loss: 1889.5392 - kl_loss: 101.9803 - false_loss: 0.0811 - true_loss: 1.0673 - val_loss: 5510.2510 - val_reconstruction_loss: 1895.9194 - val_kl_loss: 99.8956 - val_false_loss: 11.3381 - val_true_loss: 1.1300\n",
      "Epoch 182/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.3928 - reconstruction_loss: 1889.8082 - kl_loss: 100.6872 - false_loss: 0.0811 - true_loss: 1.0673 - val_loss: 5509.9683 - val_reconstruction_loss: 1895.9191 - val_kl_loss: 99.8958 - val_false_loss: 11.3372 - val_true_loss: 1.1300\n",
      "Epoch 183/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.6221 - reconstruction_loss: 1889.4867 - kl_loss: 100.7448 - false_loss: 0.0811 - true_loss: 1.0672 - val_loss: 5509.6831 - val_reconstruction_loss: 1895.9186 - val_kl_loss: 99.8964 - val_false_loss: 11.3363 - val_true_loss: 1.1299\n",
      "Epoch 184/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.3330 - reconstruction_loss: 1889.4474 - kl_loss: 102.0119 - false_loss: 0.0811 - true_loss: 1.0672 - val_loss: 5509.4072 - val_reconstruction_loss: 1895.9185 - val_kl_loss: 99.8964 - val_false_loss: 11.3353 - val_true_loss: 1.1299\n",
      "Epoch 185/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.0814 - reconstruction_loss: 1889.4296 - kl_loss: 99.8462 - false_loss: 0.0811 - true_loss: 1.0672 - val_loss: 5509.1274 - val_reconstruction_loss: 1895.9180 - val_kl_loss: 99.8964 - val_false_loss: 11.3344 - val_true_loss: 1.1299\n",
      "Epoch 186/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.3598 - reconstruction_loss: 1889.7681 - kl_loss: 98.3908 - false_loss: 0.0811 - true_loss: 1.0671 - val_loss: 5508.8423 - val_reconstruction_loss: 1895.9176 - val_kl_loss: 99.8968 - val_false_loss: 11.3335 - val_true_loss: 1.1299\n",
      "Epoch 187/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.8007 - reconstruction_loss: 1889.6622 - kl_loss: 98.4375 - false_loss: 0.0811 - true_loss: 1.0671 - val_loss: 5508.5547 - val_reconstruction_loss: 1895.9172 - val_kl_loss: 99.8977 - val_false_loss: 11.3325 - val_true_loss: 1.1298\n",
      "Epoch 188/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.6559 - reconstruction_loss: 1889.4711 - kl_loss: 101.0796 - false_loss: 0.0811 - true_loss: 1.0671 - val_loss: 5508.2710 - val_reconstruction_loss: 1895.9167 - val_kl_loss: 99.8981 - val_false_loss: 11.3316 - val_true_loss: 1.1298\n",
      "Epoch 189/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.6866 - reconstruction_loss: 1889.1295 - kl_loss: 99.1623 - false_loss: 0.0811 - true_loss: 1.0670 - val_loss: 5507.9927 - val_reconstruction_loss: 1895.9164 - val_kl_loss: 99.8979 - val_false_loss: 11.3307 - val_true_loss: 1.1298\n",
      "Epoch 190/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.7875 - reconstruction_loss: 1889.0469 - kl_loss: 101.0681 - false_loss: 0.0811 - true_loss: 1.0670 - val_loss: 5507.7178 - val_reconstruction_loss: 1895.9160 - val_kl_loss: 99.8981 - val_false_loss: 11.3298 - val_true_loss: 1.1297\n",
      "Epoch 191/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7807 - reconstruction_loss: 1889.0414 - kl_loss: 100.7971 - false_loss: 0.0811 - true_loss: 1.0669 - val_loss: 5507.4438 - val_reconstruction_loss: 1895.9156 - val_kl_loss: 99.8984 - val_false_loss: 11.3289 - val_true_loss: 1.1297\n",
      "Epoch 192/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4552 - reconstruction_loss: 1889.0190 - kl_loss: 101.0199 - false_loss: 0.0811 - true_loss: 1.0669 - val_loss: 5507.1670 - val_reconstruction_loss: 1895.9153 - val_kl_loss: 99.8987 - val_false_loss: 11.3280 - val_true_loss: 1.1296\n",
      "Epoch 193/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.8851 - reconstruction_loss: 1889.3789 - kl_loss: 100.3632 - false_loss: 0.0811 - true_loss: 1.0669 - val_loss: 5506.8901 - val_reconstruction_loss: 1895.9149 - val_kl_loss: 99.8987 - val_false_loss: 11.3271 - val_true_loss: 1.1296\n",
      "Epoch 194/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.7847 - reconstruction_loss: 1889.1781 - kl_loss: 100.1435 - false_loss: 0.0810 - true_loss: 1.0668 - val_loss: 5506.6060 - val_reconstruction_loss: 1895.9147 - val_kl_loss: 99.8992 - val_false_loss: 11.3261 - val_true_loss: 1.1296\n",
      "Epoch 195/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.5513 - reconstruction_loss: 1889.1378 - kl_loss: 98.8463 - false_loss: 0.0810 - true_loss: 1.0668 - val_loss: 5506.3281 - val_reconstruction_loss: 1895.9142 - val_kl_loss: 99.8996 - val_false_loss: 11.3252 - val_true_loss: 1.1295\n",
      "Epoch 196/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.7817 - reconstruction_loss: 1889.3661 - kl_loss: 100.5549 - false_loss: 0.0810 - true_loss: 1.0667 - val_loss: 5506.0410 - val_reconstruction_loss: 1895.9137 - val_kl_loss: 99.9000 - val_false_loss: 11.3243 - val_true_loss: 1.1295\n",
      "Epoch 197/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4621 - reconstruction_loss: 1889.0990 - kl_loss: 100.5854 - false_loss: 0.0810 - true_loss: 1.0667 - val_loss: 5505.7573 - val_reconstruction_loss: 1895.9135 - val_kl_loss: 99.9000 - val_false_loss: 11.3233 - val_true_loss: 1.1295\n",
      "Epoch 198/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.2691 - reconstruction_loss: 1889.2050 - kl_loss: 97.7059 - false_loss: 0.0810 - true_loss: 1.0667 - val_loss: 5505.4800 - val_reconstruction_loss: 1895.9130 - val_kl_loss: 99.9001 - val_false_loss: 11.3224 - val_true_loss: 1.1294\n",
      "Epoch 199/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.0008 - reconstruction_loss: 1889.2334 - kl_loss: 100.1043 - false_loss: 0.0810 - true_loss: 1.0666 - val_loss: 5505.2056 - val_reconstruction_loss: 1895.9125 - val_kl_loss: 99.9004 - val_false_loss: 11.3215 - val_true_loss: 1.1294\n",
      "Epoch 200/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.0320 - reconstruction_loss: 1889.5973 - kl_loss: 98.6684 - false_loss: 0.0810 - true_loss: 1.0666 - val_loss: 5504.9248 - val_reconstruction_loss: 1895.9124 - val_kl_loss: 99.9011 - val_false_loss: 11.3206 - val_true_loss: 1.1294\n",
      "Epoch 201/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.0126 - reconstruction_loss: 1889.4454 - kl_loss: 100.4805 - false_loss: 0.0810 - true_loss: 1.0666 - val_loss: 5504.6509 - val_reconstruction_loss: 1895.9120 - val_kl_loss: 99.9008 - val_false_loss: 11.3197 - val_true_loss: 1.1293\n",
      "Epoch 202/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.1584 - reconstruction_loss: 1889.6320 - kl_loss: 96.5769 - false_loss: 0.0810 - true_loss: 1.0665 - val_loss: 5504.3638 - val_reconstruction_loss: 1895.9116 - val_kl_loss: 99.9007 - val_false_loss: 11.3187 - val_true_loss: 1.1293\n",
      "Epoch 203/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.1952 - reconstruction_loss: 1889.3094 - kl_loss: 100.0156 - false_loss: 0.0810 - true_loss: 1.0665 - val_loss: 5504.0752 - val_reconstruction_loss: 1895.9113 - val_kl_loss: 99.9011 - val_false_loss: 11.3178 - val_true_loss: 1.1293\n",
      "Epoch 204/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6202 - reconstruction_loss: 1889.5869 - kl_loss: 98.6884 - false_loss: 0.0810 - true_loss: 1.0665 - val_loss: 5503.7900 - val_reconstruction_loss: 1895.9109 - val_kl_loss: 99.9017 - val_false_loss: 11.3169 - val_true_loss: 1.1292\n",
      "Epoch 205/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.6671 - reconstruction_loss: 1889.6564 - kl_loss: 102.2809 - false_loss: 0.0810 - true_loss: 1.0664 - val_loss: 5503.5088 - val_reconstruction_loss: 1895.9105 - val_kl_loss: 99.9022 - val_false_loss: 11.3159 - val_true_loss: 1.1292\n",
      "Epoch 206/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0857 - reconstruction_loss: 1889.0101 - kl_loss: 101.5172 - false_loss: 0.0810 - true_loss: 1.0664 - val_loss: 5503.2280 - val_reconstruction_loss: 1895.9100 - val_kl_loss: 99.9028 - val_false_loss: 11.3150 - val_true_loss: 1.1291\n",
      "Epoch 207/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.7696 - reconstruction_loss: 1889.1825 - kl_loss: 101.3582 - false_loss: 0.0810 - true_loss: 1.0663 - val_loss: 5502.9443 - val_reconstruction_loss: 1895.9097 - val_kl_loss: 99.9030 - val_false_loss: 11.3141 - val_true_loss: 1.1291\n",
      "Epoch 208/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.4396 - reconstruction_loss: 1889.1859 - kl_loss: 99.8141 - false_loss: 0.0810 - true_loss: 1.0663 - val_loss: 5502.6572 - val_reconstruction_loss: 1895.9094 - val_kl_loss: 99.9031 - val_false_loss: 11.3131 - val_true_loss: 1.1291\n",
      "Epoch 209/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2212.1655 - reconstruction_loss: 1889.6119 - kl_loss: 100.9340 - false_loss: 0.0809 - true_loss: 1.0662 - val_loss: 5502.3687 - val_reconstruction_loss: 1895.9092 - val_kl_loss: 99.9036 - val_false_loss: 11.3122 - val_true_loss: 1.1290\n",
      "Epoch 210/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.0780 - reconstruction_loss: 1889.1615 - kl_loss: 99.2882 - false_loss: 0.0809 - true_loss: 1.0662 - val_loss: 5502.0811 - val_reconstruction_loss: 1895.9087 - val_kl_loss: 99.9037 - val_false_loss: 11.3112 - val_true_loss: 1.1290\n",
      "Epoch 211/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.8978 - reconstruction_loss: 1889.4508 - kl_loss: 100.1713 - false_loss: 0.0809 - true_loss: 1.0662 - val_loss: 5501.7944 - val_reconstruction_loss: 1895.9082 - val_kl_loss: 99.9033 - val_false_loss: 11.3103 - val_true_loss: 1.1290\n",
      "Epoch 212/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4596 - reconstruction_loss: 1889.7451 - kl_loss: 99.7331 - false_loss: 0.0809 - true_loss: 1.0661 - val_loss: 5501.5171 - val_reconstruction_loss: 1895.9078 - val_kl_loss: 99.9035 - val_false_loss: 11.3094 - val_true_loss: 1.1289\n",
      "Epoch 213/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.7300 - reconstruction_loss: 1890.1774 - kl_loss: 100.2771 - false_loss: 0.0809 - true_loss: 1.0661 - val_loss: 5501.2373 - val_reconstruction_loss: 1895.9076 - val_kl_loss: 99.9039 - val_false_loss: 11.3085 - val_true_loss: 1.1289\n",
      "Epoch 214/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.5223 - reconstruction_loss: 1889.2965 - kl_loss: 102.3682 - false_loss: 0.0809 - true_loss: 1.0660 - val_loss: 5500.9585 - val_reconstruction_loss: 1895.9071 - val_kl_loss: 99.9043 - val_false_loss: 11.3076 - val_true_loss: 1.1288\n",
      "Epoch 215/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.0088 - reconstruction_loss: 1889.3812 - kl_loss: 101.1999 - false_loss: 0.0809 - true_loss: 1.0660 - val_loss: 5500.6792 - val_reconstruction_loss: 1895.9066 - val_kl_loss: 99.9045 - val_false_loss: 11.3066 - val_true_loss: 1.1288\n",
      "Epoch 216/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.4127 - reconstruction_loss: 1889.3387 - kl_loss: 100.7589 - false_loss: 0.0809 - true_loss: 1.0660 - val_loss: 5500.4053 - val_reconstruction_loss: 1895.9065 - val_kl_loss: 99.9046 - val_false_loss: 11.3057 - val_true_loss: 1.1288\n",
      "Epoch 217/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.6359 - reconstruction_loss: 1889.3146 - kl_loss: 100.4161 - false_loss: 0.0809 - true_loss: 1.0659 - val_loss: 5500.1265 - val_reconstruction_loss: 1895.9061 - val_kl_loss: 99.9054 - val_false_loss: 11.3048 - val_true_loss: 1.1287\n",
      "Epoch 218/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.8512 - reconstruction_loss: 1889.6538 - kl_loss: 102.0021 - false_loss: 0.0809 - true_loss: 1.0659 - val_loss: 5499.8408 - val_reconstruction_loss: 1895.9058 - val_kl_loss: 99.9061 - val_false_loss: 11.3039 - val_true_loss: 1.1287\n",
      "Epoch 219/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.4812 - reconstruction_loss: 1889.6196 - kl_loss: 102.1073 - false_loss: 0.0809 - true_loss: 1.0658 - val_loss: 5499.5684 - val_reconstruction_loss: 1895.9054 - val_kl_loss: 99.9068 - val_false_loss: 11.3030 - val_true_loss: 1.1286\n",
      "Epoch 220/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.5944 - reconstruction_loss: 1889.5356 - kl_loss: 101.2626 - false_loss: 0.0809 - true_loss: 1.0658 - val_loss: 5499.2954 - val_reconstruction_loss: 1895.9050 - val_kl_loss: 99.9071 - val_false_loss: 11.3021 - val_true_loss: 1.1286\n",
      "Epoch 221/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.9487 - reconstruction_loss: 1889.5758 - kl_loss: 101.1255 - false_loss: 0.0809 - true_loss: 1.0658 - val_loss: 5499.0229 - val_reconstruction_loss: 1895.9047 - val_kl_loss: 99.9077 - val_false_loss: 11.3012 - val_true_loss: 1.1286\n",
      "Epoch 222/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.3657 - reconstruction_loss: 1889.0977 - kl_loss: 101.7155 - false_loss: 0.0809 - true_loss: 1.0657 - val_loss: 5498.7456 - val_reconstruction_loss: 1895.9042 - val_kl_loss: 99.9081 - val_false_loss: 11.3003 - val_true_loss: 1.1285\n",
      "Epoch 223/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.7890 - reconstruction_loss: 1889.1104 - kl_loss: 102.1278 - false_loss: 0.0809 - true_loss: 1.0657 - val_loss: 5498.4717 - val_reconstruction_loss: 1895.9039 - val_kl_loss: 99.9085 - val_false_loss: 11.2994 - val_true_loss: 1.1285\n",
      "Epoch 224/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.8187 - reconstruction_loss: 1888.9336 - kl_loss: 101.5802 - false_loss: 0.0808 - true_loss: 1.0656 - val_loss: 5498.1943 - val_reconstruction_loss: 1895.9036 - val_kl_loss: 99.9087 - val_false_loss: 11.2985 - val_true_loss: 1.1284\n",
      "Epoch 225/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.0139 - reconstruction_loss: 1890.2500 - kl_loss: 100.1759 - false_loss: 0.0808 - true_loss: 1.0656 - val_loss: 5497.9150 - val_reconstruction_loss: 1895.9032 - val_kl_loss: 99.9083 - val_false_loss: 11.2976 - val_true_loss: 1.1284\n",
      "Epoch 226/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.0119 - reconstruction_loss: 1889.5996 - kl_loss: 100.0820 - false_loss: 0.0808 - true_loss: 1.0655 - val_loss: 5497.6348 - val_reconstruction_loss: 1895.9027 - val_kl_loss: 99.9088 - val_false_loss: 11.2966 - val_true_loss: 1.1284\n",
      "Epoch 227/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.3177 - reconstruction_loss: 1889.0719 - kl_loss: 101.9068 - false_loss: 0.0808 - true_loss: 1.0655 - val_loss: 5497.3550 - val_reconstruction_loss: 1895.9025 - val_kl_loss: 99.9096 - val_false_loss: 11.2957 - val_true_loss: 1.1283\n",
      "Epoch 228/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.0662 - reconstruction_loss: 1889.0262 - kl_loss: 102.2836 - false_loss: 0.0808 - true_loss: 1.0655 - val_loss: 5497.0786 - val_reconstruction_loss: 1895.9020 - val_kl_loss: 99.9101 - val_false_loss: 11.2948 - val_true_loss: 1.1283\n",
      "Epoch 229/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.1077 - reconstruction_loss: 1889.4648 - kl_loss: 101.6658 - false_loss: 0.0808 - true_loss: 1.0654 - val_loss: 5496.8022 - val_reconstruction_loss: 1895.9017 - val_kl_loss: 99.9107 - val_false_loss: 11.2939 - val_true_loss: 1.1282\n",
      "Epoch 230/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.9905 - reconstruction_loss: 1889.2838 - kl_loss: 101.4106 - false_loss: 0.0808 - true_loss: 1.0654 - val_loss: 5496.5171 - val_reconstruction_loss: 1895.9015 - val_kl_loss: 99.9112 - val_false_loss: 11.2930 - val_true_loss: 1.1282\n",
      "Epoch 231/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.9838 - reconstruction_loss: 1889.6123 - kl_loss: 101.4106 - false_loss: 0.0808 - true_loss: 1.0653 - val_loss: 5496.2368 - val_reconstruction_loss: 1895.9012 - val_kl_loss: 99.9119 - val_false_loss: 11.2920 - val_true_loss: 1.1282\n",
      "Epoch 232/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0076 - reconstruction_loss: 1889.7422 - kl_loss: 101.6165 - false_loss: 0.0808 - true_loss: 1.0653 - val_loss: 5495.9570 - val_reconstruction_loss: 1895.9008 - val_kl_loss: 99.9123 - val_false_loss: 11.2911 - val_true_loss: 1.1281\n",
      "Epoch 233/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.3472 - reconstruction_loss: 1889.3190 - kl_loss: 101.6490 - false_loss: 0.0808 - true_loss: 1.0653 - val_loss: 5495.6777 - val_reconstruction_loss: 1895.9003 - val_kl_loss: 99.9123 - val_false_loss: 11.2902 - val_true_loss: 1.1281\n",
      "Epoch 234/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.7286 - reconstruction_loss: 1889.3862 - kl_loss: 100.9138 - false_loss: 0.0808 - true_loss: 1.0652 - val_loss: 5495.3955 - val_reconstruction_loss: 1895.8998 - val_kl_loss: 99.9129 - val_false_loss: 11.2893 - val_true_loss: 1.1280\n",
      "Epoch 235/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.9296 - reconstruction_loss: 1889.0752 - kl_loss: 103.3497 - false_loss: 0.0808 - true_loss: 1.0652 - val_loss: 5495.1143 - val_reconstruction_loss: 1895.8995 - val_kl_loss: 99.9135 - val_false_loss: 11.2883 - val_true_loss: 1.1280\n",
      "Epoch 236/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.1605 - reconstruction_loss: 1889.0973 - kl_loss: 102.3834 - false_loss: 0.0808 - true_loss: 1.0651 - val_loss: 5494.8340 - val_reconstruction_loss: 1895.8993 - val_kl_loss: 99.9140 - val_false_loss: 11.2874 - val_true_loss: 1.1280\n",
      "Epoch 237/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.8023 - reconstruction_loss: 1889.7897 - kl_loss: 102.3780 - false_loss: 0.0808 - true_loss: 1.0651 - val_loss: 5494.5532 - val_reconstruction_loss: 1895.8989 - val_kl_loss: 99.9145 - val_false_loss: 11.2865 - val_true_loss: 1.1279\n",
      "Epoch 238/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.1070 - reconstruction_loss: 1889.3519 - kl_loss: 102.1533 - false_loss: 0.0808 - true_loss: 1.0650 - val_loss: 5494.2754 - val_reconstruction_loss: 1895.8984 - val_kl_loss: 99.9150 - val_false_loss: 11.2856 - val_true_loss: 1.1279\n",
      "Epoch 239/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.8231 - reconstruction_loss: 1889.6279 - kl_loss: 102.6666 - false_loss: 0.0807 - true_loss: 1.0650 - val_loss: 5493.9893 - val_reconstruction_loss: 1895.8981 - val_kl_loss: 99.9155 - val_false_loss: 11.2846 - val_true_loss: 1.1279\n",
      "Epoch 240/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.0364 - reconstruction_loss: 1889.8145 - kl_loss: 102.3802 - false_loss: 0.0807 - true_loss: 1.0650 - val_loss: 5493.7065 - val_reconstruction_loss: 1895.8977 - val_kl_loss: 99.9160 - val_false_loss: 11.2837 - val_true_loss: 1.1278\n",
      "Epoch 241/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.8147 - reconstruction_loss: 1889.1920 - kl_loss: 102.2083 - false_loss: 0.0807 - true_loss: 1.0649 - val_loss: 5493.4248 - val_reconstruction_loss: 1895.8972 - val_kl_loss: 99.9165 - val_false_loss: 11.2828 - val_true_loss: 1.1278\n",
      "Epoch 242/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.1860 - reconstruction_loss: 1889.2612 - kl_loss: 99.4687 - false_loss: 0.0807 - true_loss: 1.0649 - val_loss: 5493.1426 - val_reconstruction_loss: 1895.8969 - val_kl_loss: 99.9170 - val_false_loss: 11.2819 - val_true_loss: 1.1277\n",
      "Epoch 243/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.3061 - reconstruction_loss: 1889.1523 - kl_loss: 101.1792 - false_loss: 0.0807 - true_loss: 1.0648 - val_loss: 5492.8623 - val_reconstruction_loss: 1895.8966 - val_kl_loss: 99.9176 - val_false_loss: 11.2809 - val_true_loss: 1.1277\n",
      "Epoch 244/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.4233 - reconstruction_loss: 1889.0729 - kl_loss: 101.6071 - false_loss: 0.0807 - true_loss: 1.0648 - val_loss: 5492.5757 - val_reconstruction_loss: 1895.8964 - val_kl_loss: 99.9180 - val_false_loss: 11.2800 - val_true_loss: 1.1277\n",
      "Epoch 245/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.7092 - reconstruction_loss: 1889.5781 - kl_loss: 101.9466 - false_loss: 0.0807 - true_loss: 1.0647 - val_loss: 5492.2979 - val_reconstruction_loss: 1895.8960 - val_kl_loss: 99.9185 - val_false_loss: 11.2791 - val_true_loss: 1.1276\n",
      "Epoch 246/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.7637 - reconstruction_loss: 1890.0641 - kl_loss: 101.2397 - false_loss: 0.0807 - true_loss: 1.0647 - val_loss: 5492.0156 - val_reconstruction_loss: 1895.8958 - val_kl_loss: 99.9194 - val_false_loss: 11.2781 - val_true_loss: 1.1276\n",
      "Epoch 247/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.6743 - reconstruction_loss: 1889.7432 - kl_loss: 101.3921 - false_loss: 0.0807 - true_loss: 1.0647 - val_loss: 5491.7305 - val_reconstruction_loss: 1895.8954 - val_kl_loss: 99.9199 - val_false_loss: 11.2772 - val_true_loss: 1.1276\n",
      "Epoch 248/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.4995 - reconstruction_loss: 1889.4088 - kl_loss: 101.3773 - false_loss: 0.0807 - true_loss: 1.0646 - val_loss: 5491.4580 - val_reconstruction_loss: 1895.8950 - val_kl_loss: 99.9205 - val_false_loss: 11.2763 - val_true_loss: 1.1275\n",
      "Epoch 249/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.0611 - reconstruction_loss: 1889.1710 - kl_loss: 102.0745 - false_loss: 0.0807 - true_loss: 1.0646 - val_loss: 5491.1763 - val_reconstruction_loss: 1895.8947 - val_kl_loss: 99.9211 - val_false_loss: 11.2754 - val_true_loss: 1.1275\n",
      "Epoch 250/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.6128 - reconstruction_loss: 1889.0474 - kl_loss: 102.4015 - false_loss: 0.0807 - true_loss: 1.0645 - val_loss: 5490.8945 - val_reconstruction_loss: 1895.8942 - val_kl_loss: 99.9213 - val_false_loss: 11.2745 - val_true_loss: 1.1274\n",
      "Epoch 251/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.2536 - reconstruction_loss: 1889.4683 - kl_loss: 100.9452 - false_loss: 0.0807 - true_loss: 1.0645 - val_loss: 5490.6079 - val_reconstruction_loss: 1895.8939 - val_kl_loss: 99.9216 - val_false_loss: 11.2735 - val_true_loss: 1.1274\n",
      "Epoch 252/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.1181 - reconstruction_loss: 1889.3423 - kl_loss: 101.1191 - false_loss: 0.0807 - true_loss: 1.0644 - val_loss: 5490.3223 - val_reconstruction_loss: 1895.8934 - val_kl_loss: 99.9219 - val_false_loss: 11.2726 - val_true_loss: 1.1274\n",
      "Epoch 253/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.9139 - reconstruction_loss: 1889.2119 - kl_loss: 102.1491 - false_loss: 0.0807 - true_loss: 1.0644 - val_loss: 5490.0366 - val_reconstruction_loss: 1895.8929 - val_kl_loss: 99.9226 - val_false_loss: 11.2716 - val_true_loss: 1.1273\n",
      "Epoch 254/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.7390 - reconstruction_loss: 1889.7740 - kl_loss: 102.6239 - false_loss: 0.0806 - true_loss: 1.0644 - val_loss: 5489.7598 - val_reconstruction_loss: 1895.8927 - val_kl_loss: 99.9232 - val_false_loss: 11.2707 - val_true_loss: 1.1273\n",
      "Epoch 255/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.9591 - reconstruction_loss: 1890.3242 - kl_loss: 102.9422 - false_loss: 0.0806 - true_loss: 1.0643 - val_loss: 5489.4854 - val_reconstruction_loss: 1895.8925 - val_kl_loss: 99.9231 - val_false_loss: 11.2698 - val_true_loss: 1.1273\n",
      "Epoch 256/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0167 - reconstruction_loss: 1890.2916 - kl_loss: 99.5590 - false_loss: 0.0806 - true_loss: 1.0643 - val_loss: 5489.2026 - val_reconstruction_loss: 1895.8920 - val_kl_loss: 99.9227 - val_false_loss: 11.2689 - val_true_loss: 1.1272\n",
      "Epoch 257/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.3823 - reconstruction_loss: 1889.9624 - kl_loss: 99.9797 - false_loss: 0.0806 - true_loss: 1.0642 - val_loss: 5488.9160 - val_reconstruction_loss: 1895.8916 - val_kl_loss: 99.9234 - val_false_loss: 11.2680 - val_true_loss: 1.1272\n",
      "Epoch 258/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.6533 - reconstruction_loss: 1889.9189 - kl_loss: 102.3919 - false_loss: 0.0806 - true_loss: 1.0642 - val_loss: 5488.6313 - val_reconstruction_loss: 1895.8912 - val_kl_loss: 99.9236 - val_false_loss: 11.2670 - val_true_loss: 1.1271\n",
      "Epoch 259/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.6796 - reconstruction_loss: 1889.3931 - kl_loss: 101.8207 - false_loss: 0.0806 - true_loss: 1.0642 - val_loss: 5488.3472 - val_reconstruction_loss: 1895.8909 - val_kl_loss: 99.9239 - val_false_loss: 11.2661 - val_true_loss: 1.1271\n",
      "Epoch 260/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.4576 - reconstruction_loss: 1889.3823 - kl_loss: 103.3430 - false_loss: 0.0806 - true_loss: 1.0641 - val_loss: 5488.0620 - val_reconstruction_loss: 1895.8904 - val_kl_loss: 99.9242 - val_false_loss: 11.2652 - val_true_loss: 1.1270\n",
      "Epoch 261/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2208.7757 - reconstruction_loss: 1889.1271 - kl_loss: 102.7167 - false_loss: 0.0806 - true_loss: 1.0641 - val_loss: 5487.7764 - val_reconstruction_loss: 1895.8901 - val_kl_loss: 99.9247 - val_false_loss: 11.2642 - val_true_loss: 1.1270\n",
      "Epoch 262/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.3004 - reconstruction_loss: 1889.3866 - kl_loss: 101.9406 - false_loss: 0.0806 - true_loss: 1.0640 - val_loss: 5487.5039 - val_reconstruction_loss: 1895.8899 - val_kl_loss: 99.9253 - val_false_loss: 11.2633 - val_true_loss: 1.1270\n",
      "Epoch 263/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.3247 - reconstruction_loss: 1890.3607 - kl_loss: 95.5540 - false_loss: 0.0806 - true_loss: 1.0640 - val_loss: 5487.2251 - val_reconstruction_loss: 1895.8894 - val_kl_loss: 99.9251 - val_false_loss: 11.2624 - val_true_loss: 1.1269\n",
      "Epoch 264/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.6979 - reconstruction_loss: 1892.5055 - kl_loss: 92.7336 - false_loss: 0.0806 - true_loss: 1.0640 - val_loss: 5486.9326 - val_reconstruction_loss: 1895.8893 - val_kl_loss: 99.9241 - val_false_loss: 11.2614 - val_true_loss: 1.1269\n",
      "Epoch 265/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.2554 - reconstruction_loss: 1892.1168 - kl_loss: 93.0157 - false_loss: 0.0806 - true_loss: 1.0639 - val_loss: 5486.6401 - val_reconstruction_loss: 1895.8889 - val_kl_loss: 99.9237 - val_false_loss: 11.2605 - val_true_loss: 1.1269\n",
      "Epoch 266/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.8149 - reconstruction_loss: 1890.7653 - kl_loss: 95.2389 - false_loss: 0.0806 - true_loss: 1.0639 - val_loss: 5486.3574 - val_reconstruction_loss: 1895.8885 - val_kl_loss: 99.9234 - val_false_loss: 11.2595 - val_true_loss: 1.1269\n",
      "Epoch 267/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.0046 - reconstruction_loss: 1889.6846 - kl_loss: 99.0104 - false_loss: 0.0806 - true_loss: 1.0639 - val_loss: 5486.0649 - val_reconstruction_loss: 1895.8883 - val_kl_loss: 99.9231 - val_false_loss: 11.2586 - val_true_loss: 1.1268\n",
      "Epoch 268/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.1408 - reconstruction_loss: 1889.3280 - kl_loss: 100.0933 - false_loss: 0.0806 - true_loss: 1.0639 - val_loss: 5485.7720 - val_reconstruction_loss: 1895.8878 - val_kl_loss: 99.9238 - val_false_loss: 11.2576 - val_true_loss: 1.1268\n",
      "Epoch 269/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.5766 - reconstruction_loss: 1889.2670 - kl_loss: 100.6396 - false_loss: 0.0806 - true_loss: 1.0638 - val_loss: 5485.4868 - val_reconstruction_loss: 1895.8873 - val_kl_loss: 99.9238 - val_false_loss: 11.2567 - val_true_loss: 1.1268\n",
      "Epoch 270/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.0848 - reconstruction_loss: 1889.2384 - kl_loss: 101.0722 - false_loss: 0.0806 - true_loss: 1.0638 - val_loss: 5485.1909 - val_reconstruction_loss: 1895.8870 - val_kl_loss: 99.9244 - val_false_loss: 11.2557 - val_true_loss: 1.1267\n",
      "Epoch 271/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.9991 - reconstruction_loss: 1889.6622 - kl_loss: 101.6070 - false_loss: 0.0805 - true_loss: 1.0637 - val_loss: 5484.8960 - val_reconstruction_loss: 1895.8865 - val_kl_loss: 99.9247 - val_false_loss: 11.2547 - val_true_loss: 1.1267\n",
      "Epoch 272/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.7508 - reconstruction_loss: 1889.4257 - kl_loss: 101.9130 - false_loss: 0.0805 - true_loss: 1.0637 - val_loss: 5484.6030 - val_reconstruction_loss: 1895.8861 - val_kl_loss: 99.9251 - val_false_loss: 11.2538 - val_true_loss: 1.1266\n",
      "Epoch 273/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.6540 - reconstruction_loss: 1889.0952 - kl_loss: 102.0718 - false_loss: 0.0805 - true_loss: 1.0637 - val_loss: 5484.3159 - val_reconstruction_loss: 1895.8857 - val_kl_loss: 99.9254 - val_false_loss: 11.2528 - val_true_loss: 1.1266\n",
      "Epoch 274/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6964 - reconstruction_loss: 1889.1582 - kl_loss: 100.5024 - false_loss: 0.0805 - true_loss: 1.0636 - val_loss: 5484.0293 - val_reconstruction_loss: 1895.8853 - val_kl_loss: 99.9254 - val_false_loss: 11.2519 - val_true_loss: 1.1266\n",
      "Epoch 275/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.9356 - reconstruction_loss: 1889.9595 - kl_loss: 99.1547 - false_loss: 0.0805 - true_loss: 1.0636 - val_loss: 5483.7466 - val_reconstruction_loss: 1895.8849 - val_kl_loss: 99.9252 - val_false_loss: 11.2509 - val_true_loss: 1.1266\n",
      "Epoch 276/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.4583 - reconstruction_loss: 1889.9093 - kl_loss: 99.0937 - false_loss: 0.0805 - true_loss: 1.0636 - val_loss: 5483.4619 - val_reconstruction_loss: 1895.8845 - val_kl_loss: 99.9256 - val_false_loss: 11.2500 - val_true_loss: 1.1265\n",
      "Epoch 277/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.9382 - reconstruction_loss: 1889.3431 - kl_loss: 100.9907 - false_loss: 0.0805 - true_loss: 1.0635 - val_loss: 5483.1782 - val_reconstruction_loss: 1895.8840 - val_kl_loss: 99.9260 - val_false_loss: 11.2491 - val_true_loss: 1.1265\n",
      "Epoch 278/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.4176 - reconstruction_loss: 1888.9652 - kl_loss: 100.2723 - false_loss: 0.0805 - true_loss: 1.0635 - val_loss: 5482.8921 - val_reconstruction_loss: 1895.8838 - val_kl_loss: 99.9265 - val_false_loss: 11.2481 - val_true_loss: 1.1265\n",
      "Epoch 279/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.5776 - reconstruction_loss: 1889.1270 - kl_loss: 98.3163 - false_loss: 0.0805 - true_loss: 1.0634 - val_loss: 5482.5991 - val_reconstruction_loss: 1895.8834 - val_kl_loss: 99.9270 - val_false_loss: 11.2472 - val_true_loss: 1.1264\n",
      "Epoch 280/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.8206 - reconstruction_loss: 1888.9432 - kl_loss: 100.4022 - false_loss: 0.0805 - true_loss: 1.0634 - val_loss: 5482.3076 - val_reconstruction_loss: 1895.8829 - val_kl_loss: 99.9268 - val_false_loss: 11.2462 - val_true_loss: 1.1264\n",
      "Epoch 281/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.4402 - reconstruction_loss: 1889.4628 - kl_loss: 96.6378 - false_loss: 0.0805 - true_loss: 1.0634 - val_loss: 5482.0264 - val_reconstruction_loss: 1895.8827 - val_kl_loss: 99.9270 - val_false_loss: 11.2453 - val_true_loss: 1.1264\n",
      "Epoch 282/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.5669 - reconstruction_loss: 1889.4326 - kl_loss: 100.9320 - false_loss: 0.0805 - true_loss: 1.0633 - val_loss: 5481.7456 - val_reconstruction_loss: 1895.8822 - val_kl_loss: 99.9276 - val_false_loss: 11.2444 - val_true_loss: 1.1263\n",
      "Epoch 283/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.9503 - reconstruction_loss: 1889.4316 - kl_loss: 100.8479 - false_loss: 0.0805 - true_loss: 1.0633 - val_loss: 5481.4580 - val_reconstruction_loss: 1895.8820 - val_kl_loss: 99.9277 - val_false_loss: 11.2434 - val_true_loss: 1.1263\n",
      "Epoch 284/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.2506 - reconstruction_loss: 1889.1066 - kl_loss: 99.5838 - false_loss: 0.0805 - true_loss: 1.0633 - val_loss: 5481.1636 - val_reconstruction_loss: 1895.8816 - val_kl_loss: 99.9278 - val_false_loss: 11.2424 - val_true_loss: 1.1263\n",
      "Epoch 285/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.9694 - reconstruction_loss: 1889.2513 - kl_loss: 100.6466 - false_loss: 0.0805 - true_loss: 1.0632 - val_loss: 5480.8804 - val_reconstruction_loss: 1895.8811 - val_kl_loss: 99.9282 - val_false_loss: 11.2415 - val_true_loss: 1.1262\n",
      "Epoch 286/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.7509 - reconstruction_loss: 1889.5321 - kl_loss: 100.1960 - false_loss: 0.0804 - true_loss: 1.0632 - val_loss: 5480.5933 - val_reconstruction_loss: 1895.8807 - val_kl_loss: 99.9287 - val_false_loss: 11.2406 - val_true_loss: 1.1262\n",
      "Epoch 287/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.8082 - reconstruction_loss: 1889.0239 - kl_loss: 101.1089 - false_loss: 0.0804 - true_loss: 1.0632 - val_loss: 5480.3003 - val_reconstruction_loss: 1895.8804 - val_kl_loss: 99.9292 - val_false_loss: 11.2396 - val_true_loss: 1.1262\n",
      "Epoch 288/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.4428 - reconstruction_loss: 1889.1381 - kl_loss: 101.0848 - false_loss: 0.0804 - true_loss: 1.0631 - val_loss: 5480.0205 - val_reconstruction_loss: 1895.8801 - val_kl_loss: 99.9293 - val_false_loss: 11.2387 - val_true_loss: 1.1261\n",
      "Epoch 289/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.6888 - reconstruction_loss: 1889.1869 - kl_loss: 99.6641 - false_loss: 0.0804 - true_loss: 1.0631 - val_loss: 5479.7417 - val_reconstruction_loss: 1895.8799 - val_kl_loss: 99.9293 - val_false_loss: 11.2378 - val_true_loss: 1.1261\n",
      "Epoch 290/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.3550 - reconstruction_loss: 1889.2155 - kl_loss: 97.8967 - false_loss: 0.0804 - true_loss: 1.0630 - val_loss: 5479.4541 - val_reconstruction_loss: 1895.8794 - val_kl_loss: 99.9295 - val_false_loss: 11.2368 - val_true_loss: 1.1261\n",
      "Epoch 291/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.9251 - reconstruction_loss: 1889.4518 - kl_loss: 99.8451 - false_loss: 0.0804 - true_loss: 1.0630 - val_loss: 5479.1670 - val_reconstruction_loss: 1895.8789 - val_kl_loss: 99.9297 - val_false_loss: 11.2359 - val_true_loss: 1.1260\n",
      "Epoch 292/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.3001 - reconstruction_loss: 1889.6537 - kl_loss: 100.3873 - false_loss: 0.0804 - true_loss: 1.0630 - val_loss: 5478.8877 - val_reconstruction_loss: 1895.8784 - val_kl_loss: 99.9301 - val_false_loss: 11.2349 - val_true_loss: 1.1260\n",
      "Epoch 293/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.0688 - reconstruction_loss: 1889.4547 - kl_loss: 100.4484 - false_loss: 0.0804 - true_loss: 1.0629 - val_loss: 5478.6021 - val_reconstruction_loss: 1895.8782 - val_kl_loss: 99.9305 - val_false_loss: 11.2340 - val_true_loss: 1.1260\n",
      "Epoch 294/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.0418 - reconstruction_loss: 1889.1982 - kl_loss: 100.7460 - false_loss: 0.0804 - true_loss: 1.0629 - val_loss: 5478.3169 - val_reconstruction_loss: 1895.8778 - val_kl_loss: 99.9308 - val_false_loss: 11.2331 - val_true_loss: 1.1259\n",
      "Epoch 295/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.6644 - reconstruction_loss: 1889.1807 - kl_loss: 99.7270 - false_loss: 0.0804 - true_loss: 1.0628 - val_loss: 5478.0361 - val_reconstruction_loss: 1895.8773 - val_kl_loss: 99.9311 - val_false_loss: 11.2321 - val_true_loss: 1.1259\n",
      "Epoch 296/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.7445 - reconstruction_loss: 1889.2096 - kl_loss: 96.6153 - false_loss: 0.0804 - true_loss: 1.0628 - val_loss: 5477.7598 - val_reconstruction_loss: 1895.8771 - val_kl_loss: 99.9310 - val_false_loss: 11.2312 - val_true_loss: 1.1259\n",
      "Epoch 297/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.4054 - reconstruction_loss: 1889.1364 - kl_loss: 98.0034 - false_loss: 0.0804 - true_loss: 1.0628 - val_loss: 5477.4780 - val_reconstruction_loss: 1895.8766 - val_kl_loss: 99.9313 - val_false_loss: 11.2303 - val_true_loss: 1.1258\n",
      "Epoch 298/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.6929 - reconstruction_loss: 1889.6920 - kl_loss: 100.9309 - false_loss: 0.0804 - true_loss: 1.0627 - val_loss: 5477.1982 - val_reconstruction_loss: 1895.8762 - val_kl_loss: 99.9316 - val_false_loss: 11.2294 - val_true_loss: 1.1258\n",
      "Epoch 299/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.7664 - reconstruction_loss: 1889.0684 - kl_loss: 100.3945 - false_loss: 0.0804 - true_loss: 1.0627 - val_loss: 5476.9111 - val_reconstruction_loss: 1895.8760 - val_kl_loss: 99.9321 - val_false_loss: 11.2284 - val_true_loss: 1.1258\n",
      "Epoch 300/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.6116 - reconstruction_loss: 1888.9750 - kl_loss: 100.5650 - false_loss: 0.0804 - true_loss: 1.0627 - val_loss: 5476.6304 - val_reconstruction_loss: 1895.8755 - val_kl_loss: 99.9324 - val_false_loss: 11.2275 - val_true_loss: 1.1257\n",
      "Epoch 301/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8316 - reconstruction_loss: 1888.8695 - kl_loss: 100.6968 - false_loss: 0.0804 - true_loss: 1.0626 - val_loss: 5476.3530 - val_reconstruction_loss: 1895.8751 - val_kl_loss: 99.9327 - val_false_loss: 11.2266 - val_true_loss: 1.1257\n",
      "Epoch 302/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.4906 - reconstruction_loss: 1889.7770 - kl_loss: 101.3114 - false_loss: 0.0803 - true_loss: 1.0626 - val_loss: 5476.0747 - val_reconstruction_loss: 1895.8748 - val_kl_loss: 99.9329 - val_false_loss: 11.2257 - val_true_loss: 1.1256\n",
      "Epoch 303/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.8111 - reconstruction_loss: 1889.1996 - kl_loss: 100.5664 - false_loss: 0.0803 - true_loss: 1.0625 - val_loss: 5475.7915 - val_reconstruction_loss: 1895.8744 - val_kl_loss: 99.9334 - val_false_loss: 11.2248 - val_true_loss: 1.1256\n",
      "Epoch 304/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.2078 - reconstruction_loss: 1889.0856 - kl_loss: 100.2849 - false_loss: 0.0803 - true_loss: 1.0625 - val_loss: 5475.5103 - val_reconstruction_loss: 1895.8740 - val_kl_loss: 99.9335 - val_false_loss: 11.2238 - val_true_loss: 1.1256\n",
      "Epoch 305/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.9233 - reconstruction_loss: 1889.4531 - kl_loss: 99.3905 - false_loss: 0.0803 - true_loss: 1.0625 - val_loss: 5475.2334 - val_reconstruction_loss: 1895.8737 - val_kl_loss: 99.9336 - val_false_loss: 11.2229 - val_true_loss: 1.1255\n",
      "Epoch 306/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.0066 - reconstruction_loss: 1889.5192 - kl_loss: 98.0166 - false_loss: 0.0803 - true_loss: 1.0624 - val_loss: 5474.9551 - val_reconstruction_loss: 1895.8732 - val_kl_loss: 99.9339 - val_false_loss: 11.2220 - val_true_loss: 1.1255\n",
      "Epoch 307/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.6539 - reconstruction_loss: 1889.3829 - kl_loss: 101.0461 - false_loss: 0.0803 - true_loss: 1.0624 - val_loss: 5474.6807 - val_reconstruction_loss: 1895.8728 - val_kl_loss: 99.9344 - val_false_loss: 11.2211 - val_true_loss: 1.1255\n",
      "Epoch 308/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.3961 - reconstruction_loss: 1889.1139 - kl_loss: 101.5140 - false_loss: 0.0803 - true_loss: 1.0624 - val_loss: 5474.4077 - val_reconstruction_loss: 1895.8726 - val_kl_loss: 99.9346 - val_false_loss: 11.2202 - val_true_loss: 1.1254\n",
      "Epoch 309/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.5917 - reconstruction_loss: 1889.5176 - kl_loss: 100.5031 - false_loss: 0.0803 - true_loss: 1.0623 - val_loss: 5474.1294 - val_reconstruction_loss: 1895.8721 - val_kl_loss: 99.9345 - val_false_loss: 11.2193 - val_true_loss: 1.1254\n",
      "Epoch 310/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.0750 - reconstruction_loss: 1889.3535 - kl_loss: 99.8571 - false_loss: 0.0803 - true_loss: 1.0623 - val_loss: 5473.8516 - val_reconstruction_loss: 1895.8717 - val_kl_loss: 99.9352 - val_false_loss: 11.2184 - val_true_loss: 1.1254\n",
      "Epoch 311/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.3080 - reconstruction_loss: 1889.1831 - kl_loss: 101.7011 - false_loss: 0.0803 - true_loss: 1.0622 - val_loss: 5473.5742 - val_reconstruction_loss: 1895.8713 - val_kl_loss: 99.9355 - val_false_loss: 11.2175 - val_true_loss: 1.1253\n",
      "Epoch 312/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3741 - reconstruction_loss: 1889.3893 - kl_loss: 100.6949 - false_loss: 0.0803 - true_loss: 1.0622 - val_loss: 5473.2891 - val_reconstruction_loss: 1895.8708 - val_kl_loss: 99.9355 - val_false_loss: 11.2165 - val_true_loss: 1.1253\n",
      "Epoch 313/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2213.0482 - reconstruction_loss: 1889.6030 - kl_loss: 98.3868 - false_loss: 0.0803 - true_loss: 1.0622 - val_loss: 5473.0093 - val_reconstruction_loss: 1895.8706 - val_kl_loss: 99.9353 - val_false_loss: 11.2156 - val_true_loss: 1.1253\n",
      "Epoch 314/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.7989 - reconstruction_loss: 1889.3473 - kl_loss: 99.8646 - false_loss: 0.0803 - true_loss: 1.0621 - val_loss: 5472.7310 - val_reconstruction_loss: 1895.8701 - val_kl_loss: 99.9358 - val_false_loss: 11.2147 - val_true_loss: 1.1252\n",
      "Epoch 315/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.8512 - reconstruction_loss: 1888.9674 - kl_loss: 101.2893 - false_loss: 0.0803 - true_loss: 1.0621 - val_loss: 5472.4502 - val_reconstruction_loss: 1895.8698 - val_kl_loss: 99.9360 - val_false_loss: 11.2138 - val_true_loss: 1.1252\n",
      "Epoch 316/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.8595 - reconstruction_loss: 1889.4884 - kl_loss: 100.6534 - false_loss: 0.0803 - true_loss: 1.0620 - val_loss: 5472.1733 - val_reconstruction_loss: 1895.8694 - val_kl_loss: 99.9356 - val_false_loss: 11.2128 - val_true_loss: 1.1252\n",
      "Epoch 317/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.3386 - reconstruction_loss: 1889.4066 - kl_loss: 100.0338 - false_loss: 0.0802 - true_loss: 1.0620 - val_loss: 5471.8975 - val_reconstruction_loss: 1895.8689 - val_kl_loss: 99.9358 - val_false_loss: 11.2119 - val_true_loss: 1.1251\n",
      "Epoch 318/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.8935 - reconstruction_loss: 1889.3519 - kl_loss: 100.0590 - false_loss: 0.0802 - true_loss: 1.0620 - val_loss: 5471.6187 - val_reconstruction_loss: 1895.8687 - val_kl_loss: 99.9362 - val_false_loss: 11.2110 - val_true_loss: 1.1251\n",
      "Epoch 319/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.8165 - reconstruction_loss: 1889.3295 - kl_loss: 99.8657 - false_loss: 0.0802 - true_loss: 1.0619 - val_loss: 5471.3271 - val_reconstruction_loss: 1895.8684 - val_kl_loss: 99.9367 - val_false_loss: 11.2101 - val_true_loss: 1.1251\n",
      "Epoch 320/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.9399 - reconstruction_loss: 1889.2408 - kl_loss: 102.2715 - false_loss: 0.0802 - true_loss: 1.0619 - val_loss: 5471.0415 - val_reconstruction_loss: 1895.8679 - val_kl_loss: 99.9371 - val_false_loss: 11.2091 - val_true_loss: 1.1250\n",
      "Epoch 321/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.4631 - reconstruction_loss: 1889.3071 - kl_loss: 102.3832 - false_loss: 0.0802 - true_loss: 1.0618 - val_loss: 5470.7593 - val_reconstruction_loss: 1895.8674 - val_kl_loss: 99.9374 - val_false_loss: 11.2082 - val_true_loss: 1.1250\n",
      "Epoch 322/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.0019 - reconstruction_loss: 1889.1627 - kl_loss: 101.6338 - false_loss: 0.0802 - true_loss: 1.0618 - val_loss: 5470.4790 - val_reconstruction_loss: 1895.8672 - val_kl_loss: 99.9380 - val_false_loss: 11.2073 - val_true_loss: 1.1249\n",
      "Epoch 323/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.2683 - reconstruction_loss: 1889.1715 - kl_loss: 101.6755 - false_loss: 0.0802 - true_loss: 1.0618 - val_loss: 5470.1987 - val_reconstruction_loss: 1895.8668 - val_kl_loss: 99.9385 - val_false_loss: 11.2064 - val_true_loss: 1.1249\n",
      "Epoch 324/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.0124 - reconstruction_loss: 1889.3932 - kl_loss: 101.5757 - false_loss: 0.0802 - true_loss: 1.0617 - val_loss: 5469.9141 - val_reconstruction_loss: 1895.8665 - val_kl_loss: 99.9388 - val_false_loss: 11.2054 - val_true_loss: 1.1249\n",
      "Epoch 325/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.4862 - reconstruction_loss: 1889.5416 - kl_loss: 101.9915 - false_loss: 0.0802 - true_loss: 1.0617 - val_loss: 5469.6318 - val_reconstruction_loss: 1895.8660 - val_kl_loss: 99.9392 - val_false_loss: 11.2045 - val_true_loss: 1.1248\n",
      "Epoch 326/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.7631 - reconstruction_loss: 1889.0414 - kl_loss: 102.4811 - false_loss: 0.0802 - true_loss: 1.0616 - val_loss: 5469.3452 - val_reconstruction_loss: 1895.8656 - val_kl_loss: 99.9395 - val_false_loss: 11.2036 - val_true_loss: 1.1248\n",
      "Epoch 327/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.6238 - reconstruction_loss: 1889.1910 - kl_loss: 101.2582 - false_loss: 0.0802 - true_loss: 1.0616 - val_loss: 5469.0703 - val_reconstruction_loss: 1895.8655 - val_kl_loss: 99.9396 - val_false_loss: 11.2026 - val_true_loss: 1.1248\n",
      "Epoch 328/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.6079 - reconstruction_loss: 1889.7584 - kl_loss: 101.3965 - false_loss: 0.0802 - true_loss: 1.0615 - val_loss: 5468.7896 - val_reconstruction_loss: 1895.8650 - val_kl_loss: 99.9399 - val_false_loss: 11.2017 - val_true_loss: 1.1247\n",
      "Epoch 329/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.5312 - reconstruction_loss: 1889.3119 - kl_loss: 99.6696 - false_loss: 0.0802 - true_loss: 1.0615 - val_loss: 5468.5112 - val_reconstruction_loss: 1895.8645 - val_kl_loss: 99.9399 - val_false_loss: 11.2008 - val_true_loss: 1.1247\n",
      "Epoch 330/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.8060 - reconstruction_loss: 1889.3290 - kl_loss: 99.7147 - false_loss: 0.0802 - true_loss: 1.0615 - val_loss: 5468.2373 - val_reconstruction_loss: 1895.8640 - val_kl_loss: 99.9399 - val_false_loss: 11.1999 - val_true_loss: 1.1247\n",
      "Epoch 331/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.1656 - reconstruction_loss: 1889.3966 - kl_loss: 102.0103 - false_loss: 0.0802 - true_loss: 1.0614 - val_loss: 5467.9678 - val_reconstruction_loss: 1895.8639 - val_kl_loss: 99.9402 - val_false_loss: 11.1990 - val_true_loss: 1.1246\n",
      "Epoch 332/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.2724 - reconstruction_loss: 1889.5172 - kl_loss: 102.7983 - false_loss: 0.0801 - true_loss: 1.0614 - val_loss: 5467.6860 - val_reconstruction_loss: 1895.8636 - val_kl_loss: 99.9407 - val_false_loss: 11.1981 - val_true_loss: 1.1246\n",
      "Epoch 333/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.4384 - reconstruction_loss: 1889.2653 - kl_loss: 102.6873 - false_loss: 0.0801 - true_loss: 1.0613 - val_loss: 5467.4058 - val_reconstruction_loss: 1895.8633 - val_kl_loss: 99.9413 - val_false_loss: 11.1972 - val_true_loss: 1.1245\n",
      "Epoch 334/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.5645 - reconstruction_loss: 1889.4215 - kl_loss: 103.2162 - false_loss: 0.0801 - true_loss: 1.0613 - val_loss: 5467.1260 - val_reconstruction_loss: 1895.8628 - val_kl_loss: 99.9418 - val_false_loss: 11.1963 - val_true_loss: 1.1245\n",
      "Epoch 335/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.0570 - reconstruction_loss: 1889.4686 - kl_loss: 102.7056 - false_loss: 0.0801 - true_loss: 1.0612 - val_loss: 5466.8384 - val_reconstruction_loss: 1895.8624 - val_kl_loss: 99.9421 - val_false_loss: 11.1953 - val_true_loss: 1.1244\n",
      "Epoch 336/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.8050 - reconstruction_loss: 1889.5814 - kl_loss: 102.1168 - false_loss: 0.0801 - true_loss: 1.0612 - val_loss: 5466.5703 - val_reconstruction_loss: 1895.8623 - val_kl_loss: 99.9428 - val_false_loss: 11.1944 - val_true_loss: 1.1244\n",
      "Epoch 337/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.0111 - reconstruction_loss: 1890.1742 - kl_loss: 101.1994 - false_loss: 0.0801 - true_loss: 1.0612 - val_loss: 5466.2871 - val_reconstruction_loss: 1895.8621 - val_kl_loss: 99.9436 - val_false_loss: 11.1935 - val_true_loss: 1.1244\n",
      "Epoch 338/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.6638 - reconstruction_loss: 1889.5006 - kl_loss: 104.1099 - false_loss: 0.0801 - true_loss: 1.0611 - val_loss: 5466.0000 - val_reconstruction_loss: 1895.8617 - val_kl_loss: 99.9445 - val_false_loss: 11.1926 - val_true_loss: 1.1243\n",
      "Epoch 339/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.6634 - reconstruction_loss: 1889.4139 - kl_loss: 103.8067 - false_loss: 0.0801 - true_loss: 1.0611 - val_loss: 5465.7168 - val_reconstruction_loss: 1895.8613 - val_kl_loss: 99.9454 - val_false_loss: 11.1916 - val_true_loss: 1.1243\n",
      "Epoch 340/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.5761 - reconstruction_loss: 1889.1556 - kl_loss: 104.7756 - false_loss: 0.0801 - true_loss: 1.0610 - val_loss: 5465.4336 - val_reconstruction_loss: 1895.8610 - val_kl_loss: 99.9461 - val_false_loss: 11.1907 - val_true_loss: 1.1242\n",
      "Epoch 341/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.2726 - reconstruction_loss: 1889.4562 - kl_loss: 104.8146 - false_loss: 0.0801 - true_loss: 1.0610 - val_loss: 5465.1484 - val_reconstruction_loss: 1895.8607 - val_kl_loss: 99.9467 - val_false_loss: 11.1898 - val_true_loss: 1.1242\n",
      "Epoch 342/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2191.5809 - reconstruction_loss: 1889.0560 - kl_loss: 104.4967 - false_loss: 0.0801 - true_loss: 1.0609 - val_loss: 5464.8677 - val_reconstruction_loss: 1895.8604 - val_kl_loss: 99.9478 - val_false_loss: 11.1888 - val_true_loss: 1.1241\n",
      "Epoch 343/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2195.0578 - reconstruction_loss: 1889.6396 - kl_loss: 104.3225 - false_loss: 0.0801 - true_loss: 1.0609 - val_loss: 5464.5854 - val_reconstruction_loss: 1895.8600 - val_kl_loss: 99.9485 - val_false_loss: 11.1879 - val_true_loss: 1.1241\n",
      "Epoch 344/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.7872 - reconstruction_loss: 1889.0508 - kl_loss: 104.2300 - false_loss: 0.0801 - true_loss: 1.0608 - val_loss: 5464.3052 - val_reconstruction_loss: 1895.8595 - val_kl_loss: 99.9488 - val_false_loss: 11.1870 - val_true_loss: 1.1241\n",
      "Epoch 345/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.0036 - reconstruction_loss: 1889.0763 - kl_loss: 104.1152 - false_loss: 0.0801 - true_loss: 1.0608 - val_loss: 5464.0200 - val_reconstruction_loss: 1895.8593 - val_kl_loss: 99.9497 - val_false_loss: 11.1860 - val_true_loss: 1.1240\n",
      "Epoch 346/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2197.0047 - reconstruction_loss: 1889.1969 - kl_loss: 103.2658 - false_loss: 0.0801 - true_loss: 1.0607 - val_loss: 5463.7349 - val_reconstruction_loss: 1895.8589 - val_kl_loss: 99.9503 - val_false_loss: 11.1851 - val_true_loss: 1.1240\n",
      "Epoch 347/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.2485 - reconstruction_loss: 1889.3370 - kl_loss: 105.4984 - false_loss: 0.0800 - true_loss: 1.0607 - val_loss: 5463.4448 - val_reconstruction_loss: 1895.8585 - val_kl_loss: 99.9512 - val_false_loss: 11.1842 - val_true_loss: 1.1239\n",
      "Epoch 348/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.0524 - reconstruction_loss: 1889.0479 - kl_loss: 105.3677 - false_loss: 0.0800 - true_loss: 1.0606 - val_loss: 5463.1631 - val_reconstruction_loss: 1895.8580 - val_kl_loss: 99.9520 - val_false_loss: 11.1832 - val_true_loss: 1.1239\n",
      "Epoch 349/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.6225 - reconstruction_loss: 1889.5912 - kl_loss: 104.7578 - false_loss: 0.0800 - true_loss: 1.0606 - val_loss: 5462.8818 - val_reconstruction_loss: 1895.8578 - val_kl_loss: 99.9530 - val_false_loss: 11.1823 - val_true_loss: 1.1238\n",
      "Epoch 350/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.4693 - reconstruction_loss: 1889.3521 - kl_loss: 104.4581 - false_loss: 0.0800 - true_loss: 1.0605 - val_loss: 5462.5962 - val_reconstruction_loss: 1895.8575 - val_kl_loss: 99.9537 - val_false_loss: 11.1814 - val_true_loss: 1.1238\n",
      "Epoch 351/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7206 - reconstruction_loss: 1889.4659 - kl_loss: 104.0212 - false_loss: 0.0800 - true_loss: 1.0605 - val_loss: 5462.3154 - val_reconstruction_loss: 1895.8571 - val_kl_loss: 99.9537 - val_false_loss: 11.1804 - val_true_loss: 1.1238\n",
      "Epoch 352/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.9352 - reconstruction_loss: 1889.5992 - kl_loss: 98.7253 - false_loss: 0.0800 - true_loss: 1.0605 - val_loss: 5462.0322 - val_reconstruction_loss: 1895.8566 - val_kl_loss: 99.9547 - val_false_loss: 11.1795 - val_true_loss: 1.1237\n",
      "Epoch 353/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.9472 - reconstruction_loss: 1889.9591 - kl_loss: 99.2387 - false_loss: 0.0800 - true_loss: 1.0604 - val_loss: 5461.7500 - val_reconstruction_loss: 1895.8564 - val_kl_loss: 99.9550 - val_false_loss: 11.1786 - val_true_loss: 1.1237\n",
      "Epoch 354/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.7029 - reconstruction_loss: 1889.8549 - kl_loss: 98.5873 - false_loss: 0.0800 - true_loss: 1.0604 - val_loss: 5461.4653 - val_reconstruction_loss: 1895.8562 - val_kl_loss: 99.9550 - val_false_loss: 11.1776 - val_true_loss: 1.1237\n",
      "Epoch 355/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.6310 - reconstruction_loss: 1889.2406 - kl_loss: 101.4668 - false_loss: 0.0800 - true_loss: 1.0604 - val_loss: 5461.1855 - val_reconstruction_loss: 1895.8558 - val_kl_loss: 99.9554 - val_false_loss: 11.1767 - val_true_loss: 1.1236\n",
      "Epoch 356/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.0963 - reconstruction_loss: 1888.8730 - kl_loss: 101.8894 - false_loss: 0.0800 - true_loss: 1.0603 - val_loss: 5460.9048 - val_reconstruction_loss: 1895.8553 - val_kl_loss: 99.9558 - val_false_loss: 11.1758 - val_true_loss: 1.1236\n",
      "Epoch 357/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.9682 - reconstruction_loss: 1889.0922 - kl_loss: 98.8008 - false_loss: 0.0800 - true_loss: 1.0603 - val_loss: 5460.6270 - val_reconstruction_loss: 1895.8550 - val_kl_loss: 99.9562 - val_false_loss: 11.1749 - val_true_loss: 1.1236\n",
      "Epoch 358/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.4312 - reconstruction_loss: 1889.0996 - kl_loss: 98.4259 - false_loss: 0.0800 - true_loss: 1.0603 - val_loss: 5460.3457 - val_reconstruction_loss: 1895.8547 - val_kl_loss: 99.9568 - val_false_loss: 11.1739 - val_true_loss: 1.1235\n",
      "Epoch 359/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.9697 - reconstruction_loss: 1889.3431 - kl_loss: 98.5904 - false_loss: 0.0800 - true_loss: 1.0602 - val_loss: 5460.0601 - val_reconstruction_loss: 1895.8542 - val_kl_loss: 99.9572 - val_false_loss: 11.1730 - val_true_loss: 1.1235\n",
      "Epoch 360/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.5627 - reconstruction_loss: 1889.2881 - kl_loss: 100.8107 - false_loss: 0.0800 - true_loss: 1.0602 - val_loss: 5459.7744 - val_reconstruction_loss: 1895.8539 - val_kl_loss: 99.9581 - val_false_loss: 11.1721 - val_true_loss: 1.1235\n",
      "Epoch 361/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.3139 - reconstruction_loss: 1889.5621 - kl_loss: 103.2788 - false_loss: 0.0800 - true_loss: 1.0601 - val_loss: 5459.4912 - val_reconstruction_loss: 1895.8534 - val_kl_loss: 99.9583 - val_false_loss: 11.1711 - val_true_loss: 1.1234\n",
      "Epoch 362/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1255 - reconstruction_loss: 1889.0654 - kl_loss: 100.5925 - false_loss: 0.0799 - true_loss: 1.0601 - val_loss: 5459.2114 - val_reconstruction_loss: 1895.8531 - val_kl_loss: 99.9586 - val_false_loss: 11.1702 - val_true_loss: 1.1234\n",
      "Epoch 363/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.4550 - reconstruction_loss: 1889.1798 - kl_loss: 101.3106 - false_loss: 0.0799 - true_loss: 1.0601 - val_loss: 5458.9312 - val_reconstruction_loss: 1895.8528 - val_kl_loss: 99.9587 - val_false_loss: 11.1693 - val_true_loss: 1.1234\n",
      "Epoch 364/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.5960 - reconstruction_loss: 1889.4452 - kl_loss: 100.8893 - false_loss: 0.0799 - true_loss: 1.0600 - val_loss: 5458.6543 - val_reconstruction_loss: 1895.8524 - val_kl_loss: 99.9592 - val_false_loss: 11.1684 - val_true_loss: 1.1233\n",
      "Epoch 365/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2214.7958 - reconstruction_loss: 1889.2631 - kl_loss: 101.3952 - false_loss: 0.0799 - true_loss: 1.0600 - val_loss: 5458.3730 - val_reconstruction_loss: 1895.8519 - val_kl_loss: 99.9594 - val_false_loss: 11.1674 - val_true_loss: 1.1233\n",
      "Epoch 366/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.2961 - reconstruction_loss: 1889.1796 - kl_loss: 101.0693 - false_loss: 0.0799 - true_loss: 1.0600 - val_loss: 5458.0938 - val_reconstruction_loss: 1895.8517 - val_kl_loss: 99.9597 - val_false_loss: 11.1665 - val_true_loss: 1.1233\n",
      "Epoch 367/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.9018 - reconstruction_loss: 1888.9961 - kl_loss: 99.7366 - false_loss: 0.0799 - true_loss: 1.0599 - val_loss: 5457.8110 - val_reconstruction_loss: 1895.8513 - val_kl_loss: 99.9601 - val_false_loss: 11.1656 - val_true_loss: 1.1232\n",
      "Epoch 368/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.8734 - reconstruction_loss: 1889.2404 - kl_loss: 99.7987 - false_loss: 0.0799 - true_loss: 1.0599 - val_loss: 5457.5278 - val_reconstruction_loss: 1895.8510 - val_kl_loss: 99.9604 - val_false_loss: 11.1647 - val_true_loss: 1.1232\n",
      "Epoch 369/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.0152 - reconstruction_loss: 1889.5508 - kl_loss: 98.2325 - false_loss: 0.0799 - true_loss: 1.0598 - val_loss: 5457.2544 - val_reconstruction_loss: 1895.8507 - val_kl_loss: 99.9605 - val_false_loss: 11.1638 - val_true_loss: 1.1232\n",
      "Epoch 370/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2254.2519 - reconstruction_loss: 1891.2748 - kl_loss: 91.5042 - false_loss: 0.0799 - true_loss: 1.0598 - val_loss: 5456.9814 - val_reconstruction_loss: 1895.8507 - val_kl_loss: 99.9592 - val_false_loss: 11.1629 - val_true_loss: 1.1232\n",
      "Epoch 371/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2266.0947 - reconstruction_loss: 1894.9395 - kl_loss: 91.6319 - false_loss: 0.0799 - true_loss: 1.0598 - val_loss: 5456.6953 - val_reconstruction_loss: 1895.8503 - val_kl_loss: 99.9585 - val_false_loss: 11.1619 - val_true_loss: 1.1231\n",
      "Epoch 372/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.7472 - reconstruction_loss: 1892.3541 - kl_loss: 94.3697 - false_loss: 0.0799 - true_loss: 1.0598 - val_loss: 5456.4131 - val_reconstruction_loss: 1895.8500 - val_kl_loss: 99.9581 - val_false_loss: 11.1610 - val_true_loss: 1.1231\n",
      "Epoch 373/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.2957 - reconstruction_loss: 1890.6522 - kl_loss: 98.6748 - false_loss: 0.0799 - true_loss: 1.0597 - val_loss: 5456.1289 - val_reconstruction_loss: 1895.8495 - val_kl_loss: 99.9580 - val_false_loss: 11.1601 - val_true_loss: 1.1231\n",
      "Epoch 374/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.8995 - reconstruction_loss: 1889.8329 - kl_loss: 99.2380 - false_loss: 0.0799 - true_loss: 1.0597 - val_loss: 5455.8472 - val_reconstruction_loss: 1895.8492 - val_kl_loss: 99.9585 - val_false_loss: 11.1591 - val_true_loss: 1.1230\n",
      "Epoch 375/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.1258 - reconstruction_loss: 1889.4921 - kl_loss: 99.5330 - false_loss: 0.0799 - true_loss: 1.0597 - val_loss: 5455.5757 - val_reconstruction_loss: 1895.8489 - val_kl_loss: 99.9590 - val_false_loss: 11.1582 - val_true_loss: 1.1230\n",
      "Epoch 376/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.5244 - reconstruction_loss: 1889.3071 - kl_loss: 101.1157 - false_loss: 0.0799 - true_loss: 1.0596 - val_loss: 5455.2993 - val_reconstruction_loss: 1895.8484 - val_kl_loss: 99.9596 - val_false_loss: 11.1573 - val_true_loss: 1.1229\n",
      "Epoch 377/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.2911 - reconstruction_loss: 1889.2617 - kl_loss: 101.3138 - false_loss: 0.0799 - true_loss: 1.0596 - val_loss: 5455.0244 - val_reconstruction_loss: 1895.8480 - val_kl_loss: 99.9599 - val_false_loss: 11.1564 - val_true_loss: 1.1229\n",
      "Epoch 378/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.5880 - reconstruction_loss: 1889.1053 - kl_loss: 100.1656 - false_loss: 0.0799 - true_loss: 1.0596 - val_loss: 5454.7432 - val_reconstruction_loss: 1895.8477 - val_kl_loss: 99.9602 - val_false_loss: 11.1555 - val_true_loss: 1.1229\n",
      "Epoch 379/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.2324 - reconstruction_loss: 1889.0869 - kl_loss: 101.1732 - false_loss: 0.0798 - true_loss: 1.0595 - val_loss: 5454.4604 - val_reconstruction_loss: 1895.8472 - val_kl_loss: 99.9604 - val_false_loss: 11.1546 - val_true_loss: 1.1228\n",
      "Epoch 380/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.8994 - reconstruction_loss: 1889.0326 - kl_loss: 101.3411 - false_loss: 0.0798 - true_loss: 1.0595 - val_loss: 5454.1787 - val_reconstruction_loss: 1895.8468 - val_kl_loss: 99.9607 - val_false_loss: 11.1537 - val_true_loss: 1.1228\n",
      "Epoch 381/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.8889 - reconstruction_loss: 1889.1670 - kl_loss: 102.6130 - false_loss: 0.0798 - true_loss: 1.0594 - val_loss: 5453.9009 - val_reconstruction_loss: 1895.8463 - val_kl_loss: 99.9612 - val_false_loss: 11.1527 - val_true_loss: 1.1228\n",
      "Epoch 382/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.8197 - reconstruction_loss: 1888.9238 - kl_loss: 101.9633 - false_loss: 0.0798 - true_loss: 1.0594 - val_loss: 5453.6182 - val_reconstruction_loss: 1895.8461 - val_kl_loss: 99.9619 - val_false_loss: 11.1518 - val_true_loss: 1.1227\n",
      "Epoch 383/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.3624 - reconstruction_loss: 1889.4102 - kl_loss: 101.0430 - false_loss: 0.0798 - true_loss: 1.0594 - val_loss: 5453.3335 - val_reconstruction_loss: 1895.8458 - val_kl_loss: 99.9625 - val_false_loss: 11.1509 - val_true_loss: 1.1227\n",
      "Epoch 384/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.7653 - reconstruction_loss: 1889.4185 - kl_loss: 100.2350 - false_loss: 0.0798 - true_loss: 1.0593 - val_loss: 5453.0493 - val_reconstruction_loss: 1895.8453 - val_kl_loss: 99.9626 - val_false_loss: 11.1499 - val_true_loss: 1.1226\n",
      "Epoch 385/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.8832 - reconstruction_loss: 1889.1133 - kl_loss: 101.5257 - false_loss: 0.0798 - true_loss: 1.0593 - val_loss: 5452.7607 - val_reconstruction_loss: 1895.8448 - val_kl_loss: 99.9629 - val_false_loss: 11.1490 - val_true_loss: 1.1226\n",
      "Epoch 386/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.1460 - reconstruction_loss: 1888.8507 - kl_loss: 102.6847 - false_loss: 0.0798 - true_loss: 1.0592 - val_loss: 5452.4824 - val_reconstruction_loss: 1895.8445 - val_kl_loss: 99.9634 - val_false_loss: 11.1481 - val_true_loss: 1.1226\n",
      "Epoch 387/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.2414 - reconstruction_loss: 1889.2054 - kl_loss: 102.3074 - false_loss: 0.0798 - true_loss: 1.0592 - val_loss: 5452.2070 - val_reconstruction_loss: 1895.8441 - val_kl_loss: 99.9640 - val_false_loss: 11.1472 - val_true_loss: 1.1225\n",
      "Epoch 388/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.6095 - reconstruction_loss: 1889.4052 - kl_loss: 102.4795 - false_loss: 0.0798 - true_loss: 1.0591 - val_loss: 5451.9272 - val_reconstruction_loss: 1895.8439 - val_kl_loss: 99.9647 - val_false_loss: 11.1463 - val_true_loss: 1.1225\n",
      "Epoch 389/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.0284 - reconstruction_loss: 1889.0587 - kl_loss: 102.5716 - false_loss: 0.0798 - true_loss: 1.0591 - val_loss: 5451.6494 - val_reconstruction_loss: 1895.8434 - val_kl_loss: 99.9653 - val_false_loss: 11.1453 - val_true_loss: 1.1224\n",
      "Epoch 390/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.9900 - reconstruction_loss: 1889.3563 - kl_loss: 101.8341 - false_loss: 0.0798 - true_loss: 1.0591 - val_loss: 5451.3755 - val_reconstruction_loss: 1895.8430 - val_kl_loss: 99.9659 - val_false_loss: 11.1444 - val_true_loss: 1.1224\n",
      "Epoch 391/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.7666 - reconstruction_loss: 1889.4561 - kl_loss: 102.1924 - false_loss: 0.0798 - true_loss: 1.0590 - val_loss: 5451.0952 - val_reconstruction_loss: 1895.8428 - val_kl_loss: 99.9665 - val_false_loss: 11.1435 - val_true_loss: 1.1224\n",
      "Epoch 392/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.3043 - reconstruction_loss: 1889.8778 - kl_loss: 100.2651 - false_loss: 0.0798 - true_loss: 1.0590 - val_loss: 5450.8115 - val_reconstruction_loss: 1895.8424 - val_kl_loss: 99.9670 - val_false_loss: 11.1426 - val_true_loss: 1.1223\n",
      "Epoch 393/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.8903 - reconstruction_loss: 1889.5355 - kl_loss: 101.0014 - false_loss: 0.0798 - true_loss: 1.0589 - val_loss: 5450.5352 - val_reconstruction_loss: 1895.8422 - val_kl_loss: 99.9677 - val_false_loss: 11.1417 - val_true_loss: 1.1223\n",
      "Epoch 394/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.9333 - reconstruction_loss: 1889.1392 - kl_loss: 102.7363 - false_loss: 0.0797 - true_loss: 1.0589 - val_loss: 5450.2563 - val_reconstruction_loss: 1895.8418 - val_kl_loss: 99.9680 - val_false_loss: 11.1408 - val_true_loss: 1.1222\n",
      "Epoch 395/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.2464 - reconstruction_loss: 1889.1234 - kl_loss: 101.6570 - false_loss: 0.0797 - true_loss: 1.0589 - val_loss: 5449.9800 - val_reconstruction_loss: 1895.8414 - val_kl_loss: 99.9684 - val_false_loss: 11.1398 - val_true_loss: 1.1222\n",
      "Epoch 396/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.2041 - reconstruction_loss: 1889.0043 - kl_loss: 102.8113 - false_loss: 0.0797 - true_loss: 1.0588 - val_loss: 5449.6997 - val_reconstruction_loss: 1895.8411 - val_kl_loss: 99.9691 - val_false_loss: 11.1389 - val_true_loss: 1.1222\n",
      "Epoch 397/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.4212 - reconstruction_loss: 1889.5802 - kl_loss: 101.0167 - false_loss: 0.0797 - true_loss: 1.0588 - val_loss: 5449.4155 - val_reconstruction_loss: 1895.8407 - val_kl_loss: 99.9696 - val_false_loss: 11.1380 - val_true_loss: 1.1221\n",
      "Epoch 398/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.4115 - reconstruction_loss: 1889.3993 - kl_loss: 101.0225 - false_loss: 0.0797 - true_loss: 1.0587 - val_loss: 5449.1348 - val_reconstruction_loss: 1895.8402 - val_kl_loss: 99.9702 - val_false_loss: 11.1371 - val_true_loss: 1.1221\n",
      "Epoch 399/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.5890 - reconstruction_loss: 1889.6696 - kl_loss: 99.7227 - false_loss: 0.0797 - true_loss: 1.0587 - val_loss: 5448.8530 - val_reconstruction_loss: 1895.8400 - val_kl_loss: 99.9706 - val_false_loss: 11.1361 - val_true_loss: 1.1221\n",
      "Epoch 400/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4849 - reconstruction_loss: 1889.9652 - kl_loss: 100.8667 - false_loss: 0.0797 - true_loss: 1.0587 - val_loss: 5448.5781 - val_reconstruction_loss: 1895.8395 - val_kl_loss: 99.9708 - val_false_loss: 11.1352 - val_true_loss: 1.1220\n",
      "Epoch 401/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.7754 - reconstruction_loss: 1889.5957 - kl_loss: 100.6064 - false_loss: 0.0797 - true_loss: 1.0586 - val_loss: 5448.2998 - val_reconstruction_loss: 1895.8391 - val_kl_loss: 99.9712 - val_false_loss: 11.1343 - val_true_loss: 1.1220\n",
      "Epoch 402/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2192.7780 - reconstruction_loss: 1889.2671 - kl_loss: 102.7264 - false_loss: 0.0797 - true_loss: 1.0586 - val_loss: 5448.0210 - val_reconstruction_loss: 1895.8389 - val_kl_loss: 99.9718 - val_false_loss: 11.1334 - val_true_loss: 1.1219\n",
      "Epoch 403/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.4271 - reconstruction_loss: 1889.2081 - kl_loss: 102.9535 - false_loss: 0.0797 - true_loss: 1.0585 - val_loss: 5447.7451 - val_reconstruction_loss: 1895.8384 - val_kl_loss: 99.9725 - val_false_loss: 11.1325 - val_true_loss: 1.1219\n",
      "Epoch 404/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.6562 - reconstruction_loss: 1888.9701 - kl_loss: 103.2430 - false_loss: 0.0797 - true_loss: 1.0585 - val_loss: 5447.4658 - val_reconstruction_loss: 1895.8380 - val_kl_loss: 99.9732 - val_false_loss: 11.1316 - val_true_loss: 1.1219\n",
      "Epoch 405/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.4358 - reconstruction_loss: 1889.1420 - kl_loss: 103.7336 - false_loss: 0.0797 - true_loss: 1.0584 - val_loss: 5447.1880 - val_reconstruction_loss: 1895.8378 - val_kl_loss: 99.9734 - val_false_loss: 11.1307 - val_true_loss: 1.1218\n",
      "Epoch 406/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.7610 - reconstruction_loss: 1889.4574 - kl_loss: 101.9447 - false_loss: 0.0797 - true_loss: 1.0584 - val_loss: 5446.9102 - val_reconstruction_loss: 1895.8373 - val_kl_loss: 99.9737 - val_false_loss: 11.1297 - val_true_loss: 1.1218\n",
      "Epoch 407/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.2809 - reconstruction_loss: 1889.1660 - kl_loss: 101.5018 - false_loss: 0.0797 - true_loss: 1.0584 - val_loss: 5446.6309 - val_reconstruction_loss: 1895.8370 - val_kl_loss: 99.9742 - val_false_loss: 11.1288 - val_true_loss: 1.1217\n",
      "Epoch 408/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.3142 - reconstruction_loss: 1889.3400 - kl_loss: 99.8515 - false_loss: 0.0797 - true_loss: 1.0583 - val_loss: 5446.3506 - val_reconstruction_loss: 1895.8368 - val_kl_loss: 99.9744 - val_false_loss: 11.1279 - val_true_loss: 1.1217\n",
      "Epoch 409/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.6677 - reconstruction_loss: 1889.3311 - kl_loss: 101.4319 - false_loss: 0.0797 - true_loss: 1.0583 - val_loss: 5446.0742 - val_reconstruction_loss: 1895.8364 - val_kl_loss: 99.9748 - val_false_loss: 11.1270 - val_true_loss: 1.1217\n",
      "Epoch 410/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.2546 - reconstruction_loss: 1889.5903 - kl_loss: 100.8438 - false_loss: 0.0796 - true_loss: 1.0583 - val_loss: 5445.7900 - val_reconstruction_loss: 1895.8359 - val_kl_loss: 99.9751 - val_false_loss: 11.1261 - val_true_loss: 1.1216\n",
      "Epoch 411/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.4191 - reconstruction_loss: 1889.4180 - kl_loss: 98.2149 - false_loss: 0.0796 - true_loss: 1.0582 - val_loss: 5445.5107 - val_reconstruction_loss: 1895.8356 - val_kl_loss: 99.9756 - val_false_loss: 11.1251 - val_true_loss: 1.1216\n",
      "Epoch 412/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.4463 - reconstruction_loss: 1889.6989 - kl_loss: 100.1503 - false_loss: 0.0796 - true_loss: 1.0582 - val_loss: 5445.2358 - val_reconstruction_loss: 1895.8352 - val_kl_loss: 99.9757 - val_false_loss: 11.1242 - val_true_loss: 1.1216\n",
      "Epoch 413/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.4841 - reconstruction_loss: 1889.1606 - kl_loss: 100.2923 - false_loss: 0.0796 - true_loss: 1.0581 - val_loss: 5444.9595 - val_reconstruction_loss: 1895.8348 - val_kl_loss: 99.9757 - val_false_loss: 11.1233 - val_true_loss: 1.1215\n",
      "Epoch 414/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.3375 - reconstruction_loss: 1889.1299 - kl_loss: 98.4525 - false_loss: 0.0796 - true_loss: 1.0581 - val_loss: 5444.6870 - val_reconstruction_loss: 1895.8344 - val_kl_loss: 99.9759 - val_false_loss: 11.1224 - val_true_loss: 1.1215\n",
      "Epoch 415/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3262 - reconstruction_loss: 1889.1324 - kl_loss: 101.1679 - false_loss: 0.0796 - true_loss: 1.0581 - val_loss: 5444.4062 - val_reconstruction_loss: 1895.8341 - val_kl_loss: 99.9765 - val_false_loss: 11.1215 - val_true_loss: 1.1215\n",
      "Epoch 416/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.1901 - reconstruction_loss: 1889.1268 - kl_loss: 100.2728 - false_loss: 0.0796 - true_loss: 1.0580 - val_loss: 5444.1294 - val_reconstruction_loss: 1895.8336 - val_kl_loss: 99.9766 - val_false_loss: 11.1206 - val_true_loss: 1.1214\n",
      "Epoch 417/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2215.8486 - reconstruction_loss: 1889.3048 - kl_loss: 100.7768 - false_loss: 0.0796 - true_loss: 1.0580 - val_loss: 5443.8584 - val_reconstruction_loss: 1895.8333 - val_kl_loss: 99.9769 - val_false_loss: 11.1197 - val_true_loss: 1.1214\n",
      "Epoch 418/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.2318 - reconstruction_loss: 1889.1499 - kl_loss: 100.8604 - false_loss: 0.0796 - true_loss: 1.0580 - val_loss: 5443.5840 - val_reconstruction_loss: 1895.8330 - val_kl_loss: 99.9768 - val_false_loss: 11.1188 - val_true_loss: 1.1214\n",
      "Epoch 419/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.3760 - reconstruction_loss: 1888.9399 - kl_loss: 100.3114 - false_loss: 0.0796 - true_loss: 1.0579 - val_loss: 5443.3159 - val_reconstruction_loss: 1895.8326 - val_kl_loss: 99.9772 - val_false_loss: 11.1179 - val_true_loss: 1.1213\n",
      "Epoch 420/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.0646 - reconstruction_loss: 1889.1683 - kl_loss: 102.4419 - false_loss: 0.0796 - true_loss: 1.0579 - val_loss: 5443.0352 - val_reconstruction_loss: 1895.8322 - val_kl_loss: 99.9776 - val_false_loss: 11.1170 - val_true_loss: 1.1213\n",
      "Epoch 421/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.2278 - reconstruction_loss: 1889.4507 - kl_loss: 103.4911 - false_loss: 0.0796 - true_loss: 1.0578 - val_loss: 5442.7593 - val_reconstruction_loss: 1895.8319 - val_kl_loss: 99.9782 - val_false_loss: 11.1161 - val_true_loss: 1.1212\n",
      "Epoch 422/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2190.9768 - reconstruction_loss: 1889.7120 - kl_loss: 103.4552 - false_loss: 0.0796 - true_loss: 1.0578 - val_loss: 5442.4810 - val_reconstruction_loss: 1895.8317 - val_kl_loss: 99.9790 - val_false_loss: 11.1152 - val_true_loss: 1.1212\n",
      "Epoch 423/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2189.3447 - reconstruction_loss: 1889.2933 - kl_loss: 104.8626 - false_loss: 0.0796 - true_loss: 1.0577 - val_loss: 5442.2041 - val_reconstruction_loss: 1895.8314 - val_kl_loss: 99.9799 - val_false_loss: 11.1143 - val_true_loss: 1.1211\n",
      "Epoch 424/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2190.7877 - reconstruction_loss: 1889.0859 - kl_loss: 104.1567 - false_loss: 0.0796 - true_loss: 1.0577 - val_loss: 5441.9424 - val_reconstruction_loss: 1895.8309 - val_kl_loss: 99.9805 - val_false_loss: 11.1134 - val_true_loss: 1.1211\n",
      "Epoch 425/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.4821 - reconstruction_loss: 1889.1141 - kl_loss: 104.2359 - false_loss: 0.0795 - true_loss: 1.0576 - val_loss: 5441.6675 - val_reconstruction_loss: 1895.8304 - val_kl_loss: 99.9811 - val_false_loss: 11.1125 - val_true_loss: 1.1211\n",
      "Epoch 426/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.0938 - reconstruction_loss: 1889.3033 - kl_loss: 103.1069 - false_loss: 0.0795 - true_loss: 1.0576 - val_loss: 5441.3955 - val_reconstruction_loss: 1895.8302 - val_kl_loss: 99.9813 - val_false_loss: 11.1116 - val_true_loss: 1.1210\n",
      "Epoch 427/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.0756 - reconstruction_loss: 1889.4053 - kl_loss: 103.1611 - false_loss: 0.0795 - true_loss: 1.0575 - val_loss: 5441.1167 - val_reconstruction_loss: 1895.8298 - val_kl_loss: 99.9821 - val_false_loss: 11.1107 - val_true_loss: 1.1210\n",
      "Epoch 428/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.8647 - reconstruction_loss: 1889.2358 - kl_loss: 104.9459 - false_loss: 0.0795 - true_loss: 1.0575 - val_loss: 5440.8359 - val_reconstruction_loss: 1895.8295 - val_kl_loss: 99.9829 - val_false_loss: 11.1098 - val_true_loss: 1.1209\n",
      "Epoch 429/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.4920 - reconstruction_loss: 1889.3384 - kl_loss: 104.6443 - false_loss: 0.0795 - true_loss: 1.0575 - val_loss: 5440.5610 - val_reconstruction_loss: 1895.8293 - val_kl_loss: 99.9834 - val_false_loss: 11.1089 - val_true_loss: 1.1209\n",
      "Epoch 430/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2195.1377 - reconstruction_loss: 1889.3784 - kl_loss: 103.6095 - false_loss: 0.0795 - true_loss: 1.0574 - val_loss: 5440.2817 - val_reconstruction_loss: 1895.8289 - val_kl_loss: 99.9844 - val_false_loss: 11.1080 - val_true_loss: 1.1208\n",
      "Epoch 431/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2192.8026 - reconstruction_loss: 1888.9650 - kl_loss: 105.3704 - false_loss: 0.0795 - true_loss: 1.0574 - val_loss: 5439.9995 - val_reconstruction_loss: 1895.8284 - val_kl_loss: 99.9853 - val_false_loss: 11.1070 - val_true_loss: 1.1208\n",
      "Epoch 432/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.5842 - reconstruction_loss: 1889.3916 - kl_loss: 103.5093 - false_loss: 0.0795 - true_loss: 1.0573 - val_loss: 5439.7178 - val_reconstruction_loss: 1895.8281 - val_kl_loss: 99.9862 - val_false_loss: 11.1061 - val_true_loss: 1.1207\n",
      "Epoch 433/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.9766 - reconstruction_loss: 1889.2279 - kl_loss: 103.7703 - false_loss: 0.0795 - true_loss: 1.0573 - val_loss: 5439.4414 - val_reconstruction_loss: 1895.8278 - val_kl_loss: 99.9870 - val_false_loss: 11.1052 - val_true_loss: 1.1207\n",
      "Epoch 434/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.3479 - reconstruction_loss: 1889.4375 - kl_loss: 105.6207 - false_loss: 0.0795 - true_loss: 1.0572 - val_loss: 5439.1646 - val_reconstruction_loss: 1895.8274 - val_kl_loss: 99.9879 - val_false_loss: 11.1043 - val_true_loss: 1.1207\n",
      "Epoch 435/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2191.4136 - reconstruction_loss: 1888.9410 - kl_loss: 105.7228 - false_loss: 0.0795 - true_loss: 1.0572 - val_loss: 5438.8843 - val_reconstruction_loss: 1895.8270 - val_kl_loss: 99.9888 - val_false_loss: 11.1034 - val_true_loss: 1.1206\n",
      "Epoch 436/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.6969 - reconstruction_loss: 1889.4000 - kl_loss: 104.6352 - false_loss: 0.0795 - true_loss: 1.0571 - val_loss: 5438.6011 - val_reconstruction_loss: 1895.8267 - val_kl_loss: 99.9896 - val_false_loss: 11.1024 - val_true_loss: 1.1206\n",
      "Epoch 437/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2190.5643 - reconstruction_loss: 1889.2426 - kl_loss: 104.3325 - false_loss: 0.0795 - true_loss: 1.0571 - val_loss: 5438.3198 - val_reconstruction_loss: 1895.8263 - val_kl_loss: 99.9905 - val_false_loss: 11.1015 - val_true_loss: 1.1205\n",
      "Epoch 438/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.5402 - reconstruction_loss: 1889.3405 - kl_loss: 105.2104 - false_loss: 0.0795 - true_loss: 1.0570 - val_loss: 5438.0371 - val_reconstruction_loss: 1895.8259 - val_kl_loss: 99.9912 - val_false_loss: 11.1006 - val_true_loss: 1.1205\n",
      "Epoch 439/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.0670 - reconstruction_loss: 1889.1783 - kl_loss: 104.5754 - false_loss: 0.0795 - true_loss: 1.0570 - val_loss: 5437.7661 - val_reconstruction_loss: 1895.8257 - val_kl_loss: 99.9920 - val_false_loss: 11.0997 - val_true_loss: 1.1204\n",
      "Epoch 440/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2190.8998 - reconstruction_loss: 1889.4921 - kl_loss: 105.0805 - false_loss: 0.0794 - true_loss: 1.0569 - val_loss: 5437.4883 - val_reconstruction_loss: 1895.8252 - val_kl_loss: 99.9929 - val_false_loss: 11.0988 - val_true_loss: 1.1204\n",
      "Epoch 441/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2188.4160 - reconstruction_loss: 1889.0352 - kl_loss: 105.6713 - false_loss: 0.0794 - true_loss: 1.0569 - val_loss: 5437.2148 - val_reconstruction_loss: 1895.8248 - val_kl_loss: 99.9938 - val_false_loss: 11.0979 - val_true_loss: 1.1203\n",
      "Epoch 442/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2190.7386 - reconstruction_loss: 1889.7167 - kl_loss: 105.3841 - false_loss: 0.0794 - true_loss: 1.0568 - val_loss: 5436.9404 - val_reconstruction_loss: 1895.8243 - val_kl_loss: 99.9948 - val_false_loss: 11.0970 - val_true_loss: 1.1203\n",
      "Epoch 443/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.6533 - reconstruction_loss: 1889.3070 - kl_loss: 105.1878 - false_loss: 0.0794 - true_loss: 1.0568 - val_loss: 5436.6670 - val_reconstruction_loss: 1895.8242 - val_kl_loss: 99.9956 - val_false_loss: 11.0961 - val_true_loss: 1.1203\n",
      "Epoch 444/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.2080 - reconstruction_loss: 1889.3324 - kl_loss: 105.5000 - false_loss: 0.0794 - true_loss: 1.0568 - val_loss: 5436.3892 - val_reconstruction_loss: 1895.8240 - val_kl_loss: 99.9965 - val_false_loss: 11.0952 - val_true_loss: 1.1202\n",
      "Epoch 445/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.2315 - reconstruction_loss: 1889.1339 - kl_loss: 105.7251 - false_loss: 0.0794 - true_loss: 1.0567 - val_loss: 5436.1128 - val_reconstruction_loss: 1895.8236 - val_kl_loss: 99.9974 - val_false_loss: 11.0943 - val_true_loss: 1.1202\n",
      "Epoch 446/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.2426 - reconstruction_loss: 1888.9209 - kl_loss: 105.3364 - false_loss: 0.0794 - true_loss: 1.0567 - val_loss: 5435.8340 - val_reconstruction_loss: 1895.8232 - val_kl_loss: 99.9983 - val_false_loss: 11.0933 - val_true_loss: 1.1201\n",
      "Epoch 447/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.1066 - reconstruction_loss: 1889.4868 - kl_loss: 104.0954 - false_loss: 0.0794 - true_loss: 1.0566 - val_loss: 5435.5601 - val_reconstruction_loss: 1895.8229 - val_kl_loss: 99.9990 - val_false_loss: 11.0924 - val_true_loss: 1.1201\n",
      "Epoch 448/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.1345 - reconstruction_loss: 1889.8783 - kl_loss: 104.9459 - false_loss: 0.0794 - true_loss: 1.0566 - val_loss: 5435.2827 - val_reconstruction_loss: 1895.8225 - val_kl_loss: 100.0003 - val_false_loss: 11.0915 - val_true_loss: 1.1200\n",
      "Epoch 449/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.1786 - reconstruction_loss: 1889.8134 - kl_loss: 104.6432 - false_loss: 0.0794 - true_loss: 1.0565 - val_loss: 5435.0083 - val_reconstruction_loss: 1895.8221 - val_kl_loss: 100.0013 - val_false_loss: 11.0906 - val_true_loss: 1.1200\n",
      "Epoch 450/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.7488 - reconstruction_loss: 1889.1324 - kl_loss: 105.8458 - false_loss: 0.0794 - true_loss: 1.0565 - val_loss: 5434.7324 - val_reconstruction_loss: 1895.8219 - val_kl_loss: 100.0025 - val_false_loss: 11.0897 - val_true_loss: 1.1199\n",
      "Epoch 451/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2192.6351 - reconstruction_loss: 1889.4092 - kl_loss: 105.2280 - false_loss: 0.0794 - true_loss: 1.0564 - val_loss: 5434.4561 - val_reconstruction_loss: 1895.8214 - val_kl_loss: 100.0028 - val_false_loss: 11.0888 - val_true_loss: 1.1199\n",
      "Epoch 452/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2197.5723 - reconstruction_loss: 1889.3673 - kl_loss: 104.3000 - false_loss: 0.0794 - true_loss: 1.0564 - val_loss: 5434.1821 - val_reconstruction_loss: 1895.8209 - val_kl_loss: 100.0034 - val_false_loss: 11.0879 - val_true_loss: 1.1199\n",
      "Epoch 453/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2195.9063 - reconstruction_loss: 1888.8506 - kl_loss: 105.4915 - false_loss: 0.0794 - true_loss: 1.0563 - val_loss: 5433.9106 - val_reconstruction_loss: 1895.8206 - val_kl_loss: 100.0044 - val_false_loss: 11.0870 - val_true_loss: 1.1198\n",
      "Epoch 454/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.6877 - reconstruction_loss: 1889.3094 - kl_loss: 105.0059 - false_loss: 0.0793 - true_loss: 1.0563 - val_loss: 5433.6333 - val_reconstruction_loss: 1895.8203 - val_kl_loss: 100.0050 - val_false_loss: 11.0861 - val_true_loss: 1.1198\n",
      "Epoch 455/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.5078 - reconstruction_loss: 1889.2992 - kl_loss: 103.1494 - false_loss: 0.0793 - true_loss: 1.0562 - val_loss: 5433.3560 - val_reconstruction_loss: 1895.8198 - val_kl_loss: 100.0051 - val_false_loss: 11.0852 - val_true_loss: 1.1198\n",
      "Epoch 456/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3563 - reconstruction_loss: 1889.3080 - kl_loss: 102.2378 - false_loss: 0.0793 - true_loss: 1.0562 - val_loss: 5433.0825 - val_reconstruction_loss: 1895.8196 - val_kl_loss: 100.0057 - val_false_loss: 11.0843 - val_true_loss: 1.1197\n",
      "Epoch 457/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.9781 - reconstruction_loss: 1888.9142 - kl_loss: 103.3692 - false_loss: 0.0793 - true_loss: 1.0562 - val_loss: 5432.8076 - val_reconstruction_loss: 1895.8192 - val_kl_loss: 100.0066 - val_false_loss: 11.0834 - val_true_loss: 1.1197\n",
      "Epoch 458/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.7567 - reconstruction_loss: 1889.4795 - kl_loss: 103.0173 - false_loss: 0.0793 - true_loss: 1.0561 - val_loss: 5432.5361 - val_reconstruction_loss: 1895.8188 - val_kl_loss: 100.0070 - val_false_loss: 11.0825 - val_true_loss: 1.1196\n",
      "Epoch 459/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.6135 - reconstruction_loss: 1889.5494 - kl_loss: 102.3336 - false_loss: 0.0793 - true_loss: 1.0561 - val_loss: 5432.2651 - val_reconstruction_loss: 1895.8185 - val_kl_loss: 100.0074 - val_false_loss: 11.0816 - val_true_loss: 1.1196\n",
      "Epoch 460/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.4742 - reconstruction_loss: 1889.0607 - kl_loss: 102.0875 - false_loss: 0.0793 - true_loss: 1.0560 - val_loss: 5431.9893 - val_reconstruction_loss: 1895.8181 - val_kl_loss: 100.0079 - val_false_loss: 11.0807 - val_true_loss: 1.1196\n",
      "Epoch 461/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.7573 - reconstruction_loss: 1888.8763 - kl_loss: 101.4312 - false_loss: 0.0793 - true_loss: 1.0560 - val_loss: 5431.7119 - val_reconstruction_loss: 1895.8176 - val_kl_loss: 100.0085 - val_false_loss: 11.0798 - val_true_loss: 1.1195\n",
      "Epoch 462/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.5151 - reconstruction_loss: 1889.1117 - kl_loss: 100.0168 - false_loss: 0.0793 - true_loss: 1.0560 - val_loss: 5431.4370 - val_reconstruction_loss: 1895.8174 - val_kl_loss: 100.0091 - val_false_loss: 11.0789 - val_true_loss: 1.1195\n",
      "Epoch 463/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.9625 - reconstruction_loss: 1890.1582 - kl_loss: 96.4601 - false_loss: 0.0793 - true_loss: 1.0559 - val_loss: 5431.1694 - val_reconstruction_loss: 1895.8170 - val_kl_loss: 100.0096 - val_false_loss: 11.0780 - val_true_loss: 1.1195\n",
      "Epoch 464/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0045 - reconstruction_loss: 1889.9713 - kl_loss: 101.3288 - false_loss: 0.0793 - true_loss: 1.0559 - val_loss: 5430.8994 - val_reconstruction_loss: 1895.8167 - val_kl_loss: 100.0095 - val_false_loss: 11.0771 - val_true_loss: 1.1194\n",
      "Epoch 465/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.0022 - reconstruction_loss: 1889.4414 - kl_loss: 101.5948 - false_loss: 0.0793 - true_loss: 1.0559 - val_loss: 5430.6230 - val_reconstruction_loss: 1895.8163 - val_kl_loss: 100.0098 - val_false_loss: 11.0762 - val_true_loss: 1.1194\n",
      "Epoch 466/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.6858 - reconstruction_loss: 1889.5116 - kl_loss: 103.9502 - false_loss: 0.0793 - true_loss: 1.0558 - val_loss: 5430.3447 - val_reconstruction_loss: 1895.8160 - val_kl_loss: 100.0107 - val_false_loss: 11.0753 - val_true_loss: 1.1193\n",
      "Epoch 467/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.4618 - reconstruction_loss: 1889.0065 - kl_loss: 104.3785 - false_loss: 0.0793 - true_loss: 1.0558 - val_loss: 5430.0693 - val_reconstruction_loss: 1895.8156 - val_kl_loss: 100.0112 - val_false_loss: 11.0744 - val_true_loss: 1.1193\n",
      "Epoch 468/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.1599 - reconstruction_loss: 1889.1854 - kl_loss: 103.3979 - false_loss: 0.0793 - true_loss: 1.0557 - val_loss: 5429.8037 - val_reconstruction_loss: 1895.8153 - val_kl_loss: 100.0119 - val_false_loss: 11.0735 - val_true_loss: 1.1193\n",
      "Epoch 469/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2209.8605 - reconstruction_loss: 1889.2230 - kl_loss: 101.6306 - false_loss: 0.0793 - true_loss: 1.0557 - val_loss: 5429.5322 - val_reconstruction_loss: 1895.8149 - val_kl_loss: 100.0125 - val_false_loss: 11.0726 - val_true_loss: 1.1192\n",
      "Epoch 470/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.1209 - reconstruction_loss: 1889.4258 - kl_loss: 99.0100 - false_loss: 0.0792 - true_loss: 1.0557 - val_loss: 5429.2563 - val_reconstruction_loss: 1895.8147 - val_kl_loss: 100.0130 - val_false_loss: 11.0717 - val_true_loss: 1.1192\n",
      "Epoch 471/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.7533 - reconstruction_loss: 1890.1400 - kl_loss: 98.3162 - false_loss: 0.0792 - true_loss: 1.0556 - val_loss: 5428.9824 - val_reconstruction_loss: 1895.8142 - val_kl_loss: 100.0134 - val_false_loss: 11.0708 - val_true_loss: 1.1192\n",
      "Epoch 472/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.5232 - reconstruction_loss: 1889.7592 - kl_loss: 101.0511 - false_loss: 0.0792 - true_loss: 1.0556 - val_loss: 5428.7090 - val_reconstruction_loss: 1895.8140 - val_kl_loss: 100.0138 - val_false_loss: 11.0699 - val_true_loss: 1.1191\n",
      "Epoch 473/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.8134 - reconstruction_loss: 1889.4354 - kl_loss: 101.4927 - false_loss: 0.0792 - true_loss: 1.0555 - val_loss: 5428.4312 - val_reconstruction_loss: 1895.8135 - val_kl_loss: 100.0145 - val_false_loss: 11.0690 - val_true_loss: 1.1191\n",
      "Epoch 474/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.4328 - reconstruction_loss: 1890.0938 - kl_loss: 98.5569 - false_loss: 0.0792 - true_loss: 1.0555 - val_loss: 5428.1558 - val_reconstruction_loss: 1895.8131 - val_kl_loss: 100.0150 - val_false_loss: 11.0681 - val_true_loss: 1.1190\n",
      "Epoch 475/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8451 - reconstruction_loss: 1890.4401 - kl_loss: 101.0509 - false_loss: 0.0792 - true_loss: 1.0555 - val_loss: 5427.8823 - val_reconstruction_loss: 1895.8129 - val_kl_loss: 100.0156 - val_false_loss: 11.0672 - val_true_loss: 1.1190\n",
      "Epoch 476/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.9048 - reconstruction_loss: 1889.5992 - kl_loss: 100.8145 - false_loss: 0.0792 - true_loss: 1.0554 - val_loss: 5427.6025 - val_reconstruction_loss: 1895.8124 - val_kl_loss: 100.0159 - val_false_loss: 11.0663 - val_true_loss: 1.1190\n",
      "Epoch 477/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.5855 - reconstruction_loss: 1889.7002 - kl_loss: 102.4271 - false_loss: 0.0792 - true_loss: 1.0554 - val_loss: 5427.3247 - val_reconstruction_loss: 1895.8120 - val_kl_loss: 100.0167 - val_false_loss: 11.0654 - val_true_loss: 1.1189\n",
      "Epoch 478/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.0480 - reconstruction_loss: 1889.2863 - kl_loss: 103.1234 - false_loss: 0.0792 - true_loss: 1.0554 - val_loss: 5427.0522 - val_reconstruction_loss: 1895.8118 - val_kl_loss: 100.0174 - val_false_loss: 11.0645 - val_true_loss: 1.1189\n",
      "Epoch 479/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.3734 - reconstruction_loss: 1889.4789 - kl_loss: 102.6432 - false_loss: 0.0792 - true_loss: 1.0553 - val_loss: 5426.7754 - val_reconstruction_loss: 1895.8113 - val_kl_loss: 100.0180 - val_false_loss: 11.0635 - val_true_loss: 1.1189\n",
      "Epoch 480/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.1534 - reconstruction_loss: 1889.5015 - kl_loss: 103.6117 - false_loss: 0.0792 - true_loss: 1.0553 - val_loss: 5426.4951 - val_reconstruction_loss: 1895.8109 - val_kl_loss: 100.0190 - val_false_loss: 11.0626 - val_true_loss: 1.1188\n",
      "Epoch 481/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.2948 - reconstruction_loss: 1889.3818 - kl_loss: 102.8464 - false_loss: 0.0792 - true_loss: 1.0552 - val_loss: 5426.2168 - val_reconstruction_loss: 1895.8108 - val_kl_loss: 100.0194 - val_false_loss: 11.0617 - val_true_loss: 1.1188\n",
      "Epoch 482/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1273 - reconstruction_loss: 1889.1763 - kl_loss: 101.3347 - false_loss: 0.0792 - true_loss: 1.0552 - val_loss: 5425.9409 - val_reconstruction_loss: 1895.8103 - val_kl_loss: 100.0198 - val_false_loss: 11.0608 - val_true_loss: 1.1187\n",
      "Epoch 483/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.6345 - reconstruction_loss: 1889.0186 - kl_loss: 100.4889 - false_loss: 0.0792 - true_loss: 1.0552 - val_loss: 5425.6621 - val_reconstruction_loss: 1895.8098 - val_kl_loss: 100.0205 - val_false_loss: 11.0599 - val_true_loss: 1.1187\n",
      "Epoch 484/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.2575 - reconstruction_loss: 1888.8539 - kl_loss: 101.7972 - false_loss: 0.0792 - true_loss: 1.0551 - val_loss: 5425.3853 - val_reconstruction_loss: 1895.8097 - val_kl_loss: 100.0207 - val_false_loss: 11.0590 - val_true_loss: 1.1187\n",
      "Epoch 485/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.9678 - reconstruction_loss: 1889.0394 - kl_loss: 98.8896 - false_loss: 0.0792 - true_loss: 1.0551 - val_loss: 5425.1128 - val_reconstruction_loss: 1895.8092 - val_kl_loss: 100.0210 - val_false_loss: 11.0581 - val_true_loss: 1.1186\n",
      "Epoch 486/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.0570 - reconstruction_loss: 1890.0065 - kl_loss: 94.9805 - false_loss: 0.0791 - true_loss: 1.0551 - val_loss: 5424.8779 - val_reconstruction_loss: 1895.8090 - val_kl_loss: 100.0208 - val_false_loss: 11.0573 - val_true_loss: 1.1187\n",
      "Epoch 487/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 3013.7103 - reconstruction_loss: 1921.6689 - kl_loss: 133.7691 - false_loss: 0.0792 - true_loss: 1.0552 - val_loss: 5424.7603 - val_reconstruction_loss: 1895.8120 - val_kl_loss: 100.0189 - val_false_loss: 11.0568 - val_true_loss: 1.1190\n",
      "Epoch 488/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2976.9023 - reconstruction_loss: 1918.0039 - kl_loss: 72.7640 - false_loss: 0.0792 - true_loss: 1.0555 - val_loss: 5425.4912 - val_reconstruction_loss: 1895.8136 - val_kl_loss: 100.0170 - val_false_loss: 11.0592 - val_true_loss: 1.1191\n",
      "Epoch 489/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2699.4876 - reconstruction_loss: 1911.3773 - kl_loss: 75.5817 - false_loss: 0.0792 - true_loss: 1.0557 - val_loss: 5425.5015 - val_reconstruction_loss: 1895.8147 - val_kl_loss: 100.0142 - val_false_loss: 11.0592 - val_true_loss: 1.1192\n",
      "Epoch 490/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2588.3018 - reconstruction_loss: 1909.1327 - kl_loss: 75.5282 - false_loss: 0.0792 - true_loss: 1.0558 - val_loss: 5425.3774 - val_reconstruction_loss: 1895.8156 - val_kl_loss: 100.0114 - val_false_loss: 11.0587 - val_true_loss: 1.1193\n",
      "Epoch 491/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2539.1910 - reconstruction_loss: 1907.5049 - kl_loss: 77.8338 - false_loss: 0.0792 - true_loss: 1.0559 - val_loss: 5425.2607 - val_reconstruction_loss: 1895.8164 - val_kl_loss: 100.0091 - val_false_loss: 11.0583 - val_true_loss: 1.1194\n",
      "Epoch 492/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2504.2481 - reconstruction_loss: 1906.1603 - kl_loss: 77.9969 - false_loss: 0.0792 - true_loss: 1.0559 - val_loss: 5425.0977 - val_reconstruction_loss: 1895.8173 - val_kl_loss: 100.0064 - val_false_loss: 11.0578 - val_true_loss: 1.1195\n",
      "Epoch 493/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2480.1828 - reconstruction_loss: 1905.5299 - kl_loss: 79.0609 - false_loss: 0.0792 - true_loss: 1.0560 - val_loss: 5424.8813 - val_reconstruction_loss: 1895.8179 - val_kl_loss: 100.0040 - val_false_loss: 11.0570 - val_true_loss: 1.1195\n",
      "Epoch 494/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2460.1178 - reconstruction_loss: 1905.1338 - kl_loss: 79.5671 - false_loss: 0.0792 - true_loss: 1.0561 - val_loss: 5424.6572 - val_reconstruction_loss: 1895.8185 - val_kl_loss: 100.0018 - val_false_loss: 11.0563 - val_true_loss: 1.1196\n",
      "Epoch 495/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2446.9770 - reconstruction_loss: 1904.8359 - kl_loss: 80.8002 - false_loss: 0.0792 - true_loss: 1.0561 - val_loss: 5424.4355 - val_reconstruction_loss: 1895.8190 - val_kl_loss: 99.9994 - val_false_loss: 11.0555 - val_true_loss: 1.1196\n",
      "Epoch 496/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2430.9777 - reconstruction_loss: 1904.0513 - kl_loss: 78.9783 - false_loss: 0.0792 - true_loss: 1.0562 - val_loss: 5424.2065 - val_reconstruction_loss: 1895.8196 - val_kl_loss: 99.9971 - val_false_loss: 11.0548 - val_true_loss: 1.1196\n",
      "Epoch 497/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2419.6877 - reconstruction_loss: 1903.7876 - kl_loss: 80.3324 - false_loss: 0.0792 - true_loss: 1.0562 - val_loss: 5423.9849 - val_reconstruction_loss: 1895.8199 - val_kl_loss: 99.9951 - val_false_loss: 11.0540 - val_true_loss: 1.1197\n",
      "Epoch 498/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2408.4663 - reconstruction_loss: 1903.0560 - kl_loss: 81.2772 - false_loss: 0.0792 - true_loss: 1.0563 - val_loss: 5423.7485 - val_reconstruction_loss: 1895.8203 - val_kl_loss: 99.9928 - val_false_loss: 11.0532 - val_true_loss: 1.1197\n",
      "Epoch 499/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2405.4416 - reconstruction_loss: 1903.7300 - kl_loss: 80.8046 - false_loss: 0.0792 - true_loss: 1.0563 - val_loss: 5423.4995 - val_reconstruction_loss: 1895.8207 - val_kl_loss: 99.9907 - val_false_loss: 11.0524 - val_true_loss: 1.1197\n",
      "Epoch 500/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2397.1222 - reconstruction_loss: 1902.9097 - kl_loss: 82.5264 - false_loss: 0.0792 - true_loss: 1.0563 - val_loss: 5423.2651 - val_reconstruction_loss: 1895.8209 - val_kl_loss: 99.9886 - val_false_loss: 11.0516 - val_true_loss: 1.1198\n",
      "Epoch 501/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2388.4834 - reconstruction_loss: 1902.2260 - kl_loss: 81.5301 - false_loss: 0.0792 - true_loss: 1.0564 - val_loss: 5423.0244 - val_reconstruction_loss: 1895.8212 - val_kl_loss: 99.9868 - val_false_loss: 11.0508 - val_true_loss: 1.1198\n",
      "Epoch 502/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2384.7472 - reconstruction_loss: 1901.8363 - kl_loss: 82.8701 - false_loss: 0.0792 - true_loss: 1.0564 - val_loss: 5422.7778 - val_reconstruction_loss: 1895.8214 - val_kl_loss: 99.9849 - val_false_loss: 11.0500 - val_true_loss: 1.1198\n",
      "Epoch 503/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2375.3435 - reconstruction_loss: 1901.3458 - kl_loss: 82.3376 - false_loss: 0.0792 - true_loss: 1.0564 - val_loss: 5422.5366 - val_reconstruction_loss: 1895.8215 - val_kl_loss: 99.9829 - val_false_loss: 11.0492 - val_true_loss: 1.1198\n",
      "Epoch 504/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2376.5033 - reconstruction_loss: 1901.6862 - kl_loss: 82.9066 - false_loss: 0.0792 - true_loss: 1.0565 - val_loss: 5422.2900 - val_reconstruction_loss: 1895.8217 - val_kl_loss: 99.9812 - val_false_loss: 11.0484 - val_true_loss: 1.1198\n",
      "Epoch 505/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2370.8301 - reconstruction_loss: 1901.0922 - kl_loss: 83.2846 - false_loss: 0.0792 - true_loss: 1.0565 - val_loss: 5422.0503 - val_reconstruction_loss: 1895.8219 - val_kl_loss: 99.9794 - val_false_loss: 11.0476 - val_true_loss: 1.1199\n",
      "Epoch 506/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2367.0583 - reconstruction_loss: 1901.1128 - kl_loss: 83.2262 - false_loss: 0.0792 - true_loss: 1.0565 - val_loss: 5421.8081 - val_reconstruction_loss: 1895.8220 - val_kl_loss: 99.9777 - val_false_loss: 11.0467 - val_true_loss: 1.1199\n",
      "Epoch 507/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2362.7437 - reconstruction_loss: 1900.7446 - kl_loss: 84.3296 - false_loss: 0.0792 - true_loss: 1.0565 - val_loss: 5421.5625 - val_reconstruction_loss: 1895.8220 - val_kl_loss: 99.9760 - val_false_loss: 11.0459 - val_true_loss: 1.1199\n",
      "Epoch 508/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2360.3573 - reconstruction_loss: 1900.5795 - kl_loss: 84.0108 - false_loss: 0.0792 - true_loss: 1.0565 - val_loss: 5421.3330 - val_reconstruction_loss: 1895.8221 - val_kl_loss: 99.9745 - val_false_loss: 11.0452 - val_true_loss: 1.1199\n",
      "Epoch 509/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2355.9994 - reconstruction_loss: 1900.4506 - kl_loss: 85.3837 - false_loss: 0.0792 - true_loss: 1.0566 - val_loss: 5421.0879 - val_reconstruction_loss: 1895.8220 - val_kl_loss: 99.9730 - val_false_loss: 11.0443 - val_true_loss: 1.1199\n",
      "Epoch 510/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2354.2911 - reconstruction_loss: 1899.8286 - kl_loss: 84.9618 - false_loss: 0.0792 - true_loss: 1.0566 - val_loss: 5420.8359 - val_reconstruction_loss: 1895.8220 - val_kl_loss: 99.9715 - val_false_loss: 11.0435 - val_true_loss: 1.1199\n",
      "Epoch 511/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2354.3185 - reconstruction_loss: 1899.9008 - kl_loss: 85.2802 - false_loss: 0.0792 - true_loss: 1.0566 - val_loss: 5420.5820 - val_reconstruction_loss: 1895.8221 - val_kl_loss: 99.9700 - val_false_loss: 11.0427 - val_true_loss: 1.1199\n",
      "Epoch 512/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2350.4305 - reconstruction_loss: 1899.7738 - kl_loss: 86.3561 - false_loss: 0.0791 - true_loss: 1.0566 - val_loss: 5420.3301 - val_reconstruction_loss: 1895.8221 - val_kl_loss: 99.9685 - val_false_loss: 11.0418 - val_true_loss: 1.1200\n",
      "Epoch 513/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2349.6625 - reconstruction_loss: 1899.4537 - kl_loss: 85.8484 - false_loss: 0.0791 - true_loss: 1.0566 - val_loss: 5420.0762 - val_reconstruction_loss: 1895.8219 - val_kl_loss: 99.9672 - val_false_loss: 11.0410 - val_true_loss: 1.1200\n",
      "Epoch 514/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2344.3415 - reconstruction_loss: 1899.0410 - kl_loss: 86.8885 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5419.8203 - val_reconstruction_loss: 1895.8219 - val_kl_loss: 99.9658 - val_false_loss: 11.0401 - val_true_loss: 1.1200\n",
      "Epoch 515/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2341.1522 - reconstruction_loss: 1898.9620 - kl_loss: 85.9713 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5419.5620 - val_reconstruction_loss: 1895.8219 - val_kl_loss: 99.9645 - val_false_loss: 11.0393 - val_true_loss: 1.1200\n",
      "Epoch 516/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2342.6674 - reconstruction_loss: 1898.7939 - kl_loss: 87.5752 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5419.3086 - val_reconstruction_loss: 1895.8218 - val_kl_loss: 99.9632 - val_false_loss: 11.0384 - val_true_loss: 1.1200\n",
      "Epoch 517/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2338.1253 - reconstruction_loss: 1898.7448 - kl_loss: 87.3138 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5419.0542 - val_reconstruction_loss: 1895.8217 - val_kl_loss: 99.9620 - val_false_loss: 11.0376 - val_true_loss: 1.1200\n",
      "Epoch 518/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2335.6066 - reconstruction_loss: 1898.4243 - kl_loss: 87.1471 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5418.7979 - val_reconstruction_loss: 1895.8214 - val_kl_loss: 99.9609 - val_false_loss: 11.0367 - val_true_loss: 1.1200\n",
      "Epoch 519/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2338.5874 - reconstruction_loss: 1899.1681 - kl_loss: 88.4460 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5418.5435 - val_reconstruction_loss: 1895.8214 - val_kl_loss: 99.9602 - val_false_loss: 11.0359 - val_true_loss: 1.1200\n",
      "Epoch 520/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2339.8158 - reconstruction_loss: 1898.6973 - kl_loss: 88.9035 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5418.2822 - val_reconstruction_loss: 1895.8213 - val_kl_loss: 99.9592 - val_false_loss: 11.0350 - val_true_loss: 1.1200\n",
      "Epoch 521/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2330.1730 - reconstruction_loss: 1897.9326 - kl_loss: 88.7428 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5418.0195 - val_reconstruction_loss: 1895.8212 - val_kl_loss: 99.9580 - val_false_loss: 11.0341 - val_true_loss: 1.1200\n",
      "Epoch 522/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2328.1278 - reconstruction_loss: 1898.5724 - kl_loss: 89.8181 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5417.7568 - val_reconstruction_loss: 1895.8209 - val_kl_loss: 99.9571 - val_false_loss: 11.0333 - val_true_loss: 1.1200\n",
      "Epoch 523/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2330.0140 - reconstruction_loss: 1898.0663 - kl_loss: 91.3316 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5417.4917 - val_reconstruction_loss: 1895.8207 - val_kl_loss: 99.9561 - val_false_loss: 11.0324 - val_true_loss: 1.1200\n",
      "Epoch 524/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2325.1716 - reconstruction_loss: 1897.5646 - kl_loss: 89.3049 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5417.2275 - val_reconstruction_loss: 1895.8204 - val_kl_loss: 99.9551 - val_false_loss: 11.0315 - val_true_loss: 1.1200\n",
      "Epoch 525/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2322.6288 - reconstruction_loss: 1897.8478 - kl_loss: 91.0198 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5416.9604 - val_reconstruction_loss: 1895.8203 - val_kl_loss: 99.9543 - val_false_loss: 11.0306 - val_true_loss: 1.1200\n",
      "Epoch 526/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2320.0452 - reconstruction_loss: 1898.0995 - kl_loss: 91.2593 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5416.6929 - val_reconstruction_loss: 1895.8202 - val_kl_loss: 99.9537 - val_false_loss: 11.0297 - val_true_loss: 1.1200\n",
      "Epoch 527/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2322.8447 - reconstruction_loss: 1898.2085 - kl_loss: 93.5080 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5416.4258 - val_reconstruction_loss: 1895.8198 - val_kl_loss: 99.9536 - val_false_loss: 11.0288 - val_true_loss: 1.1200\n",
      "Epoch 528/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2317.8847 - reconstruction_loss: 1897.4956 - kl_loss: 93.5541 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5416.1587 - val_reconstruction_loss: 1895.8199 - val_kl_loss: 99.9535 - val_false_loss: 11.0280 - val_true_loss: 1.1200\n",
      "Epoch 529/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2312.6754 - reconstruction_loss: 1897.2584 - kl_loss: 93.1503 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5415.8916 - val_reconstruction_loss: 1895.8196 - val_kl_loss: 99.9533 - val_false_loss: 11.0271 - val_true_loss: 1.1200\n",
      "Epoch 530/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2312.6654 - reconstruction_loss: 1897.6293 - kl_loss: 94.6868 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5415.6211 - val_reconstruction_loss: 1895.8193 - val_kl_loss: 99.9528 - val_false_loss: 11.0262 - val_true_loss: 1.1200\n",
      "Epoch 531/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2309.4401 - reconstruction_loss: 1897.7396 - kl_loss: 94.4265 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5415.3516 - val_reconstruction_loss: 1895.8190 - val_kl_loss: 99.9521 - val_false_loss: 11.0253 - val_true_loss: 1.1200\n",
      "Epoch 532/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2311.9117 - reconstruction_loss: 1897.7833 - kl_loss: 93.4217 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5415.0781 - val_reconstruction_loss: 1895.8191 - val_kl_loss: 99.9517 - val_false_loss: 11.0244 - val_true_loss: 1.1200\n",
      "Epoch 533/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2300.5740 - reconstruction_loss: 1897.8285 - kl_loss: 94.8427 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5414.8057 - val_reconstruction_loss: 1895.8188 - val_kl_loss: 99.9519 - val_false_loss: 11.0235 - val_true_loss: 1.1200\n",
      "Epoch 534/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2305.7117 - reconstruction_loss: 1896.9105 - kl_loss: 95.3431 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5414.5293 - val_reconstruction_loss: 1895.8185 - val_kl_loss: 99.9512 - val_false_loss: 11.0226 - val_true_loss: 1.1200\n",
      "Epoch 535/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2306.9097 - reconstruction_loss: 1897.7695 - kl_loss: 94.9169 - false_loss: 0.0791 - true_loss: 1.0568 - val_loss: 5414.2515 - val_reconstruction_loss: 1895.8182 - val_kl_loss: 99.9507 - val_false_loss: 11.0216 - val_true_loss: 1.1200\n",
      "Epoch 536/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2306.6370 - reconstruction_loss: 1898.1650 - kl_loss: 96.2608 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5413.9727 - val_reconstruction_loss: 1895.8181 - val_kl_loss: 99.9499 - val_false_loss: 11.0207 - val_true_loss: 1.1200\n",
      "Epoch 537/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2298.4968 - reconstruction_loss: 1897.1022 - kl_loss: 95.2440 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5413.6914 - val_reconstruction_loss: 1895.8177 - val_kl_loss: 99.9490 - val_false_loss: 11.0198 - val_true_loss: 1.1199\n",
      "Epoch 538/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2299.5977 - reconstruction_loss: 1896.6605 - kl_loss: 96.7190 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5413.4106 - val_reconstruction_loss: 1895.8174 - val_kl_loss: 99.9485 - val_false_loss: 11.0188 - val_true_loss: 1.1199\n",
      "Epoch 539/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2294.5488 - reconstruction_loss: 1896.1680 - kl_loss: 94.3101 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5413.1328 - val_reconstruction_loss: 1895.8171 - val_kl_loss: 99.9482 - val_false_loss: 11.0179 - val_true_loss: 1.1199\n",
      "Epoch 540/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2297.8033 - reconstruction_loss: 1897.3643 - kl_loss: 95.9519 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5412.8604 - val_reconstruction_loss: 1895.8169 - val_kl_loss: 99.9475 - val_false_loss: 11.0170 - val_true_loss: 1.1199\n",
      "Epoch 541/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2298.7919 - reconstruction_loss: 1896.2426 - kl_loss: 95.1988 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5412.5747 - val_reconstruction_loss: 1895.8165 - val_kl_loss: 99.9472 - val_false_loss: 11.0161 - val_true_loss: 1.1199\n",
      "Epoch 542/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2287.0411 - reconstruction_loss: 1896.3153 - kl_loss: 94.3580 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5412.2920 - val_reconstruction_loss: 1895.8162 - val_kl_loss: 99.9470 - val_false_loss: 11.0151 - val_true_loss: 1.1199\n",
      "Epoch 543/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2283.4534 - reconstruction_loss: 1896.0703 - kl_loss: 94.6745 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5412.0024 - val_reconstruction_loss: 1895.8158 - val_kl_loss: 99.9467 - val_false_loss: 11.0142 - val_true_loss: 1.1199\n",
      "Epoch 544/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2282.9595 - reconstruction_loss: 1896.2755 - kl_loss: 94.9913 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5411.7261 - val_reconstruction_loss: 1895.8158 - val_kl_loss: 99.9467 - val_false_loss: 11.0133 - val_true_loss: 1.1199\n",
      "Epoch 545/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2283.3550 - reconstruction_loss: 1896.4913 - kl_loss: 94.2776 - false_loss: 0.0791 - true_loss: 1.0567 - val_loss: 5411.4434 - val_reconstruction_loss: 1895.8154 - val_kl_loss: 99.9463 - val_false_loss: 11.0123 - val_true_loss: 1.1199\n",
      "Epoch 546/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2284.4511 - reconstruction_loss: 1895.8193 - kl_loss: 94.2686 - false_loss: 0.0790 - true_loss: 1.0567 - val_loss: 5411.1587 - val_reconstruction_loss: 1895.8152 - val_kl_loss: 99.9466 - val_false_loss: 11.0114 - val_true_loss: 1.1198\n",
      "Epoch 547/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2285.1391 - reconstruction_loss: 1896.1598 - kl_loss: 94.7034 - false_loss: 0.0790 - true_loss: 1.0567 - val_loss: 5410.8745 - val_reconstruction_loss: 1895.8148 - val_kl_loss: 99.9459 - val_false_loss: 11.0104 - val_true_loss: 1.1198\n",
      "Epoch 548/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2287.8620 - reconstruction_loss: 1896.1036 - kl_loss: 93.5486 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5410.5874 - val_reconstruction_loss: 1895.8146 - val_kl_loss: 99.9461 - val_false_loss: 11.0095 - val_true_loss: 1.1198\n",
      "Epoch 549/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2283.2420 - reconstruction_loss: 1896.7396 - kl_loss: 95.0225 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5410.3013 - val_reconstruction_loss: 1895.8142 - val_kl_loss: 99.9460 - val_false_loss: 11.0085 - val_true_loss: 1.1198\n",
      "Epoch 550/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2288.2221 - reconstruction_loss: 1896.1302 - kl_loss: 95.6437 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5410.0190 - val_reconstruction_loss: 1895.8140 - val_kl_loss: 99.9451 - val_false_loss: 11.0076 - val_true_loss: 1.1198\n",
      "Epoch 551/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2298.6420 - reconstruction_loss: 1896.4159 - kl_loss: 95.4102 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5409.7407 - val_reconstruction_loss: 1895.8136 - val_kl_loss: 99.9447 - val_false_loss: 11.0067 - val_true_loss: 1.1198\n",
      "Epoch 552/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2287.2219 - reconstruction_loss: 1896.2260 - kl_loss: 95.0249 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5409.4565 - val_reconstruction_loss: 1895.8134 - val_kl_loss: 99.9439 - val_false_loss: 11.0057 - val_true_loss: 1.1198\n",
      "Epoch 553/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2294.1765 - reconstruction_loss: 1896.2173 - kl_loss: 95.2851 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5409.1743 - val_reconstruction_loss: 1895.8130 - val_kl_loss: 99.9434 - val_false_loss: 11.0048 - val_true_loss: 1.1198\n",
      "Epoch 554/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2279.6618 - reconstruction_loss: 1895.8588 - kl_loss: 93.6328 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5408.8862 - val_reconstruction_loss: 1895.8127 - val_kl_loss: 99.9430 - val_false_loss: 11.0039 - val_true_loss: 1.1197\n",
      "Epoch 555/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2288.7189 - reconstruction_loss: 1896.4037 - kl_loss: 95.2550 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5408.6006 - val_reconstruction_loss: 1895.8126 - val_kl_loss: 99.9426 - val_false_loss: 11.0029 - val_true_loss: 1.1197\n",
      "Epoch 556/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2285.8551 - reconstruction_loss: 1895.7194 - kl_loss: 95.7006 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5408.3145 - val_reconstruction_loss: 1895.8121 - val_kl_loss: 99.9419 - val_false_loss: 11.0020 - val_true_loss: 1.1197\n",
      "Epoch 557/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2278.9688 - reconstruction_loss: 1895.3789 - kl_loss: 94.8558 - false_loss: 0.0790 - true_loss: 1.0566 - val_loss: 5408.0298 - val_reconstruction_loss: 1895.8118 - val_kl_loss: 99.9416 - val_false_loss: 11.0010 - val_true_loss: 1.1197\n",
      "Epoch 558/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2280.0249 - reconstruction_loss: 1895.7528 - kl_loss: 95.0229 - false_loss: 0.0790 - true_loss: 1.0565 - val_loss: 5407.7451 - val_reconstruction_loss: 1895.8115 - val_kl_loss: 99.9414 - val_false_loss: 11.0001 - val_true_loss: 1.1197\n",
      "Epoch 559/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2274.9290 - reconstruction_loss: 1895.3719 - kl_loss: 96.1755 - false_loss: 0.0790 - true_loss: 1.0565 - val_loss: 5407.4575 - val_reconstruction_loss: 1895.8110 - val_kl_loss: 99.9408 - val_false_loss: 10.9991 - val_true_loss: 1.1197\n",
      "Epoch 560/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2275.0707 - reconstruction_loss: 1895.7744 - kl_loss: 95.3807 - false_loss: 0.0790 - true_loss: 1.0565 - val_loss: 5407.1733 - val_reconstruction_loss: 1895.8107 - val_kl_loss: 99.9411 - val_false_loss: 10.9982 - val_true_loss: 1.1196\n",
      "Epoch 561/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2271.8275 - reconstruction_loss: 1895.6591 - kl_loss: 95.8020 - false_loss: 0.0790 - true_loss: 1.0565 - val_loss: 5406.8887 - val_reconstruction_loss: 1895.8102 - val_kl_loss: 99.9410 - val_false_loss: 10.9973 - val_true_loss: 1.1196\n",
      "Epoch 562/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2274.4771 - reconstruction_loss: 1895.4662 - kl_loss: 95.3069 - false_loss: 0.0790 - true_loss: 1.0565 - val_loss: 5406.6084 - val_reconstruction_loss: 1895.8098 - val_kl_loss: 99.9406 - val_false_loss: 10.9963 - val_true_loss: 1.1196\n",
      "Epoch 563/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2275.5059 - reconstruction_loss: 1895.0580 - kl_loss: 96.5469 - false_loss: 0.0790 - true_loss: 1.0565 - val_loss: 5406.3252 - val_reconstruction_loss: 1895.8094 - val_kl_loss: 99.9401 - val_false_loss: 10.9954 - val_true_loss: 1.1196\n",
      "Epoch 564/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2273.3597 - reconstruction_loss: 1895.2325 - kl_loss: 95.7593 - false_loss: 0.0790 - true_loss: 1.0565 - val_loss: 5406.0396 - val_reconstruction_loss: 1895.8091 - val_kl_loss: 99.9405 - val_false_loss: 10.9945 - val_true_loss: 1.1196\n",
      "Epoch 565/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2278.6630 - reconstruction_loss: 1895.0438 - kl_loss: 96.9320 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5405.7603 - val_reconstruction_loss: 1895.8087 - val_kl_loss: 99.9407 - val_false_loss: 10.9935 - val_true_loss: 1.1196\n",
      "Epoch 566/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2275.0180 - reconstruction_loss: 1895.0363 - kl_loss: 95.0928 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5405.4717 - val_reconstruction_loss: 1895.8082 - val_kl_loss: 99.9407 - val_false_loss: 10.9926 - val_true_loss: 1.1195\n",
      "Epoch 567/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2273.9593 - reconstruction_loss: 1895.7396 - kl_loss: 95.8373 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5405.1904 - val_reconstruction_loss: 1895.8077 - val_kl_loss: 99.9402 - val_false_loss: 10.9916 - val_true_loss: 1.1195\n",
      "Epoch 568/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2291.3807 - reconstruction_loss: 1894.8180 - kl_loss: 95.8151 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5404.9053 - val_reconstruction_loss: 1895.8074 - val_kl_loss: 99.9394 - val_false_loss: 10.9907 - val_true_loss: 1.1195\n",
      "Epoch 569/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2301.1594 - reconstruction_loss: 1895.6302 - kl_loss: 95.9431 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5404.6230 - val_reconstruction_loss: 1895.8069 - val_kl_loss: 99.9384 - val_false_loss: 10.9898 - val_true_loss: 1.1195\n",
      "Epoch 570/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2303.7632 - reconstruction_loss: 1895.1685 - kl_loss: 92.8042 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5404.3359 - val_reconstruction_loss: 1895.8066 - val_kl_loss: 99.9377 - val_false_loss: 10.9888 - val_true_loss: 1.1195\n",
      "Epoch 571/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2277.7471 - reconstruction_loss: 1895.2174 - kl_loss: 93.8190 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5404.0503 - val_reconstruction_loss: 1895.8063 - val_kl_loss: 99.9378 - val_false_loss: 10.9879 - val_true_loss: 1.1195\n",
      "Epoch 572/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2273.5147 - reconstruction_loss: 1894.8475 - kl_loss: 96.7912 - false_loss: 0.0790 - true_loss: 1.0564 - val_loss: 5403.7642 - val_reconstruction_loss: 1895.8058 - val_kl_loss: 99.9377 - val_false_loss: 10.9869 - val_true_loss: 1.1195\n",
      "Epoch 573/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2271.8293 - reconstruction_loss: 1895.2354 - kl_loss: 96.8332 - false_loss: 0.0790 - true_loss: 1.0563 - val_loss: 5403.4814 - val_reconstruction_loss: 1895.8054 - val_kl_loss: 99.9379 - val_false_loss: 10.9860 - val_true_loss: 1.1195\n",
      "Epoch 574/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2268.2023 - reconstruction_loss: 1895.0084 - kl_loss: 95.9149 - false_loss: 0.0789 - true_loss: 1.0563 - val_loss: 5403.2021 - val_reconstruction_loss: 1895.8049 - val_kl_loss: 99.9380 - val_false_loss: 10.9851 - val_true_loss: 1.1194\n",
      "Epoch 575/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2278.3777 - reconstruction_loss: 1895.6241 - kl_loss: 95.9540 - false_loss: 0.0789 - true_loss: 1.0563 - val_loss: 5402.9185 - val_reconstruction_loss: 1895.8044 - val_kl_loss: 99.9382 - val_false_loss: 10.9841 - val_true_loss: 1.1194\n",
      "Epoch 576/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2269.6086 - reconstruction_loss: 1894.9445 - kl_loss: 95.6519 - false_loss: 0.0789 - true_loss: 1.0563 - val_loss: 5402.6362 - val_reconstruction_loss: 1895.8042 - val_kl_loss: 99.9384 - val_false_loss: 10.9832 - val_true_loss: 1.1194\n",
      "Epoch 577/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2268.2568 - reconstruction_loss: 1894.8700 - kl_loss: 96.5696 - false_loss: 0.0789 - true_loss: 1.0563 - val_loss: 5402.3496 - val_reconstruction_loss: 1895.8037 - val_kl_loss: 99.9379 - val_false_loss: 10.9822 - val_true_loss: 1.1194\n",
      "Epoch 578/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2267.8166 - reconstruction_loss: 1895.1217 - kl_loss: 97.0017 - false_loss: 0.0789 - true_loss: 1.0563 - val_loss: 5402.0625 - val_reconstruction_loss: 1895.8035 - val_kl_loss: 99.9381 - val_false_loss: 10.9813 - val_true_loss: 1.1194\n",
      "Epoch 579/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2265.7844 - reconstruction_loss: 1895.3461 - kl_loss: 96.9943 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5401.7832 - val_reconstruction_loss: 1895.8030 - val_kl_loss: 99.9381 - val_false_loss: 10.9804 - val_true_loss: 1.1193\n",
      "Epoch 580/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2288.6840 - reconstruction_loss: 1895.4235 - kl_loss: 95.7005 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5401.4976 - val_reconstruction_loss: 1895.8025 - val_kl_loss: 99.9386 - val_false_loss: 10.9794 - val_true_loss: 1.1193\n",
      "Epoch 581/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2292.6295 - reconstruction_loss: 1895.1017 - kl_loss: 96.1980 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5401.2129 - val_reconstruction_loss: 1895.8021 - val_kl_loss: 99.9383 - val_false_loss: 10.9785 - val_true_loss: 1.1193\n",
      "Epoch 582/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2275.5951 - reconstruction_loss: 1894.8617 - kl_loss: 96.0689 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5400.9268 - val_reconstruction_loss: 1895.8018 - val_kl_loss: 99.9383 - val_false_loss: 10.9775 - val_true_loss: 1.1193\n",
      "Epoch 583/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2278.0257 - reconstruction_loss: 1895.0010 - kl_loss: 96.1508 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5400.6426 - val_reconstruction_loss: 1895.8013 - val_kl_loss: 99.9379 - val_false_loss: 10.9766 - val_true_loss: 1.1193\n",
      "Epoch 584/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2278.9295 - reconstruction_loss: 1894.5895 - kl_loss: 96.4911 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5400.3599 - val_reconstruction_loss: 1895.8009 - val_kl_loss: 99.9377 - val_false_loss: 10.9757 - val_true_loss: 1.1193\n",
      "Epoch 585/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2277.0695 - reconstruction_loss: 1894.6201 - kl_loss: 96.5661 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5400.0747 - val_reconstruction_loss: 1895.8004 - val_kl_loss: 99.9371 - val_false_loss: 10.9747 - val_true_loss: 1.1193\n",
      "Epoch 586/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2265.1338 - reconstruction_loss: 1894.5233 - kl_loss: 96.1665 - false_loss: 0.0789 - true_loss: 1.0562 - val_loss: 5399.7856 - val_reconstruction_loss: 1895.8000 - val_kl_loss: 99.9370 - val_false_loss: 10.9738 - val_true_loss: 1.1192\n",
      "Epoch 587/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2259.4877 - reconstruction_loss: 1894.8837 - kl_loss: 96.5497 - false_loss: 0.0789 - true_loss: 1.0561 - val_loss: 5399.4995 - val_reconstruction_loss: 1895.7997 - val_kl_loss: 99.9369 - val_false_loss: 10.9728 - val_true_loss: 1.1192\n",
      "Epoch 588/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2257.4469 - reconstruction_loss: 1895.1227 - kl_loss: 96.9523 - false_loss: 0.0789 - true_loss: 1.0561 - val_loss: 5399.2139 - val_reconstruction_loss: 1895.7993 - val_kl_loss: 99.9372 - val_false_loss: 10.9719 - val_true_loss: 1.1192\n",
      "Epoch 589/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2276.7906 - reconstruction_loss: 1894.6381 - kl_loss: 97.7927 - false_loss: 0.0789 - true_loss: 1.0561 - val_loss: 5398.9292 - val_reconstruction_loss: 1895.7988 - val_kl_loss: 99.9362 - val_false_loss: 10.9709 - val_true_loss: 1.1192\n",
      "Epoch 590/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2288.2503 - reconstruction_loss: 1894.8148 - kl_loss: 97.1491 - false_loss: 0.0789 - true_loss: 1.0561 - val_loss: 5398.6440 - val_reconstruction_loss: 1895.7983 - val_kl_loss: 99.9360 - val_false_loss: 10.9700 - val_true_loss: 1.1192\n",
      "Epoch 591/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2276.2135 - reconstruction_loss: 1894.5424 - kl_loss: 95.6333 - false_loss: 0.0789 - true_loss: 1.0561 - val_loss: 5398.3604 - val_reconstruction_loss: 1895.7980 - val_kl_loss: 99.9360 - val_false_loss: 10.9690 - val_true_loss: 1.1191\n",
      "Epoch 592/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2284.4885 - reconstruction_loss: 1894.5908 - kl_loss: 97.1391 - false_loss: 0.0789 - true_loss: 1.0561 - val_loss: 5398.0698 - val_reconstruction_loss: 1895.7976 - val_kl_loss: 99.9351 - val_false_loss: 10.9681 - val_true_loss: 1.1191\n",
      "Epoch 593/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2268.9661 - reconstruction_loss: 1894.5824 - kl_loss: 95.3625 - false_loss: 0.0789 - true_loss: 1.0561 - val_loss: 5397.7808 - val_reconstruction_loss: 1895.7974 - val_kl_loss: 99.9346 - val_false_loss: 10.9671 - val_true_loss: 1.1191\n",
      "Epoch 594/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2269.9309 - reconstruction_loss: 1894.2548 - kl_loss: 96.0326 - false_loss: 0.0789 - true_loss: 1.0560 - val_loss: 5397.4941 - val_reconstruction_loss: 1895.7969 - val_kl_loss: 99.9342 - val_false_loss: 10.9662 - val_true_loss: 1.1191\n",
      "Epoch 595/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2278.6384 - reconstruction_loss: 1894.3461 - kl_loss: 95.5102 - false_loss: 0.0789 - true_loss: 1.0560 - val_loss: 5397.2080 - val_reconstruction_loss: 1895.7963 - val_kl_loss: 99.9336 - val_false_loss: 10.9652 - val_true_loss: 1.1191\n",
      "Epoch 596/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2274.4286 - reconstruction_loss: 1894.4464 - kl_loss: 96.3849 - false_loss: 0.0789 - true_loss: 1.0560 - val_loss: 5396.9199 - val_reconstruction_loss: 1895.7959 - val_kl_loss: 99.9330 - val_false_loss: 10.9643 - val_true_loss: 1.1191\n",
      "Epoch 597/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2278.3970 - reconstruction_loss: 1894.0912 - kl_loss: 95.3889 - false_loss: 0.0789 - true_loss: 1.0560 - val_loss: 5396.6313 - val_reconstruction_loss: 1895.7953 - val_kl_loss: 99.9324 - val_false_loss: 10.9633 - val_true_loss: 1.1190\n",
      "Epoch 598/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2276.9152 - reconstruction_loss: 1894.3815 - kl_loss: 95.6243 - false_loss: 0.0789 - true_loss: 1.0560 - val_loss: 5396.3398 - val_reconstruction_loss: 1895.7949 - val_kl_loss: 99.9316 - val_false_loss: 10.9624 - val_true_loss: 1.1190\n",
      "Epoch 599/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2283.0302 - reconstruction_loss: 1894.8384 - kl_loss: 96.1815 - false_loss: 0.0788 - true_loss: 1.0560 - val_loss: 5396.0508 - val_reconstruction_loss: 1895.7944 - val_kl_loss: 99.9309 - val_false_loss: 10.9614 - val_true_loss: 1.1190\n",
      "Epoch 600/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2274.8507 - reconstruction_loss: 1894.5734 - kl_loss: 94.7291 - false_loss: 0.0788 - true_loss: 1.0560 - val_loss: 5395.7720 - val_reconstruction_loss: 1895.7941 - val_kl_loss: 99.9307 - val_false_loss: 10.9605 - val_true_loss: 1.1190\n",
      "Epoch 601/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2271.8084 - reconstruction_loss: 1894.5104 - kl_loss: 96.8622 - false_loss: 0.0788 - true_loss: 1.0560 - val_loss: 5395.4795 - val_reconstruction_loss: 1895.7937 - val_kl_loss: 99.9307 - val_false_loss: 10.9595 - val_true_loss: 1.1190\n",
      "Epoch 602/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2272.0329 - reconstruction_loss: 1894.4801 - kl_loss: 94.7369 - false_loss: 0.0788 - true_loss: 1.0559 - val_loss: 5395.1978 - val_reconstruction_loss: 1895.7932 - val_kl_loss: 99.9300 - val_false_loss: 10.9586 - val_true_loss: 1.1189\n",
      "Epoch 603/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2268.5919 - reconstruction_loss: 1894.0897 - kl_loss: 94.6987 - false_loss: 0.0788 - true_loss: 1.0559 - val_loss: 5394.9082 - val_reconstruction_loss: 1895.7930 - val_kl_loss: 99.9289 - val_false_loss: 10.9576 - val_true_loss: 1.1189\n",
      "Epoch 604/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2278.1045 - reconstruction_loss: 1895.6030 - kl_loss: 95.4690 - false_loss: 0.0788 - true_loss: 1.0559 - val_loss: 5394.6260 - val_reconstruction_loss: 1895.7925 - val_kl_loss: 99.9280 - val_false_loss: 10.9567 - val_true_loss: 1.1189\n",
      "Epoch 605/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2271.1606 - reconstruction_loss: 1894.4502 - kl_loss: 95.3077 - false_loss: 0.0788 - true_loss: 1.0559 - val_loss: 5394.3335 - val_reconstruction_loss: 1895.7921 - val_kl_loss: 99.9274 - val_false_loss: 10.9558 - val_true_loss: 1.1189\n",
      "Epoch 606/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2257.4194 - reconstruction_loss: 1894.3505 - kl_loss: 95.4710 - false_loss: 0.0788 - true_loss: 1.0559 - val_loss: 5394.0435 - val_reconstruction_loss: 1895.7914 - val_kl_loss: 99.9270 - val_false_loss: 10.9548 - val_true_loss: 1.1189\n",
      "Epoch 607/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2253.2102 - reconstruction_loss: 1893.9624 - kl_loss: 95.2683 - false_loss: 0.0788 - true_loss: 1.0559 - val_loss: 5393.7524 - val_reconstruction_loss: 1895.7911 - val_kl_loss: 99.9266 - val_false_loss: 10.9538 - val_true_loss: 1.1189\n",
      "Epoch 608/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.4962 - reconstruction_loss: 1893.8490 - kl_loss: 96.8028 - false_loss: 0.0788 - true_loss: 1.0558 - val_loss: 5393.4614 - val_reconstruction_loss: 1895.7905 - val_kl_loss: 99.9261 - val_false_loss: 10.9529 - val_true_loss: 1.1188\n",
      "Epoch 609/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.6672 - reconstruction_loss: 1893.6583 - kl_loss: 95.6312 - false_loss: 0.0788 - true_loss: 1.0558 - val_loss: 5393.1699 - val_reconstruction_loss: 1895.7900 - val_kl_loss: 99.9261 - val_false_loss: 10.9519 - val_true_loss: 1.1188\n",
      "Epoch 610/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.4530 - reconstruction_loss: 1893.9624 - kl_loss: 96.0271 - false_loss: 0.0788 - true_loss: 1.0558 - val_loss: 5392.8789 - val_reconstruction_loss: 1895.7896 - val_kl_loss: 99.9258 - val_false_loss: 10.9510 - val_true_loss: 1.1188\n",
      "Epoch 611/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.9888 - reconstruction_loss: 1894.2797 - kl_loss: 96.4358 - false_loss: 0.0788 - true_loss: 1.0558 - val_loss: 5392.5859 - val_reconstruction_loss: 1895.7891 - val_kl_loss: 99.9256 - val_false_loss: 10.9500 - val_true_loss: 1.1187\n",
      "Epoch 612/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.6772 - reconstruction_loss: 1893.9628 - kl_loss: 97.3167 - false_loss: 0.0788 - true_loss: 1.0557 - val_loss: 5392.2920 - val_reconstruction_loss: 1895.7888 - val_kl_loss: 99.9251 - val_false_loss: 10.9490 - val_true_loss: 1.1187\n",
      "Epoch 613/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.3014 - reconstruction_loss: 1894.2006 - kl_loss: 95.5340 - false_loss: 0.0788 - true_loss: 1.0557 - val_loss: 5391.9980 - val_reconstruction_loss: 1895.7882 - val_kl_loss: 99.9248 - val_false_loss: 10.9481 - val_true_loss: 1.1187\n",
      "Epoch 614/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.6884 - reconstruction_loss: 1893.9000 - kl_loss: 96.5348 - false_loss: 0.0788 - true_loss: 1.0557 - val_loss: 5391.7065 - val_reconstruction_loss: 1895.7878 - val_kl_loss: 99.9248 - val_false_loss: 10.9471 - val_true_loss: 1.1187\n",
      "Epoch 615/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.9066 - reconstruction_loss: 1894.7753 - kl_loss: 95.9224 - false_loss: 0.0788 - true_loss: 1.0557 - val_loss: 5391.4150 - val_reconstruction_loss: 1895.7874 - val_kl_loss: 99.9245 - val_false_loss: 10.9461 - val_true_loss: 1.1186\n",
      "Epoch 616/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.7762 - reconstruction_loss: 1895.0557 - kl_loss: 96.1069 - false_loss: 0.0788 - true_loss: 1.0556 - val_loss: 5391.1221 - val_reconstruction_loss: 1895.7871 - val_kl_loss: 99.9244 - val_false_loss: 10.9452 - val_true_loss: 1.1186\n",
      "Epoch 617/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0137 - reconstruction_loss: 1894.3224 - kl_loss: 97.8812 - false_loss: 0.0788 - true_loss: 1.0556 - val_loss: 5390.8306 - val_reconstruction_loss: 1895.7865 - val_kl_loss: 99.9241 - val_false_loss: 10.9442 - val_true_loss: 1.1186\n",
      "Epoch 618/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2261.5780 - reconstruction_loss: 1894.0552 - kl_loss: 96.4777 - false_loss: 0.0788 - true_loss: 1.0556 - val_loss: 5390.5396 - val_reconstruction_loss: 1895.7861 - val_kl_loss: 99.9236 - val_false_loss: 10.9433 - val_true_loss: 1.1186\n",
      "Epoch 619/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2263.8690 - reconstruction_loss: 1894.0078 - kl_loss: 95.9535 - false_loss: 0.0788 - true_loss: 1.0556 - val_loss: 5390.2490 - val_reconstruction_loss: 1895.7855 - val_kl_loss: 99.9235 - val_false_loss: 10.9423 - val_true_loss: 1.1185\n",
      "Epoch 620/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2262.5265 - reconstruction_loss: 1893.9258 - kl_loss: 96.2514 - false_loss: 0.0788 - true_loss: 1.0556 - val_loss: 5389.9585 - val_reconstruction_loss: 1895.7850 - val_kl_loss: 99.9234 - val_false_loss: 10.9413 - val_true_loss: 1.1185\n",
      "Epoch 621/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2264.2408 - reconstruction_loss: 1893.5419 - kl_loss: 95.2250 - false_loss: 0.0788 - true_loss: 1.0555 - val_loss: 5389.6675 - val_reconstruction_loss: 1895.7845 - val_kl_loss: 99.9230 - val_false_loss: 10.9404 - val_true_loss: 1.1185\n",
      "Epoch 622/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2274.6896 - reconstruction_loss: 1893.7510 - kl_loss: 94.6803 - false_loss: 0.0787 - true_loss: 1.0555 - val_loss: 5389.3799 - val_reconstruction_loss: 1895.7841 - val_kl_loss: 99.9231 - val_false_loss: 10.9394 - val_true_loss: 1.1185\n",
      "Epoch 623/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2274.6988 - reconstruction_loss: 1893.9751 - kl_loss: 93.7626 - false_loss: 0.0787 - true_loss: 1.0555 - val_loss: 5389.0898 - val_reconstruction_loss: 1895.7836 - val_kl_loss: 99.9221 - val_false_loss: 10.9385 - val_true_loss: 1.1185\n",
      "Epoch 624/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.7842 - reconstruction_loss: 1894.0885 - kl_loss: 95.0023 - false_loss: 0.0787 - true_loss: 1.0555 - val_loss: 5388.7988 - val_reconstruction_loss: 1895.7831 - val_kl_loss: 99.9218 - val_false_loss: 10.9375 - val_true_loss: 1.1184\n",
      "Epoch 625/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2248.2946 - reconstruction_loss: 1894.2012 - kl_loss: 95.8103 - false_loss: 0.0787 - true_loss: 1.0555 - val_loss: 5388.5078 - val_reconstruction_loss: 1895.7827 - val_kl_loss: 99.9209 - val_false_loss: 10.9365 - val_true_loss: 1.1184\n",
      "Epoch 626/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.0428 - reconstruction_loss: 1894.4249 - kl_loss: 94.1455 - false_loss: 0.0787 - true_loss: 1.0555 - val_loss: 5388.2158 - val_reconstruction_loss: 1895.7822 - val_kl_loss: 99.9207 - val_false_loss: 10.9356 - val_true_loss: 1.1184\n",
      "Epoch 627/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.2160 - reconstruction_loss: 1893.5404 - kl_loss: 95.6508 - false_loss: 0.0787 - true_loss: 1.0554 - val_loss: 5387.9204 - val_reconstruction_loss: 1895.7817 - val_kl_loss: 99.9200 - val_false_loss: 10.9346 - val_true_loss: 1.1184\n",
      "Epoch 628/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2260.5686 - reconstruction_loss: 1893.4037 - kl_loss: 94.6222 - false_loss: 0.0787 - true_loss: 1.0554 - val_loss: 5387.6333 - val_reconstruction_loss: 1895.7812 - val_kl_loss: 99.9199 - val_false_loss: 10.9337 - val_true_loss: 1.1184\n",
      "Epoch 629/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2254.1360 - reconstruction_loss: 1893.7286 - kl_loss: 95.7366 - false_loss: 0.0787 - true_loss: 1.0554 - val_loss: 5387.3462 - val_reconstruction_loss: 1895.7809 - val_kl_loss: 99.9195 - val_false_loss: 10.9327 - val_true_loss: 1.1183\n",
      "Epoch 630/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.6642 - reconstruction_loss: 1893.5688 - kl_loss: 95.7907 - false_loss: 0.0787 - true_loss: 1.0554 - val_loss: 5387.0522 - val_reconstruction_loss: 1895.7803 - val_kl_loss: 99.9188 - val_false_loss: 10.9318 - val_true_loss: 1.1183\n",
      "Epoch 631/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2260.6522 - reconstruction_loss: 1893.7686 - kl_loss: 95.9313 - false_loss: 0.0787 - true_loss: 1.0554 - val_loss: 5386.7607 - val_reconstruction_loss: 1895.7799 - val_kl_loss: 99.9185 - val_false_loss: 10.9308 - val_true_loss: 1.1183\n",
      "Epoch 632/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2259.2843 - reconstruction_loss: 1893.9315 - kl_loss: 95.4750 - false_loss: 0.0787 - true_loss: 1.0553 - val_loss: 5386.4702 - val_reconstruction_loss: 1895.7794 - val_kl_loss: 99.9179 - val_false_loss: 10.9298 - val_true_loss: 1.1183\n",
      "Epoch 633/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2263.1926 - reconstruction_loss: 1893.7231 - kl_loss: 95.1671 - false_loss: 0.0787 - true_loss: 1.0553 - val_loss: 5386.1782 - val_reconstruction_loss: 1895.7791 - val_kl_loss: 99.9174 - val_false_loss: 10.9289 - val_true_loss: 1.1182\n",
      "Epoch 634/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.3968 - reconstruction_loss: 1894.0663 - kl_loss: 95.3122 - false_loss: 0.0787 - true_loss: 1.0553 - val_loss: 5385.8892 - val_reconstruction_loss: 1895.7784 - val_kl_loss: 99.9173 - val_false_loss: 10.9279 - val_true_loss: 1.1182\n",
      "Epoch 635/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.1315 - reconstruction_loss: 1893.8643 - kl_loss: 95.6163 - false_loss: 0.0787 - true_loss: 1.0553 - val_loss: 5385.5933 - val_reconstruction_loss: 1895.7780 - val_kl_loss: 99.9172 - val_false_loss: 10.9269 - val_true_loss: 1.1182\n",
      "Epoch 636/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.5779 - reconstruction_loss: 1893.2871 - kl_loss: 94.9767 - false_loss: 0.0787 - true_loss: 1.0552 - val_loss: 5385.3047 - val_reconstruction_loss: 1895.7772 - val_kl_loss: 99.9169 - val_false_loss: 10.9260 - val_true_loss: 1.1182\n",
      "Epoch 637/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2265.5530 - reconstruction_loss: 1893.9799 - kl_loss: 94.7592 - false_loss: 0.0787 - true_loss: 1.0552 - val_loss: 5385.0112 - val_reconstruction_loss: 1895.7770 - val_kl_loss: 99.9168 - val_false_loss: 10.9250 - val_true_loss: 1.1181\n",
      "Epoch 638/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2252.6659 - reconstruction_loss: 1893.7677 - kl_loss: 94.7764 - false_loss: 0.0787 - true_loss: 1.0552 - val_loss: 5384.7231 - val_reconstruction_loss: 1895.7765 - val_kl_loss: 99.9163 - val_false_loss: 10.9241 - val_true_loss: 1.1181\n",
      "Epoch 639/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.1502 - reconstruction_loss: 1893.9166 - kl_loss: 94.4882 - false_loss: 0.0787 - true_loss: 1.0552 - val_loss: 5384.4316 - val_reconstruction_loss: 1895.7760 - val_kl_loss: 99.9159 - val_false_loss: 10.9231 - val_true_loss: 1.1181\n",
      "Epoch 640/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2262.8886 - reconstruction_loss: 1893.9365 - kl_loss: 95.1737 - false_loss: 0.0787 - true_loss: 1.0552 - val_loss: 5384.1401 - val_reconstruction_loss: 1895.7755 - val_kl_loss: 99.9158 - val_false_loss: 10.9221 - val_true_loss: 1.1181\n",
      "Epoch 641/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2265.9941 - reconstruction_loss: 1893.5885 - kl_loss: 94.6360 - false_loss: 0.0787 - true_loss: 1.0552 - val_loss: 5383.8511 - val_reconstruction_loss: 1895.7750 - val_kl_loss: 99.9150 - val_false_loss: 10.9212 - val_true_loss: 1.1181\n",
      "Epoch 642/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.1434 - reconstruction_loss: 1893.6737 - kl_loss: 95.5387 - false_loss: 0.0787 - true_loss: 1.0551 - val_loss: 5383.5605 - val_reconstruction_loss: 1895.7744 - val_kl_loss: 99.9143 - val_false_loss: 10.9202 - val_true_loss: 1.1180\n",
      "Epoch 643/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.8006 - reconstruction_loss: 1893.6744 - kl_loss: 94.6136 - false_loss: 0.0787 - true_loss: 1.0551 - val_loss: 5383.2695 - val_reconstruction_loss: 1895.7740 - val_kl_loss: 99.9137 - val_false_loss: 10.9193 - val_true_loss: 1.1180\n",
      "Epoch 644/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.7793 - reconstruction_loss: 1893.7198 - kl_loss: 95.4644 - false_loss: 0.0786 - true_loss: 1.0551 - val_loss: 5382.9810 - val_reconstruction_loss: 1895.7736 - val_kl_loss: 99.9133 - val_false_loss: 10.9183 - val_true_loss: 1.1180\n",
      "Epoch 645/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.8801 - reconstruction_loss: 1893.3947 - kl_loss: 94.7482 - false_loss: 0.0786 - true_loss: 1.0551 - val_loss: 5382.6914 - val_reconstruction_loss: 1895.7731 - val_kl_loss: 99.9132 - val_false_loss: 10.9174 - val_true_loss: 1.1180\n",
      "Epoch 646/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2261.4985 - reconstruction_loss: 1893.4064 - kl_loss: 95.5012 - false_loss: 0.0786 - true_loss: 1.0550 - val_loss: 5382.4062 - val_reconstruction_loss: 1895.7725 - val_kl_loss: 99.9124 - val_false_loss: 10.9164 - val_true_loss: 1.1179\n",
      "Epoch 647/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.1491 - reconstruction_loss: 1893.5646 - kl_loss: 96.7598 - false_loss: 0.0786 - true_loss: 1.0550 - val_loss: 5382.1118 - val_reconstruction_loss: 1895.7721 - val_kl_loss: 99.9118 - val_false_loss: 10.9155 - val_true_loss: 1.1179\n",
      "Epoch 648/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2259.3999 - reconstruction_loss: 1893.4860 - kl_loss: 95.6488 - false_loss: 0.0786 - true_loss: 1.0550 - val_loss: 5381.8242 - val_reconstruction_loss: 1895.7715 - val_kl_loss: 99.9118 - val_false_loss: 10.9145 - val_true_loss: 1.1179\n",
      "Epoch 649/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2264.0812 - reconstruction_loss: 1893.4750 - kl_loss: 95.9978 - false_loss: 0.0786 - true_loss: 1.0550 - val_loss: 5381.5342 - val_reconstruction_loss: 1895.7711 - val_kl_loss: 99.9114 - val_false_loss: 10.9136 - val_true_loss: 1.1179\n",
      "Epoch 650/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2262.7438 - reconstruction_loss: 1894.3031 - kl_loss: 95.6075 - false_loss: 0.0786 - true_loss: 1.0550 - val_loss: 5381.2437 - val_reconstruction_loss: 1895.7708 - val_kl_loss: 99.9111 - val_false_loss: 10.9126 - val_true_loss: 1.1179\n",
      "Epoch 651/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2256.1850 - reconstruction_loss: 1894.1447 - kl_loss: 95.2612 - false_loss: 0.0786 - true_loss: 1.0549 - val_loss: 5380.9531 - val_reconstruction_loss: 1895.7703 - val_kl_loss: 99.9110 - val_false_loss: 10.9116 - val_true_loss: 1.1178\n",
      "Epoch 652/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.9695 - reconstruction_loss: 1893.4232 - kl_loss: 95.4585 - false_loss: 0.0786 - true_loss: 1.0549 - val_loss: 5380.6621 - val_reconstruction_loss: 1895.7698 - val_kl_loss: 99.9109 - val_false_loss: 10.9107 - val_true_loss: 1.1178\n",
      "Epoch 653/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2252.3787 - reconstruction_loss: 1893.5742 - kl_loss: 94.2901 - false_loss: 0.0786 - true_loss: 1.0549 - val_loss: 5380.3701 - val_reconstruction_loss: 1895.7692 - val_kl_loss: 99.9101 - val_false_loss: 10.9097 - val_true_loss: 1.1178\n",
      "Epoch 654/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2258.5393 - reconstruction_loss: 1893.2402 - kl_loss: 94.5432 - false_loss: 0.0786 - true_loss: 1.0549 - val_loss: 5380.0820 - val_reconstruction_loss: 1895.7688 - val_kl_loss: 99.9097 - val_false_loss: 10.9088 - val_true_loss: 1.1178\n",
      "Epoch 655/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.6195 - reconstruction_loss: 1893.3671 - kl_loss: 94.9156 - false_loss: 0.0786 - true_loss: 1.0549 - val_loss: 5379.7954 - val_reconstruction_loss: 1895.7682 - val_kl_loss: 99.9094 - val_false_loss: 10.9078 - val_true_loss: 1.1177\n",
      "Epoch 656/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2256.7302 - reconstruction_loss: 1893.9498 - kl_loss: 94.4703 - false_loss: 0.0786 - true_loss: 1.0548 - val_loss: 5379.5049 - val_reconstruction_loss: 1895.7678 - val_kl_loss: 99.9087 - val_false_loss: 10.9069 - val_true_loss: 1.1177\n",
      "Epoch 657/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.7947 - reconstruction_loss: 1893.5758 - kl_loss: 94.3041 - false_loss: 0.0786 - true_loss: 1.0548 - val_loss: 5379.2158 - val_reconstruction_loss: 1895.7675 - val_kl_loss: 99.9083 - val_false_loss: 10.9059 - val_true_loss: 1.1177\n",
      "Epoch 658/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2257.4886 - reconstruction_loss: 1893.3975 - kl_loss: 94.9547 - false_loss: 0.0786 - true_loss: 1.0548 - val_loss: 5378.9277 - val_reconstruction_loss: 1895.7670 - val_kl_loss: 99.9076 - val_false_loss: 10.9050 - val_true_loss: 1.1177\n",
      "Epoch 659/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.8191 - reconstruction_loss: 1893.1139 - kl_loss: 94.3326 - false_loss: 0.0786 - true_loss: 1.0548 - val_loss: 5378.6396 - val_reconstruction_loss: 1895.7664 - val_kl_loss: 99.9068 - val_false_loss: 10.9040 - val_true_loss: 1.1176\n",
      "Epoch 660/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.3596 - reconstruction_loss: 1893.1881 - kl_loss: 94.6714 - false_loss: 0.0786 - true_loss: 1.0548 - val_loss: 5378.3525 - val_reconstruction_loss: 1895.7660 - val_kl_loss: 99.9066 - val_false_loss: 10.9031 - val_true_loss: 1.1176\n",
      "Epoch 661/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2252.9095 - reconstruction_loss: 1894.0498 - kl_loss: 95.1465 - false_loss: 0.0786 - true_loss: 1.0547 - val_loss: 5378.0605 - val_reconstruction_loss: 1895.7654 - val_kl_loss: 99.9062 - val_false_loss: 10.9021 - val_true_loss: 1.1176\n",
      "Epoch 662/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.1444 - reconstruction_loss: 1893.5221 - kl_loss: 94.1510 - false_loss: 0.0786 - true_loss: 1.0547 - val_loss: 5377.7637 - val_reconstruction_loss: 1895.7650 - val_kl_loss: 99.9061 - val_false_loss: 10.9011 - val_true_loss: 1.1176\n",
      "Epoch 663/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2250.9525 - reconstruction_loss: 1892.8497 - kl_loss: 95.8594 - false_loss: 0.0786 - true_loss: 1.0547 - val_loss: 5377.4727 - val_reconstruction_loss: 1895.7644 - val_kl_loss: 99.9058 - val_false_loss: 10.9002 - val_true_loss: 1.1175\n",
      "Epoch 664/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.9841 - reconstruction_loss: 1893.2682 - kl_loss: 95.3626 - false_loss: 0.0786 - true_loss: 1.0547 - val_loss: 5377.1826 - val_reconstruction_loss: 1895.7640 - val_kl_loss: 99.9056 - val_false_loss: 10.8992 - val_true_loss: 1.1175\n",
      "Epoch 665/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.7870 - reconstruction_loss: 1893.7296 - kl_loss: 94.8649 - false_loss: 0.0786 - true_loss: 1.0547 - val_loss: 5376.8960 - val_reconstruction_loss: 1895.7635 - val_kl_loss: 99.9049 - val_false_loss: 10.8983 - val_true_loss: 1.1175\n",
      "Epoch 666/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.5226 - reconstruction_loss: 1893.6842 - kl_loss: 94.6687 - false_loss: 0.0785 - true_loss: 1.0546 - val_loss: 5376.6060 - val_reconstruction_loss: 1895.7632 - val_kl_loss: 99.9044 - val_false_loss: 10.8973 - val_true_loss: 1.1175\n",
      "Epoch 667/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.6978 - reconstruction_loss: 1893.1932 - kl_loss: 95.6256 - false_loss: 0.0785 - true_loss: 1.0546 - val_loss: 5376.3145 - val_reconstruction_loss: 1895.7626 - val_kl_loss: 99.9041 - val_false_loss: 10.8964 - val_true_loss: 1.1174\n",
      "Epoch 668/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2248.7127 - reconstruction_loss: 1893.2836 - kl_loss: 95.0745 - false_loss: 0.0785 - true_loss: 1.0546 - val_loss: 5376.0278 - val_reconstruction_loss: 1895.7620 - val_kl_loss: 99.9035 - val_false_loss: 10.8954 - val_true_loss: 1.1174\n",
      "Epoch 669/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.0139 - reconstruction_loss: 1893.2129 - kl_loss: 95.0055 - false_loss: 0.0785 - true_loss: 1.0546 - val_loss: 5375.7329 - val_reconstruction_loss: 1895.7617 - val_kl_loss: 99.9030 - val_false_loss: 10.8944 - val_true_loss: 1.1174\n",
      "Epoch 670/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.5609 - reconstruction_loss: 1893.3073 - kl_loss: 95.4424 - false_loss: 0.0785 - true_loss: 1.0545 - val_loss: 5375.4429 - val_reconstruction_loss: 1895.7611 - val_kl_loss: 99.9026 - val_false_loss: 10.8935 - val_true_loss: 1.1174\n",
      "Epoch 671/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.4681 - reconstruction_loss: 1893.1647 - kl_loss: 96.0204 - false_loss: 0.0785 - true_loss: 1.0545 - val_loss: 5375.1509 - val_reconstruction_loss: 1895.7607 - val_kl_loss: 99.9019 - val_false_loss: 10.8925 - val_true_loss: 1.1173\n",
      "Epoch 672/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.0386 - reconstruction_loss: 1893.1870 - kl_loss: 95.5664 - false_loss: 0.0785 - true_loss: 1.0545 - val_loss: 5374.8584 - val_reconstruction_loss: 1895.7601 - val_kl_loss: 99.9019 - val_false_loss: 10.8916 - val_true_loss: 1.1173\n",
      "Epoch 673/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.9266 - reconstruction_loss: 1893.0322 - kl_loss: 95.3162 - false_loss: 0.0785 - true_loss: 1.0545 - val_loss: 5374.5664 - val_reconstruction_loss: 1895.7598 - val_kl_loss: 99.9017 - val_false_loss: 10.8906 - val_true_loss: 1.1173\n",
      "Epoch 674/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.3542 - reconstruction_loss: 1893.1854 - kl_loss: 95.9987 - false_loss: 0.0785 - true_loss: 1.0544 - val_loss: 5374.2783 - val_reconstruction_loss: 1895.7592 - val_kl_loss: 99.9014 - val_false_loss: 10.8897 - val_true_loss: 1.1173\n",
      "Epoch 675/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.1758 - reconstruction_loss: 1893.2275 - kl_loss: 95.6616 - false_loss: 0.0785 - true_loss: 1.0544 - val_loss: 5373.9805 - val_reconstruction_loss: 1895.7588 - val_kl_loss: 99.9009 - val_false_loss: 10.8887 - val_true_loss: 1.1172\n",
      "Epoch 676/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.7783 - reconstruction_loss: 1893.2247 - kl_loss: 95.4766 - false_loss: 0.0785 - true_loss: 1.0544 - val_loss: 5373.6826 - val_reconstruction_loss: 1895.7583 - val_kl_loss: 99.9006 - val_false_loss: 10.8877 - val_true_loss: 1.1172\n",
      "Epoch 677/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2236.6969 - reconstruction_loss: 1893.3408 - kl_loss: 97.2574 - false_loss: 0.0785 - true_loss: 1.0544 - val_loss: 5373.3877 - val_reconstruction_loss: 1895.7579 - val_kl_loss: 99.9001 - val_false_loss: 10.8867 - val_true_loss: 1.1172\n",
      "Epoch 678/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.8947 - reconstruction_loss: 1893.3199 - kl_loss: 96.4913 - false_loss: 0.0785 - true_loss: 1.0543 - val_loss: 5373.0947 - val_reconstruction_loss: 1895.7573 - val_kl_loss: 99.9002 - val_false_loss: 10.8858 - val_true_loss: 1.1171\n",
      "Epoch 679/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.6945 - reconstruction_loss: 1892.9078 - kl_loss: 96.0225 - false_loss: 0.0785 - true_loss: 1.0543 - val_loss: 5372.8066 - val_reconstruction_loss: 1895.7570 - val_kl_loss: 99.8999 - val_false_loss: 10.8848 - val_true_loss: 1.1171\n",
      "Epoch 680/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.5085 - reconstruction_loss: 1892.6025 - kl_loss: 96.8161 - false_loss: 0.0785 - true_loss: 1.0543 - val_loss: 5372.5171 - val_reconstruction_loss: 1895.7562 - val_kl_loss: 99.8997 - val_false_loss: 10.8838 - val_true_loss: 1.1171\n",
      "Epoch 681/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.8209 - reconstruction_loss: 1893.1539 - kl_loss: 95.8942 - false_loss: 0.0785 - true_loss: 1.0543 - val_loss: 5372.2285 - val_reconstruction_loss: 1895.7560 - val_kl_loss: 99.8995 - val_false_loss: 10.8829 - val_true_loss: 1.1171\n",
      "Epoch 682/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.8675 - reconstruction_loss: 1892.9580 - kl_loss: 96.8081 - false_loss: 0.0785 - true_loss: 1.0542 - val_loss: 5371.9380 - val_reconstruction_loss: 1895.7552 - val_kl_loss: 99.8994 - val_false_loss: 10.8819 - val_true_loss: 1.1170\n",
      "Epoch 683/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.2584 - reconstruction_loss: 1893.3864 - kl_loss: 96.6530 - false_loss: 0.0785 - true_loss: 1.0542 - val_loss: 5371.6431 - val_reconstruction_loss: 1895.7548 - val_kl_loss: 99.8993 - val_false_loss: 10.8810 - val_true_loss: 1.1170\n",
      "Epoch 684/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.6214 - reconstruction_loss: 1893.3086 - kl_loss: 96.4007 - false_loss: 0.0785 - true_loss: 1.0542 - val_loss: 5371.3501 - val_reconstruction_loss: 1895.7543 - val_kl_loss: 99.8986 - val_false_loss: 10.8800 - val_true_loss: 1.1170\n",
      "Epoch 685/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2261.6878 - reconstruction_loss: 1892.8229 - kl_loss: 95.7190 - false_loss: 0.0785 - true_loss: 1.0542 - val_loss: 5371.0605 - val_reconstruction_loss: 1895.7539 - val_kl_loss: 99.8987 - val_false_loss: 10.8791 - val_true_loss: 1.1169\n",
      "Epoch 686/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2269.0617 - reconstruction_loss: 1893.0944 - kl_loss: 96.3288 - false_loss: 0.0785 - true_loss: 1.0542 - val_loss: 5370.7690 - val_reconstruction_loss: 1895.7535 - val_kl_loss: 99.8983 - val_false_loss: 10.8781 - val_true_loss: 1.1169\n",
      "Epoch 687/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.2302 - reconstruction_loss: 1893.0942 - kl_loss: 95.0754 - false_loss: 0.0784 - true_loss: 1.0541 - val_loss: 5370.4731 - val_reconstruction_loss: 1895.7529 - val_kl_loss: 99.8982 - val_false_loss: 10.8771 - val_true_loss: 1.1169\n",
      "Epoch 688/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.7665 - reconstruction_loss: 1893.4528 - kl_loss: 96.1205 - false_loss: 0.0784 - true_loss: 1.0541 - val_loss: 5370.1763 - val_reconstruction_loss: 1895.7526 - val_kl_loss: 99.8978 - val_false_loss: 10.8761 - val_true_loss: 1.1169\n",
      "Epoch 689/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.1575 - reconstruction_loss: 1893.4110 - kl_loss: 96.3847 - false_loss: 0.0784 - true_loss: 1.0541 - val_loss: 5369.8813 - val_reconstruction_loss: 1895.7520 - val_kl_loss: 99.8973 - val_false_loss: 10.8752 - val_true_loss: 1.1168\n",
      "Epoch 690/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2252.1042 - reconstruction_loss: 1893.2477 - kl_loss: 95.9886 - false_loss: 0.0784 - true_loss: 1.0541 - val_loss: 5369.5947 - val_reconstruction_loss: 1895.7513 - val_kl_loss: 99.8969 - val_false_loss: 10.8742 - val_true_loss: 1.1168\n",
      "Epoch 691/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.4829 - reconstruction_loss: 1892.7911 - kl_loss: 96.0153 - false_loss: 0.0784 - true_loss: 1.0540 - val_loss: 5369.3057 - val_reconstruction_loss: 1895.7509 - val_kl_loss: 99.8968 - val_false_loss: 10.8733 - val_true_loss: 1.1168\n",
      "Epoch 692/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2249.8876 - reconstruction_loss: 1892.6777 - kl_loss: 96.5632 - false_loss: 0.0784 - true_loss: 1.0540 - val_loss: 5369.0146 - val_reconstruction_loss: 1895.7505 - val_kl_loss: 99.8963 - val_false_loss: 10.8723 - val_true_loss: 1.1168\n",
      "Epoch 693/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.8914 - reconstruction_loss: 1893.3395 - kl_loss: 95.7645 - false_loss: 0.0784 - true_loss: 1.0540 - val_loss: 5368.7153 - val_reconstruction_loss: 1895.7499 - val_kl_loss: 99.8962 - val_false_loss: 10.8713 - val_true_loss: 1.1167\n",
      "Epoch 694/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.2074 - reconstruction_loss: 1893.0430 - kl_loss: 96.1650 - false_loss: 0.0784 - true_loss: 1.0540 - val_loss: 5368.4199 - val_reconstruction_loss: 1895.7494 - val_kl_loss: 99.8958 - val_false_loss: 10.8703 - val_true_loss: 1.1167\n",
      "Epoch 695/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.9782 - reconstruction_loss: 1892.9249 - kl_loss: 95.8428 - false_loss: 0.0784 - true_loss: 1.0540 - val_loss: 5368.1211 - val_reconstruction_loss: 1895.7488 - val_kl_loss: 99.8954 - val_false_loss: 10.8694 - val_true_loss: 1.1167\n",
      "Epoch 696/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.3373 - reconstruction_loss: 1893.4335 - kl_loss: 95.7002 - false_loss: 0.0784 - true_loss: 1.0539 - val_loss: 5367.8237 - val_reconstruction_loss: 1895.7483 - val_kl_loss: 99.8950 - val_false_loss: 10.8684 - val_true_loss: 1.1167\n",
      "Epoch 697/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1607 - reconstruction_loss: 1893.2145 - kl_loss: 95.8096 - false_loss: 0.0784 - true_loss: 1.0539 - val_loss: 5367.5298 - val_reconstruction_loss: 1895.7479 - val_kl_loss: 99.8945 - val_false_loss: 10.8674 - val_true_loss: 1.1167\n",
      "Epoch 698/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2264.8972 - reconstruction_loss: 1893.6006 - kl_loss: 94.9435 - false_loss: 0.0784 - true_loss: 1.0539 - val_loss: 5367.2358 - val_reconstruction_loss: 1895.7474 - val_kl_loss: 99.8941 - val_false_loss: 10.8664 - val_true_loss: 1.1166\n",
      "Epoch 699/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2253.8828 - reconstruction_loss: 1893.6947 - kl_loss: 95.6152 - false_loss: 0.0784 - true_loss: 1.0539 - val_loss: 5366.9414 - val_reconstruction_loss: 1895.7471 - val_kl_loss: 99.8936 - val_false_loss: 10.8655 - val_true_loss: 1.1166\n",
      "Epoch 700/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2252.3400 - reconstruction_loss: 1893.2012 - kl_loss: 94.8397 - false_loss: 0.0784 - true_loss: 1.0538 - val_loss: 5366.6509 - val_reconstruction_loss: 1895.7466 - val_kl_loss: 99.8928 - val_false_loss: 10.8645 - val_true_loss: 1.1166\n",
      "Epoch 701/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2251.0993 - reconstruction_loss: 1893.2920 - kl_loss: 95.5482 - false_loss: 0.0784 - true_loss: 1.0538 - val_loss: 5366.3574 - val_reconstruction_loss: 1895.7460 - val_kl_loss: 99.8926 - val_false_loss: 10.8635 - val_true_loss: 1.1166\n",
      "Epoch 702/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.5745 - reconstruction_loss: 1892.9088 - kl_loss: 95.2533 - false_loss: 0.0784 - true_loss: 1.0538 - val_loss: 5366.0649 - val_reconstruction_loss: 1895.7456 - val_kl_loss: 99.8925 - val_false_loss: 10.8626 - val_true_loss: 1.1165\n",
      "Epoch 703/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.4924 - reconstruction_loss: 1892.6698 - kl_loss: 96.2651 - false_loss: 0.0784 - true_loss: 1.0538 - val_loss: 5365.7749 - val_reconstruction_loss: 1895.7452 - val_kl_loss: 99.8921 - val_false_loss: 10.8616 - val_true_loss: 1.1165\n",
      "Epoch 704/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5076 - reconstruction_loss: 1892.5026 - kl_loss: 96.0053 - false_loss: 0.0784 - true_loss: 1.0537 - val_loss: 5365.4819 - val_reconstruction_loss: 1895.7448 - val_kl_loss: 99.8919 - val_false_loss: 10.8607 - val_true_loss: 1.1165\n",
      "Epoch 705/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.7910 - reconstruction_loss: 1892.7753 - kl_loss: 96.4500 - false_loss: 0.0784 - true_loss: 1.0537 - val_loss: 5365.1846 - val_reconstruction_loss: 1895.7440 - val_kl_loss: 99.8918 - val_false_loss: 10.8597 - val_true_loss: 1.1165\n",
      "Epoch 706/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.4238 - reconstruction_loss: 1893.1031 - kl_loss: 96.9185 - false_loss: 0.0784 - true_loss: 1.0537 - val_loss: 5364.8950 - val_reconstruction_loss: 1895.7438 - val_kl_loss: 99.8913 - val_false_loss: 10.8587 - val_true_loss: 1.1164\n",
      "Epoch 707/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.2643 - reconstruction_loss: 1893.5856 - kl_loss: 96.5909 - false_loss: 0.0783 - true_loss: 1.0537 - val_loss: 5364.6001 - val_reconstruction_loss: 1895.7433 - val_kl_loss: 99.8909 - val_false_loss: 10.8578 - val_true_loss: 1.1164\n",
      "Epoch 708/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.6236 - reconstruction_loss: 1893.0477 - kl_loss: 95.6111 - false_loss: 0.0783 - true_loss: 1.0536 - val_loss: 5364.3066 - val_reconstruction_loss: 1895.7429 - val_kl_loss: 99.8905 - val_false_loss: 10.8568 - val_true_loss: 1.1164\n",
      "Epoch 709/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.5480 - reconstruction_loss: 1893.1768 - kl_loss: 95.5788 - false_loss: 0.0783 - true_loss: 1.0536 - val_loss: 5364.0234 - val_reconstruction_loss: 1895.7426 - val_kl_loss: 99.8901 - val_false_loss: 10.8559 - val_true_loss: 1.1164\n",
      "Epoch 710/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2242.1838 - reconstruction_loss: 1893.3146 - kl_loss: 94.6940 - false_loss: 0.0783 - true_loss: 1.0536 - val_loss: 5363.7422 - val_reconstruction_loss: 1895.7421 - val_kl_loss: 99.8896 - val_false_loss: 10.8549 - val_true_loss: 1.1163\n",
      "Epoch 711/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.2216 - reconstruction_loss: 1893.0978 - kl_loss: 95.6957 - false_loss: 0.0783 - true_loss: 1.0536 - val_loss: 5363.4575 - val_reconstruction_loss: 1895.7416 - val_kl_loss: 99.8895 - val_false_loss: 10.8540 - val_true_loss: 1.1163\n",
      "Epoch 712/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.6307 - reconstruction_loss: 1893.1642 - kl_loss: 95.1834 - false_loss: 0.0783 - true_loss: 1.0535 - val_loss: 5363.1772 - val_reconstruction_loss: 1895.7411 - val_kl_loss: 99.8890 - val_false_loss: 10.8531 - val_true_loss: 1.1163\n",
      "Epoch 713/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2251.4629 - reconstruction_loss: 1892.8695 - kl_loss: 95.6357 - false_loss: 0.0783 - true_loss: 1.0535 - val_loss: 5362.8833 - val_reconstruction_loss: 1895.7406 - val_kl_loss: 99.8883 - val_false_loss: 10.8521 - val_true_loss: 1.1163\n",
      "Epoch 714/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.6462 - reconstruction_loss: 1892.5820 - kl_loss: 95.8151 - false_loss: 0.0783 - true_loss: 1.0535 - val_loss: 5362.5913 - val_reconstruction_loss: 1895.7401 - val_kl_loss: 99.8881 - val_false_loss: 10.8511 - val_true_loss: 1.1162\n",
      "Epoch 715/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.2722 - reconstruction_loss: 1892.5629 - kl_loss: 94.9810 - false_loss: 0.0783 - true_loss: 1.0535 - val_loss: 5362.3008 - val_reconstruction_loss: 1895.7395 - val_kl_loss: 99.8880 - val_false_loss: 10.8502 - val_true_loss: 1.1162\n",
      "Epoch 716/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.1923 - reconstruction_loss: 1892.3774 - kl_loss: 97.3002 - false_loss: 0.0783 - true_loss: 1.0535 - val_loss: 5362.0078 - val_reconstruction_loss: 1895.7390 - val_kl_loss: 99.8875 - val_false_loss: 10.8492 - val_true_loss: 1.1162\n",
      "Epoch 717/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.1417 - reconstruction_loss: 1892.3436 - kl_loss: 96.4370 - false_loss: 0.0783 - true_loss: 1.0534 - val_loss: 5361.7148 - val_reconstruction_loss: 1895.7384 - val_kl_loss: 99.8872 - val_false_loss: 10.8483 - val_true_loss: 1.1162\n",
      "Epoch 718/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.2615 - reconstruction_loss: 1892.3892 - kl_loss: 97.0352 - false_loss: 0.0783 - true_loss: 1.0534 - val_loss: 5361.4194 - val_reconstruction_loss: 1895.7380 - val_kl_loss: 99.8869 - val_false_loss: 10.8473 - val_true_loss: 1.1161\n",
      "Epoch 719/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.1649 - reconstruction_loss: 1892.5088 - kl_loss: 96.5248 - false_loss: 0.0783 - true_loss: 1.0534 - val_loss: 5361.1230 - val_reconstruction_loss: 1895.7377 - val_kl_loss: 99.8866 - val_false_loss: 10.8463 - val_true_loss: 1.1161\n",
      "Epoch 720/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.8610 - reconstruction_loss: 1892.6735 - kl_loss: 96.8339 - false_loss: 0.0783 - true_loss: 1.0533 - val_loss: 5360.8296 - val_reconstruction_loss: 1895.7371 - val_kl_loss: 99.8861 - val_false_loss: 10.8453 - val_true_loss: 1.1161\n",
      "Epoch 721/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.4282 - reconstruction_loss: 1892.3859 - kl_loss: 97.0141 - false_loss: 0.0783 - true_loss: 1.0533 - val_loss: 5360.5347 - val_reconstruction_loss: 1895.7367 - val_kl_loss: 99.8852 - val_false_loss: 10.8444 - val_true_loss: 1.1161\n",
      "Epoch 722/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.7043 - reconstruction_loss: 1893.4896 - kl_loss: 95.0909 - false_loss: 0.0783 - true_loss: 1.0533 - val_loss: 5360.2417 - val_reconstruction_loss: 1895.7363 - val_kl_loss: 99.8852 - val_false_loss: 10.8434 - val_true_loss: 1.1160\n",
      "Epoch 723/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.5072 - reconstruction_loss: 1893.1715 - kl_loss: 96.7933 - false_loss: 0.0783 - true_loss: 1.0533 - val_loss: 5359.9526 - val_reconstruction_loss: 1895.7357 - val_kl_loss: 99.8852 - val_false_loss: 10.8424 - val_true_loss: 1.1160\n",
      "Epoch 724/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.8328 - reconstruction_loss: 1892.6670 - kl_loss: 97.0892 - false_loss: 0.0783 - true_loss: 1.0532 - val_loss: 5359.6616 - val_reconstruction_loss: 1895.7351 - val_kl_loss: 99.8852 - val_false_loss: 10.8415 - val_true_loss: 1.1160\n",
      "Epoch 725/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.7719 - reconstruction_loss: 1892.7367 - kl_loss: 96.3016 - false_loss: 0.0783 - true_loss: 1.0532 - val_loss: 5359.3711 - val_reconstruction_loss: 1895.7347 - val_kl_loss: 99.8850 - val_false_loss: 10.8405 - val_true_loss: 1.1160\n",
      "Epoch 726/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.3037 - reconstruction_loss: 1892.9814 - kl_loss: 95.9877 - false_loss: 0.0783 - true_loss: 1.0532 - val_loss: 5359.0747 - val_reconstruction_loss: 1895.7343 - val_kl_loss: 99.8843 - val_false_loss: 10.8395 - val_true_loss: 1.1159\n",
      "Epoch 727/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.3874 - reconstruction_loss: 1893.2936 - kl_loss: 96.1257 - false_loss: 0.0783 - true_loss: 1.0532 - val_loss: 5358.7920 - val_reconstruction_loss: 1895.7336 - val_kl_loss: 99.8842 - val_false_loss: 10.8386 - val_true_loss: 1.1159\n",
      "Epoch 728/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2250.3792 - reconstruction_loss: 1892.8766 - kl_loss: 96.4667 - false_loss: 0.0782 - true_loss: 1.0532 - val_loss: 5358.5005 - val_reconstruction_loss: 1895.7333 - val_kl_loss: 99.8843 - val_false_loss: 10.8377 - val_true_loss: 1.1159\n",
      "Epoch 729/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2240.8261 - reconstruction_loss: 1892.8065 - kl_loss: 96.0179 - false_loss: 0.0782 - true_loss: 1.0531 - val_loss: 5358.2041 - val_reconstruction_loss: 1895.7327 - val_kl_loss: 99.8841 - val_false_loss: 10.8367 - val_true_loss: 1.1159\n",
      "Epoch 730/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.2505 - reconstruction_loss: 1892.4926 - kl_loss: 96.0381 - false_loss: 0.0782 - true_loss: 1.0531 - val_loss: 5357.9106 - val_reconstruction_loss: 1895.7321 - val_kl_loss: 99.8833 - val_false_loss: 10.8357 - val_true_loss: 1.1158\n",
      "Epoch 731/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.0469 - reconstruction_loss: 1892.4839 - kl_loss: 94.2881 - false_loss: 0.0782 - true_loss: 1.0531 - val_loss: 5357.6211 - val_reconstruction_loss: 1895.7316 - val_kl_loss: 99.8830 - val_false_loss: 10.8348 - val_true_loss: 1.1158\n",
      "Epoch 732/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.4693 - reconstruction_loss: 1892.8502 - kl_loss: 95.5404 - false_loss: 0.0782 - true_loss: 1.0531 - val_loss: 5357.3306 - val_reconstruction_loss: 1895.7312 - val_kl_loss: 99.8826 - val_false_loss: 10.8338 - val_true_loss: 1.1158\n",
      "Epoch 733/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.2717 - reconstruction_loss: 1892.7520 - kl_loss: 95.1044 - false_loss: 0.0782 - true_loss: 1.0530 - val_loss: 5357.0420 - val_reconstruction_loss: 1895.7308 - val_kl_loss: 99.8824 - val_false_loss: 10.8328 - val_true_loss: 1.1158\n",
      "Epoch 734/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.8446 - reconstruction_loss: 1892.6608 - kl_loss: 95.5967 - false_loss: 0.0782 - true_loss: 1.0530 - val_loss: 5356.7485 - val_reconstruction_loss: 1895.7301 - val_kl_loss: 99.8822 - val_false_loss: 10.8319 - val_true_loss: 1.1157\n",
      "Epoch 735/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2253.4872 - reconstruction_loss: 1892.6156 - kl_loss: 93.4050 - false_loss: 0.0782 - true_loss: 1.0530 - val_loss: 5356.4536 - val_reconstruction_loss: 1895.7297 - val_kl_loss: 99.8820 - val_false_loss: 10.8309 - val_true_loss: 1.1157\n",
      "Epoch 736/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.2042 - reconstruction_loss: 1892.3374 - kl_loss: 97.0805 - false_loss: 0.0782 - true_loss: 1.0530 - val_loss: 5356.1558 - val_reconstruction_loss: 1895.7291 - val_kl_loss: 99.8818 - val_false_loss: 10.8299 - val_true_loss: 1.1157\n",
      "Epoch 737/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.3022 - reconstruction_loss: 1892.6504 - kl_loss: 96.7120 - false_loss: 0.0782 - true_loss: 1.0529 - val_loss: 5355.8599 - val_reconstruction_loss: 1895.7288 - val_kl_loss: 99.8815 - val_false_loss: 10.8290 - val_true_loss: 1.1156\n",
      "Epoch 738/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.8832 - reconstruction_loss: 1892.6937 - kl_loss: 96.7231 - false_loss: 0.0782 - true_loss: 1.0529 - val_loss: 5355.5698 - val_reconstruction_loss: 1895.7283 - val_kl_loss: 99.8815 - val_false_loss: 10.8280 - val_true_loss: 1.1156\n",
      "Epoch 739/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.2595 - reconstruction_loss: 1892.4941 - kl_loss: 97.0364 - false_loss: 0.0782 - true_loss: 1.0529 - val_loss: 5355.2759 - val_reconstruction_loss: 1895.7278 - val_kl_loss: 99.8814 - val_false_loss: 10.8270 - val_true_loss: 1.1156\n",
      "Epoch 740/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.7093 - reconstruction_loss: 1893.0380 - kl_loss: 97.0752 - false_loss: 0.0782 - true_loss: 1.0529 - val_loss: 5354.9795 - val_reconstruction_loss: 1895.7273 - val_kl_loss: 99.8814 - val_false_loss: 10.8261 - val_true_loss: 1.1155\n",
      "Epoch 741/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.7771 - reconstruction_loss: 1892.8414 - kl_loss: 96.5578 - false_loss: 0.0782 - true_loss: 1.0528 - val_loss: 5354.6890 - val_reconstruction_loss: 1895.7268 - val_kl_loss: 99.8809 - val_false_loss: 10.8251 - val_true_loss: 1.1155\n",
      "Epoch 742/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.2564 - reconstruction_loss: 1892.6836 - kl_loss: 95.6440 - false_loss: 0.0782 - true_loss: 1.0528 - val_loss: 5354.3960 - val_reconstruction_loss: 1895.7262 - val_kl_loss: 99.8802 - val_false_loss: 10.8241 - val_true_loss: 1.1155\n",
      "Epoch 743/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2238.0396 - reconstruction_loss: 1893.2035 - kl_loss: 97.6673 - false_loss: 0.0782 - true_loss: 1.0528 - val_loss: 5354.1045 - val_reconstruction_loss: 1895.7257 - val_kl_loss: 99.8804 - val_false_loss: 10.8232 - val_true_loss: 1.1155\n",
      "Epoch 744/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.5740 - reconstruction_loss: 1892.4967 - kl_loss: 97.5143 - false_loss: 0.0782 - true_loss: 1.0528 - val_loss: 5353.8110 - val_reconstruction_loss: 1895.7252 - val_kl_loss: 99.8800 - val_false_loss: 10.8222 - val_true_loss: 1.1154\n",
      "Epoch 745/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.4673 - reconstruction_loss: 1892.1849 - kl_loss: 97.7694 - false_loss: 0.0782 - true_loss: 1.0527 - val_loss: 5353.5176 - val_reconstruction_loss: 1895.7246 - val_kl_loss: 99.8797 - val_false_loss: 10.8212 - val_true_loss: 1.1154\n",
      "Epoch 746/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.7674 - reconstruction_loss: 1892.5521 - kl_loss: 95.9165 - false_loss: 0.0782 - true_loss: 1.0527 - val_loss: 5353.2227 - val_reconstruction_loss: 1895.7240 - val_kl_loss: 99.8797 - val_false_loss: 10.8203 - val_true_loss: 1.1154\n",
      "Epoch 747/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.6218 - reconstruction_loss: 1892.4066 - kl_loss: 96.8585 - false_loss: 0.0782 - true_loss: 1.0527 - val_loss: 5352.9253 - val_reconstruction_loss: 1895.7235 - val_kl_loss: 99.8790 - val_false_loss: 10.8193 - val_true_loss: 1.1154\n",
      "Epoch 748/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.5024 - reconstruction_loss: 1892.5708 - kl_loss: 96.6682 - false_loss: 0.0781 - true_loss: 1.0527 - val_loss: 5352.6362 - val_reconstruction_loss: 1895.7230 - val_kl_loss: 99.8786 - val_false_loss: 10.8183 - val_true_loss: 1.1153\n",
      "Epoch 749/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.0381 - reconstruction_loss: 1892.3677 - kl_loss: 96.1789 - false_loss: 0.0781 - true_loss: 1.0526 - val_loss: 5352.3491 - val_reconstruction_loss: 1895.7224 - val_kl_loss: 99.8784 - val_false_loss: 10.8174 - val_true_loss: 1.1153\n",
      "Epoch 750/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.2606 - reconstruction_loss: 1892.4779 - kl_loss: 96.1880 - false_loss: 0.0781 - true_loss: 1.0526 - val_loss: 5352.0542 - val_reconstruction_loss: 1895.7219 - val_kl_loss: 99.8784 - val_false_loss: 10.8164 - val_true_loss: 1.1153\n",
      "Epoch 751/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.3907 - reconstruction_loss: 1892.7963 - kl_loss: 96.0662 - false_loss: 0.0781 - true_loss: 1.0526 - val_loss: 5351.7690 - val_reconstruction_loss: 1895.7216 - val_kl_loss: 99.8780 - val_false_loss: 10.8155 - val_true_loss: 1.1153\n",
      "Epoch 752/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.9696 - reconstruction_loss: 1893.0039 - kl_loss: 95.2698 - false_loss: 0.0781 - true_loss: 1.0526 - val_loss: 5351.4761 - val_reconstruction_loss: 1895.7207 - val_kl_loss: 99.8778 - val_false_loss: 10.8145 - val_true_loss: 1.1152\n",
      "Epoch 753/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2255.4120 - reconstruction_loss: 1892.7866 - kl_loss: 93.3605 - false_loss: 0.0781 - true_loss: 1.0525 - val_loss: 5351.1841 - val_reconstruction_loss: 1895.7203 - val_kl_loss: 99.8774 - val_false_loss: 10.8135 - val_true_loss: 1.1152\n",
      "Epoch 754/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2261.6033 - reconstruction_loss: 1892.4362 - kl_loss: 96.2416 - false_loss: 0.0781 - true_loss: 1.0525 - val_loss: 5350.8921 - val_reconstruction_loss: 1895.7197 - val_kl_loss: 99.8766 - val_false_loss: 10.8126 - val_true_loss: 1.1152\n",
      "Epoch 755/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.1767 - reconstruction_loss: 1892.4215 - kl_loss: 96.3651 - false_loss: 0.0781 - true_loss: 1.0525 - val_loss: 5350.5991 - val_reconstruction_loss: 1895.7192 - val_kl_loss: 99.8765 - val_false_loss: 10.8116 - val_true_loss: 1.1152\n",
      "Epoch 756/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2242.4207 - reconstruction_loss: 1892.1471 - kl_loss: 95.9956 - false_loss: 0.0781 - true_loss: 1.0525 - val_loss: 5350.3091 - val_reconstruction_loss: 1895.7186 - val_kl_loss: 99.8761 - val_false_loss: 10.8107 - val_true_loss: 1.1152\n",
      "Epoch 757/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.3509 - reconstruction_loss: 1892.2311 - kl_loss: 96.2634 - false_loss: 0.0781 - true_loss: 1.0524 - val_loss: 5350.0161 - val_reconstruction_loss: 1895.7181 - val_kl_loss: 99.8756 - val_false_loss: 10.8097 - val_true_loss: 1.1151\n",
      "Epoch 758/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.5838 - reconstruction_loss: 1892.4205 - kl_loss: 96.4812 - false_loss: 0.0781 - true_loss: 1.0524 - val_loss: 5349.7261 - val_reconstruction_loss: 1895.7175 - val_kl_loss: 99.8756 - val_false_loss: 10.8087 - val_true_loss: 1.1151\n",
      "Epoch 759/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.2778 - reconstruction_loss: 1892.5385 - kl_loss: 96.4730 - false_loss: 0.0781 - true_loss: 1.0524 - val_loss: 5349.4316 - val_reconstruction_loss: 1895.7172 - val_kl_loss: 99.8755 - val_false_loss: 10.8078 - val_true_loss: 1.1151\n",
      "Epoch 760/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7561 - reconstruction_loss: 1892.1566 - kl_loss: 96.7300 - false_loss: 0.0781 - true_loss: 1.0524 - val_loss: 5349.1440 - val_reconstruction_loss: 1895.7164 - val_kl_loss: 99.8757 - val_false_loss: 10.8068 - val_true_loss: 1.1150\n",
      "Epoch 761/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.7890 - reconstruction_loss: 1892.2012 - kl_loss: 97.6216 - false_loss: 0.0781 - true_loss: 1.0523 - val_loss: 5348.8545 - val_reconstruction_loss: 1895.7158 - val_kl_loss: 99.8758 - val_false_loss: 10.8059 - val_true_loss: 1.1150\n",
      "Epoch 762/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.9059 - reconstruction_loss: 1892.8271 - kl_loss: 98.1690 - false_loss: 0.0781 - true_loss: 1.0523 - val_loss: 5348.5703 - val_reconstruction_loss: 1895.7157 - val_kl_loss: 99.8758 - val_false_loss: 10.8049 - val_true_loss: 1.1150\n",
      "Epoch 763/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5990 - reconstruction_loss: 1892.5824 - kl_loss: 96.9161 - false_loss: 0.0781 - true_loss: 1.0523 - val_loss: 5348.2798 - val_reconstruction_loss: 1895.7150 - val_kl_loss: 99.8760 - val_false_loss: 10.8040 - val_true_loss: 1.1150\n",
      "Epoch 764/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.4136 - reconstruction_loss: 1892.3979 - kl_loss: 97.8637 - false_loss: 0.0781 - true_loss: 1.0523 - val_loss: 5347.9897 - val_reconstruction_loss: 1895.7144 - val_kl_loss: 99.8759 - val_false_loss: 10.8030 - val_true_loss: 1.1149\n",
      "Epoch 765/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5267 - reconstruction_loss: 1892.4736 - kl_loss: 97.8729 - false_loss: 0.0781 - true_loss: 1.0522 - val_loss: 5347.6968 - val_reconstruction_loss: 1895.7140 - val_kl_loss: 99.8758 - val_false_loss: 10.8021 - val_true_loss: 1.1149\n",
      "Epoch 766/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.1083 - reconstruction_loss: 1892.7871 - kl_loss: 97.1490 - false_loss: 0.0781 - true_loss: 1.0522 - val_loss: 5347.4058 - val_reconstruction_loss: 1895.7135 - val_kl_loss: 99.8756 - val_false_loss: 10.8011 - val_true_loss: 1.1149\n",
      "Epoch 767/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.0056 - reconstruction_loss: 1892.4468 - kl_loss: 96.5846 - false_loss: 0.0780 - true_loss: 1.0522 - val_loss: 5347.1113 - val_reconstruction_loss: 1895.7131 - val_kl_loss: 99.8756 - val_false_loss: 10.8001 - val_true_loss: 1.1148\n",
      "Epoch 768/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5960 - reconstruction_loss: 1892.2959 - kl_loss: 97.3379 - false_loss: 0.0780 - true_loss: 1.0521 - val_loss: 5346.8228 - val_reconstruction_loss: 1895.7126 - val_kl_loss: 99.8755 - val_false_loss: 10.7992 - val_true_loss: 1.1148\n",
      "Epoch 769/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.1477 - reconstruction_loss: 1892.1527 - kl_loss: 96.7408 - false_loss: 0.0780 - true_loss: 1.0521 - val_loss: 5346.5293 - val_reconstruction_loss: 1895.7120 - val_kl_loss: 99.8752 - val_false_loss: 10.7982 - val_true_loss: 1.1148\n",
      "Epoch 770/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.6894 - reconstruction_loss: 1892.0106 - kl_loss: 97.1926 - false_loss: 0.0780 - true_loss: 1.0521 - val_loss: 5346.2417 - val_reconstruction_loss: 1895.7114 - val_kl_loss: 99.8749 - val_false_loss: 10.7973 - val_true_loss: 1.1148\n",
      "Epoch 771/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2243.8614 - reconstruction_loss: 1892.4341 - kl_loss: 96.3340 - false_loss: 0.0780 - true_loss: 1.0521 - val_loss: 5345.9521 - val_reconstruction_loss: 1895.7109 - val_kl_loss: 99.8745 - val_false_loss: 10.7963 - val_true_loss: 1.1147\n",
      "Epoch 772/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.0461 - reconstruction_loss: 1892.4137 - kl_loss: 96.4818 - false_loss: 0.0780 - true_loss: 1.0520 - val_loss: 5345.6577 - val_reconstruction_loss: 1895.7103 - val_kl_loss: 99.8745 - val_false_loss: 10.7953 - val_true_loss: 1.1147\n",
      "Epoch 773/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.8139 - reconstruction_loss: 1892.4323 - kl_loss: 97.5768 - false_loss: 0.0780 - true_loss: 1.0520 - val_loss: 5345.3647 - val_reconstruction_loss: 1895.7100 - val_kl_loss: 99.8748 - val_false_loss: 10.7944 - val_true_loss: 1.1147\n",
      "Epoch 774/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6696 - reconstruction_loss: 1892.1022 - kl_loss: 98.1159 - false_loss: 0.0780 - true_loss: 1.0520 - val_loss: 5345.0771 - val_reconstruction_loss: 1895.7092 - val_kl_loss: 99.8748 - val_false_loss: 10.7934 - val_true_loss: 1.1146\n",
      "Epoch 775/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.6935 - reconstruction_loss: 1892.2764 - kl_loss: 97.1838 - false_loss: 0.0780 - true_loss: 1.0520 - val_loss: 5344.7881 - val_reconstruction_loss: 1895.7089 - val_kl_loss: 99.8741 - val_false_loss: 10.7925 - val_true_loss: 1.1146\n",
      "Epoch 776/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.1048 - reconstruction_loss: 1892.3600 - kl_loss: 98.1825 - false_loss: 0.0780 - true_loss: 1.0519 - val_loss: 5344.4980 - val_reconstruction_loss: 1895.7083 - val_kl_loss: 99.8744 - val_false_loss: 10.7915 - val_true_loss: 1.1146\n",
      "Epoch 777/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.6409 - reconstruction_loss: 1892.7103 - kl_loss: 97.3308 - false_loss: 0.0780 - true_loss: 1.0519 - val_loss: 5344.2065 - val_reconstruction_loss: 1895.7078 - val_kl_loss: 99.8744 - val_false_loss: 10.7906 - val_true_loss: 1.1145\n",
      "Epoch 778/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4925 - reconstruction_loss: 1892.5560 - kl_loss: 98.7499 - false_loss: 0.0780 - true_loss: 1.0519 - val_loss: 5343.9136 - val_reconstruction_loss: 1895.7074 - val_kl_loss: 99.8746 - val_false_loss: 10.7896 - val_true_loss: 1.1145\n",
      "Epoch 779/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5133 - reconstruction_loss: 1892.5215 - kl_loss: 97.6723 - false_loss: 0.0780 - true_loss: 1.0518 - val_loss: 5343.6284 - val_reconstruction_loss: 1895.7067 - val_kl_loss: 99.8746 - val_false_loss: 10.7887 - val_true_loss: 1.1145\n",
      "Epoch 780/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2100 - reconstruction_loss: 1892.4371 - kl_loss: 97.8062 - false_loss: 0.0780 - true_loss: 1.0518 - val_loss: 5343.3403 - val_reconstruction_loss: 1895.7063 - val_kl_loss: 99.8744 - val_false_loss: 10.7877 - val_true_loss: 1.1145\n",
      "Epoch 781/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0040 - reconstruction_loss: 1892.5736 - kl_loss: 97.0212 - false_loss: 0.0780 - true_loss: 1.0518 - val_loss: 5343.0483 - val_reconstruction_loss: 1895.7059 - val_kl_loss: 99.8742 - val_false_loss: 10.7868 - val_true_loss: 1.1144\n",
      "Epoch 782/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.3816 - reconstruction_loss: 1892.4819 - kl_loss: 98.4459 - false_loss: 0.0780 - true_loss: 1.0517 - val_loss: 5342.7642 - val_reconstruction_loss: 1895.7054 - val_kl_loss: 99.8744 - val_false_loss: 10.7858 - val_true_loss: 1.1144\n",
      "Epoch 783/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.4771 - reconstruction_loss: 1892.1930 - kl_loss: 98.1788 - false_loss: 0.0780 - true_loss: 1.0517 - val_loss: 5342.4761 - val_reconstruction_loss: 1895.7048 - val_kl_loss: 99.8744 - val_false_loss: 10.7849 - val_true_loss: 1.1144\n",
      "Epoch 784/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7729 - reconstruction_loss: 1892.3271 - kl_loss: 97.8636 - false_loss: 0.0780 - true_loss: 1.0517 - val_loss: 5342.1855 - val_reconstruction_loss: 1895.7045 - val_kl_loss: 99.8742 - val_false_loss: 10.7839 - val_true_loss: 1.1143\n",
      "Epoch 785/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4768 - reconstruction_loss: 1892.7611 - kl_loss: 98.7584 - false_loss: 0.0780 - true_loss: 1.0517 - val_loss: 5341.8989 - val_reconstruction_loss: 1895.7040 - val_kl_loss: 99.8744 - val_false_loss: 10.7830 - val_true_loss: 1.1143\n",
      "Epoch 786/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.0207 - reconstruction_loss: 1892.3121 - kl_loss: 98.3557 - false_loss: 0.0780 - true_loss: 1.0516 - val_loss: 5341.6094 - val_reconstruction_loss: 1895.7034 - val_kl_loss: 99.8741 - val_false_loss: 10.7820 - val_true_loss: 1.1143\n",
      "Epoch 787/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5944 - reconstruction_loss: 1891.8658 - kl_loss: 97.1206 - false_loss: 0.0779 - true_loss: 1.0516 - val_loss: 5341.3218 - val_reconstruction_loss: 1895.7029 - val_kl_loss: 99.8741 - val_false_loss: 10.7811 - val_true_loss: 1.1142\n",
      "Epoch 788/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.8386 - reconstruction_loss: 1891.8857 - kl_loss: 95.5079 - false_loss: 0.0779 - true_loss: 1.0516 - val_loss: 5341.0356 - val_reconstruction_loss: 1895.7023 - val_kl_loss: 99.8737 - val_false_loss: 10.7801 - val_true_loss: 1.1142\n",
      "Epoch 789/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4572 - reconstruction_loss: 1891.9326 - kl_loss: 97.0456 - false_loss: 0.0779 - true_loss: 1.0515 - val_loss: 5340.7480 - val_reconstruction_loss: 1895.7017 - val_kl_loss: 99.8733 - val_false_loss: 10.7792 - val_true_loss: 1.1142\n",
      "Epoch 790/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.0952 - reconstruction_loss: 1892.0170 - kl_loss: 98.7530 - false_loss: 0.0779 - true_loss: 1.0515 - val_loss: 5340.4595 - val_reconstruction_loss: 1895.7013 - val_kl_loss: 99.8733 - val_false_loss: 10.7782 - val_true_loss: 1.1141\n",
      "Epoch 791/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.3076 - reconstruction_loss: 1892.8011 - kl_loss: 97.2303 - false_loss: 0.0779 - true_loss: 1.0515 - val_loss: 5340.1724 - val_reconstruction_loss: 1895.7008 - val_kl_loss: 99.8732 - val_false_loss: 10.7773 - val_true_loss: 1.1141\n",
      "Epoch 792/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.2094 - reconstruction_loss: 1892.4364 - kl_loss: 98.6265 - false_loss: 0.0779 - true_loss: 1.0515 - val_loss: 5339.8857 - val_reconstruction_loss: 1895.7002 - val_kl_loss: 99.8734 - val_false_loss: 10.7763 - val_true_loss: 1.1141\n",
      "Epoch 793/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.1947 - reconstruction_loss: 1891.9995 - kl_loss: 99.1341 - false_loss: 0.0779 - true_loss: 1.0514 - val_loss: 5339.5991 - val_reconstruction_loss: 1895.6996 - val_kl_loss: 99.8733 - val_false_loss: 10.7754 - val_true_loss: 1.1140\n",
      "Epoch 794/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0903 - reconstruction_loss: 1892.2168 - kl_loss: 100.3029 - false_loss: 0.0779 - true_loss: 1.0514 - val_loss: 5339.3071 - val_reconstruction_loss: 1895.6993 - val_kl_loss: 99.8734 - val_false_loss: 10.7744 - val_true_loss: 1.1140\n",
      "Epoch 795/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.0856 - reconstruction_loss: 1891.9171 - kl_loss: 100.3791 - false_loss: 0.0779 - true_loss: 1.0514 - val_loss: 5339.0244 - val_reconstruction_loss: 1895.6987 - val_kl_loss: 99.8735 - val_false_loss: 10.7735 - val_true_loss: 1.1140\n",
      "Epoch 796/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.6927 - reconstruction_loss: 1892.2870 - kl_loss: 98.7095 - false_loss: 0.0779 - true_loss: 1.0513 - val_loss: 5338.7363 - val_reconstruction_loss: 1895.6982 - val_kl_loss: 99.8735 - val_false_loss: 10.7726 - val_true_loss: 1.1140\n",
      "Epoch 797/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.0329 - reconstruction_loss: 1892.2959 - kl_loss: 97.8630 - false_loss: 0.0779 - true_loss: 1.0513 - val_loss: 5338.4448 - val_reconstruction_loss: 1895.6976 - val_kl_loss: 99.8734 - val_false_loss: 10.7716 - val_true_loss: 1.1139\n",
      "Epoch 798/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.5743 - reconstruction_loss: 1892.3473 - kl_loss: 96.4170 - false_loss: 0.0779 - true_loss: 1.0513 - val_loss: 5338.1587 - val_reconstruction_loss: 1895.6973 - val_kl_loss: 99.8732 - val_false_loss: 10.7707 - val_true_loss: 1.1139\n",
      "Epoch 799/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.9940 - reconstruction_loss: 1892.9434 - kl_loss: 97.6858 - false_loss: 0.0779 - true_loss: 1.0513 - val_loss: 5337.8706 - val_reconstruction_loss: 1895.6968 - val_kl_loss: 99.8731 - val_false_loss: 10.7697 - val_true_loss: 1.1139\n",
      "Epoch 800/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2231.6537 - reconstruction_loss: 1892.5859 - kl_loss: 97.7804 - false_loss: 0.0779 - true_loss: 1.0512 - val_loss: 5337.5811 - val_reconstruction_loss: 1895.6964 - val_kl_loss: 99.8730 - val_false_loss: 10.7688 - val_true_loss: 1.1139\n",
      "Epoch 801/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.7126 - reconstruction_loss: 1892.1240 - kl_loss: 98.1438 - false_loss: 0.0779 - true_loss: 1.0512 - val_loss: 5337.2930 - val_reconstruction_loss: 1895.6958 - val_kl_loss: 99.8727 - val_false_loss: 10.7678 - val_true_loss: 1.1138\n",
      "Epoch 802/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.1487 - reconstruction_loss: 1892.0591 - kl_loss: 98.4289 - false_loss: 0.0779 - true_loss: 1.0512 - val_loss: 5337.0073 - val_reconstruction_loss: 1895.6951 - val_kl_loss: 99.8726 - val_false_loss: 10.7669 - val_true_loss: 1.1138\n",
      "Epoch 803/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2239.9751 - reconstruction_loss: 1891.9790 - kl_loss: 98.0285 - false_loss: 0.0779 - true_loss: 1.0511 - val_loss: 5336.7188 - val_reconstruction_loss: 1895.6947 - val_kl_loss: 99.8722 - val_false_loss: 10.7659 - val_true_loss: 1.1138\n",
      "Epoch 804/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.4404 - reconstruction_loss: 1892.2377 - kl_loss: 97.1364 - false_loss: 0.0779 - true_loss: 1.0511 - val_loss: 5336.4258 - val_reconstruction_loss: 1895.6941 - val_kl_loss: 99.8718 - val_false_loss: 10.7649 - val_true_loss: 1.1138\n",
      "Epoch 805/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2235.7708 - reconstruction_loss: 1892.0084 - kl_loss: 97.2471 - false_loss: 0.0779 - true_loss: 1.0511 - val_loss: 5336.1348 - val_reconstruction_loss: 1895.6935 - val_kl_loss: 99.8720 - val_false_loss: 10.7640 - val_true_loss: 1.1137\n",
      "Epoch 806/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2241.9461 - reconstruction_loss: 1892.1283 - kl_loss: 97.4035 - false_loss: 0.0778 - true_loss: 1.0511 - val_loss: 5335.8486 - val_reconstruction_loss: 1895.6927 - val_kl_loss: 99.8714 - val_false_loss: 10.7630 - val_true_loss: 1.1137\n",
      "Epoch 807/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.5704 - reconstruction_loss: 1891.8177 - kl_loss: 95.6168 - false_loss: 0.0778 - true_loss: 1.0510 - val_loss: 5335.5654 - val_reconstruction_loss: 1895.6924 - val_kl_loss: 99.8716 - val_false_loss: 10.7621 - val_true_loss: 1.1137\n",
      "Epoch 808/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2240.4651 - reconstruction_loss: 1891.8173 - kl_loss: 95.7053 - false_loss: 0.0778 - true_loss: 1.0510 - val_loss: 5335.2793 - val_reconstruction_loss: 1895.6920 - val_kl_loss: 99.8716 - val_false_loss: 10.7612 - val_true_loss: 1.1136\n",
      "Epoch 809/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.5851 - reconstruction_loss: 1891.9579 - kl_loss: 97.5927 - false_loss: 0.0778 - true_loss: 1.0510 - val_loss: 5334.9897 - val_reconstruction_loss: 1895.6913 - val_kl_loss: 99.8715 - val_false_loss: 10.7602 - val_true_loss: 1.1136\n",
      "Epoch 810/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1776 - reconstruction_loss: 1891.9772 - kl_loss: 98.4826 - false_loss: 0.0778 - true_loss: 1.0510 - val_loss: 5334.7070 - val_reconstruction_loss: 1895.6909 - val_kl_loss: 99.8713 - val_false_loss: 10.7593 - val_true_loss: 1.1136\n",
      "Epoch 811/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.0197 - reconstruction_loss: 1891.9781 - kl_loss: 97.9366 - false_loss: 0.0778 - true_loss: 1.0509 - val_loss: 5334.4214 - val_reconstruction_loss: 1895.6906 - val_kl_loss: 99.8714 - val_false_loss: 10.7583 - val_true_loss: 1.1136\n",
      "Epoch 812/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1910 - reconstruction_loss: 1892.1744 - kl_loss: 97.0555 - false_loss: 0.0778 - true_loss: 1.0509 - val_loss: 5334.1357 - val_reconstruction_loss: 1895.6901 - val_kl_loss: 99.8713 - val_false_loss: 10.7574 - val_true_loss: 1.1135\n",
      "Epoch 813/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.4816 - reconstruction_loss: 1891.7017 - kl_loss: 98.8179 - false_loss: 0.0778 - true_loss: 1.0509 - val_loss: 5333.8530 - val_reconstruction_loss: 1895.6895 - val_kl_loss: 99.8710 - val_false_loss: 10.7565 - val_true_loss: 1.1135\n",
      "Epoch 814/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.4365 - reconstruction_loss: 1891.8304 - kl_loss: 99.0663 - false_loss: 0.0778 - true_loss: 1.0508 - val_loss: 5333.5649 - val_reconstruction_loss: 1895.6891 - val_kl_loss: 99.8708 - val_false_loss: 10.7555 - val_true_loss: 1.1135\n",
      "Epoch 815/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.5251 - reconstruction_loss: 1892.6387 - kl_loss: 98.4335 - false_loss: 0.0778 - true_loss: 1.0508 - val_loss: 5333.2793 - val_reconstruction_loss: 1895.6884 - val_kl_loss: 99.8708 - val_false_loss: 10.7546 - val_true_loss: 1.1134\n",
      "Epoch 816/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2243.7478 - reconstruction_loss: 1892.2313 - kl_loss: 97.3927 - false_loss: 0.0778 - true_loss: 1.0508 - val_loss: 5332.9917 - val_reconstruction_loss: 1895.6877 - val_kl_loss: 99.8705 - val_false_loss: 10.7536 - val_true_loss: 1.1134\n",
      "Epoch 817/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.6836 - reconstruction_loss: 1892.0748 - kl_loss: 97.4482 - false_loss: 0.0778 - true_loss: 1.0508 - val_loss: 5332.7095 - val_reconstruction_loss: 1895.6874 - val_kl_loss: 99.8705 - val_false_loss: 10.7527 - val_true_loss: 1.1134\n",
      "Epoch 818/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.0746 - reconstruction_loss: 1892.1913 - kl_loss: 97.9358 - false_loss: 0.0778 - true_loss: 1.0507 - val_loss: 5332.4248 - val_reconstruction_loss: 1895.6869 - val_kl_loss: 99.8705 - val_false_loss: 10.7518 - val_true_loss: 1.1134\n",
      "Epoch 819/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.2813 - reconstruction_loss: 1891.8864 - kl_loss: 98.0666 - false_loss: 0.0778 - true_loss: 1.0507 - val_loss: 5332.1406 - val_reconstruction_loss: 1895.6860 - val_kl_loss: 99.8701 - val_false_loss: 10.7508 - val_true_loss: 1.1133\n",
      "Epoch 820/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0951 - reconstruction_loss: 1891.9463 - kl_loss: 96.0820 - false_loss: 0.0778 - true_loss: 1.0507 - val_loss: 5331.8579 - val_reconstruction_loss: 1895.6857 - val_kl_loss: 99.8699 - val_false_loss: 10.7499 - val_true_loss: 1.1133\n",
      "Epoch 821/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.6124 - reconstruction_loss: 1891.6509 - kl_loss: 97.8645 - false_loss: 0.0778 - true_loss: 1.0507 - val_loss: 5331.5698 - val_reconstruction_loss: 1895.6852 - val_kl_loss: 99.8701 - val_false_loss: 10.7490 - val_true_loss: 1.1133\n",
      "Epoch 822/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.0162 - reconstruction_loss: 1892.2897 - kl_loss: 98.9926 - false_loss: 0.0778 - true_loss: 1.0506 - val_loss: 5331.2773 - val_reconstruction_loss: 1895.6846 - val_kl_loss: 99.8702 - val_false_loss: 10.7480 - val_true_loss: 1.1132\n",
      "Epoch 823/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.5752 - reconstruction_loss: 1892.1176 - kl_loss: 98.7037 - false_loss: 0.0778 - true_loss: 1.0506 - val_loss: 5330.9883 - val_reconstruction_loss: 1895.6840 - val_kl_loss: 99.8702 - val_false_loss: 10.7470 - val_true_loss: 1.1132\n",
      "Epoch 824/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.3134 - reconstruction_loss: 1892.3766 - kl_loss: 99.4194 - false_loss: 0.0778 - true_loss: 1.0506 - val_loss: 5330.6982 - val_reconstruction_loss: 1895.6836 - val_kl_loss: 99.8697 - val_false_loss: 10.7461 - val_true_loss: 1.1132\n",
      "Epoch 825/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.5177 - reconstruction_loss: 1892.1520 - kl_loss: 98.8670 - false_loss: 0.0777 - true_loss: 1.0505 - val_loss: 5330.4155 - val_reconstruction_loss: 1895.6831 - val_kl_loss: 99.8697 - val_false_loss: 10.7452 - val_true_loss: 1.1131\n",
      "Epoch 826/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.8462 - reconstruction_loss: 1891.9008 - kl_loss: 97.7335 - false_loss: 0.0777 - true_loss: 1.0505 - val_loss: 5330.1387 - val_reconstruction_loss: 1895.6827 - val_kl_loss: 99.8696 - val_false_loss: 10.7442 - val_true_loss: 1.1131\n",
      "Epoch 827/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3236 - reconstruction_loss: 1891.7611 - kl_loss: 98.6722 - false_loss: 0.0777 - true_loss: 1.0505 - val_loss: 5329.8599 - val_reconstruction_loss: 1895.6824 - val_kl_loss: 99.8695 - val_false_loss: 10.7433 - val_true_loss: 1.1131\n",
      "Epoch 828/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.2115 - reconstruction_loss: 1892.0127 - kl_loss: 98.3312 - false_loss: 0.0777 - true_loss: 1.0504 - val_loss: 5329.5806 - val_reconstruction_loss: 1895.6816 - val_kl_loss: 99.8695 - val_false_loss: 10.7424 - val_true_loss: 1.1131\n",
      "Epoch 829/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4777 - reconstruction_loss: 1892.3384 - kl_loss: 98.2891 - false_loss: 0.0777 - true_loss: 1.0504 - val_loss: 5329.3052 - val_reconstruction_loss: 1895.6810 - val_kl_loss: 99.8698 - val_false_loss: 10.7415 - val_true_loss: 1.1130\n",
      "Epoch 830/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3300 - reconstruction_loss: 1892.3483 - kl_loss: 99.0252 - false_loss: 0.0777 - true_loss: 1.0504 - val_loss: 5329.0269 - val_reconstruction_loss: 1895.6807 - val_kl_loss: 99.8698 - val_false_loss: 10.7406 - val_true_loss: 1.1130\n",
      "Epoch 831/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.2164 - reconstruction_loss: 1892.3818 - kl_loss: 99.3368 - false_loss: 0.0777 - true_loss: 1.0503 - val_loss: 5328.7495 - val_reconstruction_loss: 1895.6802 - val_kl_loss: 99.8696 - val_false_loss: 10.7397 - val_true_loss: 1.1130\n",
      "Epoch 832/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0667 - reconstruction_loss: 1892.3068 - kl_loss: 98.7460 - false_loss: 0.0777 - true_loss: 1.0503 - val_loss: 5328.4653 - val_reconstruction_loss: 1895.6796 - val_kl_loss: 99.8694 - val_false_loss: 10.7387 - val_true_loss: 1.1129\n",
      "Epoch 833/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4144 - reconstruction_loss: 1891.8242 - kl_loss: 98.0000 - false_loss: 0.0777 - true_loss: 1.0503 - val_loss: 5328.1816 - val_reconstruction_loss: 1895.6792 - val_kl_loss: 99.8691 - val_false_loss: 10.7378 - val_true_loss: 1.1129\n",
      "Epoch 834/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.8760 - reconstruction_loss: 1891.9000 - kl_loss: 98.9519 - false_loss: 0.0777 - true_loss: 1.0502 - val_loss: 5327.8984 - val_reconstruction_loss: 1895.6786 - val_kl_loss: 99.8692 - val_false_loss: 10.7369 - val_true_loss: 1.1129\n",
      "Epoch 835/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5977 - reconstruction_loss: 1891.6406 - kl_loss: 99.0314 - false_loss: 0.0777 - true_loss: 1.0502 - val_loss: 5327.6157 - val_reconstruction_loss: 1895.6781 - val_kl_loss: 99.8692 - val_false_loss: 10.7359 - val_true_loss: 1.1128\n",
      "Epoch 836/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.0829 - reconstruction_loss: 1892.1201 - kl_loss: 97.4294 - false_loss: 0.0777 - true_loss: 1.0502 - val_loss: 5327.3325 - val_reconstruction_loss: 1895.6775 - val_kl_loss: 99.8691 - val_false_loss: 10.7350 - val_true_loss: 1.1128\n",
      "Epoch 837/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0822 - reconstruction_loss: 1892.9727 - kl_loss: 97.9251 - false_loss: 0.0777 - true_loss: 1.0502 - val_loss: 5327.0479 - val_reconstruction_loss: 1895.6772 - val_kl_loss: 99.8690 - val_false_loss: 10.7341 - val_true_loss: 1.1128\n",
      "Epoch 838/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.5372 - reconstruction_loss: 1893.7642 - kl_loss: 97.4896 - false_loss: 0.0777 - true_loss: 1.0501 - val_loss: 5326.7642 - val_reconstruction_loss: 1895.6764 - val_kl_loss: 99.8685 - val_false_loss: 10.7331 - val_true_loss: 1.1127\n",
      "Epoch 839/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5999 - reconstruction_loss: 1892.3558 - kl_loss: 97.1557 - false_loss: 0.0777 - true_loss: 1.0501 - val_loss: 5326.4810 - val_reconstruction_loss: 1895.6760 - val_kl_loss: 99.8686 - val_false_loss: 10.7322 - val_true_loss: 1.1127\n",
      "Epoch 840/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.1377 - reconstruction_loss: 1892.0082 - kl_loss: 96.6729 - false_loss: 0.0777 - true_loss: 1.0501 - val_loss: 5326.2007 - val_reconstruction_loss: 1895.6757 - val_kl_loss: 99.8684 - val_false_loss: 10.7313 - val_true_loss: 1.1127\n",
      "Epoch 841/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.6284 - reconstruction_loss: 1891.9000 - kl_loss: 97.7335 - false_loss: 0.0777 - true_loss: 1.0501 - val_loss: 5325.9214 - val_reconstruction_loss: 1895.6752 - val_kl_loss: 99.8687 - val_false_loss: 10.7304 - val_true_loss: 1.1126\n",
      "Epoch 842/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.4528 - reconstruction_loss: 1891.7573 - kl_loss: 99.1997 - false_loss: 0.0777 - true_loss: 1.0500 - val_loss: 5325.6362 - val_reconstruction_loss: 1895.6746 - val_kl_loss: 99.8690 - val_false_loss: 10.7294 - val_true_loss: 1.1126\n",
      "Epoch 843/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.5400 - reconstruction_loss: 1891.7080 - kl_loss: 98.6397 - false_loss: 0.0777 - true_loss: 1.0500 - val_loss: 5325.3511 - val_reconstruction_loss: 1895.6742 - val_kl_loss: 99.8687 - val_false_loss: 10.7285 - val_true_loss: 1.1126\n",
      "Epoch 844/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.2154 - reconstruction_loss: 1891.7953 - kl_loss: 98.4199 - false_loss: 0.0776 - true_loss: 1.0500 - val_loss: 5325.0713 - val_reconstruction_loss: 1895.6736 - val_kl_loss: 99.8688 - val_false_loss: 10.7276 - val_true_loss: 1.1125\n",
      "Epoch 845/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2241.3619 - reconstruction_loss: 1892.4088 - kl_loss: 99.1929 - false_loss: 0.0776 - true_loss: 1.0499 - val_loss: 5324.7910 - val_reconstruction_loss: 1895.6731 - val_kl_loss: 99.8689 - val_false_loss: 10.7267 - val_true_loss: 1.1125\n",
      "Epoch 846/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2237.0295 - reconstruction_loss: 1892.3158 - kl_loss: 97.9775 - false_loss: 0.0776 - true_loss: 1.0499 - val_loss: 5324.5068 - val_reconstruction_loss: 1895.6727 - val_kl_loss: 99.8691 - val_false_loss: 10.7257 - val_true_loss: 1.1125\n",
      "Epoch 847/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.1475 - reconstruction_loss: 1892.5414 - kl_loss: 98.1016 - false_loss: 0.0776 - true_loss: 1.0499 - val_loss: 5324.2246 - val_reconstruction_loss: 1895.6722 - val_kl_loss: 99.8689 - val_false_loss: 10.7248 - val_true_loss: 1.1125\n",
      "Epoch 848/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2239.8324 - reconstruction_loss: 1892.1664 - kl_loss: 98.2472 - false_loss: 0.0776 - true_loss: 1.0498 - val_loss: 5323.9443 - val_reconstruction_loss: 1895.6719 - val_kl_loss: 99.8688 - val_false_loss: 10.7239 - val_true_loss: 1.1124\n",
      "Epoch 849/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.4277 - reconstruction_loss: 1892.1792 - kl_loss: 95.9430 - false_loss: 0.0776 - true_loss: 1.0498 - val_loss: 5323.6636 - val_reconstruction_loss: 1895.6715 - val_kl_loss: 99.8685 - val_false_loss: 10.7229 - val_true_loss: 1.1124\n",
      "Epoch 850/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.3200 - reconstruction_loss: 1891.6693 - kl_loss: 95.2275 - false_loss: 0.0776 - true_loss: 1.0498 - val_loss: 5323.3774 - val_reconstruction_loss: 1895.6709 - val_kl_loss: 99.8689 - val_false_loss: 10.7220 - val_true_loss: 1.1124\n",
      "Epoch 851/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.8104 - reconstruction_loss: 1891.4562 - kl_loss: 98.0854 - false_loss: 0.0776 - true_loss: 1.0498 - val_loss: 5323.0933 - val_reconstruction_loss: 1895.6702 - val_kl_loss: 99.8690 - val_false_loss: 10.7211 - val_true_loss: 1.1124\n",
      "Epoch 852/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1568 - reconstruction_loss: 1891.4928 - kl_loss: 97.1134 - false_loss: 0.0776 - true_loss: 1.0497 - val_loss: 5322.8052 - val_reconstruction_loss: 1895.6696 - val_kl_loss: 99.8689 - val_false_loss: 10.7201 - val_true_loss: 1.1123\n",
      "Epoch 853/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.9266 - reconstruction_loss: 1891.6110 - kl_loss: 97.0384 - false_loss: 0.0776 - true_loss: 1.0497 - val_loss: 5322.5190 - val_reconstruction_loss: 1895.6692 - val_kl_loss: 99.8682 - val_false_loss: 10.7192 - val_true_loss: 1.1123\n",
      "Epoch 854/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.3836 - reconstruction_loss: 1892.4388 - kl_loss: 95.0159 - false_loss: 0.0776 - true_loss: 1.0497 - val_loss: 5322.2344 - val_reconstruction_loss: 1895.6686 - val_kl_loss: 99.8680 - val_false_loss: 10.7182 - val_true_loss: 1.1123\n",
      "Epoch 855/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.9543 - reconstruction_loss: 1892.7328 - kl_loss: 97.3459 - false_loss: 0.0776 - true_loss: 1.0497 - val_loss: 5321.9507 - val_reconstruction_loss: 1895.6683 - val_kl_loss: 99.8680 - val_false_loss: 10.7173 - val_true_loss: 1.1122\n",
      "Epoch 856/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.1501 - reconstruction_loss: 1892.1718 - kl_loss: 98.2025 - false_loss: 0.0776 - true_loss: 1.0496 - val_loss: 5321.6714 - val_reconstruction_loss: 1895.6677 - val_kl_loss: 99.8680 - val_false_loss: 10.7164 - val_true_loss: 1.1122\n",
      "Epoch 857/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.5381 - reconstruction_loss: 1892.0421 - kl_loss: 98.2964 - false_loss: 0.0776 - true_loss: 1.0496 - val_loss: 5321.3857 - val_reconstruction_loss: 1895.6674 - val_kl_loss: 99.8678 - val_false_loss: 10.7154 - val_true_loss: 1.1122\n",
      "Epoch 858/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3171 - reconstruction_loss: 1891.9146 - kl_loss: 97.8568 - false_loss: 0.0776 - true_loss: 1.0496 - val_loss: 5321.0991 - val_reconstruction_loss: 1895.6669 - val_kl_loss: 99.8677 - val_false_loss: 10.7145 - val_true_loss: 1.1121\n",
      "Epoch 859/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.9681 - reconstruction_loss: 1891.6571 - kl_loss: 97.7922 - false_loss: 0.0776 - true_loss: 1.0496 - val_loss: 5320.8218 - val_reconstruction_loss: 1895.6663 - val_kl_loss: 99.8679 - val_false_loss: 10.7136 - val_true_loss: 1.1121\n",
      "Epoch 860/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2233.9462 - reconstruction_loss: 1891.4868 - kl_loss: 98.5110 - false_loss: 0.0776 - true_loss: 1.0495 - val_loss: 5320.5386 - val_reconstruction_loss: 1895.6656 - val_kl_loss: 99.8679 - val_false_loss: 10.7126 - val_true_loss: 1.1121\n",
      "Epoch 861/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.9426 - reconstruction_loss: 1891.8759 - kl_loss: 97.9451 - false_loss: 0.0776 - true_loss: 1.0495 - val_loss: 5320.2539 - val_reconstruction_loss: 1895.6652 - val_kl_loss: 99.8673 - val_false_loss: 10.7117 - val_true_loss: 1.1121\n",
      "Epoch 862/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.1853 - reconstruction_loss: 1892.3975 - kl_loss: 97.7435 - false_loss: 0.0776 - true_loss: 1.0495 - val_loss: 5319.9756 - val_reconstruction_loss: 1895.6648 - val_kl_loss: 99.8675 - val_false_loss: 10.7108 - val_true_loss: 1.1120\n",
      "Epoch 863/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.4927 - reconstruction_loss: 1892.0508 - kl_loss: 98.0412 - false_loss: 0.0776 - true_loss: 1.0494 - val_loss: 5319.6963 - val_reconstruction_loss: 1895.6639 - val_kl_loss: 99.8671 - val_false_loss: 10.7099 - val_true_loss: 1.1120\n",
      "Epoch 864/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.5577 - reconstruction_loss: 1891.9545 - kl_loss: 96.0651 - false_loss: 0.0775 - true_loss: 1.0494 - val_loss: 5319.4131 - val_reconstruction_loss: 1895.6636 - val_kl_loss: 99.8672 - val_false_loss: 10.7089 - val_true_loss: 1.1120\n",
      "Epoch 865/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2252.9007 - reconstruction_loss: 1892.1508 - kl_loss: 95.8492 - false_loss: 0.0775 - true_loss: 1.0494 - val_loss: 5319.1309 - val_reconstruction_loss: 1895.6631 - val_kl_loss: 99.8667 - val_false_loss: 10.7080 - val_true_loss: 1.1120\n",
      "Epoch 866/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2263.2768 - reconstruction_loss: 1891.7324 - kl_loss: 95.4694 - false_loss: 0.0775 - true_loss: 1.0494 - val_loss: 5318.8491 - val_reconstruction_loss: 1895.6625 - val_kl_loss: 99.8664 - val_false_loss: 10.7071 - val_true_loss: 1.1119\n",
      "Epoch 867/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.2024 - reconstruction_loss: 1891.8754 - kl_loss: 95.4636 - false_loss: 0.0775 - true_loss: 1.0494 - val_loss: 5318.5620 - val_reconstruction_loss: 1895.6619 - val_kl_loss: 99.8661 - val_false_loss: 10.7061 - val_true_loss: 1.1119\n",
      "Epoch 868/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.0876 - reconstruction_loss: 1892.2054 - kl_loss: 97.1334 - false_loss: 0.0775 - true_loss: 1.0493 - val_loss: 5318.2827 - val_reconstruction_loss: 1895.6615 - val_kl_loss: 99.8657 - val_false_loss: 10.7052 - val_true_loss: 1.1119\n",
      "Epoch 869/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2236.1885 - reconstruction_loss: 1892.1416 - kl_loss: 98.0735 - false_loss: 0.0775 - true_loss: 1.0493 - val_loss: 5318.0020 - val_reconstruction_loss: 1895.6610 - val_kl_loss: 99.8658 - val_false_loss: 10.7043 - val_true_loss: 1.1119\n",
      "Epoch 870/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.2750 - reconstruction_loss: 1891.7643 - kl_loss: 98.0703 - false_loss: 0.0775 - true_loss: 1.0493 - val_loss: 5317.7202 - val_reconstruction_loss: 1895.6606 - val_kl_loss: 99.8659 - val_false_loss: 10.7034 - val_true_loss: 1.1118\n",
      "Epoch 871/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.0457 - reconstruction_loss: 1891.4097 - kl_loss: 98.4271 - false_loss: 0.0775 - true_loss: 1.0492 - val_loss: 5317.4360 - val_reconstruction_loss: 1895.6603 - val_kl_loss: 99.8659 - val_false_loss: 10.7024 - val_true_loss: 1.1118\n",
      "Epoch 872/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.1967 - reconstruction_loss: 1891.2775 - kl_loss: 98.9698 - false_loss: 0.0775 - true_loss: 1.0492 - val_loss: 5317.1533 - val_reconstruction_loss: 1895.6597 - val_kl_loss: 99.8660 - val_false_loss: 10.7015 - val_true_loss: 1.1118\n",
      "Epoch 873/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.7798 - reconstruction_loss: 1891.8041 - kl_loss: 97.9011 - false_loss: 0.0775 - true_loss: 1.0492 - val_loss: 5316.8716 - val_reconstruction_loss: 1895.6589 - val_kl_loss: 99.8662 - val_false_loss: 10.7006 - val_true_loss: 1.1117\n",
      "Epoch 874/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.7726 - reconstruction_loss: 1891.5762 - kl_loss: 98.2214 - false_loss: 0.0775 - true_loss: 1.0491 - val_loss: 5316.5889 - val_reconstruction_loss: 1895.6586 - val_kl_loss: 99.8661 - val_false_loss: 10.6996 - val_true_loss: 1.1117\n",
      "Epoch 875/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.0383 - reconstruction_loss: 1891.6764 - kl_loss: 97.4879 - false_loss: 0.0775 - true_loss: 1.0491 - val_loss: 5316.3042 - val_reconstruction_loss: 1895.6580 - val_kl_loss: 99.8658 - val_false_loss: 10.6987 - val_true_loss: 1.1117\n",
      "Epoch 876/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.6328 - reconstruction_loss: 1891.4482 - kl_loss: 97.9279 - false_loss: 0.0775 - true_loss: 1.0491 - val_loss: 5316.0225 - val_reconstruction_loss: 1895.6573 - val_kl_loss: 99.8663 - val_false_loss: 10.6978 - val_true_loss: 1.1116\n",
      "Epoch 877/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.4396 - reconstruction_loss: 1891.4750 - kl_loss: 97.7522 - false_loss: 0.0775 - true_loss: 1.0491 - val_loss: 5315.7412 - val_reconstruction_loss: 1895.6569 - val_kl_loss: 99.8666 - val_false_loss: 10.6968 - val_true_loss: 1.1116\n",
      "Epoch 878/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.1631 - reconstruction_loss: 1891.3203 - kl_loss: 97.7515 - false_loss: 0.0775 - true_loss: 1.0490 - val_loss: 5315.4580 - val_reconstruction_loss: 1895.6562 - val_kl_loss: 99.8668 - val_false_loss: 10.6959 - val_true_loss: 1.1116\n",
      "Epoch 879/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.6482 - reconstruction_loss: 1891.8605 - kl_loss: 96.8067 - false_loss: 0.0775 - true_loss: 1.0490 - val_loss: 5315.1743 - val_reconstruction_loss: 1895.6556 - val_kl_loss: 99.8668 - val_false_loss: 10.6950 - val_true_loss: 1.1116\n",
      "Epoch 880/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.3553 - reconstruction_loss: 1891.3745 - kl_loss: 98.5705 - false_loss: 0.0775 - true_loss: 1.0490 - val_loss: 5314.8911 - val_reconstruction_loss: 1895.6553 - val_kl_loss: 99.8670 - val_false_loss: 10.6941 - val_true_loss: 1.1115\n",
      "Epoch 881/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.5016 - reconstruction_loss: 1891.8011 - kl_loss: 99.5635 - false_loss: 0.0775 - true_loss: 1.0489 - val_loss: 5314.6094 - val_reconstruction_loss: 1895.6548 - val_kl_loss: 99.8670 - val_false_loss: 10.6931 - val_true_loss: 1.1115\n",
      "Epoch 882/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4189 - reconstruction_loss: 1892.3599 - kl_loss: 98.1843 - false_loss: 0.0775 - true_loss: 1.0489 - val_loss: 5314.3257 - val_reconstruction_loss: 1895.6544 - val_kl_loss: 99.8665 - val_false_loss: 10.6922 - val_true_loss: 1.1115\n",
      "Epoch 883/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.9880 - reconstruction_loss: 1892.1416 - kl_loss: 99.0200 - false_loss: 0.0774 - true_loss: 1.0489 - val_loss: 5314.0430 - val_reconstruction_loss: 1895.6541 - val_kl_loss: 99.8664 - val_false_loss: 10.6913 - val_true_loss: 1.1114\n",
      "Epoch 884/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8828 - reconstruction_loss: 1891.3047 - kl_loss: 98.5211 - false_loss: 0.0774 - true_loss: 1.0488 - val_loss: 5313.7603 - val_reconstruction_loss: 1895.6534 - val_kl_loss: 99.8665 - val_false_loss: 10.6903 - val_true_loss: 1.1114\n",
      "Epoch 885/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2228.1492 - reconstruction_loss: 1891.3970 - kl_loss: 98.6803 - false_loss: 0.0774 - true_loss: 1.0488 - val_loss: 5313.4780 - val_reconstruction_loss: 1895.6530 - val_kl_loss: 99.8668 - val_false_loss: 10.6894 - val_true_loss: 1.1114\n",
      "Epoch 886/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.4949 - reconstruction_loss: 1891.9635 - kl_loss: 100.0233 - false_loss: 0.0774 - true_loss: 1.0488 - val_loss: 5313.1948 - val_reconstruction_loss: 1895.6523 - val_kl_loss: 99.8668 - val_false_loss: 10.6885 - val_true_loss: 1.1113\n",
      "Epoch 887/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.2107 - reconstruction_loss: 1891.9049 - kl_loss: 99.4811 - false_loss: 0.0774 - true_loss: 1.0488 - val_loss: 5312.9136 - val_reconstruction_loss: 1895.6520 - val_kl_loss: 99.8669 - val_false_loss: 10.6875 - val_true_loss: 1.1113\n",
      "Epoch 888/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.6184 - reconstruction_loss: 1891.5094 - kl_loss: 97.0820 - false_loss: 0.0774 - true_loss: 1.0487 - val_loss: 5312.6318 - val_reconstruction_loss: 1895.6515 - val_kl_loss: 99.8664 - val_false_loss: 10.6866 - val_true_loss: 1.1113\n",
      "Epoch 889/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.3702 - reconstruction_loss: 1891.8790 - kl_loss: 98.3437 - false_loss: 0.0774 - true_loss: 1.0487 - val_loss: 5312.3501 - val_reconstruction_loss: 1895.6511 - val_kl_loss: 99.8669 - val_false_loss: 10.6857 - val_true_loss: 1.1112\n",
      "Epoch 890/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7334 - reconstruction_loss: 1892.0659 - kl_loss: 98.8335 - false_loss: 0.0774 - true_loss: 1.0487 - val_loss: 5312.0659 - val_reconstruction_loss: 1895.6508 - val_kl_loss: 99.8669 - val_false_loss: 10.6847 - val_true_loss: 1.1112\n",
      "Epoch 891/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.1908 - reconstruction_loss: 1891.5853 - kl_loss: 98.4500 - false_loss: 0.0774 - true_loss: 1.0486 - val_loss: 5311.7842 - val_reconstruction_loss: 1895.6503 - val_kl_loss: 99.8671 - val_false_loss: 10.6838 - val_true_loss: 1.1112\n",
      "Epoch 892/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.8527 - reconstruction_loss: 1891.4264 - kl_loss: 100.0713 - false_loss: 0.0774 - true_loss: 1.0486 - val_loss: 5311.5005 - val_reconstruction_loss: 1895.6497 - val_kl_loss: 99.8670 - val_false_loss: 10.6829 - val_true_loss: 1.1112\n",
      "Epoch 893/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.4910 - reconstruction_loss: 1891.7738 - kl_loss: 98.2338 - false_loss: 0.0774 - true_loss: 1.0486 - val_loss: 5311.2134 - val_reconstruction_loss: 1895.6493 - val_kl_loss: 99.8671 - val_false_loss: 10.6819 - val_true_loss: 1.1111\n",
      "Epoch 894/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.5732 - reconstruction_loss: 1891.3125 - kl_loss: 98.2482 - false_loss: 0.0774 - true_loss: 1.0485 - val_loss: 5310.9336 - val_reconstruction_loss: 1895.6487 - val_kl_loss: 99.8670 - val_false_loss: 10.6810 - val_true_loss: 1.1111\n",
      "Epoch 895/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.7544 - reconstruction_loss: 1891.5835 - kl_loss: 99.2739 - false_loss: 0.0774 - true_loss: 1.0485 - val_loss: 5310.6484 - val_reconstruction_loss: 1895.6482 - val_kl_loss: 99.8671 - val_false_loss: 10.6801 - val_true_loss: 1.1111\n",
      "Epoch 896/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.9117 - reconstruction_loss: 1891.7847 - kl_loss: 98.8268 - false_loss: 0.0774 - true_loss: 1.0485 - val_loss: 5310.3638 - val_reconstruction_loss: 1895.6478 - val_kl_loss: 99.8671 - val_false_loss: 10.6791 - val_true_loss: 1.1110\n",
      "Epoch 897/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.3235 - reconstruction_loss: 1891.8461 - kl_loss: 98.9765 - false_loss: 0.0774 - true_loss: 1.0485 - val_loss: 5310.0781 - val_reconstruction_loss: 1895.6475 - val_kl_loss: 99.8670 - val_false_loss: 10.6782 - val_true_loss: 1.1110\n",
      "Epoch 898/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.2687 - reconstruction_loss: 1891.9132 - kl_loss: 98.5214 - false_loss: 0.0774 - true_loss: 1.0484 - val_loss: 5309.7944 - val_reconstruction_loss: 1895.6469 - val_kl_loss: 99.8670 - val_false_loss: 10.6773 - val_true_loss: 1.1110\n",
      "Epoch 899/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.4021 - reconstruction_loss: 1892.1382 - kl_loss: 99.4765 - false_loss: 0.0774 - true_loss: 1.0484 - val_loss: 5309.5127 - val_reconstruction_loss: 1895.6464 - val_kl_loss: 99.8668 - val_false_loss: 10.6763 - val_true_loss: 1.1109\n",
      "Epoch 900/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.8606 - reconstruction_loss: 1891.9476 - kl_loss: 97.6027 - false_loss: 0.0774 - true_loss: 1.0484 - val_loss: 5309.2295 - val_reconstruction_loss: 1895.6458 - val_kl_loss: 99.8668 - val_false_loss: 10.6754 - val_true_loss: 1.1109\n",
      "Epoch 901/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.8657 - reconstruction_loss: 1891.5363 - kl_loss: 98.5431 - false_loss: 0.0773 - true_loss: 1.0483 - val_loss: 5308.9443 - val_reconstruction_loss: 1895.6454 - val_kl_loss: 99.8666 - val_false_loss: 10.6745 - val_true_loss: 1.1109\n",
      "Epoch 902/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.5945 - reconstruction_loss: 1891.5459 - kl_loss: 98.5612 - false_loss: 0.0773 - true_loss: 1.0483 - val_loss: 5308.6616 - val_reconstruction_loss: 1895.6448 - val_kl_loss: 99.8666 - val_false_loss: 10.6735 - val_true_loss: 1.1108\n",
      "Epoch 903/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.4610 - reconstruction_loss: 1891.5736 - kl_loss: 96.9410 - false_loss: 0.0773 - true_loss: 1.0483 - val_loss: 5308.3779 - val_reconstruction_loss: 1895.6443 - val_kl_loss: 99.8664 - val_false_loss: 10.6726 - val_true_loss: 1.1108\n",
      "Epoch 904/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.3794 - reconstruction_loss: 1891.4462 - kl_loss: 98.2068 - false_loss: 0.0773 - true_loss: 1.0483 - val_loss: 5308.0952 - val_reconstruction_loss: 1895.6437 - val_kl_loss: 99.8663 - val_false_loss: 10.6717 - val_true_loss: 1.1108\n",
      "Epoch 905/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3861 - reconstruction_loss: 1891.5839 - kl_loss: 98.0937 - false_loss: 0.0773 - true_loss: 1.0482 - val_loss: 5307.8091 - val_reconstruction_loss: 1895.6433 - val_kl_loss: 99.8663 - val_false_loss: 10.6707 - val_true_loss: 1.1108\n",
      "Epoch 906/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8037 - reconstruction_loss: 1891.4414 - kl_loss: 98.5360 - false_loss: 0.0773 - true_loss: 1.0482 - val_loss: 5307.5239 - val_reconstruction_loss: 1895.6429 - val_kl_loss: 99.8664 - val_false_loss: 10.6698 - val_true_loss: 1.1107\n",
      "Epoch 907/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.1999 - reconstruction_loss: 1891.5850 - kl_loss: 96.8571 - false_loss: 0.0773 - true_loss: 1.0482 - val_loss: 5307.2417 - val_reconstruction_loss: 1895.6421 - val_kl_loss: 99.8657 - val_false_loss: 10.6689 - val_true_loss: 1.1107\n",
      "Epoch 908/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2236.8489 - reconstruction_loss: 1891.7535 - kl_loss: 95.7193 - false_loss: 0.0773 - true_loss: 1.0481 - val_loss: 5306.9561 - val_reconstruction_loss: 1895.6416 - val_kl_loss: 99.8651 - val_false_loss: 10.6679 - val_true_loss: 1.1107\n",
      "Epoch 909/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.9498 - reconstruction_loss: 1892.1991 - kl_loss: 96.8142 - false_loss: 0.0773 - true_loss: 1.0481 - val_loss: 5306.6680 - val_reconstruction_loss: 1895.6412 - val_kl_loss: 99.8650 - val_false_loss: 10.6670 - val_true_loss: 1.1106\n",
      "Epoch 910/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.1043 - reconstruction_loss: 1891.4928 - kl_loss: 97.2799 - false_loss: 0.0773 - true_loss: 1.0481 - val_loss: 5306.3794 - val_reconstruction_loss: 1895.6409 - val_kl_loss: 99.8645 - val_false_loss: 10.6660 - val_true_loss: 1.1106\n",
      "Epoch 911/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.5699 - reconstruction_loss: 1891.5273 - kl_loss: 97.3780 - false_loss: 0.0773 - true_loss: 1.0481 - val_loss: 5306.0972 - val_reconstruction_loss: 1895.6403 - val_kl_loss: 99.8647 - val_false_loss: 10.6651 - val_true_loss: 1.1106\n",
      "Epoch 912/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2232.8910 - reconstruction_loss: 1891.4161 - kl_loss: 99.2284 - false_loss: 0.0773 - true_loss: 1.0480 - val_loss: 5305.8149 - val_reconstruction_loss: 1895.6398 - val_kl_loss: 99.8650 - val_false_loss: 10.6642 - val_true_loss: 1.1106\n",
      "Epoch 913/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.6057 - reconstruction_loss: 1891.8739 - kl_loss: 100.0171 - false_loss: 0.0773 - true_loss: 1.0480 - val_loss: 5305.5332 - val_reconstruction_loss: 1895.6392 - val_kl_loss: 99.8648 - val_false_loss: 10.6632 - val_true_loss: 1.1105\n",
      "Epoch 914/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2230.1646 - reconstruction_loss: 1891.8180 - kl_loss: 98.2070 - false_loss: 0.0773 - true_loss: 1.0480 - val_loss: 5305.2476 - val_reconstruction_loss: 1895.6385 - val_kl_loss: 99.8650 - val_false_loss: 10.6623 - val_true_loss: 1.1105\n",
      "Epoch 915/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.5961 - reconstruction_loss: 1891.4888 - kl_loss: 98.6958 - false_loss: 0.0773 - true_loss: 1.0479 - val_loss: 5304.9600 - val_reconstruction_loss: 1895.6379 - val_kl_loss: 99.8648 - val_false_loss: 10.6614 - val_true_loss: 1.1105\n",
      "Epoch 916/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8244 - reconstruction_loss: 1891.2162 - kl_loss: 99.5058 - false_loss: 0.0773 - true_loss: 1.0479 - val_loss: 5304.6768 - val_reconstruction_loss: 1895.6376 - val_kl_loss: 99.8652 - val_false_loss: 10.6604 - val_true_loss: 1.1104\n",
      "Epoch 917/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.9415 - reconstruction_loss: 1891.2266 - kl_loss: 100.5809 - false_loss: 0.0773 - true_loss: 1.0479 - val_loss: 5304.3901 - val_reconstruction_loss: 1895.6371 - val_kl_loss: 99.8652 - val_false_loss: 10.6595 - val_true_loss: 1.1104\n",
      "Epoch 918/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4905 - reconstruction_loss: 1891.1920 - kl_loss: 99.7064 - false_loss: 0.0773 - true_loss: 1.0478 - val_loss: 5304.1040 - val_reconstruction_loss: 1895.6365 - val_kl_loss: 99.8655 - val_false_loss: 10.6585 - val_true_loss: 1.1104\n",
      "Epoch 919/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.5040 - reconstruction_loss: 1892.1891 - kl_loss: 98.8088 - false_loss: 0.0773 - true_loss: 1.0478 - val_loss: 5303.8174 - val_reconstruction_loss: 1895.6359 - val_kl_loss: 99.8658 - val_false_loss: 10.6576 - val_true_loss: 1.1103\n",
      "Epoch 920/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.7412 - reconstruction_loss: 1891.8066 - kl_loss: 100.2753 - false_loss: 0.0772 - true_loss: 1.0478 - val_loss: 5303.5337 - val_reconstruction_loss: 1895.6355 - val_kl_loss: 99.8660 - val_false_loss: 10.6567 - val_true_loss: 1.1103\n",
      "Epoch 921/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.4428 - reconstruction_loss: 1891.4774 - kl_loss: 99.5788 - false_loss: 0.0772 - true_loss: 1.0477 - val_loss: 5303.2451 - val_reconstruction_loss: 1895.6351 - val_kl_loss: 99.8658 - val_false_loss: 10.6557 - val_true_loss: 1.1103\n",
      "Epoch 922/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.8082 - reconstruction_loss: 1891.1696 - kl_loss: 99.0447 - false_loss: 0.0772 - true_loss: 1.0477 - val_loss: 5302.9595 - val_reconstruction_loss: 1895.6343 - val_kl_loss: 99.8664 - val_false_loss: 10.6548 - val_true_loss: 1.1102\n",
      "Epoch 923/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6965 - reconstruction_loss: 1891.7750 - kl_loss: 97.5516 - false_loss: 0.0772 - true_loss: 1.0477 - val_loss: 5302.6699 - val_reconstruction_loss: 1895.6335 - val_kl_loss: 99.8665 - val_false_loss: 10.6538 - val_true_loss: 1.1102\n",
      "Epoch 924/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2233.7833 - reconstruction_loss: 1892.7158 - kl_loss: 97.1298 - false_loss: 0.0772 - true_loss: 1.0476 - val_loss: 5302.3857 - val_reconstruction_loss: 1895.6334 - val_kl_loss: 99.8667 - val_false_loss: 10.6529 - val_true_loss: 1.1102\n",
      "Epoch 925/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.5932 - reconstruction_loss: 1891.8744 - kl_loss: 100.0772 - false_loss: 0.0772 - true_loss: 1.0476 - val_loss: 5302.1021 - val_reconstruction_loss: 1895.6328 - val_kl_loss: 99.8668 - val_false_loss: 10.6520 - val_true_loss: 1.1101\n",
      "Epoch 926/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.7066 - reconstruction_loss: 1891.4896 - kl_loss: 99.4035 - false_loss: 0.0772 - true_loss: 1.0476 - val_loss: 5301.8125 - val_reconstruction_loss: 1895.6322 - val_kl_loss: 99.8672 - val_false_loss: 10.6510 - val_true_loss: 1.1101\n",
      "Epoch 927/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.8701 - reconstruction_loss: 1891.4896 - kl_loss: 100.7470 - false_loss: 0.0772 - true_loss: 1.0476 - val_loss: 5301.5239 - val_reconstruction_loss: 1895.6317 - val_kl_loss: 99.8674 - val_false_loss: 10.6501 - val_true_loss: 1.1101\n",
      "Epoch 928/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.8381 - reconstruction_loss: 1891.2847 - kl_loss: 98.6223 - false_loss: 0.0772 - true_loss: 1.0475 - val_loss: 5301.2344 - val_reconstruction_loss: 1895.6313 - val_kl_loss: 99.8679 - val_false_loss: 10.6491 - val_true_loss: 1.1100\n",
      "Epoch 929/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.3700 - reconstruction_loss: 1891.3628 - kl_loss: 99.6422 - false_loss: 0.0772 - true_loss: 1.0475 - val_loss: 5300.9468 - val_reconstruction_loss: 1895.6310 - val_kl_loss: 99.8684 - val_false_loss: 10.6482 - val_true_loss: 1.1100\n",
      "Epoch 930/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7565 - reconstruction_loss: 1891.4360 - kl_loss: 100.4880 - false_loss: 0.0772 - true_loss: 1.0475 - val_loss: 5300.6611 - val_reconstruction_loss: 1895.6301 - val_kl_loss: 99.8685 - val_false_loss: 10.6472 - val_true_loss: 1.1100\n",
      "Epoch 931/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.3485 - reconstruction_loss: 1891.2089 - kl_loss: 98.4473 - false_loss: 0.0772 - true_loss: 1.0474 - val_loss: 5300.3726 - val_reconstruction_loss: 1895.6298 - val_kl_loss: 99.8686 - val_false_loss: 10.6463 - val_true_loss: 1.1099\n",
      "Epoch 932/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.0942 - reconstruction_loss: 1891.5879 - kl_loss: 98.7066 - false_loss: 0.0772 - true_loss: 1.0474 - val_loss: 5300.0879 - val_reconstruction_loss: 1895.6293 - val_kl_loss: 99.8683 - val_false_loss: 10.6453 - val_true_loss: 1.1099\n",
      "Epoch 933/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2245.2437 - reconstruction_loss: 1891.5238 - kl_loss: 97.4008 - false_loss: 0.0772 - true_loss: 1.0474 - val_loss: 5299.8013 - val_reconstruction_loss: 1895.6287 - val_kl_loss: 99.8685 - val_false_loss: 10.6444 - val_true_loss: 1.1099\n",
      "Epoch 934/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7133 - reconstruction_loss: 1891.3545 - kl_loss: 99.6742 - false_loss: 0.0772 - true_loss: 1.0473 - val_loss: 5299.5146 - val_reconstruction_loss: 1895.6283 - val_kl_loss: 99.8687 - val_false_loss: 10.6434 - val_true_loss: 1.1099\n",
      "Epoch 935/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.7099 - reconstruction_loss: 1891.3258 - kl_loss: 100.4493 - false_loss: 0.0772 - true_loss: 1.0473 - val_loss: 5299.2251 - val_reconstruction_loss: 1895.6277 - val_kl_loss: 99.8686 - val_false_loss: 10.6425 - val_true_loss: 1.1098\n",
      "Epoch 936/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.3500 - reconstruction_loss: 1891.3951 - kl_loss: 98.6608 - false_loss: 0.0772 - true_loss: 1.0473 - val_loss: 5298.9375 - val_reconstruction_loss: 1895.6273 - val_kl_loss: 99.8682 - val_false_loss: 10.6415 - val_true_loss: 1.1098\n",
      "Epoch 937/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2226.3295 - reconstruction_loss: 1891.5898 - kl_loss: 98.5414 - false_loss: 0.0772 - true_loss: 1.0473 - val_loss: 5298.6494 - val_reconstruction_loss: 1895.6268 - val_kl_loss: 99.8683 - val_false_loss: 10.6406 - val_true_loss: 1.1098\n",
      "Epoch 938/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.4889 - reconstruction_loss: 1891.2098 - kl_loss: 99.5356 - false_loss: 0.0772 - true_loss: 1.0472 - val_loss: 5298.3643 - val_reconstruction_loss: 1895.6260 - val_kl_loss: 99.8687 - val_false_loss: 10.6396 - val_true_loss: 1.1097\n",
      "Epoch 939/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.8778 - reconstruction_loss: 1891.4747 - kl_loss: 97.9967 - false_loss: 0.0771 - true_loss: 1.0472 - val_loss: 5298.0718 - val_reconstruction_loss: 1895.6256 - val_kl_loss: 99.8688 - val_false_loss: 10.6387 - val_true_loss: 1.1097\n",
      "Epoch 940/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.2242 - reconstruction_loss: 1891.6273 - kl_loss: 99.3113 - false_loss: 0.0771 - true_loss: 1.0472 - val_loss: 5297.7817 - val_reconstruction_loss: 1895.6252 - val_kl_loss: 99.8692 - val_false_loss: 10.6377 - val_true_loss: 1.1097\n",
      "Epoch 941/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.6125 - reconstruction_loss: 1891.9458 - kl_loss: 99.2857 - false_loss: 0.0771 - true_loss: 1.0471 - val_loss: 5297.4902 - val_reconstruction_loss: 1895.6246 - val_kl_loss: 99.8694 - val_false_loss: 10.6368 - val_true_loss: 1.1096\n",
      "Epoch 942/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.4283 - reconstruction_loss: 1891.2863 - kl_loss: 99.6283 - false_loss: 0.0771 - true_loss: 1.0471 - val_loss: 5297.1973 - val_reconstruction_loss: 1895.6240 - val_kl_loss: 99.8693 - val_false_loss: 10.6358 - val_true_loss: 1.1096\n",
      "Epoch 943/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4647 - reconstruction_loss: 1891.1631 - kl_loss: 98.9852 - false_loss: 0.0771 - true_loss: 1.0471 - val_loss: 5296.9067 - val_reconstruction_loss: 1895.6235 - val_kl_loss: 99.8694 - val_false_loss: 10.6349 - val_true_loss: 1.1096\n",
      "Epoch 944/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.4965 - reconstruction_loss: 1891.5077 - kl_loss: 98.5556 - false_loss: 0.0771 - true_loss: 1.0470 - val_loss: 5296.6138 - val_reconstruction_loss: 1895.6232 - val_kl_loss: 99.8691 - val_false_loss: 10.6339 - val_true_loss: 1.1095\n",
      "Epoch 945/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.7869 - reconstruction_loss: 1891.7925 - kl_loss: 99.4099 - false_loss: 0.0771 - true_loss: 1.0470 - val_loss: 5296.3267 - val_reconstruction_loss: 1895.6226 - val_kl_loss: 99.8693 - val_false_loss: 10.6329 - val_true_loss: 1.1095\n",
      "Epoch 946/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.7965 - reconstruction_loss: 1891.5309 - kl_loss: 98.8343 - false_loss: 0.0771 - true_loss: 1.0470 - val_loss: 5296.0352 - val_reconstruction_loss: 1895.6222 - val_kl_loss: 99.8691 - val_false_loss: 10.6320 - val_true_loss: 1.1094\n",
      "Epoch 947/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.2466 - reconstruction_loss: 1891.5504 - kl_loss: 98.2447 - false_loss: 0.0771 - true_loss: 1.0469 - val_loss: 5295.7437 - val_reconstruction_loss: 1895.6217 - val_kl_loss: 99.8692 - val_false_loss: 10.6310 - val_true_loss: 1.1094\n",
      "Epoch 948/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8749 - reconstruction_loss: 1891.4843 - kl_loss: 99.7885 - false_loss: 0.0771 - true_loss: 1.0469 - val_loss: 5295.4517 - val_reconstruction_loss: 1895.6213 - val_kl_loss: 99.8692 - val_false_loss: 10.6301 - val_true_loss: 1.1094\n",
      "Epoch 949/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.6361 - reconstruction_loss: 1891.2504 - kl_loss: 99.1498 - false_loss: 0.0771 - true_loss: 1.0469 - val_loss: 5295.1616 - val_reconstruction_loss: 1895.6207 - val_kl_loss: 99.8694 - val_false_loss: 10.6291 - val_true_loss: 1.1094\n",
      "Epoch 950/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3019 - reconstruction_loss: 1891.2133 - kl_loss: 99.8074 - false_loss: 0.0771 - true_loss: 1.0469 - val_loss: 5294.8740 - val_reconstruction_loss: 1895.6201 - val_kl_loss: 99.8698 - val_false_loss: 10.6282 - val_true_loss: 1.1093\n",
      "Epoch 951/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.0313 - reconstruction_loss: 1891.3573 - kl_loss: 99.2945 - false_loss: 0.0771 - true_loss: 1.0468 - val_loss: 5294.5874 - val_reconstruction_loss: 1895.6195 - val_kl_loss: 99.8696 - val_false_loss: 10.6272 - val_true_loss: 1.1093\n",
      "Epoch 952/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6151 - reconstruction_loss: 1891.6591 - kl_loss: 97.2642 - false_loss: 0.0771 - true_loss: 1.0468 - val_loss: 5294.2998 - val_reconstruction_loss: 1895.6191 - val_kl_loss: 99.8697 - val_false_loss: 10.6263 - val_true_loss: 1.1093\n",
      "Epoch 953/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2777 - reconstruction_loss: 1891.9427 - kl_loss: 98.8833 - false_loss: 0.0771 - true_loss: 1.0468 - val_loss: 5294.0122 - val_reconstruction_loss: 1895.6187 - val_kl_loss: 99.8694 - val_false_loss: 10.6253 - val_true_loss: 1.1092\n",
      "Epoch 954/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2003 - reconstruction_loss: 1891.5529 - kl_loss: 98.6594 - false_loss: 0.0771 - true_loss: 1.0467 - val_loss: 5293.7275 - val_reconstruction_loss: 1895.6183 - val_kl_loss: 99.8691 - val_false_loss: 10.6244 - val_true_loss: 1.1092\n",
      "Epoch 955/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6073 - reconstruction_loss: 1891.4603 - kl_loss: 99.0726 - false_loss: 0.0771 - true_loss: 1.0467 - val_loss: 5293.4395 - val_reconstruction_loss: 1895.6179 - val_kl_loss: 99.8691 - val_false_loss: 10.6234 - val_true_loss: 1.1092\n",
      "Epoch 956/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.4324 - reconstruction_loss: 1891.5205 - kl_loss: 99.4499 - false_loss: 0.0771 - true_loss: 1.0467 - val_loss: 5293.1519 - val_reconstruction_loss: 1895.6173 - val_kl_loss: 99.8694 - val_false_loss: 10.6225 - val_true_loss: 1.1091\n",
      "Epoch 957/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.8418 - reconstruction_loss: 1891.2362 - kl_loss: 99.5945 - false_loss: 0.0770 - true_loss: 1.0466 - val_loss: 5292.8657 - val_reconstruction_loss: 1895.6168 - val_kl_loss: 99.8693 - val_false_loss: 10.6216 - val_true_loss: 1.1091\n",
      "Epoch 958/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.8142 - reconstruction_loss: 1891.1459 - kl_loss: 99.1052 - false_loss: 0.0770 - true_loss: 1.0466 - val_loss: 5292.5781 - val_reconstruction_loss: 1895.6165 - val_kl_loss: 99.8692 - val_false_loss: 10.6206 - val_true_loss: 1.1091\n",
      "Epoch 959/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.6162 - reconstruction_loss: 1891.9012 - kl_loss: 97.7305 - false_loss: 0.0770 - true_loss: 1.0466 - val_loss: 5292.2900 - val_reconstruction_loss: 1895.6158 - val_kl_loss: 99.8693 - val_false_loss: 10.6197 - val_true_loss: 1.1090\n",
      "Epoch 960/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8142 - reconstruction_loss: 1891.7916 - kl_loss: 99.1038 - false_loss: 0.0770 - true_loss: 1.0466 - val_loss: 5292.0020 - val_reconstruction_loss: 1895.6155 - val_kl_loss: 99.8692 - val_false_loss: 10.6187 - val_true_loss: 1.1090\n",
      "Epoch 961/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.5386 - reconstruction_loss: 1891.3070 - kl_loss: 98.4955 - false_loss: 0.0770 - true_loss: 1.0465 - val_loss: 5291.7139 - val_reconstruction_loss: 1895.6151 - val_kl_loss: 99.8695 - val_false_loss: 10.6178 - val_true_loss: 1.1090\n",
      "Epoch 962/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.3525 - reconstruction_loss: 1891.4645 - kl_loss: 99.5312 - false_loss: 0.0770 - true_loss: 1.0465 - val_loss: 5291.4233 - val_reconstruction_loss: 1895.6144 - val_kl_loss: 99.8697 - val_false_loss: 10.6168 - val_true_loss: 1.1089\n",
      "Epoch 963/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.0565 - reconstruction_loss: 1891.2651 - kl_loss: 99.3146 - false_loss: 0.0770 - true_loss: 1.0465 - val_loss: 5291.1309 - val_reconstruction_loss: 1895.6140 - val_kl_loss: 99.8699 - val_false_loss: 10.6158 - val_true_loss: 1.1089\n",
      "Epoch 964/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.9386 - reconstruction_loss: 1891.2347 - kl_loss: 99.4858 - false_loss: 0.0770 - true_loss: 1.0464 - val_loss: 5290.8389 - val_reconstruction_loss: 1895.6136 - val_kl_loss: 99.8699 - val_false_loss: 10.6149 - val_true_loss: 1.1089\n",
      "Epoch 965/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2232.2617 - reconstruction_loss: 1891.7227 - kl_loss: 97.8500 - false_loss: 0.0770 - true_loss: 1.0464 - val_loss: 5290.5469 - val_reconstruction_loss: 1895.6130 - val_kl_loss: 99.8701 - val_false_loss: 10.6139 - val_true_loss: 1.1088\n",
      "Epoch 966/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.8221 - reconstruction_loss: 1891.4688 - kl_loss: 98.8422 - false_loss: 0.0770 - true_loss: 1.0464 - val_loss: 5290.2559 - val_reconstruction_loss: 1895.6127 - val_kl_loss: 99.8701 - val_false_loss: 10.6130 - val_true_loss: 1.1088\n",
      "Epoch 967/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.0147 - reconstruction_loss: 1891.2881 - kl_loss: 99.6101 - false_loss: 0.0770 - true_loss: 1.0463 - val_loss: 5289.9673 - val_reconstruction_loss: 1895.6122 - val_kl_loss: 99.8704 - val_false_loss: 10.6120 - val_true_loss: 1.1088\n",
      "Epoch 968/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.7833 - reconstruction_loss: 1891.2212 - kl_loss: 99.1725 - false_loss: 0.0770 - true_loss: 1.0463 - val_loss: 5289.6763 - val_reconstruction_loss: 1895.6118 - val_kl_loss: 99.8706 - val_false_loss: 10.6111 - val_true_loss: 1.1087\n",
      "Epoch 969/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.0988 - reconstruction_loss: 1891.2372 - kl_loss: 100.5059 - false_loss: 0.0770 - true_loss: 1.0463 - val_loss: 5289.3911 - val_reconstruction_loss: 1895.6112 - val_kl_loss: 99.8708 - val_false_loss: 10.6101 - val_true_loss: 1.1087\n",
      "Epoch 970/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7448 - reconstruction_loss: 1891.1222 - kl_loss: 99.3890 - false_loss: 0.0770 - true_loss: 1.0462 - val_loss: 5289.1021 - val_reconstruction_loss: 1895.6108 - val_kl_loss: 99.8708 - val_false_loss: 10.6092 - val_true_loss: 1.1087\n",
      "Epoch 971/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.4880 - reconstruction_loss: 1891.6093 - kl_loss: 99.7175 - false_loss: 0.0770 - true_loss: 1.0462 - val_loss: 5288.8101 - val_reconstruction_loss: 1895.6104 - val_kl_loss: 99.8705 - val_false_loss: 10.6082 - val_true_loss: 1.1086\n",
      "Epoch 972/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.8705 - reconstruction_loss: 1891.8726 - kl_loss: 98.8669 - false_loss: 0.0770 - true_loss: 1.0462 - val_loss: 5288.5181 - val_reconstruction_loss: 1895.6097 - val_kl_loss: 99.8704 - val_false_loss: 10.6072 - val_true_loss: 1.1086\n",
      "Epoch 973/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.5973 - reconstruction_loss: 1891.5067 - kl_loss: 98.6167 - false_loss: 0.0770 - true_loss: 1.0461 - val_loss: 5288.2295 - val_reconstruction_loss: 1895.6091 - val_kl_loss: 99.8707 - val_false_loss: 10.6063 - val_true_loss: 1.1086\n",
      "Epoch 974/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.4173 - reconstruction_loss: 1891.8873 - kl_loss: 98.5840 - false_loss: 0.0770 - true_loss: 1.0461 - val_loss: 5287.9419 - val_reconstruction_loss: 1895.6088 - val_kl_loss: 99.8708 - val_false_loss: 10.6054 - val_true_loss: 1.1085\n",
      "Epoch 975/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.2487 - reconstruction_loss: 1891.4127 - kl_loss: 99.3544 - false_loss: 0.0770 - true_loss: 1.0461 - val_loss: 5287.6558 - val_reconstruction_loss: 1895.6082 - val_kl_loss: 99.8708 - val_false_loss: 10.6044 - val_true_loss: 1.1085\n",
      "Epoch 976/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.3542 - reconstruction_loss: 1891.0350 - kl_loss: 100.3607 - false_loss: 0.0769 - true_loss: 1.0460 - val_loss: 5287.3696 - val_reconstruction_loss: 1895.6075 - val_kl_loss: 99.8710 - val_false_loss: 10.6035 - val_true_loss: 1.1085\n",
      "Epoch 977/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.6177 - reconstruction_loss: 1891.0734 - kl_loss: 99.1924 - false_loss: 0.0769 - true_loss: 1.0460 - val_loss: 5287.0781 - val_reconstruction_loss: 1895.6069 - val_kl_loss: 99.8707 - val_false_loss: 10.6025 - val_true_loss: 1.1084\n",
      "Epoch 978/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0542 - reconstruction_loss: 1892.5372 - kl_loss: 99.2322 - false_loss: 0.0769 - true_loss: 1.0460 - val_loss: 5286.7896 - val_reconstruction_loss: 1895.6067 - val_kl_loss: 99.8708 - val_false_loss: 10.6016 - val_true_loss: 1.1084\n",
      "Epoch 979/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.3260 - reconstruction_loss: 1892.1305 - kl_loss: 98.5219 - false_loss: 0.0769 - true_loss: 1.0460 - val_loss: 5286.4985 - val_reconstruction_loss: 1895.6061 - val_kl_loss: 99.8709 - val_false_loss: 10.6006 - val_true_loss: 1.1084\n",
      "Epoch 980/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.3878 - reconstruction_loss: 1891.8507 - kl_loss: 99.4359 - false_loss: 0.0769 - true_loss: 1.0459 - val_loss: 5286.2095 - val_reconstruction_loss: 1895.6057 - val_kl_loss: 99.8711 - val_false_loss: 10.5997 - val_true_loss: 1.1084\n",
      "Epoch 981/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.7899 - reconstruction_loss: 1891.3481 - kl_loss: 99.1770 - false_loss: 0.0769 - true_loss: 1.0459 - val_loss: 5285.9219 - val_reconstruction_loss: 1895.6053 - val_kl_loss: 99.8713 - val_false_loss: 10.5987 - val_true_loss: 1.1083\n",
      "Epoch 982/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6610 - reconstruction_loss: 1890.9854 - kl_loss: 98.9764 - false_loss: 0.0769 - true_loss: 1.0459 - val_loss: 5285.6333 - val_reconstruction_loss: 1895.6047 - val_kl_loss: 99.8713 - val_false_loss: 10.5977 - val_true_loss: 1.1083\n",
      "Epoch 983/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.0504 - reconstruction_loss: 1891.3910 - kl_loss: 98.5613 - false_loss: 0.0769 - true_loss: 1.0458 - val_loss: 5285.3442 - val_reconstruction_loss: 1895.6041 - val_kl_loss: 99.8715 - val_false_loss: 10.5968 - val_true_loss: 1.1083\n",
      "Epoch 984/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.7013 - reconstruction_loss: 1891.3584 - kl_loss: 99.6157 - false_loss: 0.0769 - true_loss: 1.0458 - val_loss: 5285.0566 - val_reconstruction_loss: 1895.6038 - val_kl_loss: 99.8713 - val_false_loss: 10.5959 - val_true_loss: 1.1082\n",
      "Epoch 985/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.1298 - reconstruction_loss: 1891.1464 - kl_loss: 97.7107 - false_loss: 0.0769 - true_loss: 1.0458 - val_loss: 5284.7700 - val_reconstruction_loss: 1895.6033 - val_kl_loss: 99.8712 - val_false_loss: 10.5949 - val_true_loss: 1.1082\n",
      "Epoch 986/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.7092 - reconstruction_loss: 1891.5260 - kl_loss: 98.7965 - false_loss: 0.0769 - true_loss: 1.0457 - val_loss: 5284.4800 - val_reconstruction_loss: 1895.6029 - val_kl_loss: 99.8713 - val_false_loss: 10.5940 - val_true_loss: 1.1082\n",
      "Epoch 987/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.9411 - reconstruction_loss: 1891.9957 - kl_loss: 96.6483 - false_loss: 0.0769 - true_loss: 1.0457 - val_loss: 5284.1885 - val_reconstruction_loss: 1895.6023 - val_kl_loss: 99.8715 - val_false_loss: 10.5930 - val_true_loss: 1.1081\n",
      "Epoch 988/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.2437 - reconstruction_loss: 1891.5677 - kl_loss: 100.9154 - false_loss: 0.0769 - true_loss: 1.0457 - val_loss: 5283.8965 - val_reconstruction_loss: 1895.6017 - val_kl_loss: 99.8717 - val_false_loss: 10.5920 - val_true_loss: 1.1081\n",
      "Epoch 989/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2202.6019 - reconstruction_loss: 1891.0625 - kl_loss: 101.0837 - false_loss: 0.0769 - true_loss: 1.0456 - val_loss: 5283.6055 - val_reconstruction_loss: 1895.6013 - val_kl_loss: 99.8722 - val_false_loss: 10.5911 - val_true_loss: 1.1081\n",
      "Epoch 990/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.8362 - reconstruction_loss: 1891.0270 - kl_loss: 103.0791 - false_loss: 0.0769 - true_loss: 1.0456 - val_loss: 5283.3164 - val_reconstruction_loss: 1895.6007 - val_kl_loss: 99.8726 - val_false_loss: 10.5901 - val_true_loss: 1.1080\n",
      "Epoch 991/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.6042 - reconstruction_loss: 1891.2208 - kl_loss: 101.3819 - false_loss: 0.0769 - true_loss: 1.0456 - val_loss: 5283.0234 - val_reconstruction_loss: 1895.6001 - val_kl_loss: 99.8725 - val_false_loss: 10.5892 - val_true_loss: 1.1080\n",
      "Epoch 992/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.7276 - reconstruction_loss: 1891.2949 - kl_loss: 100.4820 - false_loss: 0.0769 - true_loss: 1.0455 - val_loss: 5282.7314 - val_reconstruction_loss: 1895.5996 - val_kl_loss: 99.8727 - val_false_loss: 10.5882 - val_true_loss: 1.1079\n",
      "Epoch 993/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.5554 - reconstruction_loss: 1891.4170 - kl_loss: 101.7573 - false_loss: 0.0769 - true_loss: 1.0455 - val_loss: 5282.4395 - val_reconstruction_loss: 1895.5992 - val_kl_loss: 99.8732 - val_false_loss: 10.5872 - val_true_loss: 1.1079\n",
      "Epoch 994/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0470 - reconstruction_loss: 1891.3322 - kl_loss: 102.5795 - false_loss: 0.0768 - true_loss: 1.0454 - val_loss: 5282.1475 - val_reconstruction_loss: 1895.5984 - val_kl_loss: 99.8734 - val_false_loss: 10.5863 - val_true_loss: 1.1079\n",
      "Epoch 995/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.2239 - reconstruction_loss: 1891.1885 - kl_loss: 102.3666 - false_loss: 0.0768 - true_loss: 1.0454 - val_loss: 5281.8608 - val_reconstruction_loss: 1895.5978 - val_kl_loss: 99.8738 - val_false_loss: 10.5853 - val_true_loss: 1.1078\n",
      "Epoch 996/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.8904 - reconstruction_loss: 1891.4139 - kl_loss: 101.6692 - false_loss: 0.0768 - true_loss: 1.0454 - val_loss: 5281.5728 - val_reconstruction_loss: 1895.5974 - val_kl_loss: 99.8743 - val_false_loss: 10.5844 - val_true_loss: 1.1078\n",
      "Epoch 997/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.6451 - reconstruction_loss: 1891.7760 - kl_loss: 102.0116 - false_loss: 0.0768 - true_loss: 1.0453 - val_loss: 5281.2925 - val_reconstruction_loss: 1895.5970 - val_kl_loss: 99.8749 - val_false_loss: 10.5835 - val_true_loss: 1.1078\n",
      "Epoch 998/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.1010 - reconstruction_loss: 1892.1089 - kl_loss: 103.0879 - false_loss: 0.0768 - true_loss: 1.0453 - val_loss: 5281.0010 - val_reconstruction_loss: 1895.5964 - val_kl_loss: 99.8753 - val_false_loss: 10.5825 - val_true_loss: 1.1077\n",
      "Epoch 999/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.3356 - reconstruction_loss: 1891.9926 - kl_loss: 101.5418 - false_loss: 0.0768 - true_loss: 1.0453 - val_loss: 5280.7212 - val_reconstruction_loss: 1895.5959 - val_kl_loss: 99.8757 - val_false_loss: 10.5816 - val_true_loss: 1.1077\n",
      "Epoch 1000/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.5840 - reconstruction_loss: 1891.5488 - kl_loss: 101.5133 - false_loss: 0.0768 - true_loss: 1.0452 - val_loss: 5280.4370 - val_reconstruction_loss: 1895.5953 - val_kl_loss: 99.8758 - val_false_loss: 10.5807 - val_true_loss: 1.1076\n",
      "Epoch 1001/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.2678 - reconstruction_loss: 1891.1178 - kl_loss: 100.4430 - false_loss: 0.0768 - true_loss: 1.0452 - val_loss: 5280.1470 - val_reconstruction_loss: 1895.5947 - val_kl_loss: 99.8758 - val_false_loss: 10.5797 - val_true_loss: 1.1076\n",
      "Epoch 1002/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4214 - reconstruction_loss: 1891.4686 - kl_loss: 102.0785 - false_loss: 0.0768 - true_loss: 1.0452 - val_loss: 5279.8569 - val_reconstruction_loss: 1895.5944 - val_kl_loss: 99.8761 - val_false_loss: 10.5788 - val_true_loss: 1.1076\n",
      "Epoch 1003/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1785 - reconstruction_loss: 1891.3458 - kl_loss: 102.1928 - false_loss: 0.0768 - true_loss: 1.0451 - val_loss: 5279.5669 - val_reconstruction_loss: 1895.5940 - val_kl_loss: 99.8763 - val_false_loss: 10.5778 - val_true_loss: 1.1075\n",
      "Epoch 1004/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.5509 - reconstruction_loss: 1890.9467 - kl_loss: 101.1091 - false_loss: 0.0768 - true_loss: 1.0451 - val_loss: 5279.2759 - val_reconstruction_loss: 1895.5934 - val_kl_loss: 99.8766 - val_false_loss: 10.5768 - val_true_loss: 1.1075\n",
      "Epoch 1005/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.8014 - reconstruction_loss: 1890.7914 - kl_loss: 101.0243 - false_loss: 0.0768 - true_loss: 1.0451 - val_loss: 5278.9868 - val_reconstruction_loss: 1895.5928 - val_kl_loss: 99.8767 - val_false_loss: 10.5759 - val_true_loss: 1.1075\n",
      "Epoch 1006/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.2099 - reconstruction_loss: 1891.5931 - kl_loss: 99.1799 - false_loss: 0.0768 - true_loss: 1.0450 - val_loss: 5278.6938 - val_reconstruction_loss: 1895.5924 - val_kl_loss: 99.8762 - val_false_loss: 10.5749 - val_true_loss: 1.1074\n",
      "Epoch 1007/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.4562 - reconstruction_loss: 1891.8340 - kl_loss: 98.3203 - false_loss: 0.0768 - true_loss: 1.0450 - val_loss: 5278.4028 - val_reconstruction_loss: 1895.5919 - val_kl_loss: 99.8765 - val_false_loss: 10.5740 - val_true_loss: 1.1074\n",
      "Epoch 1008/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.8933 - reconstruction_loss: 1891.4789 - kl_loss: 100.9112 - false_loss: 0.0768 - true_loss: 1.0450 - val_loss: 5278.1113 - val_reconstruction_loss: 1895.5912 - val_kl_loss: 99.8769 - val_false_loss: 10.5730 - val_true_loss: 1.1074\n",
      "Epoch 1009/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.2970 - reconstruction_loss: 1891.0643 - kl_loss: 102.6137 - false_loss: 0.0768 - true_loss: 1.0449 - val_loss: 5277.8218 - val_reconstruction_loss: 1895.5907 - val_kl_loss: 99.8775 - val_false_loss: 10.5721 - val_true_loss: 1.1073\n",
      "Epoch 1010/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.5627 - reconstruction_loss: 1891.1249 - kl_loss: 100.7300 - false_loss: 0.0768 - true_loss: 1.0449 - val_loss: 5277.5337 - val_reconstruction_loss: 1895.5901 - val_kl_loss: 99.8779 - val_false_loss: 10.5711 - val_true_loss: 1.1073\n",
      "Epoch 1011/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.3757 - reconstruction_loss: 1891.4374 - kl_loss: 102.1306 - false_loss: 0.0768 - true_loss: 1.0449 - val_loss: 5277.2437 - val_reconstruction_loss: 1895.5895 - val_kl_loss: 99.8780 - val_false_loss: 10.5702 - val_true_loss: 1.1073\n",
      "Epoch 1012/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.8841 - reconstruction_loss: 1891.7445 - kl_loss: 97.4389 - false_loss: 0.0767 - true_loss: 1.0448 - val_loss: 5276.9502 - val_reconstruction_loss: 1895.5891 - val_kl_loss: 99.8782 - val_false_loss: 10.5692 - val_true_loss: 1.1072\n",
      "Epoch 1013/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.1449 - reconstruction_loss: 1891.4515 - kl_loss: 100.8610 - false_loss: 0.0767 - true_loss: 1.0448 - val_loss: 5276.6650 - val_reconstruction_loss: 1895.5887 - val_kl_loss: 99.8784 - val_false_loss: 10.5683 - val_true_loss: 1.1072\n",
      "Epoch 1014/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.2624 - reconstruction_loss: 1891.5861 - kl_loss: 101.2822 - false_loss: 0.0767 - true_loss: 1.0448 - val_loss: 5276.3789 - val_reconstruction_loss: 1895.5884 - val_kl_loss: 99.8790 - val_false_loss: 10.5673 - val_true_loss: 1.1072\n",
      "Epoch 1015/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.9651 - reconstruction_loss: 1891.2155 - kl_loss: 100.1494 - false_loss: 0.0767 - true_loss: 1.0447 - val_loss: 5276.0889 - val_reconstruction_loss: 1895.5878 - val_kl_loss: 99.8789 - val_false_loss: 10.5664 - val_true_loss: 1.1071\n",
      "Epoch 1016/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.5638 - reconstruction_loss: 1891.0781 - kl_loss: 99.9292 - false_loss: 0.0767 - true_loss: 1.0447 - val_loss: 5275.7959 - val_reconstruction_loss: 1895.5872 - val_kl_loss: 99.8785 - val_false_loss: 10.5654 - val_true_loss: 1.1071\n",
      "Epoch 1017/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.6735 - reconstruction_loss: 1890.8666 - kl_loss: 99.3955 - false_loss: 0.0767 - true_loss: 1.0447 - val_loss: 5275.5093 - val_reconstruction_loss: 1895.5867 - val_kl_loss: 99.8791 - val_false_loss: 10.5644 - val_true_loss: 1.1071\n",
      "Epoch 1018/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.5439 - reconstruction_loss: 1891.2749 - kl_loss: 101.3923 - false_loss: 0.0767 - true_loss: 1.0446 - val_loss: 5275.2236 - val_reconstruction_loss: 1895.5861 - val_kl_loss: 99.8792 - val_false_loss: 10.5635 - val_true_loss: 1.1070\n",
      "Epoch 1019/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.9307 - reconstruction_loss: 1891.3173 - kl_loss: 100.6955 - false_loss: 0.0767 - true_loss: 1.0446 - val_loss: 5274.9380 - val_reconstruction_loss: 1895.5854 - val_kl_loss: 99.8795 - val_false_loss: 10.5626 - val_true_loss: 1.1070\n",
      "Epoch 1020/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4818 - reconstruction_loss: 1891.1517 - kl_loss: 99.3472 - false_loss: 0.0767 - true_loss: 1.0446 - val_loss: 5274.6465 - val_reconstruction_loss: 1895.5851 - val_kl_loss: 99.8794 - val_false_loss: 10.5616 - val_true_loss: 1.1070\n",
      "Epoch 1021/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.0110 - reconstruction_loss: 1891.3027 - kl_loss: 99.4188 - false_loss: 0.0767 - true_loss: 1.0446 - val_loss: 5274.3594 - val_reconstruction_loss: 1895.5845 - val_kl_loss: 99.8794 - val_false_loss: 10.5607 - val_true_loss: 1.1069\n",
      "Epoch 1022/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.8535 - reconstruction_loss: 1891.2692 - kl_loss: 100.7890 - false_loss: 0.0767 - true_loss: 1.0445 - val_loss: 5274.0718 - val_reconstruction_loss: 1895.5839 - val_kl_loss: 99.8796 - val_false_loss: 10.5597 - val_true_loss: 1.1069\n",
      "Epoch 1023/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4900 - reconstruction_loss: 1891.1693 - kl_loss: 100.3851 - false_loss: 0.0767 - true_loss: 1.0445 - val_loss: 5273.7827 - val_reconstruction_loss: 1895.5835 - val_kl_loss: 99.8800 - val_false_loss: 10.5588 - val_true_loss: 1.1069\n",
      "Epoch 1024/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.4964 - reconstruction_loss: 1890.7843 - kl_loss: 100.9630 - false_loss: 0.0767 - true_loss: 1.0445 - val_loss: 5273.4961 - val_reconstruction_loss: 1895.5829 - val_kl_loss: 99.8805 - val_false_loss: 10.5578 - val_true_loss: 1.1068\n",
      "Epoch 1025/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.3812 - reconstruction_loss: 1891.0284 - kl_loss: 101.0624 - false_loss: 0.0767 - true_loss: 1.0444 - val_loss: 5273.2070 - val_reconstruction_loss: 1895.5825 - val_kl_loss: 99.8806 - val_false_loss: 10.5569 - val_true_loss: 1.1068\n",
      "Epoch 1026/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.3818 - reconstruction_loss: 1891.1300 - kl_loss: 100.0240 - false_loss: 0.0767 - true_loss: 1.0444 - val_loss: 5272.9204 - val_reconstruction_loss: 1895.5820 - val_kl_loss: 99.8811 - val_false_loss: 10.5559 - val_true_loss: 1.1068\n",
      "Epoch 1027/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.6657 - reconstruction_loss: 1890.8345 - kl_loss: 99.3410 - false_loss: 0.0767 - true_loss: 1.0444 - val_loss: 5272.6323 - val_reconstruction_loss: 1895.5814 - val_kl_loss: 99.8811 - val_false_loss: 10.5550 - val_true_loss: 1.1067\n",
      "Epoch 1028/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7723 - reconstruction_loss: 1890.9415 - kl_loss: 99.2759 - false_loss: 0.0767 - true_loss: 1.0443 - val_loss: 5272.3442 - val_reconstruction_loss: 1895.5808 - val_kl_loss: 99.8811 - val_false_loss: 10.5540 - val_true_loss: 1.1067\n",
      "Epoch 1029/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.2438 - reconstruction_loss: 1891.2272 - kl_loss: 100.3646 - false_loss: 0.0767 - true_loss: 1.0443 - val_loss: 5272.0581 - val_reconstruction_loss: 1895.5802 - val_kl_loss: 99.8815 - val_false_loss: 10.5531 - val_true_loss: 1.1067\n",
      "Epoch 1030/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.1535 - reconstruction_loss: 1890.9442 - kl_loss: 100.7028 - false_loss: 0.0767 - true_loss: 1.0443 - val_loss: 5271.7739 - val_reconstruction_loss: 1895.5798 - val_kl_loss: 99.8817 - val_false_loss: 10.5521 - val_true_loss: 1.1066\n",
      "Epoch 1031/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.1278 - reconstruction_loss: 1890.9893 - kl_loss: 99.0871 - false_loss: 0.0766 - true_loss: 1.0442 - val_loss: 5271.4849 - val_reconstruction_loss: 1895.5795 - val_kl_loss: 99.8815 - val_false_loss: 10.5512 - val_true_loss: 1.1066\n",
      "Epoch 1032/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.9143 - reconstruction_loss: 1891.3124 - kl_loss: 99.3878 - false_loss: 0.0766 - true_loss: 1.0442 - val_loss: 5271.1992 - val_reconstruction_loss: 1895.5786 - val_kl_loss: 99.8819 - val_false_loss: 10.5503 - val_true_loss: 1.1066\n",
      "Epoch 1033/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.1646 - reconstruction_loss: 1891.4092 - kl_loss: 99.4575 - false_loss: 0.0766 - true_loss: 1.0442 - val_loss: 5270.9097 - val_reconstruction_loss: 1895.5782 - val_kl_loss: 99.8821 - val_false_loss: 10.5493 - val_true_loss: 1.1065\n",
      "Epoch 1034/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.3883 - reconstruction_loss: 1891.2948 - kl_loss: 100.2070 - false_loss: 0.0766 - true_loss: 1.0441 - val_loss: 5270.6221 - val_reconstruction_loss: 1895.5779 - val_kl_loss: 99.8820 - val_false_loss: 10.5484 - val_true_loss: 1.1065\n",
      "Epoch 1035/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.9712 - reconstruction_loss: 1890.9708 - kl_loss: 98.8774 - false_loss: 0.0766 - true_loss: 1.0441 - val_loss: 5270.3364 - val_reconstruction_loss: 1895.5773 - val_kl_loss: 99.8821 - val_false_loss: 10.5474 - val_true_loss: 1.1065\n",
      "Epoch 1036/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6570 - reconstruction_loss: 1891.2155 - kl_loss: 100.0535 - false_loss: 0.0766 - true_loss: 1.0441 - val_loss: 5270.0498 - val_reconstruction_loss: 1895.5767 - val_kl_loss: 99.8820 - val_false_loss: 10.5465 - val_true_loss: 1.1065\n",
      "Epoch 1037/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7748 - reconstruction_loss: 1891.1807 - kl_loss: 100.8314 - false_loss: 0.0766 - true_loss: 1.0440 - val_loss: 5269.7583 - val_reconstruction_loss: 1895.5762 - val_kl_loss: 99.8820 - val_false_loss: 10.5455 - val_true_loss: 1.1064\n",
      "Epoch 1038/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5526 - reconstruction_loss: 1891.3906 - kl_loss: 99.5185 - false_loss: 0.0766 - true_loss: 1.0440 - val_loss: 5269.4678 - val_reconstruction_loss: 1895.5758 - val_kl_loss: 99.8817 - val_false_loss: 10.5446 - val_true_loss: 1.1064\n",
      "Epoch 1039/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.9336 - reconstruction_loss: 1891.5195 - kl_loss: 99.2864 - false_loss: 0.0766 - true_loss: 1.0440 - val_loss: 5269.1807 - val_reconstruction_loss: 1895.5752 - val_kl_loss: 99.8819 - val_false_loss: 10.5436 - val_true_loss: 1.1064\n",
      "Epoch 1040/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.1067 - reconstruction_loss: 1891.3949 - kl_loss: 100.6437 - false_loss: 0.0766 - true_loss: 1.0439 - val_loss: 5268.8955 - val_reconstruction_loss: 1895.5746 - val_kl_loss: 99.8823 - val_false_loss: 10.5427 - val_true_loss: 1.1063\n",
      "Epoch 1041/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2220.5734 - reconstruction_loss: 1891.1104 - kl_loss: 100.0015 - false_loss: 0.0766 - true_loss: 1.0439 - val_loss: 5268.6079 - val_reconstruction_loss: 1895.5740 - val_kl_loss: 99.8822 - val_false_loss: 10.5417 - val_true_loss: 1.1063\n",
      "Epoch 1042/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2226.4003 - reconstruction_loss: 1891.0338 - kl_loss: 97.3592 - false_loss: 0.0766 - true_loss: 1.0439 - val_loss: 5268.3179 - val_reconstruction_loss: 1895.5736 - val_kl_loss: 99.8821 - val_false_loss: 10.5408 - val_true_loss: 1.1063\n",
      "Epoch 1043/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.5223 - reconstruction_loss: 1890.8271 - kl_loss: 100.0946 - false_loss: 0.0766 - true_loss: 1.0439 - val_loss: 5268.0317 - val_reconstruction_loss: 1895.5730 - val_kl_loss: 99.8823 - val_false_loss: 10.5398 - val_true_loss: 1.1062\n",
      "Epoch 1044/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.4277 - reconstruction_loss: 1890.9326 - kl_loss: 100.6168 - false_loss: 0.0766 - true_loss: 1.0438 - val_loss: 5267.7476 - val_reconstruction_loss: 1895.5726 - val_kl_loss: 99.8824 - val_false_loss: 10.5389 - val_true_loss: 1.1062\n",
      "Epoch 1045/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.7034 - reconstruction_loss: 1891.4336 - kl_loss: 99.4789 - false_loss: 0.0766 - true_loss: 1.0438 - val_loss: 5267.4556 - val_reconstruction_loss: 1895.5723 - val_kl_loss: 99.8824 - val_false_loss: 10.5379 - val_true_loss: 1.1062\n",
      "Epoch 1046/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.2417 - reconstruction_loss: 1891.6129 - kl_loss: 100.1737 - false_loss: 0.0766 - true_loss: 1.0438 - val_loss: 5267.1670 - val_reconstruction_loss: 1895.5714 - val_kl_loss: 99.8825 - val_false_loss: 10.5370 - val_true_loss: 1.1061\n",
      "Epoch 1047/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.0378 - reconstruction_loss: 1891.0024 - kl_loss: 100.0421 - false_loss: 0.0766 - true_loss: 1.0437 - val_loss: 5266.8774 - val_reconstruction_loss: 1895.5708 - val_kl_loss: 99.8824 - val_false_loss: 10.5360 - val_true_loss: 1.1061\n",
      "Epoch 1048/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2463 - reconstruction_loss: 1891.0978 - kl_loss: 98.1645 - false_loss: 0.0766 - true_loss: 1.0437 - val_loss: 5266.5923 - val_reconstruction_loss: 1895.5704 - val_kl_loss: 99.8822 - val_false_loss: 10.5351 - val_true_loss: 1.1060\n",
      "Epoch 1049/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.6278 - reconstruction_loss: 1891.7015 - kl_loss: 99.4846 - false_loss: 0.0766 - true_loss: 1.0437 - val_loss: 5266.3037 - val_reconstruction_loss: 1895.5701 - val_kl_loss: 99.8824 - val_false_loss: 10.5342 - val_true_loss: 1.1060\n",
      "Epoch 1050/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.3109 - reconstruction_loss: 1891.6113 - kl_loss: 98.2798 - false_loss: 0.0765 - true_loss: 1.0436 - val_loss: 5266.0137 - val_reconstruction_loss: 1895.5696 - val_kl_loss: 99.8829 - val_false_loss: 10.5332 - val_true_loss: 1.1060\n",
      "Epoch 1051/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.5329 - reconstruction_loss: 1891.5428 - kl_loss: 99.0427 - false_loss: 0.0765 - true_loss: 1.0436 - val_loss: 5265.7246 - val_reconstruction_loss: 1895.5690 - val_kl_loss: 99.8833 - val_false_loss: 10.5322 - val_true_loss: 1.1059\n",
      "Epoch 1052/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.5661 - reconstruction_loss: 1891.1266 - kl_loss: 102.6856 - false_loss: 0.0765 - true_loss: 1.0436 - val_loss: 5265.4390 - val_reconstruction_loss: 1895.5686 - val_kl_loss: 99.8839 - val_false_loss: 10.5313 - val_true_loss: 1.1059\n",
      "Epoch 1053/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.5614 - reconstruction_loss: 1891.1416 - kl_loss: 100.8433 - false_loss: 0.0765 - true_loss: 1.0435 - val_loss: 5265.1514 - val_reconstruction_loss: 1895.5682 - val_kl_loss: 99.8844 - val_false_loss: 10.5304 - val_true_loss: 1.1059\n",
      "Epoch 1054/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2227.0245 - reconstruction_loss: 1891.2402 - kl_loss: 100.1791 - false_loss: 0.0765 - true_loss: 1.0435 - val_loss: 5264.8643 - val_reconstruction_loss: 1895.5674 - val_kl_loss: 99.8846 - val_false_loss: 10.5294 - val_true_loss: 1.1058\n",
      "Epoch 1055/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.8530 - reconstruction_loss: 1892.0446 - kl_loss: 100.1186 - false_loss: 0.0765 - true_loss: 1.0435 - val_loss: 5264.5781 - val_reconstruction_loss: 1895.5673 - val_kl_loss: 99.8846 - val_false_loss: 10.5285 - val_true_loss: 1.1058\n",
      "Epoch 1056/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.4057 - reconstruction_loss: 1891.9320 - kl_loss: 100.8529 - false_loss: 0.0765 - true_loss: 1.0434 - val_loss: 5264.2925 - val_reconstruction_loss: 1895.5667 - val_kl_loss: 99.8851 - val_false_loss: 10.5275 - val_true_loss: 1.1058\n",
      "Epoch 1057/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.0976 - reconstruction_loss: 1890.9332 - kl_loss: 101.9963 - false_loss: 0.0765 - true_loss: 1.0434 - val_loss: 5264.0088 - val_reconstruction_loss: 1895.5660 - val_kl_loss: 99.8853 - val_false_loss: 10.5266 - val_true_loss: 1.1057\n",
      "Epoch 1058/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6521 - reconstruction_loss: 1890.8715 - kl_loss: 100.3881 - false_loss: 0.0765 - true_loss: 1.0434 - val_loss: 5263.7207 - val_reconstruction_loss: 1895.5657 - val_kl_loss: 99.8854 - val_false_loss: 10.5257 - val_true_loss: 1.1057\n",
      "Epoch 1059/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.7684 - reconstruction_loss: 1890.8956 - kl_loss: 100.9763 - false_loss: 0.0765 - true_loss: 1.0433 - val_loss: 5263.4360 - val_reconstruction_loss: 1895.5651 - val_kl_loss: 99.8857 - val_false_loss: 10.5247 - val_true_loss: 1.1057\n",
      "Epoch 1060/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.9264 - reconstruction_loss: 1890.7806 - kl_loss: 101.3713 - false_loss: 0.0765 - true_loss: 1.0433 - val_loss: 5263.1470 - val_reconstruction_loss: 1895.5646 - val_kl_loss: 99.8861 - val_false_loss: 10.5238 - val_true_loss: 1.1056\n",
      "Epoch 1061/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.6009 - reconstruction_loss: 1890.9645 - kl_loss: 101.9768 - false_loss: 0.0765 - true_loss: 1.0433 - val_loss: 5262.8560 - val_reconstruction_loss: 1895.5640 - val_kl_loss: 99.8865 - val_false_loss: 10.5228 - val_true_loss: 1.1056\n",
      "Epoch 1062/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.5047 - reconstruction_loss: 1891.1259 - kl_loss: 101.4111 - false_loss: 0.0765 - true_loss: 1.0432 - val_loss: 5262.5669 - val_reconstruction_loss: 1895.5634 - val_kl_loss: 99.8870 - val_false_loss: 10.5219 - val_true_loss: 1.1056\n",
      "Epoch 1063/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.7697 - reconstruction_loss: 1891.5402 - kl_loss: 100.0858 - false_loss: 0.0765 - true_loss: 1.0432 - val_loss: 5262.2793 - val_reconstruction_loss: 1895.5630 - val_kl_loss: 99.8874 - val_false_loss: 10.5209 - val_true_loss: 1.1055\n",
      "Epoch 1064/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.1319 - reconstruction_loss: 1891.2977 - kl_loss: 101.3817 - false_loss: 0.0765 - true_loss: 1.0432 - val_loss: 5261.9907 - val_reconstruction_loss: 1895.5624 - val_kl_loss: 99.8880 - val_false_loss: 10.5200 - val_true_loss: 1.1055\n",
      "Epoch 1065/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.6324 - reconstruction_loss: 1890.9603 - kl_loss: 102.0514 - false_loss: 0.0765 - true_loss: 1.0431 - val_loss: 5261.7017 - val_reconstruction_loss: 1895.5618 - val_kl_loss: 99.8886 - val_false_loss: 10.5190 - val_true_loss: 1.1055\n",
      "Epoch 1066/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.8625 - reconstruction_loss: 1890.5612 - kl_loss: 102.0767 - false_loss: 0.0765 - true_loss: 1.0431 - val_loss: 5261.4106 - val_reconstruction_loss: 1895.5614 - val_kl_loss: 99.8888 - val_false_loss: 10.5180 - val_true_loss: 1.1054\n",
      "Epoch 1067/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.7326 - reconstruction_loss: 1890.7509 - kl_loss: 101.0676 - false_loss: 0.0765 - true_loss: 1.0430 - val_loss: 5261.1211 - val_reconstruction_loss: 1895.5610 - val_kl_loss: 99.8890 - val_false_loss: 10.5171 - val_true_loss: 1.1054\n",
      "Epoch 1068/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.4501 - reconstruction_loss: 1891.1571 - kl_loss: 100.3293 - false_loss: 0.0764 - true_loss: 1.0430 - val_loss: 5260.8320 - val_reconstruction_loss: 1895.5602 - val_kl_loss: 99.8895 - val_false_loss: 10.5161 - val_true_loss: 1.1053\n",
      "Epoch 1069/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.6220 - reconstruction_loss: 1890.7720 - kl_loss: 101.9286 - false_loss: 0.0764 - true_loss: 1.0430 - val_loss: 5260.5439 - val_reconstruction_loss: 1895.5598 - val_kl_loss: 99.8896 - val_false_loss: 10.5152 - val_true_loss: 1.1053\n",
      "Epoch 1070/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.8861 - reconstruction_loss: 1890.6837 - kl_loss: 101.7390 - false_loss: 0.0764 - true_loss: 1.0429 - val_loss: 5260.2573 - val_reconstruction_loss: 1895.5594 - val_kl_loss: 99.8898 - val_false_loss: 10.5143 - val_true_loss: 1.1053\n",
      "Epoch 1071/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.4876 - reconstruction_loss: 1891.5052 - kl_loss: 100.3517 - false_loss: 0.0764 - true_loss: 1.0429 - val_loss: 5259.9692 - val_reconstruction_loss: 1895.5591 - val_kl_loss: 99.8900 - val_false_loss: 10.5133 - val_true_loss: 1.1052\n",
      "Epoch 1072/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.9130 - reconstruction_loss: 1891.1791 - kl_loss: 99.8395 - false_loss: 0.0764 - true_loss: 1.0429 - val_loss: 5259.6797 - val_reconstruction_loss: 1895.5587 - val_kl_loss: 99.8900 - val_false_loss: 10.5124 - val_true_loss: 1.1052\n",
      "Epoch 1073/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.1438 - reconstruction_loss: 1891.3320 - kl_loss: 101.5584 - false_loss: 0.0764 - true_loss: 1.0428 - val_loss: 5259.3960 - val_reconstruction_loss: 1895.5581 - val_kl_loss: 99.8906 - val_false_loss: 10.5114 - val_true_loss: 1.1052\n",
      "Epoch 1074/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.4270 - reconstruction_loss: 1891.2052 - kl_loss: 102.0352 - false_loss: 0.0764 - true_loss: 1.0428 - val_loss: 5259.1118 - val_reconstruction_loss: 1895.5576 - val_kl_loss: 99.8908 - val_false_loss: 10.5105 - val_true_loss: 1.1051\n",
      "Epoch 1075/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.9375 - reconstruction_loss: 1891.7939 - kl_loss: 100.2921 - false_loss: 0.0764 - true_loss: 1.0428 - val_loss: 5258.8232 - val_reconstruction_loss: 1895.5570 - val_kl_loss: 99.8905 - val_false_loss: 10.5095 - val_true_loss: 1.1051\n",
      "Epoch 1076/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.0900 - reconstruction_loss: 1891.6724 - kl_loss: 101.7635 - false_loss: 0.0764 - true_loss: 1.0427 - val_loss: 5258.5376 - val_reconstruction_loss: 1895.5566 - val_kl_loss: 99.8908 - val_false_loss: 10.5086 - val_true_loss: 1.1051\n",
      "Epoch 1077/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.2170 - reconstruction_loss: 1891.1710 - kl_loss: 101.5285 - false_loss: 0.0764 - true_loss: 1.0427 - val_loss: 5258.2534 - val_reconstruction_loss: 1895.5560 - val_kl_loss: 99.8913 - val_false_loss: 10.5077 - val_true_loss: 1.1050\n",
      "Epoch 1078/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.2519 - reconstruction_loss: 1891.0380 - kl_loss: 99.4208 - false_loss: 0.0764 - true_loss: 1.0427 - val_loss: 5257.9683 - val_reconstruction_loss: 1895.5554 - val_kl_loss: 99.8917 - val_false_loss: 10.5067 - val_true_loss: 1.1050\n",
      "Epoch 1079/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.7603 - reconstruction_loss: 1890.9366 - kl_loss: 100.3188 - false_loss: 0.0764 - true_loss: 1.0427 - val_loss: 5257.6841 - val_reconstruction_loss: 1895.5551 - val_kl_loss: 99.8918 - val_false_loss: 10.5058 - val_true_loss: 1.1050\n",
      "Epoch 1080/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1832 - reconstruction_loss: 1890.8636 - kl_loss: 100.8651 - false_loss: 0.0764 - true_loss: 1.0426 - val_loss: 5257.3979 - val_reconstruction_loss: 1895.5544 - val_kl_loss: 99.8924 - val_false_loss: 10.5048 - val_true_loss: 1.1049\n",
      "Epoch 1081/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.0718 - reconstruction_loss: 1890.9037 - kl_loss: 101.0899 - false_loss: 0.0764 - true_loss: 1.0426 - val_loss: 5257.1128 - val_reconstruction_loss: 1895.5538 - val_kl_loss: 99.8928 - val_false_loss: 10.5039 - val_true_loss: 1.1049\n",
      "Epoch 1082/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.9504 - reconstruction_loss: 1891.1115 - kl_loss: 99.8557 - false_loss: 0.0764 - true_loss: 1.0426 - val_loss: 5256.8228 - val_reconstruction_loss: 1895.5535 - val_kl_loss: 99.8926 - val_false_loss: 10.5030 - val_true_loss: 1.1049\n",
      "Epoch 1083/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5654 - reconstruction_loss: 1891.7281 - kl_loss: 95.6707 - false_loss: 0.0764 - true_loss: 1.0425 - val_loss: 5256.5361 - val_reconstruction_loss: 1895.5531 - val_kl_loss: 99.8919 - val_false_loss: 10.5020 - val_true_loss: 1.1048\n",
      "Epoch 1084/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.4875 - reconstruction_loss: 1891.1904 - kl_loss: 97.9134 - false_loss: 0.0764 - true_loss: 1.0425 - val_loss: 5256.2529 - val_reconstruction_loss: 1895.5527 - val_kl_loss: 99.8920 - val_false_loss: 10.5011 - val_true_loss: 1.1048\n",
      "Epoch 1085/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.9967 - reconstruction_loss: 1891.1044 - kl_loss: 100.7703 - false_loss: 0.0764 - true_loss: 1.0425 - val_loss: 5255.9722 - val_reconstruction_loss: 1895.5519 - val_kl_loss: 99.8923 - val_false_loss: 10.5002 - val_true_loss: 1.1048\n",
      "Epoch 1086/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.1423 - reconstruction_loss: 1890.6818 - kl_loss: 101.1864 - false_loss: 0.0763 - true_loss: 1.0424 - val_loss: 5255.6880 - val_reconstruction_loss: 1895.5515 - val_kl_loss: 99.8925 - val_false_loss: 10.4992 - val_true_loss: 1.1047\n",
      "Epoch 1087/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.7969 - reconstruction_loss: 1890.8444 - kl_loss: 100.8246 - false_loss: 0.0763 - true_loss: 1.0424 - val_loss: 5255.3989 - val_reconstruction_loss: 1895.5511 - val_kl_loss: 99.8920 - val_false_loss: 10.4983 - val_true_loss: 1.1047\n",
      "Epoch 1088/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.6915 - reconstruction_loss: 1891.2152 - kl_loss: 99.3104 - false_loss: 0.0763 - true_loss: 1.0424 - val_loss: 5255.1128 - val_reconstruction_loss: 1895.5505 - val_kl_loss: 99.8921 - val_false_loss: 10.4973 - val_true_loss: 1.1047\n",
      "Epoch 1089/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.7032 - reconstruction_loss: 1891.2396 - kl_loss: 102.5264 - false_loss: 0.0763 - true_loss: 1.0423 - val_loss: 5254.8193 - val_reconstruction_loss: 1895.5502 - val_kl_loss: 99.8919 - val_false_loss: 10.4964 - val_true_loss: 1.1046\n",
      "Epoch 1090/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.7404 - reconstruction_loss: 1891.5186 - kl_loss: 100.4043 - false_loss: 0.0763 - true_loss: 1.0423 - val_loss: 5254.5298 - val_reconstruction_loss: 1895.5496 - val_kl_loss: 99.8925 - val_false_loss: 10.4954 - val_true_loss: 1.1046\n",
      "Epoch 1091/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.0701 - reconstruction_loss: 1891.6943 - kl_loss: 101.4225 - false_loss: 0.0763 - true_loss: 1.0423 - val_loss: 5254.2402 - val_reconstruction_loss: 1895.5490 - val_kl_loss: 99.8930 - val_false_loss: 10.4945 - val_true_loss: 1.1046\n",
      "Epoch 1092/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.3410 - reconstruction_loss: 1890.9030 - kl_loss: 100.5191 - false_loss: 0.0763 - true_loss: 1.0422 - val_loss: 5253.9561 - val_reconstruction_loss: 1895.5483 - val_kl_loss: 99.8931 - val_false_loss: 10.4935 - val_true_loss: 1.1045\n",
      "Epoch 1093/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2215.9111 - reconstruction_loss: 1890.7213 - kl_loss: 99.4951 - false_loss: 0.0763 - true_loss: 1.0422 - val_loss: 5253.6709 - val_reconstruction_loss: 1895.5480 - val_kl_loss: 99.8928 - val_false_loss: 10.4926 - val_true_loss: 1.1045\n",
      "Epoch 1094/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.9956 - reconstruction_loss: 1890.6073 - kl_loss: 100.2416 - false_loss: 0.0763 - true_loss: 1.0422 - val_loss: 5253.3896 - val_reconstruction_loss: 1895.5475 - val_kl_loss: 99.8928 - val_false_loss: 10.4917 - val_true_loss: 1.1045\n",
      "Epoch 1095/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.4275 - reconstruction_loss: 1891.2432 - kl_loss: 100.5531 - false_loss: 0.0763 - true_loss: 1.0421 - val_loss: 5253.1050 - val_reconstruction_loss: 1895.5469 - val_kl_loss: 99.8928 - val_false_loss: 10.4907 - val_true_loss: 1.1044\n",
      "Epoch 1096/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.0556 - reconstruction_loss: 1891.0656 - kl_loss: 99.6336 - false_loss: 0.0763 - true_loss: 1.0421 - val_loss: 5252.8203 - val_reconstruction_loss: 1895.5463 - val_kl_loss: 99.8933 - val_false_loss: 10.4898 - val_true_loss: 1.1044\n",
      "Epoch 1097/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.0414 - reconstruction_loss: 1890.8457 - kl_loss: 100.3700 - false_loss: 0.0763 - true_loss: 1.0421 - val_loss: 5252.5386 - val_reconstruction_loss: 1895.5459 - val_kl_loss: 99.8937 - val_false_loss: 10.4889 - val_true_loss: 1.1044\n",
      "Epoch 1098/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.7369 - reconstruction_loss: 1890.7529 - kl_loss: 96.7674 - false_loss: 0.0763 - true_loss: 1.0421 - val_loss: 5252.2563 - val_reconstruction_loss: 1895.5455 - val_kl_loss: 99.8934 - val_false_loss: 10.4879 - val_true_loss: 1.1043\n",
      "Epoch 1099/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.1387 - reconstruction_loss: 1890.7909 - kl_loss: 100.2276 - false_loss: 0.0763 - true_loss: 1.0420 - val_loss: 5251.9736 - val_reconstruction_loss: 1895.5452 - val_kl_loss: 99.8936 - val_false_loss: 10.4870 - val_true_loss: 1.1043\n",
      "Epoch 1100/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.7435 - reconstruction_loss: 1891.2295 - kl_loss: 100.3564 - false_loss: 0.0763 - true_loss: 1.0420 - val_loss: 5251.6914 - val_reconstruction_loss: 1895.5446 - val_kl_loss: 99.8938 - val_false_loss: 10.4861 - val_true_loss: 1.1043\n",
      "Epoch 1101/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.0349 - reconstruction_loss: 1890.6979 - kl_loss: 99.3276 - false_loss: 0.0763 - true_loss: 1.0420 - val_loss: 5251.4077 - val_reconstruction_loss: 1895.5439 - val_kl_loss: 99.8940 - val_false_loss: 10.4851 - val_true_loss: 1.1043\n",
      "Epoch 1102/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.4070 - reconstruction_loss: 1890.8307 - kl_loss: 101.1473 - false_loss: 0.0763 - true_loss: 1.0419 - val_loss: 5251.1245 - val_reconstruction_loss: 1895.5436 - val_kl_loss: 99.8943 - val_false_loss: 10.4842 - val_true_loss: 1.1042\n",
      "Epoch 1103/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.8663 - reconstruction_loss: 1890.6420 - kl_loss: 98.5495 - false_loss: 0.0763 - true_loss: 1.0419 - val_loss: 5250.8428 - val_reconstruction_loss: 1895.5430 - val_kl_loss: 99.8942 - val_false_loss: 10.4833 - val_true_loss: 1.1042\n",
      "Epoch 1104/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.8667 - reconstruction_loss: 1890.7162 - kl_loss: 100.6633 - false_loss: 0.0763 - true_loss: 1.0419 - val_loss: 5250.5635 - val_reconstruction_loss: 1895.5426 - val_kl_loss: 99.8945 - val_false_loss: 10.4823 - val_true_loss: 1.1042\n",
      "Epoch 1105/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.3266 - reconstruction_loss: 1891.0306 - kl_loss: 97.6179 - false_loss: 0.0762 - true_loss: 1.0418 - val_loss: 5250.2812 - val_reconstruction_loss: 1895.5420 - val_kl_loss: 99.8946 - val_false_loss: 10.4814 - val_true_loss: 1.1041\n",
      "Epoch 1106/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.7450 - reconstruction_loss: 1890.7959 - kl_loss: 98.5777 - false_loss: 0.0762 - true_loss: 1.0418 - val_loss: 5249.9976 - val_reconstruction_loss: 1895.5414 - val_kl_loss: 99.8949 - val_false_loss: 10.4805 - val_true_loss: 1.1041\n",
      "Epoch 1107/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.2441 - reconstruction_loss: 1891.1700 - kl_loss: 101.1064 - false_loss: 0.0762 - true_loss: 1.0418 - val_loss: 5249.7173 - val_reconstruction_loss: 1895.5410 - val_kl_loss: 99.8951 - val_false_loss: 10.4796 - val_true_loss: 1.1041\n",
      "Epoch 1108/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.1378 - reconstruction_loss: 1891.1871 - kl_loss: 100.2319 - false_loss: 0.0762 - true_loss: 1.0417 - val_loss: 5249.4326 - val_reconstruction_loss: 1895.5404 - val_kl_loss: 99.8951 - val_false_loss: 10.4786 - val_true_loss: 1.1040\n",
      "Epoch 1109/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2223.4920 - reconstruction_loss: 1890.9760 - kl_loss: 99.7468 - false_loss: 0.0762 - true_loss: 1.0417 - val_loss: 5249.1499 - val_reconstruction_loss: 1895.5400 - val_kl_loss: 99.8954 - val_false_loss: 10.4777 - val_true_loss: 1.1040\n",
      "Epoch 1110/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.0277 - reconstruction_loss: 1890.9493 - kl_loss: 99.4809 - false_loss: 0.0762 - true_loss: 1.0417 - val_loss: 5248.8657 - val_reconstruction_loss: 1895.5394 - val_kl_loss: 99.8954 - val_false_loss: 10.4768 - val_true_loss: 1.1040\n",
      "Epoch 1111/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.1710 - reconstruction_loss: 1890.7925 - kl_loss: 101.0801 - false_loss: 0.0762 - true_loss: 1.0416 - val_loss: 5248.5840 - val_reconstruction_loss: 1895.5388 - val_kl_loss: 99.8954 - val_false_loss: 10.4758 - val_true_loss: 1.1039\n",
      "Epoch 1112/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.6410 - reconstruction_loss: 1890.6323 - kl_loss: 101.3019 - false_loss: 0.0762 - true_loss: 1.0416 - val_loss: 5248.3027 - val_reconstruction_loss: 1895.5385 - val_kl_loss: 99.8957 - val_false_loss: 10.4749 - val_true_loss: 1.1039\n",
      "Epoch 1113/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.9842 - reconstruction_loss: 1891.1300 - kl_loss: 101.8703 - false_loss: 0.0762 - true_loss: 1.0416 - val_loss: 5248.0234 - val_reconstruction_loss: 1895.5378 - val_kl_loss: 99.8959 - val_false_loss: 10.4740 - val_true_loss: 1.1039\n",
      "Epoch 1114/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.9912 - reconstruction_loss: 1890.9777 - kl_loss: 99.5010 - false_loss: 0.0762 - true_loss: 1.0415 - val_loss: 5247.7437 - val_reconstruction_loss: 1895.5372 - val_kl_loss: 99.8962 - val_false_loss: 10.4731 - val_true_loss: 1.1038\n",
      "Epoch 1115/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.9484 - reconstruction_loss: 1890.5594 - kl_loss: 100.8738 - false_loss: 0.0762 - true_loss: 1.0415 - val_loss: 5247.4600 - val_reconstruction_loss: 1895.5369 - val_kl_loss: 99.8965 - val_false_loss: 10.4721 - val_true_loss: 1.1038\n",
      "Epoch 1116/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.4822 - reconstruction_loss: 1891.5021 - kl_loss: 100.3889 - false_loss: 0.0762 - true_loss: 1.0415 - val_loss: 5247.1738 - val_reconstruction_loss: 1895.5365 - val_kl_loss: 99.8968 - val_false_loss: 10.4712 - val_true_loss: 1.1037\n",
      "Epoch 1117/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.0644 - reconstruction_loss: 1890.7881 - kl_loss: 101.0425 - false_loss: 0.0762 - true_loss: 1.0414 - val_loss: 5246.8936 - val_reconstruction_loss: 1895.5359 - val_kl_loss: 99.8969 - val_false_loss: 10.4703 - val_true_loss: 1.1037\n",
      "Epoch 1118/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.9300 - reconstruction_loss: 1890.9095 - kl_loss: 101.8567 - false_loss: 0.0762 - true_loss: 1.0414 - val_loss: 5246.6123 - val_reconstruction_loss: 1895.5353 - val_kl_loss: 99.8973 - val_false_loss: 10.4694 - val_true_loss: 1.1037\n",
      "Epoch 1119/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.9110 - reconstruction_loss: 1890.6499 - kl_loss: 102.6944 - false_loss: 0.0762 - true_loss: 1.0414 - val_loss: 5246.3262 - val_reconstruction_loss: 1895.5347 - val_kl_loss: 99.8975 - val_false_loss: 10.4684 - val_true_loss: 1.1036\n",
      "Epoch 1120/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.1086 - reconstruction_loss: 1890.4761 - kl_loss: 101.8043 - false_loss: 0.0762 - true_loss: 1.0413 - val_loss: 5246.0420 - val_reconstruction_loss: 1895.5343 - val_kl_loss: 99.8981 - val_false_loss: 10.4675 - val_true_loss: 1.1036\n",
      "Epoch 1121/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.3505 - reconstruction_loss: 1890.9711 - kl_loss: 102.5099 - false_loss: 0.0762 - true_loss: 1.0413 - val_loss: 5245.7583 - val_reconstruction_loss: 1895.5337 - val_kl_loss: 99.8980 - val_false_loss: 10.4666 - val_true_loss: 1.1036\n",
      "Epoch 1122/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.4545 - reconstruction_loss: 1890.8414 - kl_loss: 102.2033 - false_loss: 0.0762 - true_loss: 1.0413 - val_loss: 5245.4736 - val_reconstruction_loss: 1895.5331 - val_kl_loss: 99.8978 - val_false_loss: 10.4656 - val_true_loss: 1.1035\n",
      "Epoch 1123/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.7832 - reconstruction_loss: 1890.6520 - kl_loss: 101.9768 - false_loss: 0.0761 - true_loss: 1.0412 - val_loss: 5245.1880 - val_reconstruction_loss: 1895.5327 - val_kl_loss: 99.8982 - val_false_loss: 10.4647 - val_true_loss: 1.1035\n",
      "Epoch 1124/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.6063 - reconstruction_loss: 1890.6060 - kl_loss: 102.5770 - false_loss: 0.0761 - true_loss: 1.0412 - val_loss: 5244.9033 - val_reconstruction_loss: 1895.5323 - val_kl_loss: 99.8987 - val_false_loss: 10.4637 - val_true_loss: 1.1034\n",
      "Epoch 1125/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8874 - reconstruction_loss: 1890.6998 - kl_loss: 100.6677 - false_loss: 0.0761 - true_loss: 1.0411 - val_loss: 5244.6187 - val_reconstruction_loss: 1895.5317 - val_kl_loss: 99.8989 - val_false_loss: 10.4628 - val_true_loss: 1.1034\n",
      "Epoch 1126/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.5552 - reconstruction_loss: 1891.1478 - kl_loss: 101.8256 - false_loss: 0.0761 - true_loss: 1.0411 - val_loss: 5244.3315 - val_reconstruction_loss: 1895.5311 - val_kl_loss: 99.8992 - val_false_loss: 10.4619 - val_true_loss: 1.1034\n",
      "Epoch 1127/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.8051 - reconstruction_loss: 1890.9990 - kl_loss: 102.9970 - false_loss: 0.0761 - true_loss: 1.0411 - val_loss: 5244.0464 - val_reconstruction_loss: 1895.5305 - val_kl_loss: 99.8996 - val_false_loss: 10.4609 - val_true_loss: 1.1033\n",
      "Epoch 1128/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.4970 - reconstruction_loss: 1890.7760 - kl_loss: 102.1256 - false_loss: 0.0761 - true_loss: 1.0410 - val_loss: 5243.7651 - val_reconstruction_loss: 1895.5302 - val_kl_loss: 99.8992 - val_false_loss: 10.4600 - val_true_loss: 1.1033\n",
      "Epoch 1129/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2570 - reconstruction_loss: 1891.3042 - kl_loss: 96.2468 - false_loss: 0.0761 - true_loss: 1.0410 - val_loss: 5243.4839 - val_reconstruction_loss: 1895.5295 - val_kl_loss: 99.8994 - val_false_loss: 10.4591 - val_true_loss: 1.1033\n",
      "Epoch 1130/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.3565 - reconstruction_loss: 1891.6582 - kl_loss: 101.1641 - false_loss: 0.0761 - true_loss: 1.0410 - val_loss: 5243.2026 - val_reconstruction_loss: 1895.5289 - val_kl_loss: 99.8996 - val_false_loss: 10.4581 - val_true_loss: 1.1032\n",
      "Epoch 1131/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.0729 - reconstruction_loss: 1891.3612 - kl_loss: 100.5772 - false_loss: 0.0761 - true_loss: 1.0409 - val_loss: 5242.9229 - val_reconstruction_loss: 1895.5286 - val_kl_loss: 99.9000 - val_false_loss: 10.4572 - val_true_loss: 1.1032\n",
      "Epoch 1132/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.4876 - reconstruction_loss: 1891.2345 - kl_loss: 102.4081 - false_loss: 0.0761 - true_loss: 1.0409 - val_loss: 5242.6426 - val_reconstruction_loss: 1895.5282 - val_kl_loss: 99.9006 - val_false_loss: 10.4563 - val_true_loss: 1.1032\n",
      "Epoch 1133/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.0681 - reconstruction_loss: 1890.7968 - kl_loss: 101.4482 - false_loss: 0.0761 - true_loss: 1.0409 - val_loss: 5242.3623 - val_reconstruction_loss: 1895.5276 - val_kl_loss: 99.9005 - val_false_loss: 10.4554 - val_true_loss: 1.1031\n",
      "Epoch 1134/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.2526 - reconstruction_loss: 1890.6089 - kl_loss: 102.2746 - false_loss: 0.0761 - true_loss: 1.0408 - val_loss: 5242.0811 - val_reconstruction_loss: 1895.5272 - val_kl_loss: 99.9008 - val_false_loss: 10.4545 - val_true_loss: 1.1031\n",
      "Epoch 1135/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.2743 - reconstruction_loss: 1891.5096 - kl_loss: 101.5362 - false_loss: 0.0761 - true_loss: 1.0408 - val_loss: 5241.7944 - val_reconstruction_loss: 1895.5269 - val_kl_loss: 99.9008 - val_false_loss: 10.4535 - val_true_loss: 1.1031\n",
      "Epoch 1136/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.5773 - reconstruction_loss: 1891.2880 - kl_loss: 101.5636 - false_loss: 0.0761 - true_loss: 1.0408 - val_loss: 5241.5146 - val_reconstruction_loss: 1895.5262 - val_kl_loss: 99.9011 - val_false_loss: 10.4526 - val_true_loss: 1.1030\n",
      "Epoch 1137/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.2081 - reconstruction_loss: 1890.8994 - kl_loss: 100.6167 - false_loss: 0.0761 - true_loss: 1.0407 - val_loss: 5241.2339 - val_reconstruction_loss: 1895.5259 - val_kl_loss: 99.9016 - val_false_loss: 10.4517 - val_true_loss: 1.1030\n",
      "Epoch 1138/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.3030 - reconstruction_loss: 1890.5597 - kl_loss: 102.4444 - false_loss: 0.0761 - true_loss: 1.0407 - val_loss: 5240.9492 - val_reconstruction_loss: 1895.5253 - val_kl_loss: 99.9015 - val_false_loss: 10.4507 - val_true_loss: 1.1030\n",
      "Epoch 1139/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.8548 - reconstruction_loss: 1890.5176 - kl_loss: 100.9068 - false_loss: 0.0761 - true_loss: 1.0407 - val_loss: 5240.6665 - val_reconstruction_loss: 1895.5248 - val_kl_loss: 99.9021 - val_false_loss: 10.4498 - val_true_loss: 1.1029\n",
      "Epoch 1140/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.2415 - reconstruction_loss: 1890.6986 - kl_loss: 101.4879 - false_loss: 0.0761 - true_loss: 1.0406 - val_loss: 5240.3823 - val_reconstruction_loss: 1895.5243 - val_kl_loss: 99.9021 - val_false_loss: 10.4489 - val_true_loss: 1.1029\n",
      "Epoch 1141/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2225.3536 - reconstruction_loss: 1890.6014 - kl_loss: 99.0808 - false_loss: 0.0760 - true_loss: 1.0406 - val_loss: 5240.1006 - val_reconstruction_loss: 1895.5238 - val_kl_loss: 99.9024 - val_false_loss: 10.4479 - val_true_loss: 1.1029\n",
      "Epoch 1142/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9857 - reconstruction_loss: 1890.6937 - kl_loss: 99.8188 - false_loss: 0.0760 - true_loss: 1.0406 - val_loss: 5239.8164 - val_reconstruction_loss: 1895.5233 - val_kl_loss: 99.9027 - val_false_loss: 10.4470 - val_true_loss: 1.1028\n",
      "Epoch 1143/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.3094 - reconstruction_loss: 1890.6577 - kl_loss: 98.2697 - false_loss: 0.0760 - true_loss: 1.0406 - val_loss: 5239.5303 - val_reconstruction_loss: 1895.5227 - val_kl_loss: 99.9023 - val_false_loss: 10.4461 - val_true_loss: 1.1028\n",
      "Epoch 1144/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.3997 - reconstruction_loss: 1890.5370 - kl_loss: 100.7346 - false_loss: 0.0760 - true_loss: 1.0405 - val_loss: 5239.2466 - val_reconstruction_loss: 1895.5221 - val_kl_loss: 99.9026 - val_false_loss: 10.4451 - val_true_loss: 1.1028\n",
      "Epoch 1145/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2213.6076 - reconstruction_loss: 1890.3872 - kl_loss: 101.2775 - false_loss: 0.0760 - true_loss: 1.0405 - val_loss: 5238.9644 - val_reconstruction_loss: 1895.5215 - val_kl_loss: 99.9028 - val_false_loss: 10.4442 - val_true_loss: 1.1027\n",
      "Epoch 1146/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.8469 - reconstruction_loss: 1890.6783 - kl_loss: 101.3755 - false_loss: 0.0760 - true_loss: 1.0405 - val_loss: 5238.6851 - val_reconstruction_loss: 1895.5211 - val_kl_loss: 99.9031 - val_false_loss: 10.4433 - val_true_loss: 1.1027\n",
      "Epoch 1147/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.9263 - reconstruction_loss: 1890.9015 - kl_loss: 99.8226 - false_loss: 0.0760 - true_loss: 1.0404 - val_loss: 5238.4019 - val_reconstruction_loss: 1895.5205 - val_kl_loss: 99.9033 - val_false_loss: 10.4423 - val_true_loss: 1.1027\n",
      "Epoch 1148/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1933 - reconstruction_loss: 1890.8392 - kl_loss: 96.9281 - false_loss: 0.0760 - true_loss: 1.0404 - val_loss: 5238.1216 - val_reconstruction_loss: 1895.5199 - val_kl_loss: 99.9029 - val_false_loss: 10.4414 - val_true_loss: 1.1027\n",
      "Epoch 1149/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2229.0328 - reconstruction_loss: 1891.2764 - kl_loss: 98.7047 - false_loss: 0.0760 - true_loss: 1.0404 - val_loss: 5237.8403 - val_reconstruction_loss: 1895.5195 - val_kl_loss: 99.9027 - val_false_loss: 10.4405 - val_true_loss: 1.1026\n",
      "Epoch 1150/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2224.2005 - reconstruction_loss: 1891.0453 - kl_loss: 98.8699 - false_loss: 0.0760 - true_loss: 1.0403 - val_loss: 5237.5566 - val_reconstruction_loss: 1895.5192 - val_kl_loss: 99.9027 - val_false_loss: 10.4396 - val_true_loss: 1.1026\n",
      "Epoch 1151/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4654 - reconstruction_loss: 1890.6154 - kl_loss: 100.1375 - false_loss: 0.0760 - true_loss: 1.0403 - val_loss: 5237.2764 - val_reconstruction_loss: 1895.5183 - val_kl_loss: 99.9030 - val_false_loss: 10.4386 - val_true_loss: 1.1026\n",
      "Epoch 1152/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.0656 - reconstruction_loss: 1890.7207 - kl_loss: 99.8288 - false_loss: 0.0760 - true_loss: 1.0403 - val_loss: 5236.9941 - val_reconstruction_loss: 1895.5182 - val_kl_loss: 99.9033 - val_false_loss: 10.4377 - val_true_loss: 1.1026\n",
      "Epoch 1153/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.0491 - reconstruction_loss: 1890.6613 - kl_loss: 101.4714 - false_loss: 0.0760 - true_loss: 1.0402 - val_loss: 5236.7119 - val_reconstruction_loss: 1895.5176 - val_kl_loss: 99.9035 - val_false_loss: 10.4368 - val_true_loss: 1.1025\n",
      "Epoch 1154/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.5676 - reconstruction_loss: 1890.4552 - kl_loss: 101.6056 - false_loss: 0.0760 - true_loss: 1.0402 - val_loss: 5236.4312 - val_reconstruction_loss: 1895.5170 - val_kl_loss: 99.9037 - val_false_loss: 10.4359 - val_true_loss: 1.1025\n",
      "Epoch 1155/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.4202 - reconstruction_loss: 1890.4364 - kl_loss: 101.0419 - false_loss: 0.0760 - true_loss: 1.0402 - val_loss: 5236.1509 - val_reconstruction_loss: 1895.5166 - val_kl_loss: 99.9042 - val_false_loss: 10.4349 - val_true_loss: 1.1025\n",
      "Epoch 1156/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.0388 - reconstruction_loss: 1890.7889 - kl_loss: 101.2593 - false_loss: 0.0760 - true_loss: 1.0401 - val_loss: 5235.8696 - val_reconstruction_loss: 1895.5160 - val_kl_loss: 99.9043 - val_false_loss: 10.4340 - val_true_loss: 1.1024\n",
      "Epoch 1157/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.5326 - reconstruction_loss: 1891.0067 - kl_loss: 101.2856 - false_loss: 0.0760 - true_loss: 1.0401 - val_loss: 5235.5884 - val_reconstruction_loss: 1895.5154 - val_kl_loss: 99.9044 - val_false_loss: 10.4331 - val_true_loss: 1.1024\n",
      "Epoch 1158/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.6784 - reconstruction_loss: 1890.4790 - kl_loss: 101.7418 - false_loss: 0.0760 - true_loss: 1.0401 - val_loss: 5235.3096 - val_reconstruction_loss: 1895.5148 - val_kl_loss: 99.9046 - val_false_loss: 10.4322 - val_true_loss: 1.1023\n",
      "Epoch 1159/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0019 - reconstruction_loss: 1890.6735 - kl_loss: 101.7517 - false_loss: 0.0760 - true_loss: 1.0400 - val_loss: 5235.0317 - val_reconstruction_loss: 1895.5144 - val_kl_loss: 99.9048 - val_false_loss: 10.4313 - val_true_loss: 1.1023\n",
      "Epoch 1160/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.1704 - reconstruction_loss: 1890.9271 - kl_loss: 100.6151 - false_loss: 0.0759 - true_loss: 1.0400 - val_loss: 5234.7549 - val_reconstruction_loss: 1895.5140 - val_kl_loss: 99.9052 - val_false_loss: 10.4303 - val_true_loss: 1.1023\n",
      "Epoch 1161/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.1327 - reconstruction_loss: 1890.6719 - kl_loss: 101.0051 - false_loss: 0.0759 - true_loss: 1.0400 - val_loss: 5234.4736 - val_reconstruction_loss: 1895.5132 - val_kl_loss: 99.9052 - val_false_loss: 10.4294 - val_true_loss: 1.1022\n",
      "Epoch 1162/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.1612 - reconstruction_loss: 1890.8231 - kl_loss: 98.1569 - false_loss: 0.0759 - true_loss: 1.0399 - val_loss: 5234.1929 - val_reconstruction_loss: 1895.5128 - val_kl_loss: 99.9056 - val_false_loss: 10.4285 - val_true_loss: 1.1022\n",
      "Epoch 1163/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.8225 - reconstruction_loss: 1890.5934 - kl_loss: 99.2009 - false_loss: 0.0759 - true_loss: 1.0399 - val_loss: 5233.9106 - val_reconstruction_loss: 1895.5125 - val_kl_loss: 99.9058 - val_false_loss: 10.4276 - val_true_loss: 1.1022\n",
      "Epoch 1164/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.7999 - reconstruction_loss: 1890.5850 - kl_loss: 98.2705 - false_loss: 0.0759 - true_loss: 1.0399 - val_loss: 5233.6289 - val_reconstruction_loss: 1895.5118 - val_kl_loss: 99.9061 - val_false_loss: 10.4266 - val_true_loss: 1.1021\n",
      "Epoch 1165/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.7404 - reconstruction_loss: 1890.6744 - kl_loss: 100.3206 - false_loss: 0.0759 - true_loss: 1.0399 - val_loss: 5233.3486 - val_reconstruction_loss: 1895.5115 - val_kl_loss: 99.9060 - val_false_loss: 10.4257 - val_true_loss: 1.1021\n",
      "Epoch 1166/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2227.5563 - reconstruction_loss: 1890.7028 - kl_loss: 98.5320 - false_loss: 0.0759 - true_loss: 1.0398 - val_loss: 5233.0688 - val_reconstruction_loss: 1895.5109 - val_kl_loss: 99.9061 - val_false_loss: 10.4248 - val_true_loss: 1.1021\n",
      "Epoch 1167/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.5816 - reconstruction_loss: 1890.9102 - kl_loss: 100.0633 - false_loss: 0.0759 - true_loss: 1.0398 - val_loss: 5232.7896 - val_reconstruction_loss: 1895.5103 - val_kl_loss: 99.9065 - val_false_loss: 10.4239 - val_true_loss: 1.1020\n",
      "Epoch 1168/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.4504 - reconstruction_loss: 1891.0680 - kl_loss: 101.3927 - false_loss: 0.0759 - true_loss: 1.0398 - val_loss: 5232.5117 - val_reconstruction_loss: 1895.5098 - val_kl_loss: 99.9072 - val_false_loss: 10.4230 - val_true_loss: 1.1020\n",
      "Epoch 1169/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.6630 - reconstruction_loss: 1890.6167 - kl_loss: 102.2402 - false_loss: 0.0759 - true_loss: 1.0397 - val_loss: 5232.2358 - val_reconstruction_loss: 1895.5093 - val_kl_loss: 99.9076 - val_false_loss: 10.4221 - val_true_loss: 1.1020\n",
      "Epoch 1170/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.8357 - reconstruction_loss: 1890.9891 - kl_loss: 100.6822 - false_loss: 0.0759 - true_loss: 1.0397 - val_loss: 5231.9585 - val_reconstruction_loss: 1895.5089 - val_kl_loss: 99.9076 - val_false_loss: 10.4211 - val_true_loss: 1.1019\n",
      "Epoch 1171/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.1235 - reconstruction_loss: 1891.4867 - kl_loss: 100.6044 - false_loss: 0.0759 - true_loss: 1.0397 - val_loss: 5231.6758 - val_reconstruction_loss: 1895.5083 - val_kl_loss: 99.9076 - val_false_loss: 10.4202 - val_true_loss: 1.1019\n",
      "Epoch 1172/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.1591 - reconstruction_loss: 1890.8770 - kl_loss: 102.3264 - false_loss: 0.0759 - true_loss: 1.0396 - val_loss: 5231.3960 - val_reconstruction_loss: 1895.5078 - val_kl_loss: 99.9082 - val_false_loss: 10.4193 - val_true_loss: 1.1019\n",
      "Epoch 1173/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.5227 - reconstruction_loss: 1890.8047 - kl_loss: 102.5857 - false_loss: 0.0759 - true_loss: 1.0396 - val_loss: 5231.1133 - val_reconstruction_loss: 1895.5074 - val_kl_loss: 99.9089 - val_false_loss: 10.4184 - val_true_loss: 1.1018\n",
      "Epoch 1174/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.2805 - reconstruction_loss: 1891.5243 - kl_loss: 102.1189 - false_loss: 0.0759 - true_loss: 1.0396 - val_loss: 5230.8311 - val_reconstruction_loss: 1895.5068 - val_kl_loss: 99.9092 - val_false_loss: 10.4174 - val_true_loss: 1.1018\n",
      "Epoch 1175/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.6044 - reconstruction_loss: 1890.8878 - kl_loss: 101.4013 - false_loss: 0.0759 - true_loss: 1.0395 - val_loss: 5230.5483 - val_reconstruction_loss: 1895.5062 - val_kl_loss: 99.9095 - val_false_loss: 10.4165 - val_true_loss: 1.1018\n",
      "Epoch 1176/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.5879 - reconstruction_loss: 1890.5951 - kl_loss: 101.2792 - false_loss: 0.0759 - true_loss: 1.0395 - val_loss: 5230.2666 - val_reconstruction_loss: 1895.5059 - val_kl_loss: 99.9100 - val_false_loss: 10.4156 - val_true_loss: 1.1017\n",
      "Epoch 1177/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.5919 - reconstruction_loss: 1890.7220 - kl_loss: 99.8449 - false_loss: 0.0759 - true_loss: 1.0395 - val_loss: 5229.9854 - val_reconstruction_loss: 1895.5055 - val_kl_loss: 99.9100 - val_false_loss: 10.4146 - val_true_loss: 1.1017\n",
      "Epoch 1178/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.0354 - reconstruction_loss: 1890.4731 - kl_loss: 100.5976 - false_loss: 0.0758 - true_loss: 1.0394 - val_loss: 5229.7065 - val_reconstruction_loss: 1895.5046 - val_kl_loss: 99.9104 - val_false_loss: 10.4137 - val_true_loss: 1.1017\n",
      "Epoch 1179/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.0778 - reconstruction_loss: 1891.0453 - kl_loss: 99.8556 - false_loss: 0.0758 - true_loss: 1.0394 - val_loss: 5229.4258 - val_reconstruction_loss: 1895.5040 - val_kl_loss: 99.9104 - val_false_loss: 10.4128 - val_true_loss: 1.1016\n",
      "Epoch 1180/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.4795 - reconstruction_loss: 1890.6377 - kl_loss: 100.2313 - false_loss: 0.0758 - true_loss: 1.0394 - val_loss: 5229.1460 - val_reconstruction_loss: 1895.5037 - val_kl_loss: 99.9105 - val_false_loss: 10.4119 - val_true_loss: 1.1016\n",
      "Epoch 1181/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7647 - reconstruction_loss: 1890.6938 - kl_loss: 99.7978 - false_loss: 0.0758 - true_loss: 1.0393 - val_loss: 5228.8657 - val_reconstruction_loss: 1895.5033 - val_kl_loss: 99.9112 - val_false_loss: 10.4110 - val_true_loss: 1.1016\n",
      "Epoch 1182/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.7847 - reconstruction_loss: 1890.5538 - kl_loss: 101.9522 - false_loss: 0.0758 - true_loss: 1.0393 - val_loss: 5228.5835 - val_reconstruction_loss: 1895.5027 - val_kl_loss: 99.9113 - val_false_loss: 10.4100 - val_true_loss: 1.1015\n",
      "Epoch 1183/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4512 - reconstruction_loss: 1890.6049 - kl_loss: 101.6790 - false_loss: 0.0758 - true_loss: 1.0393 - val_loss: 5228.3027 - val_reconstruction_loss: 1895.5018 - val_kl_loss: 99.9114 - val_false_loss: 10.4091 - val_true_loss: 1.1015\n",
      "Epoch 1184/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8240 - reconstruction_loss: 1890.6890 - kl_loss: 102.2818 - false_loss: 0.0758 - true_loss: 1.0392 - val_loss: 5228.0229 - val_reconstruction_loss: 1895.5015 - val_kl_loss: 99.9115 - val_false_loss: 10.4082 - val_true_loss: 1.1015\n",
      "Epoch 1185/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.4874 - reconstruction_loss: 1890.7850 - kl_loss: 102.3382 - false_loss: 0.0758 - true_loss: 1.0392 - val_loss: 5227.7422 - val_reconstruction_loss: 1895.5011 - val_kl_loss: 99.9120 - val_false_loss: 10.4073 - val_true_loss: 1.1014\n",
      "Epoch 1186/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.9834 - reconstruction_loss: 1890.7408 - kl_loss: 102.4560 - false_loss: 0.0758 - true_loss: 1.0392 - val_loss: 5227.4609 - val_reconstruction_loss: 1895.5005 - val_kl_loss: 99.9124 - val_false_loss: 10.4063 - val_true_loss: 1.1014\n",
      "Epoch 1187/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.9911 - reconstruction_loss: 1891.1608 - kl_loss: 101.9953 - false_loss: 0.0758 - true_loss: 1.0391 - val_loss: 5227.1802 - val_reconstruction_loss: 1895.5000 - val_kl_loss: 99.9126 - val_false_loss: 10.4054 - val_true_loss: 1.1014\n",
      "Epoch 1188/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.6944 - reconstruction_loss: 1890.5938 - kl_loss: 100.5183 - false_loss: 0.0758 - true_loss: 1.0391 - val_loss: 5226.9028 - val_reconstruction_loss: 1895.4994 - val_kl_loss: 99.9131 - val_false_loss: 10.4045 - val_true_loss: 1.1014\n",
      "Epoch 1189/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.7561 - reconstruction_loss: 1890.5659 - kl_loss: 97.9006 - false_loss: 0.0758 - true_loss: 1.0391 - val_loss: 5226.6245 - val_reconstruction_loss: 1895.4990 - val_kl_loss: 99.9137 - val_false_loss: 10.4036 - val_true_loss: 1.1013\n",
      "Epoch 1190/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.2949 - reconstruction_loss: 1890.8287 - kl_loss: 100.5680 - false_loss: 0.0758 - true_loss: 1.0390 - val_loss: 5226.3477 - val_reconstruction_loss: 1895.4984 - val_kl_loss: 99.9140 - val_false_loss: 10.4027 - val_true_loss: 1.1013\n",
      "Epoch 1191/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.7235 - reconstruction_loss: 1890.9492 - kl_loss: 100.6075 - false_loss: 0.0758 - true_loss: 1.0390 - val_loss: 5226.0679 - val_reconstruction_loss: 1895.4978 - val_kl_loss: 99.9143 - val_false_loss: 10.4017 - val_true_loss: 1.1013\n",
      "Epoch 1192/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.9503 - reconstruction_loss: 1890.9781 - kl_loss: 100.6558 - false_loss: 0.0758 - true_loss: 1.0390 - val_loss: 5225.7886 - val_reconstruction_loss: 1895.4972 - val_kl_loss: 99.9147 - val_false_loss: 10.4008 - val_true_loss: 1.1012\n",
      "Epoch 1193/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.0635 - reconstruction_loss: 1890.7163 - kl_loss: 100.2927 - false_loss: 0.0758 - true_loss: 1.0389 - val_loss: 5225.5049 - val_reconstruction_loss: 1895.4968 - val_kl_loss: 99.9149 - val_false_loss: 10.3999 - val_true_loss: 1.1012\n",
      "Epoch 1194/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8392 - reconstruction_loss: 1890.4574 - kl_loss: 100.3358 - false_loss: 0.0758 - true_loss: 1.0389 - val_loss: 5225.2212 - val_reconstruction_loss: 1895.4962 - val_kl_loss: 99.9150 - val_false_loss: 10.3990 - val_true_loss: 1.1012\n",
      "Epoch 1195/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9623 - reconstruction_loss: 1890.7896 - kl_loss: 99.0785 - false_loss: 0.0758 - true_loss: 1.0389 - val_loss: 5224.9375 - val_reconstruction_loss: 1895.4956 - val_kl_loss: 99.9141 - val_false_loss: 10.3980 - val_true_loss: 1.1011\n",
      "Epoch 1196/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.8252 - reconstruction_loss: 1891.2007 - kl_loss: 99.4060 - false_loss: 0.0758 - true_loss: 1.0388 - val_loss: 5224.6567 - val_reconstruction_loss: 1895.4952 - val_kl_loss: 99.9145 - val_false_loss: 10.3971 - val_true_loss: 1.1011\n",
      "Epoch 1197/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2205.5802 - reconstruction_loss: 1891.4371 - kl_loss: 102.0114 - false_loss: 0.0757 - true_loss: 1.0388 - val_loss: 5224.3730 - val_reconstruction_loss: 1895.4949 - val_kl_loss: 99.9150 - val_false_loss: 10.3962 - val_true_loss: 1.1010\n",
      "Epoch 1198/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.1066 - reconstruction_loss: 1892.5776 - kl_loss: 103.8438 - false_loss: 0.0757 - true_loss: 1.0388 - val_loss: 5224.0923 - val_reconstruction_loss: 1895.4943 - val_kl_loss: 99.9154 - val_false_loss: 10.3953 - val_true_loss: 1.1010\n",
      "Epoch 1199/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9229 - reconstruction_loss: 1891.3221 - kl_loss: 99.2719 - false_loss: 0.0757 - true_loss: 1.0387 - val_loss: 5223.8096 - val_reconstruction_loss: 1895.4939 - val_kl_loss: 99.9153 - val_false_loss: 10.3943 - val_true_loss: 1.1010\n",
      "Epoch 1200/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.8879 - reconstruction_loss: 1890.9435 - kl_loss: 100.7062 - false_loss: 0.0757 - true_loss: 1.0387 - val_loss: 5223.5293 - val_reconstruction_loss: 1895.4933 - val_kl_loss: 99.9158 - val_false_loss: 10.3934 - val_true_loss: 1.1009\n",
      "Epoch 1201/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.3494 - reconstruction_loss: 1890.8695 - kl_loss: 101.7663 - false_loss: 0.0757 - true_loss: 1.0387 - val_loss: 5223.2510 - val_reconstruction_loss: 1895.4929 - val_kl_loss: 99.9160 - val_false_loss: 10.3925 - val_true_loss: 1.1009\n",
      "Epoch 1202/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.3625 - reconstruction_loss: 1890.4108 - kl_loss: 100.4203 - false_loss: 0.0757 - true_loss: 1.0386 - val_loss: 5222.9727 - val_reconstruction_loss: 1895.4923 - val_kl_loss: 99.9158 - val_false_loss: 10.3916 - val_true_loss: 1.1009\n",
      "Epoch 1203/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.7850 - reconstruction_loss: 1891.1842 - kl_loss: 101.5117 - false_loss: 0.0757 - true_loss: 1.0386 - val_loss: 5222.6948 - val_reconstruction_loss: 1895.4919 - val_kl_loss: 99.9156 - val_false_loss: 10.3907 - val_true_loss: 1.1009\n",
      "Epoch 1204/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2220.4996 - reconstruction_loss: 1890.9352 - kl_loss: 99.3777 - false_loss: 0.0757 - true_loss: 1.0386 - val_loss: 5222.4175 - val_reconstruction_loss: 1895.4915 - val_kl_loss: 99.9153 - val_false_loss: 10.3897 - val_true_loss: 1.1008\n",
      "Epoch 1205/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2219.6611 - reconstruction_loss: 1891.6420 - kl_loss: 100.2524 - false_loss: 0.0757 - true_loss: 1.0385 - val_loss: 5222.1401 - val_reconstruction_loss: 1895.4910 - val_kl_loss: 99.9154 - val_false_loss: 10.3888 - val_true_loss: 1.1008\n",
      "Epoch 1206/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.3587 - reconstruction_loss: 1891.4219 - kl_loss: 99.5720 - false_loss: 0.0757 - true_loss: 1.0385 - val_loss: 5221.8643 - val_reconstruction_loss: 1895.4905 - val_kl_loss: 99.9155 - val_false_loss: 10.3879 - val_true_loss: 1.1008\n",
      "Epoch 1207/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2216.8804 - reconstruction_loss: 1890.6608 - kl_loss: 99.2269 - false_loss: 0.0757 - true_loss: 1.0385 - val_loss: 5221.5850 - val_reconstruction_loss: 1895.4899 - val_kl_loss: 99.9158 - val_false_loss: 10.3870 - val_true_loss: 1.1007\n",
      "Epoch 1208/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.4265 - reconstruction_loss: 1890.3950 - kl_loss: 100.7835 - false_loss: 0.0757 - true_loss: 1.0384 - val_loss: 5221.3086 - val_reconstruction_loss: 1895.4893 - val_kl_loss: 99.9162 - val_false_loss: 10.3861 - val_true_loss: 1.1007\n",
      "Epoch 1209/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.7241 - reconstruction_loss: 1890.4183 - kl_loss: 101.5445 - false_loss: 0.0757 - true_loss: 1.0384 - val_loss: 5221.0327 - val_reconstruction_loss: 1895.4886 - val_kl_loss: 99.9166 - val_false_loss: 10.3852 - val_true_loss: 1.1007\n",
      "Epoch 1210/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.3360 - reconstruction_loss: 1890.3287 - kl_loss: 102.1763 - false_loss: 0.0757 - true_loss: 1.0384 - val_loss: 5220.7588 - val_reconstruction_loss: 1895.4883 - val_kl_loss: 99.9170 - val_false_loss: 10.3843 - val_true_loss: 1.1006\n",
      "Epoch 1211/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.9885 - reconstruction_loss: 1890.8424 - kl_loss: 102.3887 - false_loss: 0.0757 - true_loss: 1.0383 - val_loss: 5220.4888 - val_reconstruction_loss: 1895.4877 - val_kl_loss: 99.9170 - val_false_loss: 10.3834 - val_true_loss: 1.1006\n",
      "Epoch 1212/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.0986 - reconstruction_loss: 1890.5162 - kl_loss: 102.1208 - false_loss: 0.0757 - true_loss: 1.0383 - val_loss: 5220.2207 - val_reconstruction_loss: 1895.4871 - val_kl_loss: 99.9173 - val_false_loss: 10.3825 - val_true_loss: 1.1005\n",
      "Epoch 1213/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.1304 - reconstruction_loss: 1890.4630 - kl_loss: 102.1889 - false_loss: 0.0757 - true_loss: 1.0383 - val_loss: 5219.9487 - val_reconstruction_loss: 1895.4867 - val_kl_loss: 99.9178 - val_false_loss: 10.3816 - val_true_loss: 1.1005\n",
      "Epoch 1214/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.5830 - reconstruction_loss: 1890.7461 - kl_loss: 101.2453 - false_loss: 0.0757 - true_loss: 1.0382 - val_loss: 5219.6787 - val_reconstruction_loss: 1895.4863 - val_kl_loss: 99.9183 - val_false_loss: 10.3807 - val_true_loss: 1.1005\n",
      "Epoch 1215/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.3536 - reconstruction_loss: 1890.7944 - kl_loss: 103.5561 - false_loss: 0.0756 - true_loss: 1.0382 - val_loss: 5219.4062 - val_reconstruction_loss: 1895.4857 - val_kl_loss: 99.9184 - val_false_loss: 10.3798 - val_true_loss: 1.1004\n",
      "Epoch 1216/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.3045 - reconstruction_loss: 1890.6832 - kl_loss: 100.7927 - false_loss: 0.0756 - true_loss: 1.0382 - val_loss: 5219.1333 - val_reconstruction_loss: 1895.4854 - val_kl_loss: 99.9190 - val_false_loss: 10.3789 - val_true_loss: 1.1004\n",
      "Epoch 1217/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.8557 - reconstruction_loss: 1890.9567 - kl_loss: 103.6461 - false_loss: 0.0756 - true_loss: 1.0381 - val_loss: 5218.8569 - val_reconstruction_loss: 1895.4849 - val_kl_loss: 99.9187 - val_false_loss: 10.3780 - val_true_loss: 1.1004\n",
      "Epoch 1218/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.4242 - reconstruction_loss: 1890.6781 - kl_loss: 98.0724 - false_loss: 0.0756 - true_loss: 1.0381 - val_loss: 5218.5786 - val_reconstruction_loss: 1895.4843 - val_kl_loss: 99.9194 - val_false_loss: 10.3771 - val_true_loss: 1.1003\n",
      "Epoch 1219/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.5118 - reconstruction_loss: 1890.4261 - kl_loss: 102.9663 - false_loss: 0.0756 - true_loss: 1.0381 - val_loss: 5218.3032 - val_reconstruction_loss: 1895.4836 - val_kl_loss: 99.9200 - val_false_loss: 10.3762 - val_true_loss: 1.1003\n",
      "Epoch 1220/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.9712 - reconstruction_loss: 1890.2871 - kl_loss: 103.2178 - false_loss: 0.0756 - true_loss: 1.0380 - val_loss: 5218.0254 - val_reconstruction_loss: 1895.4833 - val_kl_loss: 99.9205 - val_false_loss: 10.3753 - val_true_loss: 1.1002\n",
      "Epoch 1221/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.6175 - reconstruction_loss: 1890.4360 - kl_loss: 102.9224 - false_loss: 0.0756 - true_loss: 1.0380 - val_loss: 5217.7480 - val_reconstruction_loss: 1895.4827 - val_kl_loss: 99.9205 - val_false_loss: 10.3744 - val_true_loss: 1.1002\n",
      "Epoch 1222/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.0284 - reconstruction_loss: 1890.5068 - kl_loss: 103.8063 - false_loss: 0.0756 - true_loss: 1.0380 - val_loss: 5217.4712 - val_reconstruction_loss: 1895.4823 - val_kl_loss: 99.9209 - val_false_loss: 10.3735 - val_true_loss: 1.1002\n",
      "Epoch 1223/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.6097 - reconstruction_loss: 1890.7289 - kl_loss: 101.4915 - false_loss: 0.0756 - true_loss: 1.0379 - val_loss: 5217.1909 - val_reconstruction_loss: 1895.4817 - val_kl_loss: 99.9206 - val_false_loss: 10.3726 - val_true_loss: 1.1001\n",
      "Epoch 1224/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.4640 - reconstruction_loss: 1891.4222 - kl_loss: 99.6601 - false_loss: 0.0756 - true_loss: 1.0379 - val_loss: 5216.9160 - val_reconstruction_loss: 1895.4813 - val_kl_loss: 99.9207 - val_false_loss: 10.3717 - val_true_loss: 1.1001\n",
      "Epoch 1225/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2230.2310 - reconstruction_loss: 1891.1840 - kl_loss: 94.9621 - false_loss: 0.0756 - true_loss: 1.0379 - val_loss: 5216.6382 - val_reconstruction_loss: 1895.4810 - val_kl_loss: 99.9202 - val_false_loss: 10.3707 - val_true_loss: 1.1001\n",
      "Epoch 1226/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4139 - reconstruction_loss: 1890.8633 - kl_loss: 99.1430 - false_loss: 0.0756 - true_loss: 1.0378 - val_loss: 5216.3613 - val_reconstruction_loss: 1895.4803 - val_kl_loss: 99.9204 - val_false_loss: 10.3698 - val_true_loss: 1.1000\n",
      "Epoch 1227/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.1233 - reconstruction_loss: 1890.7167 - kl_loss: 101.2030 - false_loss: 0.0756 - true_loss: 1.0378 - val_loss: 5216.0825 - val_reconstruction_loss: 1895.4800 - val_kl_loss: 99.9207 - val_false_loss: 10.3689 - val_true_loss: 1.1000\n",
      "Epoch 1228/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.1651 - reconstruction_loss: 1890.9609 - kl_loss: 105.8496 - false_loss: 0.0756 - true_loss: 1.0378 - val_loss: 5215.8071 - val_reconstruction_loss: 1895.4794 - val_kl_loss: 99.9215 - val_false_loss: 10.3680 - val_true_loss: 1.1000\n",
      "Epoch 1229/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2197.1311 - reconstruction_loss: 1890.5902 - kl_loss: 103.6376 - false_loss: 0.0756 - true_loss: 1.0377 - val_loss: 5215.5283 - val_reconstruction_loss: 1895.4790 - val_kl_loss: 99.9226 - val_false_loss: 10.3671 - val_true_loss: 1.0999\n",
      "Epoch 1230/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.1197 - reconstruction_loss: 1890.3667 - kl_loss: 103.8453 - false_loss: 0.0756 - true_loss: 1.0377 - val_loss: 5215.2500 - val_reconstruction_loss: 1895.4786 - val_kl_loss: 99.9236 - val_false_loss: 10.3662 - val_true_loss: 1.0999\n",
      "Epoch 1231/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.1752 - reconstruction_loss: 1890.4712 - kl_loss: 105.8775 - false_loss: 0.0756 - true_loss: 1.0376 - val_loss: 5214.9717 - val_reconstruction_loss: 1895.4780 - val_kl_loss: 99.9244 - val_false_loss: 10.3653 - val_true_loss: 1.0998\n",
      "Epoch 1232/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.7163 - reconstruction_loss: 1890.2648 - kl_loss: 104.0357 - false_loss: 0.0756 - true_loss: 1.0376 - val_loss: 5214.6929 - val_reconstruction_loss: 1895.4775 - val_kl_loss: 99.9249 - val_false_loss: 10.3643 - val_true_loss: 1.0998\n",
      "Epoch 1233/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7579 - reconstruction_loss: 1890.2504 - kl_loss: 103.9970 - false_loss: 0.0755 - true_loss: 1.0376 - val_loss: 5214.4150 - val_reconstruction_loss: 1895.4769 - val_kl_loss: 99.9255 - val_false_loss: 10.3634 - val_true_loss: 1.0998\n",
      "Epoch 1234/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.3812 - reconstruction_loss: 1890.5088 - kl_loss: 101.4373 - false_loss: 0.0755 - true_loss: 1.0375 - val_loss: 5214.1353 - val_reconstruction_loss: 1895.4766 - val_kl_loss: 99.9256 - val_false_loss: 10.3625 - val_true_loss: 1.0997\n",
      "Epoch 1235/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9575 - reconstruction_loss: 1890.6846 - kl_loss: 103.5291 - false_loss: 0.0755 - true_loss: 1.0375 - val_loss: 5213.8584 - val_reconstruction_loss: 1895.4760 - val_kl_loss: 99.9260 - val_false_loss: 10.3616 - val_true_loss: 1.0997\n",
      "Epoch 1236/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.3974 - reconstruction_loss: 1890.7109 - kl_loss: 102.3088 - false_loss: 0.0755 - true_loss: 1.0375 - val_loss: 5213.5811 - val_reconstruction_loss: 1895.4756 - val_kl_loss: 99.9264 - val_false_loss: 10.3607 - val_true_loss: 1.0997\n",
      "Epoch 1237/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.6465 - reconstruction_loss: 1890.4614 - kl_loss: 102.6548 - false_loss: 0.0755 - true_loss: 1.0374 - val_loss: 5213.3032 - val_reconstruction_loss: 1895.4750 - val_kl_loss: 99.9264 - val_false_loss: 10.3598 - val_true_loss: 1.0996\n",
      "Epoch 1238/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.3687 - reconstruction_loss: 1890.5726 - kl_loss: 99.8084 - false_loss: 0.0755 - true_loss: 1.0374 - val_loss: 5213.0259 - val_reconstruction_loss: 1895.4744 - val_kl_loss: 99.9269 - val_false_loss: 10.3589 - val_true_loss: 1.0996\n",
      "Epoch 1239/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.7722 - reconstruction_loss: 1890.7931 - kl_loss: 96.6300 - false_loss: 0.0755 - true_loss: 1.0374 - val_loss: 5212.7451 - val_reconstruction_loss: 1895.4740 - val_kl_loss: 99.9267 - val_false_loss: 10.3579 - val_true_loss: 1.0996\n",
      "Epoch 1240/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2240.0516 - reconstruction_loss: 1891.4644 - kl_loss: 90.4194 - false_loss: 0.0755 - true_loss: 1.0373 - val_loss: 5212.4634 - val_reconstruction_loss: 1895.4736 - val_kl_loss: 99.9274 - val_false_loss: 10.3570 - val_true_loss: 1.0996\n",
      "Epoch 1241/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.3642 - reconstruction_loss: 1891.3883 - kl_loss: 103.0529 - false_loss: 0.0755 - true_loss: 1.0373 - val_loss: 5212.1851 - val_reconstruction_loss: 1895.4733 - val_kl_loss: 99.9282 - val_false_loss: 10.3561 - val_true_loss: 1.0995\n",
      "Epoch 1242/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.2344 - reconstruction_loss: 1891.1309 - kl_loss: 105.1255 - false_loss: 0.0755 - true_loss: 1.0373 - val_loss: 5211.9067 - val_reconstruction_loss: 1895.4727 - val_kl_loss: 99.9288 - val_false_loss: 10.3552 - val_true_loss: 1.0995\n",
      "Epoch 1243/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.5032 - reconstruction_loss: 1890.9664 - kl_loss: 103.2929 - false_loss: 0.0755 - true_loss: 1.0373 - val_loss: 5211.6284 - val_reconstruction_loss: 1895.4722 - val_kl_loss: 99.9290 - val_false_loss: 10.3543 - val_true_loss: 1.0994\n",
      "Epoch 1244/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.2564 - reconstruction_loss: 1890.3939 - kl_loss: 103.0488 - false_loss: 0.0755 - true_loss: 1.0372 - val_loss: 5211.3506 - val_reconstruction_loss: 1895.4718 - val_kl_loss: 99.9294 - val_false_loss: 10.3533 - val_true_loss: 1.0994\n",
      "Epoch 1245/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.4717 - reconstruction_loss: 1890.3104 - kl_loss: 102.5709 - false_loss: 0.0755 - true_loss: 1.0372 - val_loss: 5211.0723 - val_reconstruction_loss: 1895.4712 - val_kl_loss: 99.9297 - val_false_loss: 10.3524 - val_true_loss: 1.0994\n",
      "Epoch 1246/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.1845 - reconstruction_loss: 1890.4725 - kl_loss: 103.2191 - false_loss: 0.0755 - true_loss: 1.0371 - val_loss: 5210.7935 - val_reconstruction_loss: 1895.4706 - val_kl_loss: 99.9302 - val_false_loss: 10.3515 - val_true_loss: 1.0993\n",
      "Epoch 1247/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.9314 - reconstruction_loss: 1890.4420 - kl_loss: 103.2973 - false_loss: 0.0755 - true_loss: 1.0371 - val_loss: 5210.5151 - val_reconstruction_loss: 1895.4702 - val_kl_loss: 99.9307 - val_false_loss: 10.3506 - val_true_loss: 1.0993\n",
      "Epoch 1248/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.7912 - reconstruction_loss: 1890.4155 - kl_loss: 103.9199 - false_loss: 0.0755 - true_loss: 1.0371 - val_loss: 5210.2368 - val_reconstruction_loss: 1895.4698 - val_kl_loss: 99.9312 - val_false_loss: 10.3497 - val_true_loss: 1.0992\n",
      "Epoch 1249/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2204.2763 - reconstruction_loss: 1890.4565 - kl_loss: 102.8325 - false_loss: 0.0755 - true_loss: 1.0370 - val_loss: 5209.9590 - val_reconstruction_loss: 1895.4690 - val_kl_loss: 99.9318 - val_false_loss: 10.3488 - val_true_loss: 1.0992\n",
      "Epoch 1250/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.2960 - reconstruction_loss: 1890.3353 - kl_loss: 103.8456 - false_loss: 0.0755 - true_loss: 1.0370 - val_loss: 5209.6831 - val_reconstruction_loss: 1895.4686 - val_kl_loss: 99.9321 - val_false_loss: 10.3479 - val_true_loss: 1.0992\n",
      "Epoch 1251/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.4334 - reconstruction_loss: 1890.6093 - kl_loss: 104.3606 - false_loss: 0.0755 - true_loss: 1.0370 - val_loss: 5209.4072 - val_reconstruction_loss: 1895.4683 - val_kl_loss: 99.9327 - val_false_loss: 10.3470 - val_true_loss: 1.0991\n",
      "Epoch 1252/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.8541 - reconstruction_loss: 1891.0250 - kl_loss: 103.9391 - false_loss: 0.0754 - true_loss: 1.0369 - val_loss: 5209.1304 - val_reconstruction_loss: 1895.4677 - val_kl_loss: 99.9331 - val_false_loss: 10.3460 - val_true_loss: 1.0991\n",
      "Epoch 1253/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.6068 - reconstruction_loss: 1890.8623 - kl_loss: 100.3365 - false_loss: 0.0754 - true_loss: 1.0369 - val_loss: 5208.8574 - val_reconstruction_loss: 1895.4673 - val_kl_loss: 99.9338 - val_false_loss: 10.3451 - val_true_loss: 1.0990\n",
      "Epoch 1254/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.4423 - reconstruction_loss: 1890.5514 - kl_loss: 105.1859 - false_loss: 0.0754 - true_loss: 1.0368 - val_loss: 5208.5854 - val_reconstruction_loss: 1895.4668 - val_kl_loss: 99.9343 - val_false_loss: 10.3443 - val_true_loss: 1.0990\n",
      "Epoch 1255/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.5894 - reconstruction_loss: 1890.7568 - kl_loss: 103.6750 - false_loss: 0.0754 - true_loss: 1.0368 - val_loss: 5208.3081 - val_reconstruction_loss: 1895.4662 - val_kl_loss: 99.9349 - val_false_loss: 10.3433 - val_true_loss: 1.0990\n",
      "Epoch 1256/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.5127 - reconstruction_loss: 1890.4531 - kl_loss: 104.1614 - false_loss: 0.0754 - true_loss: 1.0368 - val_loss: 5208.0327 - val_reconstruction_loss: 1895.4658 - val_kl_loss: 99.9356 - val_false_loss: 10.3424 - val_true_loss: 1.0989\n",
      "Epoch 1257/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.3529 - reconstruction_loss: 1890.7466 - kl_loss: 103.7638 - false_loss: 0.0754 - true_loss: 1.0367 - val_loss: 5207.7563 - val_reconstruction_loss: 1895.4655 - val_kl_loss: 99.9363 - val_false_loss: 10.3415 - val_true_loss: 1.0989\n",
      "Epoch 1258/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.5295 - reconstruction_loss: 1890.5677 - kl_loss: 101.9432 - false_loss: 0.0754 - true_loss: 1.0367 - val_loss: 5207.4795 - val_reconstruction_loss: 1895.4648 - val_kl_loss: 99.9365 - val_false_loss: 10.3406 - val_true_loss: 1.0989\n",
      "Epoch 1259/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.6690 - reconstruction_loss: 1890.1489 - kl_loss: 102.7442 - false_loss: 0.0754 - true_loss: 1.0367 - val_loss: 5207.2031 - val_reconstruction_loss: 1895.4640 - val_kl_loss: 99.9371 - val_false_loss: 10.3397 - val_true_loss: 1.0988\n",
      "Epoch 1260/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.7634 - reconstruction_loss: 1890.3945 - kl_loss: 102.9719 - false_loss: 0.0754 - true_loss: 1.0366 - val_loss: 5206.9229 - val_reconstruction_loss: 1895.4636 - val_kl_loss: 99.9378 - val_false_loss: 10.3388 - val_true_loss: 1.0988\n",
      "Epoch 1261/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.1755 - reconstruction_loss: 1890.3583 - kl_loss: 104.2485 - false_loss: 0.0754 - true_loss: 1.0366 - val_loss: 5206.6465 - val_reconstruction_loss: 1895.4633 - val_kl_loss: 99.9381 - val_false_loss: 10.3379 - val_true_loss: 1.0988\n",
      "Epoch 1262/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.1534 - reconstruction_loss: 1890.3447 - kl_loss: 101.5271 - false_loss: 0.0754 - true_loss: 1.0366 - val_loss: 5206.3662 - val_reconstruction_loss: 1895.4628 - val_kl_loss: 99.9384 - val_false_loss: 10.3370 - val_true_loss: 1.0987\n",
      "Epoch 1263/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.0237 - reconstruction_loss: 1890.2582 - kl_loss: 101.0580 - false_loss: 0.0754 - true_loss: 1.0365 - val_loss: 5206.0913 - val_reconstruction_loss: 1895.4622 - val_kl_loss: 99.9388 - val_false_loss: 10.3361 - val_true_loss: 1.0987\n",
      "Epoch 1264/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.9115 - reconstruction_loss: 1890.2142 - kl_loss: 103.8662 - false_loss: 0.0754 - true_loss: 1.0365 - val_loss: 5205.8154 - val_reconstruction_loss: 1895.4615 - val_kl_loss: 99.9394 - val_false_loss: 10.3351 - val_true_loss: 1.0986\n",
      "Epoch 1265/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.1020 - reconstruction_loss: 1890.4517 - kl_loss: 104.3964 - false_loss: 0.0754 - true_loss: 1.0364 - val_loss: 5205.5405 - val_reconstruction_loss: 1895.4612 - val_kl_loss: 99.9399 - val_false_loss: 10.3342 - val_true_loss: 1.0986\n",
      "Epoch 1266/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.9160 - reconstruction_loss: 1890.8807 - kl_loss: 104.7563 - false_loss: 0.0754 - true_loss: 1.0364 - val_loss: 5205.2661 - val_reconstruction_loss: 1895.4606 - val_kl_loss: 99.9404 - val_false_loss: 10.3333 - val_true_loss: 1.0986\n",
      "Epoch 1267/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.4518 - reconstruction_loss: 1890.7728 - kl_loss: 103.3690 - false_loss: 0.0754 - true_loss: 1.0364 - val_loss: 5204.9868 - val_reconstruction_loss: 1895.4602 - val_kl_loss: 99.9407 - val_false_loss: 10.3324 - val_true_loss: 1.0985\n",
      "Epoch 1268/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.2895 - reconstruction_loss: 1890.5238 - kl_loss: 102.5542 - false_loss: 0.0754 - true_loss: 1.0363 - val_loss: 5204.7080 - val_reconstruction_loss: 1895.4596 - val_kl_loss: 99.9409 - val_false_loss: 10.3315 - val_true_loss: 1.0985\n",
      "Epoch 1269/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.2309 - reconstruction_loss: 1890.3102 - kl_loss: 102.3150 - false_loss: 0.0754 - true_loss: 1.0363 - val_loss: 5204.4297 - val_reconstruction_loss: 1895.4591 - val_kl_loss: 99.9411 - val_false_loss: 10.3306 - val_true_loss: 1.0985\n",
      "Epoch 1270/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.2698 - reconstruction_loss: 1890.2148 - kl_loss: 101.2334 - false_loss: 0.0753 - true_loss: 1.0363 - val_loss: 5204.1519 - val_reconstruction_loss: 1895.4585 - val_kl_loss: 99.9414 - val_false_loss: 10.3297 - val_true_loss: 1.0984\n",
      "Epoch 1271/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.3453 - reconstruction_loss: 1890.4532 - kl_loss: 101.0321 - false_loss: 0.0753 - true_loss: 1.0362 - val_loss: 5203.8740 - val_reconstruction_loss: 1895.4581 - val_kl_loss: 99.9420 - val_false_loss: 10.3288 - val_true_loss: 1.0984\n",
      "Epoch 1272/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.6088 - reconstruction_loss: 1890.4258 - kl_loss: 101.6529 - false_loss: 0.0753 - true_loss: 1.0362 - val_loss: 5203.5938 - val_reconstruction_loss: 1895.4575 - val_kl_loss: 99.9425 - val_false_loss: 10.3278 - val_true_loss: 1.0984\n",
      "Epoch 1273/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.6445 - reconstruction_loss: 1890.6344 - kl_loss: 102.1347 - false_loss: 0.0753 - true_loss: 1.0362 - val_loss: 5203.3149 - val_reconstruction_loss: 1895.4569 - val_kl_loss: 99.9426 - val_false_loss: 10.3269 - val_true_loss: 1.0983\n",
      "Epoch 1274/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.1800 - reconstruction_loss: 1890.6207 - kl_loss: 99.6595 - false_loss: 0.0753 - true_loss: 1.0361 - val_loss: 5203.0322 - val_reconstruction_loss: 1895.4564 - val_kl_loss: 99.9426 - val_false_loss: 10.3260 - val_true_loss: 1.0983\n",
      "Epoch 1275/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.5768 - reconstruction_loss: 1890.3311 - kl_loss: 101.2928 - false_loss: 0.0753 - true_loss: 1.0361 - val_loss: 5202.7510 - val_reconstruction_loss: 1895.4561 - val_kl_loss: 99.9429 - val_false_loss: 10.3251 - val_true_loss: 1.0983\n",
      "Epoch 1276/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.7450 - reconstruction_loss: 1890.2300 - kl_loss: 102.1782 - false_loss: 0.0753 - true_loss: 1.0361 - val_loss: 5202.4717 - val_reconstruction_loss: 1895.4554 - val_kl_loss: 99.9434 - val_false_loss: 10.3241 - val_true_loss: 1.0982\n",
      "Epoch 1277/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.2685 - reconstruction_loss: 1890.6235 - kl_loss: 101.9463 - false_loss: 0.0753 - true_loss: 1.0360 - val_loss: 5202.1924 - val_reconstruction_loss: 1895.4548 - val_kl_loss: 99.9438 - val_false_loss: 10.3232 - val_true_loss: 1.0982\n",
      "Epoch 1278/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.2864 - reconstruction_loss: 1890.3802 - kl_loss: 101.8073 - false_loss: 0.0753 - true_loss: 1.0360 - val_loss: 5201.9170 - val_reconstruction_loss: 1895.4542 - val_kl_loss: 99.9442 - val_false_loss: 10.3223 - val_true_loss: 1.0982\n",
      "Epoch 1279/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.8749 - reconstruction_loss: 1890.2882 - kl_loss: 102.1931 - false_loss: 0.0753 - true_loss: 1.0360 - val_loss: 5201.6396 - val_reconstruction_loss: 1895.4539 - val_kl_loss: 99.9447 - val_false_loss: 10.3214 - val_true_loss: 1.0981\n",
      "Epoch 1280/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.4192 - reconstruction_loss: 1890.3475 - kl_loss: 99.4544 - false_loss: 0.0753 - true_loss: 1.0359 - val_loss: 5201.3633 - val_reconstruction_loss: 1895.4532 - val_kl_loss: 99.9451 - val_false_loss: 10.3205 - val_true_loss: 1.0981\n",
      "Epoch 1281/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.0890 - reconstruction_loss: 1891.0270 - kl_loss: 97.4678 - false_loss: 0.0753 - true_loss: 1.0359 - val_loss: 5201.0845 - val_reconstruction_loss: 1895.4529 - val_kl_loss: 99.9451 - val_false_loss: 10.3196 - val_true_loss: 1.0981\n",
      "Epoch 1282/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2219.0142 - reconstruction_loss: 1892.4457 - kl_loss: 99.0980 - false_loss: 0.0753 - true_loss: 1.0359 - val_loss: 5200.8052 - val_reconstruction_loss: 1895.4524 - val_kl_loss: 99.9456 - val_false_loss: 10.3187 - val_true_loss: 1.0980\n",
      "Epoch 1283/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.5301 - reconstruction_loss: 1891.2448 - kl_loss: 104.2598 - false_loss: 0.0753 - true_loss: 1.0358 - val_loss: 5200.5278 - val_reconstruction_loss: 1895.4518 - val_kl_loss: 99.9465 - val_false_loss: 10.3177 - val_true_loss: 1.0980\n",
      "Epoch 1284/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.1177 - reconstruction_loss: 1890.8052 - kl_loss: 101.3628 - false_loss: 0.0753 - true_loss: 1.0358 - val_loss: 5200.2495 - val_reconstruction_loss: 1895.4514 - val_kl_loss: 99.9463 - val_false_loss: 10.3168 - val_true_loss: 1.0980\n",
      "Epoch 1285/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.5956 - reconstruction_loss: 1890.7960 - kl_loss: 102.6380 - false_loss: 0.0753 - true_loss: 1.0358 - val_loss: 5199.9736 - val_reconstruction_loss: 1895.4508 - val_kl_loss: 99.9465 - val_false_loss: 10.3159 - val_true_loss: 1.0979\n",
      "Epoch 1286/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.2106 - reconstruction_loss: 1890.7709 - kl_loss: 101.4460 - false_loss: 0.0753 - true_loss: 1.0357 - val_loss: 5199.6978 - val_reconstruction_loss: 1895.4504 - val_kl_loss: 99.9467 - val_false_loss: 10.3150 - val_true_loss: 1.0979\n",
      "Epoch 1287/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.9779 - reconstruction_loss: 1890.6919 - kl_loss: 100.7279 - false_loss: 0.0753 - true_loss: 1.0357 - val_loss: 5199.4204 - val_reconstruction_loss: 1895.4498 - val_kl_loss: 99.9472 - val_false_loss: 10.3141 - val_true_loss: 1.0978\n",
      "Epoch 1288/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.9298 - reconstruction_loss: 1890.2944 - kl_loss: 102.6003 - false_loss: 0.0752 - true_loss: 1.0357 - val_loss: 5199.1489 - val_reconstruction_loss: 1895.4493 - val_kl_loss: 99.9476 - val_false_loss: 10.3132 - val_true_loss: 1.0978\n",
      "Epoch 1289/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2223.5763 - reconstruction_loss: 1890.9357 - kl_loss: 95.2454 - false_loss: 0.0752 - true_loss: 1.0356 - val_loss: 5198.8706 - val_reconstruction_loss: 1895.4487 - val_kl_loss: 99.9474 - val_false_loss: 10.3123 - val_true_loss: 1.0978\n",
      "Epoch 1290/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9974 - reconstruction_loss: 1891.0049 - kl_loss: 100.8202 - false_loss: 0.0752 - true_loss: 1.0356 - val_loss: 5198.5972 - val_reconstruction_loss: 1895.4484 - val_kl_loss: 99.9480 - val_false_loss: 10.3114 - val_true_loss: 1.0977\n",
      "Epoch 1291/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.5285 - reconstruction_loss: 1890.6217 - kl_loss: 102.7912 - false_loss: 0.0752 - true_loss: 1.0356 - val_loss: 5198.3198 - val_reconstruction_loss: 1895.4478 - val_kl_loss: 99.9483 - val_false_loss: 10.3105 - val_true_loss: 1.0977\n",
      "Epoch 1292/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.2609 - reconstruction_loss: 1890.6088 - kl_loss: 102.1002 - false_loss: 0.0752 - true_loss: 1.0356 - val_loss: 5198.0420 - val_reconstruction_loss: 1895.4471 - val_kl_loss: 99.9488 - val_false_loss: 10.3096 - val_true_loss: 1.0977\n",
      "Epoch 1293/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.1910 - reconstruction_loss: 1890.9707 - kl_loss: 96.7847 - false_loss: 0.0752 - true_loss: 1.0355 - val_loss: 5197.7656 - val_reconstruction_loss: 1895.4468 - val_kl_loss: 99.9484 - val_false_loss: 10.3087 - val_true_loss: 1.0976\n",
      "Epoch 1294/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.6368 - reconstruction_loss: 1891.3588 - kl_loss: 101.6514 - false_loss: 0.0752 - true_loss: 1.0355 - val_loss: 5197.4873 - val_reconstruction_loss: 1895.4463 - val_kl_loss: 99.9485 - val_false_loss: 10.3078 - val_true_loss: 1.0976\n",
      "Epoch 1295/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.7272 - reconstruction_loss: 1890.6537 - kl_loss: 101.7295 - false_loss: 0.0752 - true_loss: 1.0355 - val_loss: 5197.2085 - val_reconstruction_loss: 1895.4457 - val_kl_loss: 99.9487 - val_false_loss: 10.3068 - val_true_loss: 1.0976\n",
      "Epoch 1296/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2209.5960 - reconstruction_loss: 1890.6460 - kl_loss: 102.3348 - false_loss: 0.0752 - true_loss: 1.0354 - val_loss: 5196.9287 - val_reconstruction_loss: 1895.4451 - val_kl_loss: 99.9491 - val_false_loss: 10.3059 - val_true_loss: 1.0975\n",
      "Epoch 1297/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.9650 - reconstruction_loss: 1891.1176 - kl_loss: 100.6575 - false_loss: 0.0752 - true_loss: 1.0354 - val_loss: 5196.6533 - val_reconstruction_loss: 1895.4447 - val_kl_loss: 99.9492 - val_false_loss: 10.3050 - val_true_loss: 1.0975\n",
      "Epoch 1298/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.6235 - reconstruction_loss: 1891.6188 - kl_loss: 100.1594 - false_loss: 0.0752 - true_loss: 1.0354 - val_loss: 5196.3706 - val_reconstruction_loss: 1895.4441 - val_kl_loss: 99.9492 - val_false_loss: 10.3041 - val_true_loss: 1.0974\n",
      "Epoch 1299/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.5595 - reconstruction_loss: 1891.4003 - kl_loss: 101.1518 - false_loss: 0.0752 - true_loss: 1.0353 - val_loss: 5196.0874 - val_reconstruction_loss: 1895.4436 - val_kl_loss: 99.9490 - val_false_loss: 10.3032 - val_true_loss: 1.0974\n",
      "Epoch 1300/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.8903 - reconstruction_loss: 1891.1675 - kl_loss: 94.2730 - false_loss: 0.0752 - true_loss: 1.0353 - val_loss: 5195.8032 - val_reconstruction_loss: 1895.4434 - val_kl_loss: 99.9483 - val_false_loss: 10.3022 - val_true_loss: 1.0974\n",
      "Epoch 1301/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2215.5523 - reconstruction_loss: 1891.1735 - kl_loss: 105.1252 - false_loss: 0.0752 - true_loss: 1.0353 - val_loss: 5195.5283 - val_reconstruction_loss: 1895.4429 - val_kl_loss: 99.9485 - val_false_loss: 10.3013 - val_true_loss: 1.0973\n",
      "Epoch 1302/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.2000 - reconstruction_loss: 1890.6664 - kl_loss: 101.8359 - false_loss: 0.0752 - true_loss: 1.0352 - val_loss: 5195.2510 - val_reconstruction_loss: 1895.4423 - val_kl_loss: 99.9485 - val_false_loss: 10.3004 - val_true_loss: 1.0973\n",
      "Epoch 1303/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.4182 - reconstruction_loss: 1890.4403 - kl_loss: 99.5855 - false_loss: 0.0752 - true_loss: 1.0352 - val_loss: 5194.9736 - val_reconstruction_loss: 1895.4417 - val_kl_loss: 99.9488 - val_false_loss: 10.2995 - val_true_loss: 1.0973\n",
      "Epoch 1304/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.1498 - reconstruction_loss: 1890.6124 - kl_loss: 104.5993 - false_loss: 0.0752 - true_loss: 1.0352 - val_loss: 5194.6982 - val_reconstruction_loss: 1895.4413 - val_kl_loss: 99.9493 - val_false_loss: 10.2986 - val_true_loss: 1.0972\n",
      "Epoch 1305/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2213.5423 - reconstruction_loss: 1890.4962 - kl_loss: 101.7669 - false_loss: 0.0752 - true_loss: 1.0351 - val_loss: 5194.4214 - val_reconstruction_loss: 1895.4407 - val_kl_loss: 99.9491 - val_false_loss: 10.2977 - val_true_loss: 1.0972\n",
      "Epoch 1306/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.4821 - reconstruction_loss: 1890.7552 - kl_loss: 103.1020 - false_loss: 0.0752 - true_loss: 1.0351 - val_loss: 5194.1499 - val_reconstruction_loss: 1895.4399 - val_kl_loss: 99.9495 - val_false_loss: 10.2968 - val_true_loss: 1.0972\n",
      "Epoch 1307/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.7028 - reconstruction_loss: 1890.5562 - kl_loss: 103.3049 - false_loss: 0.0751 - true_loss: 1.0351 - val_loss: 5193.8750 - val_reconstruction_loss: 1895.4396 - val_kl_loss: 99.9498 - val_false_loss: 10.2959 - val_true_loss: 1.0971\n",
      "Epoch 1308/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.2142 - reconstruction_loss: 1890.3995 - kl_loss: 101.4695 - false_loss: 0.0751 - true_loss: 1.0350 - val_loss: 5193.5972 - val_reconstruction_loss: 1895.4392 - val_kl_loss: 99.9501 - val_false_loss: 10.2950 - val_true_loss: 1.0971\n",
      "Epoch 1309/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.5864 - reconstruction_loss: 1890.5319 - kl_loss: 103.7678 - false_loss: 0.0751 - true_loss: 1.0350 - val_loss: 5193.3242 - val_reconstruction_loss: 1895.4386 - val_kl_loss: 99.9504 - val_false_loss: 10.2941 - val_true_loss: 1.0971\n",
      "Epoch 1310/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.2428 - reconstruction_loss: 1890.1237 - kl_loss: 102.6892 - false_loss: 0.0751 - true_loss: 1.0350 - val_loss: 5193.0493 - val_reconstruction_loss: 1895.4380 - val_kl_loss: 99.9510 - val_false_loss: 10.2932 - val_true_loss: 1.0970\n",
      "Epoch 1311/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.7542 - reconstruction_loss: 1890.5078 - kl_loss: 102.8143 - false_loss: 0.0751 - true_loss: 1.0349 - val_loss: 5192.7754 - val_reconstruction_loss: 1895.4376 - val_kl_loss: 99.9515 - val_false_loss: 10.2923 - val_true_loss: 1.0970\n",
      "Epoch 1312/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.8986 - reconstruction_loss: 1890.3662 - kl_loss: 102.7308 - false_loss: 0.0751 - true_loss: 1.0349 - val_loss: 5192.5000 - val_reconstruction_loss: 1895.4373 - val_kl_loss: 99.9519 - val_false_loss: 10.2914 - val_true_loss: 1.0970\n",
      "Epoch 1313/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.6616 - reconstruction_loss: 1890.4132 - kl_loss: 101.1301 - false_loss: 0.0751 - true_loss: 1.0349 - val_loss: 5192.2251 - val_reconstruction_loss: 1895.4365 - val_kl_loss: 99.9522 - val_false_loss: 10.2905 - val_true_loss: 1.0969\n",
      "Epoch 1314/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.1230 - reconstruction_loss: 1890.6367 - kl_loss: 94.1218 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5191.9458 - val_reconstruction_loss: 1895.4362 - val_kl_loss: 99.9517 - val_false_loss: 10.2895 - val_true_loss: 1.0969\n",
      "Epoch 1315/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.1497 - reconstruction_loss: 1890.9564 - kl_loss: 102.2182 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5191.6714 - val_reconstruction_loss: 1895.4358 - val_kl_loss: 99.9522 - val_false_loss: 10.2886 - val_true_loss: 1.0969\n",
      "Epoch 1316/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.2293 - reconstruction_loss: 1891.3955 - kl_loss: 97.4276 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5191.3901 - val_reconstruction_loss: 1895.4352 - val_kl_loss: 99.9515 - val_false_loss: 10.2877 - val_true_loss: 1.0968\n",
      "Epoch 1317/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2307.5850 - reconstruction_loss: 1892.3717 - kl_loss: 80.8338 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5191.1182 - val_reconstruction_loss: 1895.4348 - val_kl_loss: 99.9510 - val_false_loss: 10.2868 - val_true_loss: 1.0968\n",
      "Epoch 1318/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2334.0695 - reconstruction_loss: 1892.5345 - kl_loss: 83.6510 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5190.8516 - val_reconstruction_loss: 1895.4344 - val_kl_loss: 99.9510 - val_false_loss: 10.2859 - val_true_loss: 1.0968\n",
      "Epoch 1319/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2288.2577 - reconstruction_loss: 1892.1029 - kl_loss: 88.9894 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5190.5903 - val_reconstruction_loss: 1895.4341 - val_kl_loss: 99.9508 - val_false_loss: 10.2851 - val_true_loss: 1.0968\n",
      "Epoch 1320/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2288.9721 - reconstruction_loss: 1892.2520 - kl_loss: 83.7814 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5190.3320 - val_reconstruction_loss: 1895.4337 - val_kl_loss: 99.9488 - val_false_loss: 10.2842 - val_true_loss: 1.0968\n",
      "Epoch 1321/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2313.9927 - reconstruction_loss: 1891.8721 - kl_loss: 84.2389 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5190.0615 - val_reconstruction_loss: 1895.4332 - val_kl_loss: 99.9475 - val_false_loss: 10.2833 - val_true_loss: 1.0968\n",
      "Epoch 1322/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2284.6727 - reconstruction_loss: 1891.6422 - kl_loss: 89.2015 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5189.7866 - val_reconstruction_loss: 1895.4329 - val_kl_loss: 99.9471 - val_false_loss: 10.2824 - val_true_loss: 1.0968\n",
      "Epoch 1323/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.5489 - reconstruction_loss: 1891.2897 - kl_loss: 97.6964 - false_loss: 0.0751 - true_loss: 1.0348 - val_loss: 5189.5103 - val_reconstruction_loss: 1895.4323 - val_kl_loss: 99.9466 - val_false_loss: 10.2815 - val_true_loss: 1.0967\n",
      "Epoch 1324/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.1816 - reconstruction_loss: 1890.9609 - kl_loss: 103.5537 - false_loss: 0.0751 - true_loss: 1.0347 - val_loss: 5189.2393 - val_reconstruction_loss: 1895.4316 - val_kl_loss: 99.9475 - val_false_loss: 10.2806 - val_true_loss: 1.0967\n",
      "Epoch 1325/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.3200 - reconstruction_loss: 1890.7067 - kl_loss: 103.3013 - false_loss: 0.0751 - true_loss: 1.0347 - val_loss: 5188.9722 - val_reconstruction_loss: 1895.4310 - val_kl_loss: 99.9481 - val_false_loss: 10.2797 - val_true_loss: 1.0967\n",
      "Epoch 1326/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.3518 - reconstruction_loss: 1890.8833 - kl_loss: 102.4790 - false_loss: 0.0751 - true_loss: 1.0347 - val_loss: 5188.6997 - val_reconstruction_loss: 1895.4305 - val_kl_loss: 99.9487 - val_false_loss: 10.2788 - val_true_loss: 1.0966\n",
      "Epoch 1327/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.2779 - reconstruction_loss: 1890.8986 - kl_loss: 104.9622 - false_loss: 0.0751 - true_loss: 1.0347 - val_loss: 5188.4292 - val_reconstruction_loss: 1895.4302 - val_kl_loss: 99.9493 - val_false_loss: 10.2779 - val_true_loss: 1.0966\n",
      "Epoch 1328/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.9931 - reconstruction_loss: 1890.8202 - kl_loss: 103.8049 - false_loss: 0.0751 - true_loss: 1.0346 - val_loss: 5188.1592 - val_reconstruction_loss: 1895.4296 - val_kl_loss: 99.9499 - val_false_loss: 10.2771 - val_true_loss: 1.0965\n",
      "Epoch 1329/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.1898 - reconstruction_loss: 1890.7902 - kl_loss: 104.4015 - false_loss: 0.0751 - true_loss: 1.0346 - val_loss: 5187.8921 - val_reconstruction_loss: 1895.4290 - val_kl_loss: 99.9504 - val_false_loss: 10.2762 - val_true_loss: 1.0965\n",
      "Epoch 1330/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.5463 - reconstruction_loss: 1890.5537 - kl_loss: 104.5664 - false_loss: 0.0750 - true_loss: 1.0345 - val_loss: 5187.6201 - val_reconstruction_loss: 1895.4286 - val_kl_loss: 99.9509 - val_false_loss: 10.2753 - val_true_loss: 1.0965\n",
      "Epoch 1331/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.1165 - reconstruction_loss: 1890.5771 - kl_loss: 104.2697 - false_loss: 0.0750 - true_loss: 1.0345 - val_loss: 5187.3472 - val_reconstruction_loss: 1895.4281 - val_kl_loss: 99.9514 - val_false_loss: 10.2744 - val_true_loss: 1.0964\n",
      "Epoch 1332/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.4655 - reconstruction_loss: 1891.0605 - kl_loss: 104.1070 - false_loss: 0.0750 - true_loss: 1.0345 - val_loss: 5187.0747 - val_reconstruction_loss: 1895.4275 - val_kl_loss: 99.9519 - val_false_loss: 10.2735 - val_true_loss: 1.0964\n",
      "Epoch 1333/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.5175 - reconstruction_loss: 1890.5367 - kl_loss: 104.0711 - false_loss: 0.0750 - true_loss: 1.0344 - val_loss: 5186.7974 - val_reconstruction_loss: 1895.4271 - val_kl_loss: 99.9525 - val_false_loss: 10.2726 - val_true_loss: 1.0963\n",
      "Epoch 1334/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2197.6901 - reconstruction_loss: 1890.2755 - kl_loss: 105.0957 - false_loss: 0.0750 - true_loss: 1.0344 - val_loss: 5186.5161 - val_reconstruction_loss: 1895.4268 - val_kl_loss: 99.9531 - val_false_loss: 10.2717 - val_true_loss: 1.0963\n",
      "Epoch 1335/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.8693 - reconstruction_loss: 1890.0931 - kl_loss: 104.6932 - false_loss: 0.0750 - true_loss: 1.0344 - val_loss: 5186.2383 - val_reconstruction_loss: 1895.4260 - val_kl_loss: 99.9539 - val_false_loss: 10.2707 - val_true_loss: 1.0963\n",
      "Epoch 1336/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2197.9652 - reconstruction_loss: 1890.1051 - kl_loss: 104.2999 - false_loss: 0.0750 - true_loss: 1.0343 - val_loss: 5185.9629 - val_reconstruction_loss: 1895.4254 - val_kl_loss: 99.9543 - val_false_loss: 10.2698 - val_true_loss: 1.0962\n",
      "Epoch 1337/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.1927 - reconstruction_loss: 1890.3320 - kl_loss: 104.4743 - false_loss: 0.0750 - true_loss: 1.0343 - val_loss: 5185.6860 - val_reconstruction_loss: 1895.4250 - val_kl_loss: 99.9552 - val_false_loss: 10.2689 - val_true_loss: 1.0962\n",
      "Epoch 1338/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.3215 - reconstruction_loss: 1890.0503 - kl_loss: 105.6033 - false_loss: 0.0750 - true_loss: 1.0342 - val_loss: 5185.4082 - val_reconstruction_loss: 1895.4247 - val_kl_loss: 99.9559 - val_false_loss: 10.2680 - val_true_loss: 1.0961\n",
      "Epoch 1339/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2195.4798 - reconstruction_loss: 1890.2749 - kl_loss: 105.1905 - false_loss: 0.0750 - true_loss: 1.0342 - val_loss: 5185.1318 - val_reconstruction_loss: 1895.4241 - val_kl_loss: 99.9566 - val_false_loss: 10.2671 - val_true_loss: 1.0961\n",
      "Epoch 1340/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.4927 - reconstruction_loss: 1890.5382 - kl_loss: 104.3062 - false_loss: 0.0750 - true_loss: 1.0342 - val_loss: 5184.8511 - val_reconstruction_loss: 1895.4233 - val_kl_loss: 99.9571 - val_false_loss: 10.2662 - val_true_loss: 1.0961\n",
      "Epoch 1341/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.3962 - reconstruction_loss: 1890.2531 - kl_loss: 102.6417 - false_loss: 0.0750 - true_loss: 1.0341 - val_loss: 5184.5718 - val_reconstruction_loss: 1895.4230 - val_kl_loss: 99.9576 - val_false_loss: 10.2653 - val_true_loss: 1.0960\n",
      "Epoch 1342/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2190.7580 - reconstruction_loss: 1890.2062 - kl_loss: 105.0670 - false_loss: 0.0750 - true_loss: 1.0341 - val_loss: 5184.2954 - val_reconstruction_loss: 1895.4224 - val_kl_loss: 99.9582 - val_false_loss: 10.2644 - val_true_loss: 1.0960\n",
      "Epoch 1343/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.6532 - reconstruction_loss: 1890.2875 - kl_loss: 106.2310 - false_loss: 0.0750 - true_loss: 1.0340 - val_loss: 5184.0161 - val_reconstruction_loss: 1895.4220 - val_kl_loss: 99.9592 - val_false_loss: 10.2634 - val_true_loss: 1.0959\n",
      "Epoch 1344/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2190.0653 - reconstruction_loss: 1890.8286 - kl_loss: 106.3986 - false_loss: 0.0750 - true_loss: 1.0340 - val_loss: 5183.7397 - val_reconstruction_loss: 1895.4214 - val_kl_loss: 99.9600 - val_false_loss: 10.2625 - val_true_loss: 1.0959\n",
      "Epoch 1345/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2188.7627 - reconstruction_loss: 1890.4678 - kl_loss: 106.3298 - false_loss: 0.0750 - true_loss: 1.0340 - val_loss: 5183.4683 - val_reconstruction_loss: 1895.4210 - val_kl_loss: 99.9606 - val_false_loss: 10.2617 - val_true_loss: 1.0958\n",
      "Epoch 1346/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.8581 - reconstruction_loss: 1890.3734 - kl_loss: 106.1130 - false_loss: 0.0750 - true_loss: 1.0339 - val_loss: 5183.1934 - val_reconstruction_loss: 1895.4207 - val_kl_loss: 99.9610 - val_false_loss: 10.2607 - val_true_loss: 1.0958\n",
      "Epoch 1347/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.1651 - reconstruction_loss: 1890.5214 - kl_loss: 104.9359 - false_loss: 0.0749 - true_loss: 1.0339 - val_loss: 5182.9160 - val_reconstruction_loss: 1895.4202 - val_kl_loss: 99.9617 - val_false_loss: 10.2598 - val_true_loss: 1.0957\n",
      "Epoch 1348/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2190.5879 - reconstruction_loss: 1890.1626 - kl_loss: 107.3616 - false_loss: 0.0749 - true_loss: 1.0338 - val_loss: 5182.6406 - val_reconstruction_loss: 1895.4196 - val_kl_loss: 99.9627 - val_false_loss: 10.2589 - val_true_loss: 1.0957\n",
      "Epoch 1349/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.6041 - reconstruction_loss: 1890.8921 - kl_loss: 105.1520 - false_loss: 0.0749 - true_loss: 1.0338 - val_loss: 5182.3662 - val_reconstruction_loss: 1895.4189 - val_kl_loss: 99.9636 - val_false_loss: 10.2580 - val_true_loss: 1.0957\n",
      "Epoch 1350/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2188.6824 - reconstruction_loss: 1890.2568 - kl_loss: 108.3453 - false_loss: 0.0749 - true_loss: 1.0338 - val_loss: 5182.0908 - val_reconstruction_loss: 1895.4185 - val_kl_loss: 99.9648 - val_false_loss: 10.2571 - val_true_loss: 1.0956\n",
      "Epoch 1351/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2185.8403 - reconstruction_loss: 1890.3541 - kl_loss: 108.6515 - false_loss: 0.0749 - true_loss: 1.0337 - val_loss: 5181.8130 - val_reconstruction_loss: 1895.4181 - val_kl_loss: 99.9660 - val_false_loss: 10.2562 - val_true_loss: 1.0956\n",
      "Epoch 1352/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2186.3469 - reconstruction_loss: 1890.3365 - kl_loss: 106.3366 - false_loss: 0.0749 - true_loss: 1.0337 - val_loss: 5181.5356 - val_reconstruction_loss: 1895.4175 - val_kl_loss: 99.9669 - val_false_loss: 10.2553 - val_true_loss: 1.0955\n",
      "Epoch 1353/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2191.2479 - reconstruction_loss: 1890.3159 - kl_loss: 104.3085 - false_loss: 0.0749 - true_loss: 1.0336 - val_loss: 5181.2578 - val_reconstruction_loss: 1895.4171 - val_kl_loss: 99.9668 - val_false_loss: 10.2544 - val_true_loss: 1.0955\n",
      "Epoch 1354/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.2359 - reconstruction_loss: 1890.5273 - kl_loss: 101.2348 - false_loss: 0.0749 - true_loss: 1.0336 - val_loss: 5180.9775 - val_reconstruction_loss: 1895.4165 - val_kl_loss: 99.9673 - val_false_loss: 10.2535 - val_true_loss: 1.0954\n",
      "Epoch 1355/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.2016 - reconstruction_loss: 1890.4609 - kl_loss: 106.4837 - false_loss: 0.0749 - true_loss: 1.0335 - val_loss: 5180.7061 - val_reconstruction_loss: 1895.4161 - val_kl_loss: 99.9686 - val_false_loss: 10.2526 - val_true_loss: 1.0954\n",
      "Epoch 1356/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2190.1983 - reconstruction_loss: 1890.1289 - kl_loss: 109.5007 - false_loss: 0.0749 - true_loss: 1.0335 - val_loss: 5180.4341 - val_reconstruction_loss: 1895.4154 - val_kl_loss: 99.9698 - val_false_loss: 10.2517 - val_true_loss: 1.0953\n",
      "Epoch 1357/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2188.4703 - reconstruction_loss: 1890.8104 - kl_loss: 109.4380 - false_loss: 0.0749 - true_loss: 1.0335 - val_loss: 5180.1621 - val_reconstruction_loss: 1895.4150 - val_kl_loss: 99.9707 - val_false_loss: 10.2508 - val_true_loss: 1.0953\n",
      "Epoch 1358/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.0811 - reconstruction_loss: 1890.5883 - kl_loss: 106.6605 - false_loss: 0.0749 - true_loss: 1.0334 - val_loss: 5179.8950 - val_reconstruction_loss: 1895.4144 - val_kl_loss: 99.9716 - val_false_loss: 10.2499 - val_true_loss: 1.0953\n",
      "Epoch 1359/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2188.3707 - reconstruction_loss: 1890.3512 - kl_loss: 108.1199 - false_loss: 0.0749 - true_loss: 1.0334 - val_loss: 5179.6255 - val_reconstruction_loss: 1895.4139 - val_kl_loss: 99.9726 - val_false_loss: 10.2490 - val_true_loss: 1.0952\n",
      "Epoch 1360/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2186.1850 - reconstruction_loss: 1890.2982 - kl_loss: 109.6614 - false_loss: 0.0749 - true_loss: 1.0333 - val_loss: 5179.3535 - val_reconstruction_loss: 1895.4136 - val_kl_loss: 99.9734 - val_false_loss: 10.2481 - val_true_loss: 1.0952\n",
      "Epoch 1361/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2189.4218 - reconstruction_loss: 1890.5659 - kl_loss: 107.4774 - false_loss: 0.0749 - true_loss: 1.0333 - val_loss: 5179.0820 - val_reconstruction_loss: 1895.4130 - val_kl_loss: 99.9741 - val_false_loss: 10.2472 - val_true_loss: 1.0951\n",
      "Epoch 1362/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.7614 - reconstruction_loss: 1890.3336 - kl_loss: 104.7629 - false_loss: 0.0749 - true_loss: 1.0333 - val_loss: 5178.8130 - val_reconstruction_loss: 1895.4126 - val_kl_loss: 99.9745 - val_false_loss: 10.2464 - val_true_loss: 1.0951\n",
      "Epoch 1363/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.4626 - reconstruction_loss: 1890.9766 - kl_loss: 103.0994 - false_loss: 0.0749 - true_loss: 1.0332 - val_loss: 5178.5464 - val_reconstruction_loss: 1895.4120 - val_kl_loss: 99.9748 - val_false_loss: 10.2455 - val_true_loss: 1.0951\n",
      "Epoch 1364/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2212.2132 - reconstruction_loss: 1890.3652 - kl_loss: 104.5227 - false_loss: 0.0748 - true_loss: 1.0332 - val_loss: 5178.2798 - val_reconstruction_loss: 1895.4116 - val_kl_loss: 99.9758 - val_false_loss: 10.2446 - val_true_loss: 1.0950\n",
      "Epoch 1365/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.1032 - reconstruction_loss: 1890.4083 - kl_loss: 101.8895 - false_loss: 0.0748 - true_loss: 1.0332 - val_loss: 5178.0083 - val_reconstruction_loss: 1895.4113 - val_kl_loss: 99.9754 - val_false_loss: 10.2437 - val_true_loss: 1.0950\n",
      "Epoch 1366/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.3770 - reconstruction_loss: 1890.5748 - kl_loss: 99.6648 - false_loss: 0.0748 - true_loss: 1.0331 - val_loss: 5177.7378 - val_reconstruction_loss: 1895.4105 - val_kl_loss: 99.9750 - val_false_loss: 10.2428 - val_true_loss: 1.0950\n",
      "Epoch 1367/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2222.7798 - reconstruction_loss: 1890.8893 - kl_loss: 99.7663 - false_loss: 0.0748 - true_loss: 1.0331 - val_loss: 5177.4761 - val_reconstruction_loss: 1895.4102 - val_kl_loss: 99.9755 - val_false_loss: 10.2420 - val_true_loss: 1.0949\n",
      "Epoch 1368/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.9487 - reconstruction_loss: 1890.6646 - kl_loss: 101.3723 - false_loss: 0.0748 - true_loss: 1.0331 - val_loss: 5177.2056 - val_reconstruction_loss: 1895.4098 - val_kl_loss: 99.9764 - val_false_loss: 10.2411 - val_true_loss: 1.0949\n",
      "Epoch 1369/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.8076 - reconstruction_loss: 1890.3516 - kl_loss: 104.5975 - false_loss: 0.0748 - true_loss: 1.0330 - val_loss: 5176.9341 - val_reconstruction_loss: 1895.4092 - val_kl_loss: 99.9770 - val_false_loss: 10.2402 - val_true_loss: 1.0949\n",
      "Epoch 1370/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.0948 - reconstruction_loss: 1890.1844 - kl_loss: 105.4712 - false_loss: 0.0748 - true_loss: 1.0330 - val_loss: 5176.6670 - val_reconstruction_loss: 1895.4087 - val_kl_loss: 99.9777 - val_false_loss: 10.2393 - val_true_loss: 1.0948\n",
      "Epoch 1371/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.4455 - reconstruction_loss: 1890.1334 - kl_loss: 105.2704 - false_loss: 0.0748 - true_loss: 1.0330 - val_loss: 5176.3955 - val_reconstruction_loss: 1895.4081 - val_kl_loss: 99.9783 - val_false_loss: 10.2384 - val_true_loss: 1.0948\n",
      "Epoch 1372/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2205.0476 - reconstruction_loss: 1890.4901 - kl_loss: 103.6857 - false_loss: 0.0748 - true_loss: 1.0329 - val_loss: 5176.1230 - val_reconstruction_loss: 1895.4075 - val_kl_loss: 99.9788 - val_false_loss: 10.2375 - val_true_loss: 1.0948\n",
      "Epoch 1373/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.6363 - reconstruction_loss: 1889.9728 - kl_loss: 104.4079 - false_loss: 0.0748 - true_loss: 1.0329 - val_loss: 5175.8589 - val_reconstruction_loss: 1895.4071 - val_kl_loss: 99.9794 - val_false_loss: 10.2366 - val_true_loss: 1.0947\n",
      "Epoch 1374/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.9213 - reconstruction_loss: 1890.7054 - kl_loss: 103.2116 - false_loss: 0.0748 - true_loss: 1.0328 - val_loss: 5175.5889 - val_reconstruction_loss: 1895.4066 - val_kl_loss: 99.9795 - val_false_loss: 10.2357 - val_true_loss: 1.0947\n",
      "Epoch 1375/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.6660 - reconstruction_loss: 1890.4464 - kl_loss: 102.7637 - false_loss: 0.0748 - true_loss: 1.0328 - val_loss: 5175.3203 - val_reconstruction_loss: 1895.4060 - val_kl_loss: 99.9802 - val_false_loss: 10.2349 - val_true_loss: 1.0946\n",
      "Epoch 1376/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.2054 - reconstruction_loss: 1890.1885 - kl_loss: 104.5688 - false_loss: 0.0748 - true_loss: 1.0328 - val_loss: 5175.0483 - val_reconstruction_loss: 1895.4056 - val_kl_loss: 99.9809 - val_false_loss: 10.2340 - val_true_loss: 1.0946\n",
      "Epoch 1377/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.3740 - reconstruction_loss: 1890.0394 - kl_loss: 104.8323 - false_loss: 0.0748 - true_loss: 1.0327 - val_loss: 5174.7720 - val_reconstruction_loss: 1895.4053 - val_kl_loss: 99.9815 - val_false_loss: 10.2331 - val_true_loss: 1.0946\n",
      "Epoch 1378/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.9570 - reconstruction_loss: 1891.1417 - kl_loss: 104.1211 - false_loss: 0.0748 - true_loss: 1.0327 - val_loss: 5174.4980 - val_reconstruction_loss: 1895.4045 - val_kl_loss: 99.9820 - val_false_loss: 10.2322 - val_true_loss: 1.0945\n",
      "Epoch 1379/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.1110 - reconstruction_loss: 1891.9482 - kl_loss: 101.5736 - false_loss: 0.0748 - true_loss: 1.0327 - val_loss: 5174.2290 - val_reconstruction_loss: 1895.4042 - val_kl_loss: 99.9819 - val_false_loss: 10.2313 - val_true_loss: 1.0945\n",
      "Epoch 1380/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2210.7583 - reconstruction_loss: 1891.7352 - kl_loss: 99.6346 - false_loss: 0.0748 - true_loss: 1.0326 - val_loss: 5173.9663 - val_reconstruction_loss: 1895.4038 - val_kl_loss: 99.9812 - val_false_loss: 10.2304 - val_true_loss: 1.0945\n",
      "Epoch 1381/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2234.2218 - reconstruction_loss: 1892.3055 - kl_loss: 86.4009 - false_loss: 0.0748 - true_loss: 1.0326 - val_loss: 5173.6895 - val_reconstruction_loss: 1895.4037 - val_kl_loss: 99.9787 - val_false_loss: 10.2295 - val_true_loss: 1.0945\n",
      "Epoch 1382/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2380.9295 - reconstruction_loss: 1895.3475 - kl_loss: 69.2586 - false_loss: 0.0748 - true_loss: 1.0326 - val_loss: 5173.4268 - val_reconstruction_loss: 1895.4034 - val_kl_loss: 99.9762 - val_false_loss: 10.2286 - val_true_loss: 1.0945\n",
      "Epoch 1383/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2386.0117 - reconstruction_loss: 1895.1832 - kl_loss: 80.9033 - false_loss: 0.0748 - true_loss: 1.0327 - val_loss: 5173.1729 - val_reconstruction_loss: 1895.4032 - val_kl_loss: 99.9753 - val_false_loss: 10.2278 - val_true_loss: 1.0945\n",
      "Epoch 1384/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2265.9236 - reconstruction_loss: 1893.6416 - kl_loss: 95.4701 - false_loss: 0.0748 - true_loss: 1.0327 - val_loss: 5172.9087 - val_reconstruction_loss: 1895.4028 - val_kl_loss: 99.9756 - val_false_loss: 10.2269 - val_true_loss: 1.0945\n",
      "Epoch 1385/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2235.5901 - reconstruction_loss: 1892.3158 - kl_loss: 105.4955 - false_loss: 0.0747 - true_loss: 1.0327 - val_loss: 5172.6387 - val_reconstruction_loss: 1895.4022 - val_kl_loss: 99.9764 - val_false_loss: 10.2260 - val_true_loss: 1.0945\n",
      "Epoch 1386/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.1359 - reconstruction_loss: 1891.5924 - kl_loss: 105.6898 - false_loss: 0.0747 - true_loss: 1.0326 - val_loss: 5172.3696 - val_reconstruction_loss: 1895.4016 - val_kl_loss: 99.9770 - val_false_loss: 10.2251 - val_true_loss: 1.0944\n",
      "Epoch 1387/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2247.7773 - reconstruction_loss: 1891.2994 - kl_loss: 104.9690 - false_loss: 0.0747 - true_loss: 1.0326 - val_loss: 5172.1050 - val_reconstruction_loss: 1895.4011 - val_kl_loss: 99.9778 - val_false_loss: 10.2243 - val_true_loss: 1.0944\n",
      "Epoch 1388/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.7641 - reconstruction_loss: 1891.0758 - kl_loss: 104.8632 - false_loss: 0.0747 - true_loss: 1.0326 - val_loss: 5171.8374 - val_reconstruction_loss: 1895.4005 - val_kl_loss: 99.9785 - val_false_loss: 10.2234 - val_true_loss: 1.0944\n",
      "Epoch 1389/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.5552 - reconstruction_loss: 1890.8339 - kl_loss: 104.7919 - false_loss: 0.0747 - true_loss: 1.0325 - val_loss: 5171.5713 - val_reconstruction_loss: 1895.4001 - val_kl_loss: 99.9791 - val_false_loss: 10.2225 - val_true_loss: 1.0943\n",
      "Epoch 1390/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.1837 - reconstruction_loss: 1890.8839 - kl_loss: 104.0172 - false_loss: 0.0747 - true_loss: 1.0325 - val_loss: 5171.3052 - val_reconstruction_loss: 1895.3995 - val_kl_loss: 99.9796 - val_false_loss: 10.2216 - val_true_loss: 1.0943\n",
      "Epoch 1391/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.7028 - reconstruction_loss: 1890.4022 - kl_loss: 102.4153 - false_loss: 0.0747 - true_loss: 1.0325 - val_loss: 5171.0376 - val_reconstruction_loss: 1895.3990 - val_kl_loss: 99.9803 - val_false_loss: 10.2207 - val_true_loss: 1.0943\n",
      "Epoch 1392/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.6924 - reconstruction_loss: 1890.3678 - kl_loss: 105.0570 - false_loss: 0.0747 - true_loss: 1.0324 - val_loss: 5170.7734 - val_reconstruction_loss: 1895.3987 - val_kl_loss: 99.9810 - val_false_loss: 10.2199 - val_true_loss: 1.0942\n",
      "Epoch 1393/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2212.1310 - reconstruction_loss: 1890.7914 - kl_loss: 103.5444 - false_loss: 0.0747 - true_loss: 1.0324 - val_loss: 5170.5068 - val_reconstruction_loss: 1895.3978 - val_kl_loss: 99.9817 - val_false_loss: 10.2190 - val_true_loss: 1.0942\n",
      "Epoch 1394/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.0319 - reconstruction_loss: 1890.9535 - kl_loss: 104.8428 - false_loss: 0.0747 - true_loss: 1.0324 - val_loss: 5170.2373 - val_reconstruction_loss: 1895.3973 - val_kl_loss: 99.9824 - val_false_loss: 10.2181 - val_true_loss: 1.0942\n",
      "Epoch 1395/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.9772 - reconstruction_loss: 1890.4941 - kl_loss: 103.9721 - false_loss: 0.0747 - true_loss: 1.0323 - val_loss: 5169.9648 - val_reconstruction_loss: 1895.3970 - val_kl_loss: 99.9828 - val_false_loss: 10.2172 - val_true_loss: 1.0941\n",
      "Epoch 1396/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.9030 - reconstruction_loss: 1890.5214 - kl_loss: 103.8986 - false_loss: 0.0747 - true_loss: 1.0323 - val_loss: 5169.6885 - val_reconstruction_loss: 1895.3964 - val_kl_loss: 99.9834 - val_false_loss: 10.2163 - val_true_loss: 1.0941\n",
      "Epoch 1397/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.3956 - reconstruction_loss: 1890.2760 - kl_loss: 101.8100 - false_loss: 0.0747 - true_loss: 1.0323 - val_loss: 5169.4106 - val_reconstruction_loss: 1895.3958 - val_kl_loss: 99.9840 - val_false_loss: 10.2154 - val_true_loss: 1.0941\n",
      "Epoch 1398/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.4311 - reconstruction_loss: 1890.5717 - kl_loss: 105.1512 - false_loss: 0.0747 - true_loss: 1.0322 - val_loss: 5169.1318 - val_reconstruction_loss: 1895.3953 - val_kl_loss: 99.9843 - val_false_loss: 10.2145 - val_true_loss: 1.0940\n",
      "Epoch 1399/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.3399 - reconstruction_loss: 1890.6338 - kl_loss: 103.0534 - false_loss: 0.0747 - true_loss: 1.0322 - val_loss: 5168.8555 - val_reconstruction_loss: 1895.3947 - val_kl_loss: 99.9846 - val_false_loss: 10.2136 - val_true_loss: 1.0940\n",
      "Epoch 1400/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.4229 - reconstruction_loss: 1890.5299 - kl_loss: 105.4110 - false_loss: 0.0747 - true_loss: 1.0322 - val_loss: 5168.5767 - val_reconstruction_loss: 1895.3945 - val_kl_loss: 99.9852 - val_false_loss: 10.2126 - val_true_loss: 1.0939\n",
      "Epoch 1401/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.8499 - reconstruction_loss: 1890.6532 - kl_loss: 105.4060 - false_loss: 0.0747 - true_loss: 1.0321 - val_loss: 5168.3042 - val_reconstruction_loss: 1895.3938 - val_kl_loss: 99.9857 - val_false_loss: 10.2118 - val_true_loss: 1.0939\n",
      "Epoch 1402/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.8859 - reconstruction_loss: 1890.4633 - kl_loss: 103.3929 - false_loss: 0.0747 - true_loss: 1.0321 - val_loss: 5168.0317 - val_reconstruction_loss: 1895.3932 - val_kl_loss: 99.9860 - val_false_loss: 10.2109 - val_true_loss: 1.0939\n",
      "Epoch 1403/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.4990 - reconstruction_loss: 1890.4790 - kl_loss: 102.9633 - false_loss: 0.0747 - true_loss: 1.0321 - val_loss: 5167.7544 - val_reconstruction_loss: 1895.3928 - val_kl_loss: 99.9865 - val_false_loss: 10.2099 - val_true_loss: 1.0938\n",
      "Epoch 1404/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.3267 - reconstruction_loss: 1890.7036 - kl_loss: 103.8645 - false_loss: 0.0746 - true_loss: 1.0320 - val_loss: 5167.4771 - val_reconstruction_loss: 1895.3922 - val_kl_loss: 99.9871 - val_false_loss: 10.2090 - val_true_loss: 1.0938\n",
      "Epoch 1405/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2203.2160 - reconstruction_loss: 1890.2562 - kl_loss: 104.7553 - false_loss: 0.0746 - true_loss: 1.0320 - val_loss: 5167.2002 - val_reconstruction_loss: 1895.3917 - val_kl_loss: 99.9875 - val_false_loss: 10.2081 - val_true_loss: 1.0938\n",
      "Epoch 1406/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.6400 - reconstruction_loss: 1890.4987 - kl_loss: 104.0946 - false_loss: 0.0746 - true_loss: 1.0319 - val_loss: 5166.9204 - val_reconstruction_loss: 1895.3911 - val_kl_loss: 99.9880 - val_false_loss: 10.2072 - val_true_loss: 1.0937\n",
      "Epoch 1407/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.9098 - reconstruction_loss: 1890.7767 - kl_loss: 105.5143 - false_loss: 0.0746 - true_loss: 1.0319 - val_loss: 5166.6401 - val_reconstruction_loss: 1895.3907 - val_kl_loss: 99.9885 - val_false_loss: 10.2063 - val_true_loss: 1.0937\n",
      "Epoch 1408/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.1126 - reconstruction_loss: 1890.4948 - kl_loss: 104.1945 - false_loss: 0.0746 - true_loss: 1.0319 - val_loss: 5166.3604 - val_reconstruction_loss: 1895.3904 - val_kl_loss: 99.9890 - val_false_loss: 10.2054 - val_true_loss: 1.0936\n",
      "Epoch 1409/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.9003 - reconstruction_loss: 1891.4122 - kl_loss: 99.4696 - false_loss: 0.0746 - true_loss: 1.0318 - val_loss: 5166.0801 - val_reconstruction_loss: 1895.3899 - val_kl_loss: 99.9894 - val_false_loss: 10.2044 - val_true_loss: 1.0936\n",
      "Epoch 1410/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.0216 - reconstruction_loss: 1890.9340 - kl_loss: 106.2742 - false_loss: 0.0746 - true_loss: 1.0318 - val_loss: 5165.8018 - val_reconstruction_loss: 1895.3895 - val_kl_loss: 99.9902 - val_false_loss: 10.2035 - val_true_loss: 1.0936\n",
      "Epoch 1411/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.2359 - reconstruction_loss: 1890.3500 - kl_loss: 105.1021 - false_loss: 0.0746 - true_loss: 1.0318 - val_loss: 5165.5244 - val_reconstruction_loss: 1895.3889 - val_kl_loss: 99.9907 - val_false_loss: 10.2026 - val_true_loss: 1.0935\n",
      "Epoch 1412/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2197.8605 - reconstruction_loss: 1890.1058 - kl_loss: 104.8204 - false_loss: 0.0746 - true_loss: 1.0317 - val_loss: 5165.2471 - val_reconstruction_loss: 1895.3883 - val_kl_loss: 99.9912 - val_false_loss: 10.2017 - val_true_loss: 1.0935\n",
      "Epoch 1413/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.5231 - reconstruction_loss: 1890.3802 - kl_loss: 105.7830 - false_loss: 0.0746 - true_loss: 1.0317 - val_loss: 5164.9707 - val_reconstruction_loss: 1895.3878 - val_kl_loss: 99.9918 - val_false_loss: 10.2008 - val_true_loss: 1.0934\n",
      "Epoch 1414/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.3609 - reconstruction_loss: 1890.3524 - kl_loss: 105.7398 - false_loss: 0.0746 - true_loss: 1.0316 - val_loss: 5164.6924 - val_reconstruction_loss: 1895.3872 - val_kl_loss: 99.9923 - val_false_loss: 10.1999 - val_true_loss: 1.0934\n",
      "Epoch 1415/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2197.1422 - reconstruction_loss: 1890.4052 - kl_loss: 104.2179 - false_loss: 0.0746 - true_loss: 1.0316 - val_loss: 5164.4155 - val_reconstruction_loss: 1895.3866 - val_kl_loss: 99.9928 - val_false_loss: 10.1990 - val_true_loss: 1.0934\n",
      "Epoch 1416/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.6637 - reconstruction_loss: 1890.4497 - kl_loss: 105.4321 - false_loss: 0.0746 - true_loss: 1.0316 - val_loss: 5164.1460 - val_reconstruction_loss: 1895.3864 - val_kl_loss: 99.9935 - val_false_loss: 10.1981 - val_true_loss: 1.0933\n",
      "Epoch 1417/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2192.0936 - reconstruction_loss: 1890.5475 - kl_loss: 106.3408 - false_loss: 0.0746 - true_loss: 1.0315 - val_loss: 5163.8745 - val_reconstruction_loss: 1895.3857 - val_kl_loss: 99.9943 - val_false_loss: 10.1972 - val_true_loss: 1.0933\n",
      "Epoch 1418/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2192.4959 - reconstruction_loss: 1890.2941 - kl_loss: 105.9695 - false_loss: 0.0746 - true_loss: 1.0315 - val_loss: 5163.6006 - val_reconstruction_loss: 1895.3851 - val_kl_loss: 99.9949 - val_false_loss: 10.1963 - val_true_loss: 1.0932\n",
      "Epoch 1419/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.7219 - reconstruction_loss: 1890.6343 - kl_loss: 105.1048 - false_loss: 0.0746 - true_loss: 1.0314 - val_loss: 5163.3301 - val_reconstruction_loss: 1895.3848 - val_kl_loss: 99.9956 - val_false_loss: 10.1954 - val_true_loss: 1.0932\n",
      "Epoch 1420/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.0474 - reconstruction_loss: 1890.5074 - kl_loss: 105.6970 - false_loss: 0.0746 - true_loss: 1.0314 - val_loss: 5163.0527 - val_reconstruction_loss: 1895.3844 - val_kl_loss: 99.9962 - val_false_loss: 10.1945 - val_true_loss: 1.0931\n",
      "Epoch 1421/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.7197 - reconstruction_loss: 1890.3379 - kl_loss: 105.3079 - false_loss: 0.0745 - true_loss: 1.0314 - val_loss: 5162.7734 - val_reconstruction_loss: 1895.3837 - val_kl_loss: 99.9967 - val_false_loss: 10.1936 - val_true_loss: 1.0931\n",
      "Epoch 1422/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.7942 - reconstruction_loss: 1890.7365 - kl_loss: 105.8436 - false_loss: 0.0745 - true_loss: 1.0313 - val_loss: 5162.4961 - val_reconstruction_loss: 1895.3833 - val_kl_loss: 99.9974 - val_false_loss: 10.1927 - val_true_loss: 1.0931\n",
      "Epoch 1423/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.4447 - reconstruction_loss: 1890.4821 - kl_loss: 105.9010 - false_loss: 0.0745 - true_loss: 1.0313 - val_loss: 5162.2192 - val_reconstruction_loss: 1895.3828 - val_kl_loss: 99.9978 - val_false_loss: 10.1918 - val_true_loss: 1.0930\n",
      "Epoch 1424/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.4409 - reconstruction_loss: 1890.5367 - kl_loss: 104.9444 - false_loss: 0.0745 - true_loss: 1.0312 - val_loss: 5161.9473 - val_reconstruction_loss: 1895.3824 - val_kl_loss: 99.9985 - val_false_loss: 10.1909 - val_true_loss: 1.0930\n",
      "Epoch 1425/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.8333 - reconstruction_loss: 1890.3063 - kl_loss: 106.0315 - false_loss: 0.0745 - true_loss: 1.0312 - val_loss: 5161.6729 - val_reconstruction_loss: 1895.3818 - val_kl_loss: 99.9994 - val_false_loss: 10.1900 - val_true_loss: 1.0929\n",
      "Epoch 1426/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.6380 - reconstruction_loss: 1890.2687 - kl_loss: 104.8488 - false_loss: 0.0745 - true_loss: 1.0312 - val_loss: 5161.3970 - val_reconstruction_loss: 1895.3812 - val_kl_loss: 100.0003 - val_false_loss: 10.1891 - val_true_loss: 1.0929\n",
      "Epoch 1427/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.9196 - reconstruction_loss: 1890.5211 - kl_loss: 104.6099 - false_loss: 0.0745 - true_loss: 1.0311 - val_loss: 5161.1221 - val_reconstruction_loss: 1895.3809 - val_kl_loss: 100.0011 - val_false_loss: 10.1882 - val_true_loss: 1.0929\n",
      "Epoch 1428/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.5267 - reconstruction_loss: 1890.6895 - kl_loss: 101.9009 - false_loss: 0.0745 - true_loss: 1.0311 - val_loss: 5160.8457 - val_reconstruction_loss: 1895.3804 - val_kl_loss: 100.0001 - val_false_loss: 10.1872 - val_true_loss: 1.0928\n",
      "Epoch 1429/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.4718 - reconstruction_loss: 1891.4023 - kl_loss: 102.6649 - false_loss: 0.0745 - true_loss: 1.0311 - val_loss: 5160.5737 - val_reconstruction_loss: 1895.3798 - val_kl_loss: 100.0013 - val_false_loss: 10.1864 - val_true_loss: 1.0928\n",
      "Epoch 1430/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.4231 - reconstruction_loss: 1890.9141 - kl_loss: 108.0559 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5160.3037 - val_reconstruction_loss: 1895.3794 - val_kl_loss: 100.0022 - val_false_loss: 10.1855 - val_true_loss: 1.0927\n",
      "Epoch 1431/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.6532 - reconstruction_loss: 1890.2817 - kl_loss: 105.6526 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5160.0283 - val_reconstruction_loss: 1895.3789 - val_kl_loss: 100.0026 - val_false_loss: 10.1846 - val_true_loss: 1.0927\n",
      "Epoch 1432/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.6274 - reconstruction_loss: 1890.0874 - kl_loss: 105.1664 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5159.7559 - val_reconstruction_loss: 1895.3783 - val_kl_loss: 100.0033 - val_false_loss: 10.1837 - val_true_loss: 1.0927\n",
      "Epoch 1433/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.6170 - reconstruction_loss: 1890.3687 - kl_loss: 104.1018 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5159.4805 - val_reconstruction_loss: 1895.3779 - val_kl_loss: 100.0031 - val_false_loss: 10.1828 - val_true_loss: 1.0926\n",
      "Epoch 1434/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.3567 - reconstruction_loss: 1890.5763 - kl_loss: 99.3600 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5159.2012 - val_reconstruction_loss: 1895.3774 - val_kl_loss: 100.0024 - val_false_loss: 10.1818 - val_true_loss: 1.0926\n",
      "Epoch 1435/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2375.4698 - reconstruction_loss: 1894.3619 - kl_loss: 74.0759 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5158.9565 - val_reconstruction_loss: 1895.3774 - val_kl_loss: 99.9984 - val_false_loss: 10.1810 - val_true_loss: 1.0927\n",
      "Epoch 1436/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2569.0712 - reconstruction_loss: 1899.1865 - kl_loss: 67.6730 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5158.7104 - val_reconstruction_loss: 1895.3776 - val_kl_loss: 99.9946 - val_false_loss: 10.1802 - val_true_loss: 1.0928\n",
      "Epoch 1437/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2423.2676 - reconstruction_loss: 1899.6915 - kl_loss: 73.9692 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5158.4795 - val_reconstruction_loss: 1895.3776 - val_kl_loss: 99.9924 - val_false_loss: 10.1794 - val_true_loss: 1.0928\n",
      "Epoch 1438/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2293.1813 - reconstruction_loss: 1897.8324 - kl_loss: 83.2448 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5158.2617 - val_reconstruction_loss: 1895.3772 - val_kl_loss: 99.9911 - val_false_loss: 10.1787 - val_true_loss: 1.0928\n",
      "Epoch 1439/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2267.6933 - reconstruction_loss: 1895.7579 - kl_loss: 91.3743 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5158.0273 - val_reconstruction_loss: 1895.3768 - val_kl_loss: 99.9906 - val_false_loss: 10.1779 - val_true_loss: 1.0928\n",
      "Epoch 1440/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2257.2248 - reconstruction_loss: 1895.5693 - kl_loss: 92.2912 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5157.7847 - val_reconstruction_loss: 1895.3765 - val_kl_loss: 99.9899 - val_false_loss: 10.1771 - val_true_loss: 1.0927\n",
      "Epoch 1441/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2246.6645 - reconstruction_loss: 1894.6124 - kl_loss: 92.2251 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5157.5200 - val_reconstruction_loss: 1895.3762 - val_kl_loss: 99.9892 - val_false_loss: 10.1763 - val_true_loss: 1.0927\n",
      "Epoch 1442/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2244.7855 - reconstruction_loss: 1894.4760 - kl_loss: 93.6087 - false_loss: 0.0745 - true_loss: 1.0310 - val_loss: 5157.2549 - val_reconstruction_loss: 1895.3759 - val_kl_loss: 99.9888 - val_false_loss: 10.1754 - val_true_loss: 1.0927\n",
      "Epoch 1443/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2247.2812 - reconstruction_loss: 1893.7948 - kl_loss: 94.7664 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5156.9902 - val_reconstruction_loss: 1895.3752 - val_kl_loss: 99.9883 - val_false_loss: 10.1745 - val_true_loss: 1.0927\n",
      "Epoch 1444/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2274.5264 - reconstruction_loss: 1893.3043 - kl_loss: 94.9998 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5156.7241 - val_reconstruction_loss: 1895.3746 - val_kl_loss: 99.9879 - val_false_loss: 10.1736 - val_true_loss: 1.0927\n",
      "Epoch 1445/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2237.2603 - reconstruction_loss: 1892.6530 - kl_loss: 94.4028 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5156.4600 - val_reconstruction_loss: 1895.3745 - val_kl_loss: 99.9876 - val_false_loss: 10.1727 - val_true_loss: 1.0926\n",
      "Epoch 1446/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2261.6893 - reconstruction_loss: 1893.7983 - kl_loss: 94.1752 - false_loss: 0.0745 - true_loss: 1.0309 - val_loss: 5156.1992 - val_reconstruction_loss: 1895.3740 - val_kl_loss: 99.9870 - val_false_loss: 10.1719 - val_true_loss: 1.0926\n",
      "Epoch 1447/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2258.5815 - reconstruction_loss: 1893.4264 - kl_loss: 90.9558 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5155.9341 - val_reconstruction_loss: 1895.3734 - val_kl_loss: 99.9855 - val_false_loss: 10.1710 - val_true_loss: 1.0926\n",
      "Epoch 1448/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2267.7012 - reconstruction_loss: 1893.2977 - kl_loss: 89.5871 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5155.6802 - val_reconstruction_loss: 1895.3730 - val_kl_loss: 99.9832 - val_false_loss: 10.1702 - val_true_loss: 1.0926\n",
      "Epoch 1449/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2406.0887 - reconstruction_loss: 1895.6471 - kl_loss: 75.3651 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5155.4238 - val_reconstruction_loss: 1895.3726 - val_kl_loss: 99.9818 - val_false_loss: 10.1693 - val_true_loss: 1.0926\n",
      "Epoch 1450/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2289.0668 - reconstruction_loss: 1894.0229 - kl_loss: 86.3758 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5155.1670 - val_reconstruction_loss: 1895.3722 - val_kl_loss: 99.9805 - val_false_loss: 10.1685 - val_true_loss: 1.0926\n",
      "Epoch 1451/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2274.1006 - reconstruction_loss: 1892.4877 - kl_loss: 90.7271 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5154.9116 - val_reconstruction_loss: 1895.3718 - val_kl_loss: 99.9798 - val_false_loss: 10.1676 - val_true_loss: 1.0926\n",
      "Epoch 1452/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2289.4975 - reconstruction_loss: 1892.0078 - kl_loss: 93.9936 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5154.6567 - val_reconstruction_loss: 1895.3710 - val_kl_loss: 99.9799 - val_false_loss: 10.1668 - val_true_loss: 1.0926\n",
      "Epoch 1453/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2263.2174 - reconstruction_loss: 1891.6787 - kl_loss: 97.8690 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5154.3970 - val_reconstruction_loss: 1895.3707 - val_kl_loss: 99.9801 - val_false_loss: 10.1659 - val_true_loss: 1.0926\n",
      "Epoch 1454/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2245.9152 - reconstruction_loss: 1891.4337 - kl_loss: 99.4959 - false_loss: 0.0744 - true_loss: 1.0309 - val_loss: 5154.1387 - val_reconstruction_loss: 1895.3701 - val_kl_loss: 99.9800 - val_false_loss: 10.1651 - val_true_loss: 1.0925\n",
      "Epoch 1455/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2249.0454 - reconstruction_loss: 1891.4567 - kl_loss: 96.1757 - false_loss: 0.0744 - true_loss: 1.0308 - val_loss: 5153.8838 - val_reconstruction_loss: 1895.3695 - val_kl_loss: 99.9795 - val_false_loss: 10.1642 - val_true_loss: 1.0925\n",
      "Epoch 1456/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2248.8987 - reconstruction_loss: 1891.3873 - kl_loss: 95.2937 - false_loss: 0.0744 - true_loss: 1.0308 - val_loss: 5153.6284 - val_reconstruction_loss: 1895.3690 - val_kl_loss: 99.9794 - val_false_loss: 10.1634 - val_true_loss: 1.0925\n",
      "Epoch 1457/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2238.6643 - reconstruction_loss: 1891.2855 - kl_loss: 98.2177 - false_loss: 0.0744 - true_loss: 1.0308 - val_loss: 5153.3691 - val_reconstruction_loss: 1895.3684 - val_kl_loss: 99.9793 - val_false_loss: 10.1625 - val_true_loss: 1.0925\n",
      "Epoch 1458/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.4306 - reconstruction_loss: 1891.2426 - kl_loss: 98.5013 - false_loss: 0.0744 - true_loss: 1.0308 - val_loss: 5153.1108 - val_reconstruction_loss: 1895.3680 - val_kl_loss: 99.9790 - val_false_loss: 10.1617 - val_true_loss: 1.0924\n",
      "Epoch 1459/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2229.5289 - reconstruction_loss: 1891.2386 - kl_loss: 98.2852 - false_loss: 0.0744 - true_loss: 1.0308 - val_loss: 5152.8501 - val_reconstruction_loss: 1895.3676 - val_kl_loss: 99.9789 - val_false_loss: 10.1608 - val_true_loss: 1.0924\n",
      "Epoch 1460/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2228.4038 - reconstruction_loss: 1891.1996 - kl_loss: 98.9068 - false_loss: 0.0744 - true_loss: 1.0307 - val_loss: 5152.5923 - val_reconstruction_loss: 1895.3669 - val_kl_loss: 99.9791 - val_false_loss: 10.1600 - val_true_loss: 1.0924\n",
      "Epoch 1461/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.1988 - reconstruction_loss: 1891.2207 - kl_loss: 99.4759 - false_loss: 0.0744 - true_loss: 1.0307 - val_loss: 5152.3320 - val_reconstruction_loss: 1895.3663 - val_kl_loss: 99.9790 - val_false_loss: 10.1591 - val_true_loss: 1.0924\n",
      "Epoch 1462/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2225.0608 - reconstruction_loss: 1891.2559 - kl_loss: 98.4321 - false_loss: 0.0744 - true_loss: 1.0307 - val_loss: 5152.0713 - val_reconstruction_loss: 1895.3661 - val_kl_loss: 99.9786 - val_false_loss: 10.1583 - val_true_loss: 1.0923\n",
      "Epoch 1463/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.1436 - reconstruction_loss: 1891.2686 - kl_loss: 98.8179 - false_loss: 0.0744 - true_loss: 1.0307 - val_loss: 5151.8076 - val_reconstruction_loss: 1895.3655 - val_kl_loss: 99.9787 - val_false_loss: 10.1574 - val_true_loss: 1.0923\n",
      "Epoch 1464/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.2999 - reconstruction_loss: 1890.9738 - kl_loss: 100.4513 - false_loss: 0.0744 - true_loss: 1.0306 - val_loss: 5151.5493 - val_reconstruction_loss: 1895.3647 - val_kl_loss: 99.9791 - val_false_loss: 10.1566 - val_true_loss: 1.0923\n",
      "Epoch 1465/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.5286 - reconstruction_loss: 1890.9146 - kl_loss: 101.0510 - false_loss: 0.0744 - true_loss: 1.0306 - val_loss: 5151.2915 - val_reconstruction_loss: 1895.3644 - val_kl_loss: 99.9792 - val_false_loss: 10.1557 - val_true_loss: 1.0922\n",
      "Epoch 1466/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9603 - reconstruction_loss: 1890.9723 - kl_loss: 99.5439 - false_loss: 0.0744 - true_loss: 1.0306 - val_loss: 5151.0352 - val_reconstruction_loss: 1895.3638 - val_kl_loss: 99.9792 - val_false_loss: 10.1549 - val_true_loss: 1.0922\n",
      "Epoch 1467/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2221.2795 - reconstruction_loss: 1891.3213 - kl_loss: 99.0663 - false_loss: 0.0744 - true_loss: 1.0305 - val_loss: 5150.7700 - val_reconstruction_loss: 1895.3634 - val_kl_loss: 99.9786 - val_false_loss: 10.1540 - val_true_loss: 1.0922\n",
      "Epoch 1468/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2228.5271 - reconstruction_loss: 1891.6021 - kl_loss: 95.0737 - false_loss: 0.0744 - true_loss: 1.0305 - val_loss: 5150.5034 - val_reconstruction_loss: 1895.3629 - val_kl_loss: 99.9789 - val_false_loss: 10.1531 - val_true_loss: 1.0921\n",
      "Epoch 1469/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.6657 - reconstruction_loss: 1890.8529 - kl_loss: 103.1453 - false_loss: 0.0744 - true_loss: 1.0305 - val_loss: 5150.2388 - val_reconstruction_loss: 1895.3623 - val_kl_loss: 99.9792 - val_false_loss: 10.1523 - val_true_loss: 1.0921\n",
      "Epoch 1470/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.8055 - reconstruction_loss: 1891.0367 - kl_loss: 100.6700 - false_loss: 0.0744 - true_loss: 1.0304 - val_loss: 5149.9727 - val_reconstruction_loss: 1895.3619 - val_kl_loss: 99.9794 - val_false_loss: 10.1514 - val_true_loss: 1.0921\n",
      "Epoch 1471/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2215.5823 - reconstruction_loss: 1891.3419 - kl_loss: 102.3412 - false_loss: 0.0744 - true_loss: 1.0304 - val_loss: 5149.7090 - val_reconstruction_loss: 1895.3615 - val_kl_loss: 99.9796 - val_false_loss: 10.1505 - val_true_loss: 1.0920\n",
      "Epoch 1472/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.6705 - reconstruction_loss: 1890.8564 - kl_loss: 100.9806 - false_loss: 0.0743 - true_loss: 1.0304 - val_loss: 5149.4448 - val_reconstruction_loss: 1895.3611 - val_kl_loss: 99.9799 - val_false_loss: 10.1497 - val_true_loss: 1.0920\n",
      "Epoch 1473/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2211.9156 - reconstruction_loss: 1890.5270 - kl_loss: 103.0260 - false_loss: 0.0743 - true_loss: 1.0304 - val_loss: 5149.1782 - val_reconstruction_loss: 1895.3602 - val_kl_loss: 99.9801 - val_false_loss: 10.1488 - val_true_loss: 1.0920\n",
      "Epoch 1474/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2214.8390 - reconstruction_loss: 1891.0389 - kl_loss: 99.3059 - false_loss: 0.0743 - true_loss: 1.0303 - val_loss: 5148.9136 - val_reconstruction_loss: 1895.3600 - val_kl_loss: 99.9797 - val_false_loss: 10.1479 - val_true_loss: 1.0919\n",
      "Epoch 1475/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2270.7010 - reconstruction_loss: 1893.8636 - kl_loss: 81.5700 - false_loss: 0.0743 - true_loss: 1.0303 - val_loss: 5148.6553 - val_reconstruction_loss: 1895.3597 - val_kl_loss: 99.9761 - val_false_loss: 10.1470 - val_true_loss: 1.0920\n",
      "Epoch 1476/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2368.2406 - reconstruction_loss: 1896.1642 - kl_loss: 82.2739 - false_loss: 0.0743 - true_loss: 1.0303 - val_loss: 5148.4009 - val_reconstruction_loss: 1895.3595 - val_kl_loss: 99.9750 - val_false_loss: 10.1462 - val_true_loss: 1.0920\n",
      "Epoch 1477/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2279.6503 - reconstruction_loss: 1893.2760 - kl_loss: 88.4828 - false_loss: 0.0743 - true_loss: 1.0303 - val_loss: 5148.1387 - val_reconstruction_loss: 1895.3589 - val_kl_loss: 99.9743 - val_false_loss: 10.1453 - val_true_loss: 1.0920\n",
      "Epoch 1478/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2254.9431 - reconstruction_loss: 1891.9795 - kl_loss: 95.4120 - false_loss: 0.0743 - true_loss: 1.0303 - val_loss: 5147.8779 - val_reconstruction_loss: 1895.3585 - val_kl_loss: 99.9741 - val_false_loss: 10.1445 - val_true_loss: 1.0920\n",
      "Epoch 1479/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2246.2565 - reconstruction_loss: 1891.4541 - kl_loss: 102.0825 - false_loss: 0.0743 - true_loss: 1.0303 - val_loss: 5147.6113 - val_reconstruction_loss: 1895.3579 - val_kl_loss: 99.9746 - val_false_loss: 10.1436 - val_true_loss: 1.0919\n",
      "Epoch 1480/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2231.5532 - reconstruction_loss: 1891.0724 - kl_loss: 104.1761 - false_loss: 0.0743 - true_loss: 1.0303 - val_loss: 5147.3462 - val_reconstruction_loss: 1895.3574 - val_kl_loss: 99.9752 - val_false_loss: 10.1427 - val_true_loss: 1.0919\n",
      "Epoch 1481/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.0732 - reconstruction_loss: 1890.8373 - kl_loss: 102.1539 - false_loss: 0.0743 - true_loss: 1.0302 - val_loss: 5147.0781 - val_reconstruction_loss: 1895.3568 - val_kl_loss: 99.9754 - val_false_loss: 10.1418 - val_true_loss: 1.0919\n",
      "Epoch 1482/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2216.7363 - reconstruction_loss: 1890.6929 - kl_loss: 102.5309 - false_loss: 0.0743 - true_loss: 1.0302 - val_loss: 5146.8120 - val_reconstruction_loss: 1895.3563 - val_kl_loss: 99.9756 - val_false_loss: 10.1410 - val_true_loss: 1.0918\n",
      "Epoch 1483/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2218.9396 - reconstruction_loss: 1890.8667 - kl_loss: 99.7561 - false_loss: 0.0743 - true_loss: 1.0302 - val_loss: 5146.5464 - val_reconstruction_loss: 1895.3557 - val_kl_loss: 99.9759 - val_false_loss: 10.1401 - val_true_loss: 1.0918\n",
      "Epoch 1484/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2213.3438 - reconstruction_loss: 1890.7037 - kl_loss: 103.1648 - false_loss: 0.0743 - true_loss: 1.0302 - val_loss: 5146.2822 - val_reconstruction_loss: 1895.3552 - val_kl_loss: 99.9762 - val_false_loss: 10.1392 - val_true_loss: 1.0918\n",
      "Epoch 1485/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2211.5761 - reconstruction_loss: 1891.1823 - kl_loss: 102.7238 - false_loss: 0.0743 - true_loss: 1.0301 - val_loss: 5146.0151 - val_reconstruction_loss: 1895.3546 - val_kl_loss: 99.9765 - val_false_loss: 10.1383 - val_true_loss: 1.0917\n",
      "Epoch 1486/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2209.6487 - reconstruction_loss: 1890.9648 - kl_loss: 103.0735 - false_loss: 0.0743 - true_loss: 1.0301 - val_loss: 5145.7544 - val_reconstruction_loss: 1895.3540 - val_kl_loss: 99.9771 - val_false_loss: 10.1375 - val_true_loss: 1.0917\n",
      "Epoch 1487/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.7156 - reconstruction_loss: 1890.7295 - kl_loss: 103.6679 - false_loss: 0.0743 - true_loss: 1.0301 - val_loss: 5145.4897 - val_reconstruction_loss: 1895.3535 - val_kl_loss: 99.9776 - val_false_loss: 10.1366 - val_true_loss: 1.0916\n",
      "Epoch 1488/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.2797 - reconstruction_loss: 1890.8403 - kl_loss: 103.5740 - false_loss: 0.0743 - true_loss: 1.0300 - val_loss: 5145.2256 - val_reconstruction_loss: 1895.3529 - val_kl_loss: 99.9776 - val_false_loss: 10.1358 - val_true_loss: 1.0916\n",
      "Epoch 1489/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2206.9885 - reconstruction_loss: 1890.9038 - kl_loss: 102.4710 - false_loss: 0.0743 - true_loss: 1.0300 - val_loss: 5144.9683 - val_reconstruction_loss: 1895.3525 - val_kl_loss: 99.9780 - val_false_loss: 10.1349 - val_true_loss: 1.0916\n",
      "Epoch 1490/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2206.8472 - reconstruction_loss: 1890.8179 - kl_loss: 103.0512 - false_loss: 0.0743 - true_loss: 1.0300 - val_loss: 5144.7056 - val_reconstruction_loss: 1895.3518 - val_kl_loss: 99.9784 - val_false_loss: 10.1340 - val_true_loss: 1.0915\n",
      "Epoch 1491/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.6662 - reconstruction_loss: 1890.8475 - kl_loss: 104.4409 - false_loss: 0.0743 - true_loss: 1.0299 - val_loss: 5144.4429 - val_reconstruction_loss: 1895.3514 - val_kl_loss: 99.9790 - val_false_loss: 10.1332 - val_true_loss: 1.0915\n",
      "Epoch 1492/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.9294 - reconstruction_loss: 1891.2211 - kl_loss: 103.9511 - false_loss: 0.0743 - true_loss: 1.0299 - val_loss: 5144.1821 - val_reconstruction_loss: 1895.3510 - val_kl_loss: 99.9794 - val_false_loss: 10.1323 - val_true_loss: 1.0914\n",
      "Epoch 1493/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.9879 - reconstruction_loss: 1890.8895 - kl_loss: 102.5704 - false_loss: 0.0743 - true_loss: 1.0298 - val_loss: 5143.9292 - val_reconstruction_loss: 1895.3503 - val_kl_loss: 99.9797 - val_false_loss: 10.1315 - val_true_loss: 1.0914\n",
      "Epoch 1494/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2207.1111 - reconstruction_loss: 1890.7863 - kl_loss: 102.2329 - false_loss: 0.0742 - true_loss: 1.0298 - val_loss: 5143.6670 - val_reconstruction_loss: 1895.3500 - val_kl_loss: 99.9802 - val_false_loss: 10.1306 - val_true_loss: 1.0914\n",
      "Epoch 1495/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.9134 - reconstruction_loss: 1890.6588 - kl_loss: 102.2274 - false_loss: 0.0742 - true_loss: 1.0298 - val_loss: 5143.4028 - val_reconstruction_loss: 1895.3496 - val_kl_loss: 99.9804 - val_false_loss: 10.1298 - val_true_loss: 1.0913\n",
      "Epoch 1496/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.0442 - reconstruction_loss: 1891.3116 - kl_loss: 104.7500 - false_loss: 0.0742 - true_loss: 1.0297 - val_loss: 5143.1382 - val_reconstruction_loss: 1895.3489 - val_kl_loss: 99.9811 - val_false_loss: 10.1289 - val_true_loss: 1.0913\n",
      "Epoch 1497/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2203.5344 - reconstruction_loss: 1890.6503 - kl_loss: 101.8492 - false_loss: 0.0742 - true_loss: 1.0297 - val_loss: 5142.8784 - val_reconstruction_loss: 1895.3484 - val_kl_loss: 99.9817 - val_false_loss: 10.1280 - val_true_loss: 1.0913\n",
      "Epoch 1498/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.6239 - reconstruction_loss: 1890.5840 - kl_loss: 104.9225 - false_loss: 0.0742 - true_loss: 1.0297 - val_loss: 5142.6274 - val_reconstruction_loss: 1895.3478 - val_kl_loss: 99.9822 - val_false_loss: 10.1272 - val_true_loss: 1.0912\n",
      "Epoch 1499/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.8226 - reconstruction_loss: 1890.9950 - kl_loss: 104.5204 - false_loss: 0.0742 - true_loss: 1.0296 - val_loss: 5142.3677 - val_reconstruction_loss: 1895.3474 - val_kl_loss: 99.9827 - val_false_loss: 10.1264 - val_true_loss: 1.0912\n",
      "Epoch 1500/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.5592 - reconstruction_loss: 1891.0831 - kl_loss: 104.7093 - false_loss: 0.0742 - true_loss: 1.0296 - val_loss: 5142.1030 - val_reconstruction_loss: 1895.3467 - val_kl_loss: 99.9834 - val_false_loss: 10.1255 - val_true_loss: 1.0911\n",
      "Epoch 1501/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.3936 - reconstruction_loss: 1891.0806 - kl_loss: 104.9961 - false_loss: 0.0742 - true_loss: 1.0296 - val_loss: 5141.8408 - val_reconstruction_loss: 1895.3463 - val_kl_loss: 99.9841 - val_false_loss: 10.1246 - val_true_loss: 1.0911\n",
      "Epoch 1502/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.0436 - reconstruction_loss: 1890.7423 - kl_loss: 103.9548 - false_loss: 0.0742 - true_loss: 1.0295 - val_loss: 5141.5845 - val_reconstruction_loss: 1895.3459 - val_kl_loss: 99.9840 - val_false_loss: 10.1238 - val_true_loss: 1.0911\n",
      "Epoch 1503/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.1168 - reconstruction_loss: 1890.8438 - kl_loss: 100.1896 - false_loss: 0.0742 - true_loss: 1.0295 - val_loss: 5141.3340 - val_reconstruction_loss: 1895.3455 - val_kl_loss: 99.9846 - val_false_loss: 10.1230 - val_true_loss: 1.0910\n",
      "Epoch 1504/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.3688 - reconstruction_loss: 1890.5361 - kl_loss: 106.7188 - false_loss: 0.0742 - true_loss: 1.0295 - val_loss: 5141.0703 - val_reconstruction_loss: 1895.3448 - val_kl_loss: 99.9848 - val_false_loss: 10.1221 - val_true_loss: 1.0910\n",
      "Epoch 1505/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.5834 - reconstruction_loss: 1890.4681 - kl_loss: 104.9094 - false_loss: 0.0742 - true_loss: 1.0294 - val_loss: 5140.8052 - val_reconstruction_loss: 1895.3441 - val_kl_loss: 99.9857 - val_false_loss: 10.1212 - val_true_loss: 1.0909\n",
      "Epoch 1506/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.9971 - reconstruction_loss: 1891.2573 - kl_loss: 105.6344 - false_loss: 0.0742 - true_loss: 1.0294 - val_loss: 5140.5396 - val_reconstruction_loss: 1895.3438 - val_kl_loss: 99.9863 - val_false_loss: 10.1204 - val_true_loss: 1.0909\n",
      "Epoch 1507/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.1877 - reconstruction_loss: 1890.5844 - kl_loss: 103.3422 - false_loss: 0.0742 - true_loss: 1.0293 - val_loss: 5140.2729 - val_reconstruction_loss: 1895.3431 - val_kl_loss: 99.9868 - val_false_loss: 10.1195 - val_true_loss: 1.0909\n",
      "Epoch 1508/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.9814 - reconstruction_loss: 1890.7617 - kl_loss: 104.9186 - false_loss: 0.0742 - true_loss: 1.0293 - val_loss: 5140.0049 - val_reconstruction_loss: 1895.3429 - val_kl_loss: 99.9874 - val_false_loss: 10.1186 - val_true_loss: 1.0908\n",
      "Epoch 1509/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2200.2565 - reconstruction_loss: 1891.1232 - kl_loss: 105.1644 - false_loss: 0.0742 - true_loss: 1.0293 - val_loss: 5139.7383 - val_reconstruction_loss: 1895.3423 - val_kl_loss: 99.9882 - val_false_loss: 10.1177 - val_true_loss: 1.0908\n",
      "Epoch 1510/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.3896 - reconstruction_loss: 1890.9025 - kl_loss: 104.1228 - false_loss: 0.0742 - true_loss: 1.0292 - val_loss: 5139.4751 - val_reconstruction_loss: 1895.3417 - val_kl_loss: 99.9885 - val_false_loss: 10.1169 - val_true_loss: 1.0907\n",
      "Epoch 1511/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2200.3846 - reconstruction_loss: 1890.7809 - kl_loss: 100.4696 - false_loss: 0.0742 - true_loss: 1.0292 - val_loss: 5139.2280 - val_reconstruction_loss: 1895.3416 - val_kl_loss: 99.9874 - val_false_loss: 10.1161 - val_true_loss: 1.0907\n",
      "Epoch 1512/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2274.8986 - reconstruction_loss: 1893.2432 - kl_loss: 85.3642 - false_loss: 0.0741 - true_loss: 1.0292 - val_loss: 5138.9702 - val_reconstruction_loss: 1895.3411 - val_kl_loss: 99.9877 - val_false_loss: 10.1152 - val_true_loss: 1.0907\n",
      "Epoch 1513/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2224.2883 - reconstruction_loss: 1892.3402 - kl_loss: 101.9603 - false_loss: 0.0741 - true_loss: 1.0292 - val_loss: 5138.7178 - val_reconstruction_loss: 1895.3405 - val_kl_loss: 99.9878 - val_false_loss: 10.1144 - val_true_loss: 1.0907\n",
      "Epoch 1514/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.8790 - reconstruction_loss: 1891.0438 - kl_loss: 103.8180 - false_loss: 0.0741 - true_loss: 1.0291 - val_loss: 5138.4595 - val_reconstruction_loss: 1895.3400 - val_kl_loss: 99.9887 - val_false_loss: 10.1135 - val_true_loss: 1.0906\n",
      "Epoch 1515/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.1992 - reconstruction_loss: 1890.5068 - kl_loss: 106.1486 - false_loss: 0.0741 - true_loss: 1.0291 - val_loss: 5138.2012 - val_reconstruction_loss: 1895.3394 - val_kl_loss: 99.9895 - val_false_loss: 10.1127 - val_true_loss: 1.0906\n",
      "Epoch 1516/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.0039 - reconstruction_loss: 1890.5487 - kl_loss: 106.9113 - false_loss: 0.0741 - true_loss: 1.0291 - val_loss: 5137.9360 - val_reconstruction_loss: 1895.3389 - val_kl_loss: 99.9904 - val_false_loss: 10.1118 - val_true_loss: 1.0905\n",
      "Epoch 1517/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.3117 - reconstruction_loss: 1890.5050 - kl_loss: 106.9742 - false_loss: 0.0741 - true_loss: 1.0290 - val_loss: 5137.6704 - val_reconstruction_loss: 1895.3383 - val_kl_loss: 99.9912 - val_false_loss: 10.1109 - val_true_loss: 1.0905\n",
      "Epoch 1518/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.3085 - reconstruction_loss: 1890.4095 - kl_loss: 104.8028 - false_loss: 0.0741 - true_loss: 1.0290 - val_loss: 5137.4019 - val_reconstruction_loss: 1895.3376 - val_kl_loss: 99.9918 - val_false_loss: 10.1101 - val_true_loss: 1.0905\n",
      "Epoch 1519/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.9012 - reconstruction_loss: 1891.0709 - kl_loss: 105.8214 - false_loss: 0.0741 - true_loss: 1.0289 - val_loss: 5137.1294 - val_reconstruction_loss: 1895.3374 - val_kl_loss: 99.9923 - val_false_loss: 10.1092 - val_true_loss: 1.0904\n",
      "Epoch 1520/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.1957 - reconstruction_loss: 1890.5947 - kl_loss: 104.9570 - false_loss: 0.0741 - true_loss: 1.0289 - val_loss: 5136.8608 - val_reconstruction_loss: 1895.3368 - val_kl_loss: 99.9927 - val_false_loss: 10.1083 - val_true_loss: 1.0904\n",
      "Epoch 1521/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.0490 - reconstruction_loss: 1891.2357 - kl_loss: 103.7646 - false_loss: 0.0741 - true_loss: 1.0289 - val_loss: 5136.6030 - val_reconstruction_loss: 1895.3363 - val_kl_loss: 99.9935 - val_false_loss: 10.1074 - val_true_loss: 1.0903\n",
      "Epoch 1522/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.0141 - reconstruction_loss: 1890.7783 - kl_loss: 104.9327 - false_loss: 0.0741 - true_loss: 1.0288 - val_loss: 5136.3423 - val_reconstruction_loss: 1895.3357 - val_kl_loss: 99.9941 - val_false_loss: 10.1066 - val_true_loss: 1.0903\n",
      "Epoch 1523/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.3222 - reconstruction_loss: 1890.5807 - kl_loss: 106.3408 - false_loss: 0.0741 - true_loss: 1.0288 - val_loss: 5136.0718 - val_reconstruction_loss: 1895.3353 - val_kl_loss: 99.9942 - val_false_loss: 10.1057 - val_true_loss: 1.0903\n",
      "Epoch 1524/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.1811 - reconstruction_loss: 1890.6625 - kl_loss: 100.9997 - false_loss: 0.0741 - true_loss: 1.0288 - val_loss: 5135.8018 - val_reconstruction_loss: 1895.3348 - val_kl_loss: 99.9950 - val_false_loss: 10.1048 - val_true_loss: 1.0902\n",
      "Epoch 1525/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.4364 - reconstruction_loss: 1890.2711 - kl_loss: 107.1346 - false_loss: 0.0741 - true_loss: 1.0287 - val_loss: 5135.5308 - val_reconstruction_loss: 1895.3342 - val_kl_loss: 99.9959 - val_false_loss: 10.1039 - val_true_loss: 1.0902\n",
      "Epoch 1526/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.4277 - reconstruction_loss: 1891.0321 - kl_loss: 108.1463 - false_loss: 0.0741 - true_loss: 1.0287 - val_loss: 5135.2837 - val_reconstruction_loss: 1895.3337 - val_kl_loss: 99.9966 - val_false_loss: 10.1031 - val_true_loss: 1.0901\n",
      "Epoch 1527/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.4463 - reconstruction_loss: 1890.9772 - kl_loss: 102.4691 - false_loss: 0.0741 - true_loss: 1.0286 - val_loss: 5135.0420 - val_reconstruction_loss: 1895.3331 - val_kl_loss: 99.9974 - val_false_loss: 10.1023 - val_true_loss: 1.0901\n",
      "Epoch 1528/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2192.6829 - reconstruction_loss: 1890.7432 - kl_loss: 108.5866 - false_loss: 0.0741 - true_loss: 1.0286 - val_loss: 5134.7729 - val_reconstruction_loss: 1895.3328 - val_kl_loss: 99.9981 - val_false_loss: 10.1014 - val_true_loss: 1.0900\n",
      "Epoch 1529/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2191.1471 - reconstruction_loss: 1890.7939 - kl_loss: 107.4361 - false_loss: 0.0741 - true_loss: 1.0286 - val_loss: 5134.5039 - val_reconstruction_loss: 1895.3324 - val_kl_loss: 99.9992 - val_false_loss: 10.1005 - val_true_loss: 1.0900\n",
      "Epoch 1530/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2192.2531 - reconstruction_loss: 1891.4077 - kl_loss: 107.1679 - false_loss: 0.0741 - true_loss: 1.0285 - val_loss: 5134.2334 - val_reconstruction_loss: 1895.3317 - val_kl_loss: 99.9999 - val_false_loss: 10.0997 - val_true_loss: 1.0900\n",
      "Epoch 1531/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.6541 - reconstruction_loss: 1890.5045 - kl_loss: 107.9950 - false_loss: 0.0740 - true_loss: 1.0285 - val_loss: 5133.9697 - val_reconstruction_loss: 1895.3312 - val_kl_loss: 100.0007 - val_false_loss: 10.0988 - val_true_loss: 1.0899\n",
      "Epoch 1532/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.5807 - reconstruction_loss: 1890.1530 - kl_loss: 105.6836 - false_loss: 0.0740 - true_loss: 1.0284 - val_loss: 5133.7168 - val_reconstruction_loss: 1895.3306 - val_kl_loss: 100.0012 - val_false_loss: 10.0980 - val_true_loss: 1.0899\n",
      "Epoch 1533/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.0140 - reconstruction_loss: 1890.3276 - kl_loss: 101.3800 - false_loss: 0.0740 - true_loss: 1.0284 - val_loss: 5133.4536 - val_reconstruction_loss: 1895.3302 - val_kl_loss: 100.0012 - val_false_loss: 10.0971 - val_true_loss: 1.0898\n",
      "Epoch 1534/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.5474 - reconstruction_loss: 1890.3932 - kl_loss: 103.8921 - false_loss: 0.0740 - true_loss: 1.0284 - val_loss: 5133.1860 - val_reconstruction_loss: 1895.3297 - val_kl_loss: 100.0015 - val_false_loss: 10.0962 - val_true_loss: 1.0898\n",
      "Epoch 1535/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2214.4298 - reconstruction_loss: 1891.0118 - kl_loss: 94.9911 - false_loss: 0.0740 - true_loss: 1.0283 - val_loss: 5132.9199 - val_reconstruction_loss: 1895.3291 - val_kl_loss: 100.0019 - val_false_loss: 10.0953 - val_true_loss: 1.0897\n",
      "Epoch 1536/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.4352 - reconstruction_loss: 1890.8507 - kl_loss: 107.3541 - false_loss: 0.0740 - true_loss: 1.0283 - val_loss: 5132.6470 - val_reconstruction_loss: 1895.3286 - val_kl_loss: 100.0028 - val_false_loss: 10.0944 - val_true_loss: 1.0897\n",
      "Epoch 1537/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.1058 - reconstruction_loss: 1890.7567 - kl_loss: 108.0198 - false_loss: 0.0740 - true_loss: 1.0283 - val_loss: 5132.3750 - val_reconstruction_loss: 1895.3280 - val_kl_loss: 100.0037 - val_false_loss: 10.0936 - val_true_loss: 1.0897\n",
      "Epoch 1538/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.2732 - reconstruction_loss: 1890.5236 - kl_loss: 107.4373 - false_loss: 0.0740 - true_loss: 1.0282 - val_loss: 5132.1050 - val_reconstruction_loss: 1895.3275 - val_kl_loss: 100.0045 - val_false_loss: 10.0927 - val_true_loss: 1.0896\n",
      "Epoch 1539/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.9039 - reconstruction_loss: 1890.4186 - kl_loss: 106.9040 - false_loss: 0.0740 - true_loss: 1.0282 - val_loss: 5131.8394 - val_reconstruction_loss: 1895.3269 - val_kl_loss: 100.0051 - val_false_loss: 10.0918 - val_true_loss: 1.0896\n",
      "Epoch 1540/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.8472 - reconstruction_loss: 1890.3511 - kl_loss: 105.1930 - false_loss: 0.0740 - true_loss: 1.0282 - val_loss: 5131.5879 - val_reconstruction_loss: 1895.3265 - val_kl_loss: 100.0057 - val_false_loss: 10.0910 - val_true_loss: 1.0895\n",
      "Epoch 1541/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.3756 - reconstruction_loss: 1890.5449 - kl_loss: 105.8965 - false_loss: 0.0740 - true_loss: 1.0281 - val_loss: 5131.3320 - val_reconstruction_loss: 1895.3260 - val_kl_loss: 100.0064 - val_false_loss: 10.0901 - val_true_loss: 1.0895\n",
      "Epoch 1542/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.9584 - reconstruction_loss: 1890.3480 - kl_loss: 106.3170 - false_loss: 0.0740 - true_loss: 1.0281 - val_loss: 5131.0649 - val_reconstruction_loss: 1895.3254 - val_kl_loss: 100.0070 - val_false_loss: 10.0893 - val_true_loss: 1.0895\n",
      "Epoch 1543/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2195.9133 - reconstruction_loss: 1890.3422 - kl_loss: 102.7472 - false_loss: 0.0740 - true_loss: 1.0280 - val_loss: 5130.7935 - val_reconstruction_loss: 1895.3250 - val_kl_loss: 100.0079 - val_false_loss: 10.0884 - val_true_loss: 1.0894\n",
      "Epoch 1544/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2195.8706 - reconstruction_loss: 1891.5826 - kl_loss: 107.6869 - false_loss: 0.0740 - true_loss: 1.0280 - val_loss: 5130.5215 - val_reconstruction_loss: 1895.3246 - val_kl_loss: 100.0085 - val_false_loss: 10.0875 - val_true_loss: 1.0894\n",
      "Epoch 1545/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.5958 - reconstruction_loss: 1891.9205 - kl_loss: 104.3801 - false_loss: 0.0740 - true_loss: 1.0280 - val_loss: 5130.2461 - val_reconstruction_loss: 1895.3242 - val_kl_loss: 100.0089 - val_false_loss: 10.0866 - val_true_loss: 1.0893\n",
      "Epoch 1546/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.7373 - reconstruction_loss: 1891.5377 - kl_loss: 101.8505 - false_loss: 0.0740 - true_loss: 1.0279 - val_loss: 5129.9746 - val_reconstruction_loss: 1895.3236 - val_kl_loss: 100.0083 - val_false_loss: 10.0857 - val_true_loss: 1.0893\n",
      "Epoch 1547/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2204.2968 - reconstruction_loss: 1891.3236 - kl_loss: 100.5520 - false_loss: 0.0740 - true_loss: 1.0279 - val_loss: 5129.7119 - val_reconstruction_loss: 1895.3234 - val_kl_loss: 100.0091 - val_false_loss: 10.0848 - val_true_loss: 1.0893\n",
      "Epoch 1548/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2195.4880 - reconstruction_loss: 1891.0326 - kl_loss: 106.5597 - false_loss: 0.0740 - true_loss: 1.0279 - val_loss: 5129.4409 - val_reconstruction_loss: 1895.3228 - val_kl_loss: 100.0098 - val_false_loss: 10.0839 - val_true_loss: 1.0892\n",
      "Epoch 1549/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.3577 - reconstruction_loss: 1890.6798 - kl_loss: 107.4027 - false_loss: 0.0739 - true_loss: 1.0278 - val_loss: 5129.1860 - val_reconstruction_loss: 1895.3223 - val_kl_loss: 100.0106 - val_false_loss: 10.0831 - val_true_loss: 1.0892\n",
      "Epoch 1550/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.0352 - reconstruction_loss: 1890.6710 - kl_loss: 105.7617 - false_loss: 0.0739 - true_loss: 1.0278 - val_loss: 5128.9287 - val_reconstruction_loss: 1895.3217 - val_kl_loss: 100.0111 - val_false_loss: 10.0822 - val_true_loss: 1.0891\n",
      "Epoch 1551/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2194.4679 - reconstruction_loss: 1890.6212 - kl_loss: 105.3970 - false_loss: 0.0739 - true_loss: 1.0277 - val_loss: 5128.6616 - val_reconstruction_loss: 1895.3212 - val_kl_loss: 100.0119 - val_false_loss: 10.0814 - val_true_loss: 1.0891\n",
      "Epoch 1552/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.6029 - reconstruction_loss: 1890.5175 - kl_loss: 104.4280 - false_loss: 0.0739 - true_loss: 1.0277 - val_loss: 5128.3906 - val_reconstruction_loss: 1895.3208 - val_kl_loss: 100.0117 - val_false_loss: 10.0805 - val_true_loss: 1.0891\n",
      "Epoch 1553/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2195.4732 - reconstruction_loss: 1890.2809 - kl_loss: 102.5086 - false_loss: 0.0739 - true_loss: 1.0277 - val_loss: 5128.1196 - val_reconstruction_loss: 1895.3199 - val_kl_loss: 100.0125 - val_false_loss: 10.0796 - val_true_loss: 1.0890\n",
      "Epoch 1554/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2191.4289 - reconstruction_loss: 1890.5845 - kl_loss: 106.7783 - false_loss: 0.0739 - true_loss: 1.0276 - val_loss: 5127.8501 - val_reconstruction_loss: 1895.3195 - val_kl_loss: 100.0135 - val_false_loss: 10.0787 - val_true_loss: 1.0890\n",
      "Epoch 1555/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.5774 - reconstruction_loss: 1890.4413 - kl_loss: 107.7413 - false_loss: 0.0739 - true_loss: 1.0276 - val_loss: 5127.5796 - val_reconstruction_loss: 1895.3188 - val_kl_loss: 100.0142 - val_false_loss: 10.0778 - val_true_loss: 1.0889\n",
      "Epoch 1556/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2190.1492 - reconstruction_loss: 1890.6045 - kl_loss: 106.4425 - false_loss: 0.0739 - true_loss: 1.0275 - val_loss: 5127.3057 - val_reconstruction_loss: 1895.3186 - val_kl_loss: 100.0148 - val_false_loss: 10.0769 - val_true_loss: 1.0889\n",
      "Epoch 1557/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2191.2476 - reconstruction_loss: 1890.3234 - kl_loss: 106.4205 - false_loss: 0.0739 - true_loss: 1.0275 - val_loss: 5127.0337 - val_reconstruction_loss: 1895.3177 - val_kl_loss: 100.0156 - val_false_loss: 10.0760 - val_true_loss: 1.0888\n",
      "Epoch 1558/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.3832 - reconstruction_loss: 1890.3164 - kl_loss: 105.5104 - false_loss: 0.0739 - true_loss: 1.0275 - val_loss: 5126.7617 - val_reconstruction_loss: 1895.3173 - val_kl_loss: 100.0162 - val_false_loss: 10.0751 - val_true_loss: 1.0888\n",
      "Epoch 1559/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.2039 - reconstruction_loss: 1890.5548 - kl_loss: 104.4012 - false_loss: 0.0739 - true_loss: 1.0274 - val_loss: 5126.4893 - val_reconstruction_loss: 1895.3167 - val_kl_loss: 100.0168 - val_false_loss: 10.0742 - val_true_loss: 1.0887\n",
      "Epoch 1560/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.7017 - reconstruction_loss: 1890.5983 - kl_loss: 103.7907 - false_loss: 0.0739 - true_loss: 1.0274 - val_loss: 5126.2197 - val_reconstruction_loss: 1895.3164 - val_kl_loss: 100.0166 - val_false_loss: 10.0733 - val_true_loss: 1.0887\n",
      "Epoch 1561/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2203.7121 - reconstruction_loss: 1890.4801 - kl_loss: 97.5072 - false_loss: 0.0739 - true_loss: 1.0274 - val_loss: 5125.9478 - val_reconstruction_loss: 1895.3158 - val_kl_loss: 100.0170 - val_false_loss: 10.0725 - val_true_loss: 1.0887\n",
      "Epoch 1562/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.0693 - reconstruction_loss: 1890.5013 - kl_loss: 103.6174 - false_loss: 0.0739 - true_loss: 1.0273 - val_loss: 5125.6758 - val_reconstruction_loss: 1895.3153 - val_kl_loss: 100.0174 - val_false_loss: 10.0716 - val_true_loss: 1.0886\n",
      "Epoch 1563/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2196.0570 - reconstruction_loss: 1890.4741 - kl_loss: 106.8215 - false_loss: 0.0739 - true_loss: 1.0273 - val_loss: 5125.4072 - val_reconstruction_loss: 1895.3149 - val_kl_loss: 100.0183 - val_false_loss: 10.0707 - val_true_loss: 1.0886\n",
      "Epoch 1564/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.7822 - reconstruction_loss: 1891.0924 - kl_loss: 100.7097 - false_loss: 0.0739 - true_loss: 1.0272 - val_loss: 5125.1377 - val_reconstruction_loss: 1895.3143 - val_kl_loss: 100.0166 - val_false_loss: 10.0698 - val_true_loss: 1.0886\n",
      "Epoch 1565/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2220.7278 - reconstruction_loss: 1891.9269 - kl_loss: 97.3115 - false_loss: 0.0739 - true_loss: 1.0272 - val_loss: 5124.8677 - val_reconstruction_loss: 1895.3140 - val_kl_loss: 100.0174 - val_false_loss: 10.0689 - val_true_loss: 1.0885\n",
      "Epoch 1566/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2208.6057 - reconstruction_loss: 1890.9990 - kl_loss: 100.9049 - false_loss: 0.0739 - true_loss: 1.0272 - val_loss: 5124.5972 - val_reconstruction_loss: 1895.3137 - val_kl_loss: 100.0180 - val_false_loss: 10.0680 - val_true_loss: 1.0885\n",
      "Epoch 1567/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2201.4708 - reconstruction_loss: 1890.6754 - kl_loss: 109.7377 - false_loss: 0.0738 - true_loss: 1.0271 - val_loss: 5124.3281 - val_reconstruction_loss: 1895.3131 - val_kl_loss: 100.0187 - val_false_loss: 10.0671 - val_true_loss: 1.0884\n",
      "Epoch 1568/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2195.5226 - reconstruction_loss: 1890.3877 - kl_loss: 107.1975 - false_loss: 0.0738 - true_loss: 1.0271 - val_loss: 5124.0571 - val_reconstruction_loss: 1895.3126 - val_kl_loss: 100.0197 - val_false_loss: 10.0662 - val_true_loss: 1.0884\n",
      "Epoch 1569/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2191.8259 - reconstruction_loss: 1890.2020 - kl_loss: 109.7868 - false_loss: 0.0738 - true_loss: 1.0271 - val_loss: 5123.7856 - val_reconstruction_loss: 1895.3123 - val_kl_loss: 100.0206 - val_false_loss: 10.0654 - val_true_loss: 1.0884\n",
      "Epoch 1570/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2190.5005 - reconstruction_loss: 1890.2487 - kl_loss: 108.3230 - false_loss: 0.0738 - true_loss: 1.0270 - val_loss: 5123.5137 - val_reconstruction_loss: 1895.3116 - val_kl_loss: 100.0214 - val_false_loss: 10.0645 - val_true_loss: 1.0883\n",
      "Epoch 1571/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2189.0268 - reconstruction_loss: 1890.5861 - kl_loss: 107.6916 - false_loss: 0.0738 - true_loss: 1.0270 - val_loss: 5123.2388 - val_reconstruction_loss: 1895.3114 - val_kl_loss: 100.0222 - val_false_loss: 10.0636 - val_true_loss: 1.0883\n",
      "Epoch 1572/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2189.7931 - reconstruction_loss: 1890.8099 - kl_loss: 106.8473 - false_loss: 0.0738 - true_loss: 1.0269 - val_loss: 5122.9663 - val_reconstruction_loss: 1895.3110 - val_kl_loss: 100.0228 - val_false_loss: 10.0627 - val_true_loss: 1.0882\n",
      "Epoch 1573/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2188.0991 - reconstruction_loss: 1890.1703 - kl_loss: 106.5620 - false_loss: 0.0738 - true_loss: 1.0269 - val_loss: 5122.6914 - val_reconstruction_loss: 1895.3103 - val_kl_loss: 100.0237 - val_false_loss: 10.0618 - val_true_loss: 1.0882\n",
      "Epoch 1574/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2190.5402 - reconstruction_loss: 1890.1613 - kl_loss: 106.1492 - false_loss: 0.0738 - true_loss: 1.0269 - val_loss: 5122.4180 - val_reconstruction_loss: 1895.3097 - val_kl_loss: 100.0245 - val_false_loss: 10.0609 - val_true_loss: 1.0881\n",
      "Epoch 1575/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2184.0678 - reconstruction_loss: 1890.3452 - kl_loss: 108.2000 - false_loss: 0.0738 - true_loss: 1.0268 - val_loss: 5122.1450 - val_reconstruction_loss: 1895.3092 - val_kl_loss: 100.0254 - val_false_loss: 10.0600 - val_true_loss: 1.0881\n",
      "Epoch 1576/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2187.2125 - reconstruction_loss: 1890.4756 - kl_loss: 105.6913 - false_loss: 0.0738 - true_loss: 1.0268 - val_loss: 5121.8721 - val_reconstruction_loss: 1895.3088 - val_kl_loss: 100.0259 - val_false_loss: 10.0591 - val_true_loss: 1.0881\n",
      "Epoch 1577/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.0251 - reconstruction_loss: 1891.1039 - kl_loss: 97.6705 - false_loss: 0.0738 - true_loss: 1.0267 - val_loss: 5121.6016 - val_reconstruction_loss: 1895.3085 - val_kl_loss: 100.0258 - val_false_loss: 10.0582 - val_true_loss: 1.0880\n",
      "Epoch 1578/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2195.3861 - reconstruction_loss: 1891.2524 - kl_loss: 105.1152 - false_loss: 0.0738 - true_loss: 1.0267 - val_loss: 5121.3311 - val_reconstruction_loss: 1895.3079 - val_kl_loss: 100.0264 - val_false_loss: 10.0573 - val_true_loss: 1.0880\n",
      "Epoch 1579/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2191.8098 - reconstruction_loss: 1890.6388 - kl_loss: 106.6553 - false_loss: 0.0738 - true_loss: 1.0267 - val_loss: 5121.0625 - val_reconstruction_loss: 1895.3074 - val_kl_loss: 100.0275 - val_false_loss: 10.0564 - val_true_loss: 1.0879\n",
      "Epoch 1580/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2187.3806 - reconstruction_loss: 1890.3785 - kl_loss: 110.7185 - false_loss: 0.0738 - true_loss: 1.0266 - val_loss: 5120.7925 - val_reconstruction_loss: 1895.3068 - val_kl_loss: 100.0285 - val_false_loss: 10.0555 - val_true_loss: 1.0879\n",
      "Epoch 1581/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2185.9183 - reconstruction_loss: 1890.2865 - kl_loss: 108.5574 - false_loss: 0.0738 - true_loss: 1.0266 - val_loss: 5120.5205 - val_reconstruction_loss: 1895.3065 - val_kl_loss: 100.0296 - val_false_loss: 10.0546 - val_true_loss: 1.0878\n",
      "Epoch 1582/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2184.0610 - reconstruction_loss: 1890.1544 - kl_loss: 108.7280 - false_loss: 0.0738 - true_loss: 1.0265 - val_loss: 5120.2500 - val_reconstruction_loss: 1895.3059 - val_kl_loss: 100.0303 - val_false_loss: 10.0537 - val_true_loss: 1.0878\n",
      "Epoch 1583/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2185.5106 - reconstruction_loss: 1890.0846 - kl_loss: 106.6718 - false_loss: 0.0738 - true_loss: 1.0265 - val_loss: 5119.9819 - val_reconstruction_loss: 1895.3052 - val_kl_loss: 100.0312 - val_false_loss: 10.0529 - val_true_loss: 1.0877\n",
      "Epoch 1584/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2184.9945 - reconstruction_loss: 1890.3467 - kl_loss: 106.1817 - false_loss: 0.0737 - true_loss: 1.0265 - val_loss: 5119.7119 - val_reconstruction_loss: 1895.3048 - val_kl_loss: 100.0316 - val_false_loss: 10.0520 - val_true_loss: 1.0877\n",
      "Epoch 1585/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2184.5020 - reconstruction_loss: 1890.3632 - kl_loss: 107.0555 - false_loss: 0.0737 - true_loss: 1.0264 - val_loss: 5119.4409 - val_reconstruction_loss: 1895.3043 - val_kl_loss: 100.0322 - val_false_loss: 10.0511 - val_true_loss: 1.0877\n",
      "Epoch 1586/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2188.7792 - reconstruction_loss: 1890.2462 - kl_loss: 103.7320 - false_loss: 0.0737 - true_loss: 1.0264 - val_loss: 5119.1685 - val_reconstruction_loss: 1895.3037 - val_kl_loss: 100.0328 - val_false_loss: 10.0502 - val_true_loss: 1.0876\n",
      "Epoch 1587/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2186.8282 - reconstruction_loss: 1890.4147 - kl_loss: 107.2546 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5118.8960 - val_reconstruction_loss: 1895.3032 - val_kl_loss: 100.0337 - val_false_loss: 10.0493 - val_true_loss: 1.0876\n",
      "Epoch 1588/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2186.4972 - reconstruction_loss: 1890.0249 - kl_loss: 109.4842 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5118.6240 - val_reconstruction_loss: 1895.3026 - val_kl_loss: 100.0350 - val_false_loss: 10.0484 - val_true_loss: 1.0875\n",
      "Epoch 1589/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2187.4557 - reconstruction_loss: 1890.0698 - kl_loss: 107.1046 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5118.3745 - val_reconstruction_loss: 1895.3022 - val_kl_loss: 100.0334 - val_false_loss: 10.0475 - val_true_loss: 1.0877\n",
      "Epoch 1590/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2586.0071 - reconstruction_loss: 1904.4933 - kl_loss: 68.7546 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5118.3193 - val_reconstruction_loss: 1895.3032 - val_kl_loss: 100.0317 - val_false_loss: 10.0473 - val_true_loss: 1.0878\n",
      "Epoch 1591/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2340.0873 - reconstruction_loss: 1905.1244 - kl_loss: 85.0074 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5118.2144 - val_reconstruction_loss: 1895.3037 - val_kl_loss: 100.0303 - val_false_loss: 10.0470 - val_true_loss: 1.0877\n",
      "Epoch 1592/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2265.8147 - reconstruction_loss: 1903.3512 - kl_loss: 92.5075 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5118.0513 - val_reconstruction_loss: 1895.3040 - val_kl_loss: 100.0303 - val_false_loss: 10.0464 - val_true_loss: 1.0877\n",
      "Epoch 1593/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2238.0100 - reconstruction_loss: 1903.0420 - kl_loss: 102.0136 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5117.8618 - val_reconstruction_loss: 1895.3044 - val_kl_loss: 100.0309 - val_false_loss: 10.0458 - val_true_loss: 1.0877\n",
      "Epoch 1594/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2222.4696 - reconstruction_loss: 1902.4648 - kl_loss: 106.9480 - false_loss: 0.0737 - true_loss: 1.0263 - val_loss: 5117.6533 - val_reconstruction_loss: 1895.3047 - val_kl_loss: 100.0318 - val_false_loss: 10.0451 - val_true_loss: 1.0876\n",
      "Epoch 1595/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2218.7950 - reconstruction_loss: 1901.9814 - kl_loss: 106.9634 - false_loss: 0.0737 - true_loss: 1.0262 - val_loss: 5117.4414 - val_reconstruction_loss: 1895.3048 - val_kl_loss: 100.0326 - val_false_loss: 10.0444 - val_true_loss: 1.0876\n",
      "Epoch 1596/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2234.1222 - reconstruction_loss: 1901.4805 - kl_loss: 105.7121 - false_loss: 0.0737 - true_loss: 1.0262 - val_loss: 5117.2256 - val_reconstruction_loss: 1895.3048 - val_kl_loss: 100.0333 - val_false_loss: 10.0437 - val_true_loss: 1.0876\n",
      "Epoch 1597/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.0900 - reconstruction_loss: 1901.4482 - kl_loss: 104.1764 - false_loss: 0.0737 - true_loss: 1.0262 - val_loss: 5117.0063 - val_reconstruction_loss: 1895.3052 - val_kl_loss: 100.0338 - val_false_loss: 10.0430 - val_true_loss: 1.0875\n",
      "Epoch 1598/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2226.6368 - reconstruction_loss: 1901.2993 - kl_loss: 103.9200 - false_loss: 0.0737 - true_loss: 1.0261 - val_loss: 5116.7861 - val_reconstruction_loss: 1895.3054 - val_kl_loss: 100.0344 - val_false_loss: 10.0423 - val_true_loss: 1.0875\n",
      "Epoch 1599/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2221.4310 - reconstruction_loss: 1901.0581 - kl_loss: 105.3479 - false_loss: 0.0737 - true_loss: 1.0261 - val_loss: 5116.5625 - val_reconstruction_loss: 1895.3055 - val_kl_loss: 100.0349 - val_false_loss: 10.0415 - val_true_loss: 1.0875\n",
      "Epoch 1600/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2217.9964 - reconstruction_loss: 1901.0303 - kl_loss: 103.5433 - false_loss: 0.0737 - true_loss: 1.0261 - val_loss: 5116.3369 - val_reconstruction_loss: 1895.3055 - val_kl_loss: 100.0355 - val_false_loss: 10.0408 - val_true_loss: 1.0874\n",
      "Epoch 1601/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2217.7374 - reconstruction_loss: 1900.9800 - kl_loss: 105.0592 - false_loss: 0.0737 - true_loss: 1.0260 - val_loss: 5116.1089 - val_reconstruction_loss: 1895.3058 - val_kl_loss: 100.0359 - val_false_loss: 10.0401 - val_true_loss: 1.0874\n",
      "Epoch 1602/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2215.5701 - reconstruction_loss: 1901.0013 - kl_loss: 103.7571 - false_loss: 0.0737 - true_loss: 1.0260 - val_loss: 5115.8740 - val_reconstruction_loss: 1895.3062 - val_kl_loss: 100.0364 - val_false_loss: 10.0393 - val_true_loss: 1.0874\n",
      "Epoch 1603/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2210.7541 - reconstruction_loss: 1900.8314 - kl_loss: 104.1680 - false_loss: 0.0737 - true_loss: 1.0260 - val_loss: 5115.6328 - val_reconstruction_loss: 1895.3060 - val_kl_loss: 100.0369 - val_false_loss: 10.0385 - val_true_loss: 1.0873\n",
      "Epoch 1604/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.7543 - reconstruction_loss: 1901.0690 - kl_loss: 105.1487 - false_loss: 0.0737 - true_loss: 1.0259 - val_loss: 5115.3896 - val_reconstruction_loss: 1895.3063 - val_kl_loss: 100.0374 - val_false_loss: 10.0377 - val_true_loss: 1.0873\n",
      "Epoch 1605/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2208.8120 - reconstruction_loss: 1900.6835 - kl_loss: 104.2845 - false_loss: 0.0737 - true_loss: 1.0259 - val_loss: 5115.1504 - val_reconstruction_loss: 1895.3064 - val_kl_loss: 100.0378 - val_false_loss: 10.0369 - val_true_loss: 1.0872\n",
      "Epoch 1606/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2207.9361 - reconstruction_loss: 1900.4956 - kl_loss: 105.2683 - false_loss: 0.0736 - true_loss: 1.0259 - val_loss: 5114.9102 - val_reconstruction_loss: 1895.3064 - val_kl_loss: 100.0384 - val_false_loss: 10.0361 - val_true_loss: 1.0872\n",
      "Epoch 1607/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.7912 - reconstruction_loss: 1902.4354 - kl_loss: 105.0082 - false_loss: 0.0736 - true_loss: 1.0258 - val_loss: 5114.6670 - val_reconstruction_loss: 1895.3069 - val_kl_loss: 100.0391 - val_false_loss: 10.0353 - val_true_loss: 1.0871\n",
      "Epoch 1608/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2205.0023 - reconstruction_loss: 1901.5664 - kl_loss: 105.6901 - false_loss: 0.0736 - true_loss: 1.0258 - val_loss: 5114.4248 - val_reconstruction_loss: 1895.3070 - val_kl_loss: 100.0397 - val_false_loss: 10.0345 - val_true_loss: 1.0871\n",
      "Epoch 1609/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.8555 - reconstruction_loss: 1900.7793 - kl_loss: 104.7556 - false_loss: 0.0736 - true_loss: 1.0257 - val_loss: 5114.1826 - val_reconstruction_loss: 1895.3070 - val_kl_loss: 100.0401 - val_false_loss: 10.0337 - val_true_loss: 1.0871\n",
      "Epoch 1610/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.3421 - reconstruction_loss: 1900.5322 - kl_loss: 104.6507 - false_loss: 0.0736 - true_loss: 1.0257 - val_loss: 5113.9409 - val_reconstruction_loss: 1895.3071 - val_kl_loss: 100.0407 - val_false_loss: 10.0329 - val_true_loss: 1.0870\n",
      "Epoch 1611/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2204.7910 - reconstruction_loss: 1900.3940 - kl_loss: 103.9795 - false_loss: 0.0736 - true_loss: 1.0257 - val_loss: 5113.6997 - val_reconstruction_loss: 1895.3074 - val_kl_loss: 100.0411 - val_false_loss: 10.0321 - val_true_loss: 1.0870\n",
      "Epoch 1612/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.7111 - reconstruction_loss: 1900.3467 - kl_loss: 106.4208 - false_loss: 0.0736 - true_loss: 1.0256 - val_loss: 5113.4619 - val_reconstruction_loss: 1895.3075 - val_kl_loss: 100.0420 - val_false_loss: 10.0314 - val_true_loss: 1.0869\n",
      "Epoch 1613/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2203.1296 - reconstruction_loss: 1900.4688 - kl_loss: 106.3537 - false_loss: 0.0736 - true_loss: 1.0256 - val_loss: 5113.2148 - val_reconstruction_loss: 1895.3075 - val_kl_loss: 100.0426 - val_false_loss: 10.0305 - val_true_loss: 1.0869\n",
      "Epoch 1614/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.4663 - reconstruction_loss: 1901.1471 - kl_loss: 105.8599 - false_loss: 0.0736 - true_loss: 1.0256 - val_loss: 5112.9712 - val_reconstruction_loss: 1895.3079 - val_kl_loss: 100.0433 - val_false_loss: 10.0297 - val_true_loss: 1.0869\n",
      "Epoch 1615/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.8733 - reconstruction_loss: 1900.8270 - kl_loss: 105.6742 - false_loss: 0.0736 - true_loss: 1.0255 - val_loss: 5112.7295 - val_reconstruction_loss: 1895.3079 - val_kl_loss: 100.0441 - val_false_loss: 10.0289 - val_true_loss: 1.0868\n",
      "Epoch 1616/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.0855 - reconstruction_loss: 1900.3568 - kl_loss: 106.4794 - false_loss: 0.0736 - true_loss: 1.0255 - val_loss: 5112.4873 - val_reconstruction_loss: 1895.3080 - val_kl_loss: 100.0448 - val_false_loss: 10.0281 - val_true_loss: 1.0868\n",
      "Epoch 1617/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.2498 - reconstruction_loss: 1900.2816 - kl_loss: 105.6865 - false_loss: 0.0736 - true_loss: 1.0254 - val_loss: 5112.2427 - val_reconstruction_loss: 1895.3080 - val_kl_loss: 100.0454 - val_false_loss: 10.0273 - val_true_loss: 1.0867\n",
      "Epoch 1618/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2201.0637 - reconstruction_loss: 1900.5283 - kl_loss: 105.6935 - false_loss: 0.0736 - true_loss: 1.0254 - val_loss: 5111.9946 - val_reconstruction_loss: 1895.3083 - val_kl_loss: 100.0461 - val_false_loss: 10.0265 - val_true_loss: 1.0867\n",
      "Epoch 1619/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.6810 - reconstruction_loss: 1900.1981 - kl_loss: 106.3671 - false_loss: 0.0736 - true_loss: 1.0254 - val_loss: 5111.7510 - val_reconstruction_loss: 1895.3081 - val_kl_loss: 100.0467 - val_false_loss: 10.0257 - val_true_loss: 1.0867\n",
      "Epoch 1620/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.0486 - reconstruction_loss: 1900.5778 - kl_loss: 105.5252 - false_loss: 0.0736 - true_loss: 1.0253 - val_loss: 5111.5049 - val_reconstruction_loss: 1895.3085 - val_kl_loss: 100.0474 - val_false_loss: 10.0249 - val_true_loss: 1.0866\n",
      "Epoch 1621/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.0249 - reconstruction_loss: 1900.5697 - kl_loss: 106.0075 - false_loss: 0.0736 - true_loss: 1.0253 - val_loss: 5111.2549 - val_reconstruction_loss: 1895.3085 - val_kl_loss: 100.0480 - val_false_loss: 10.0241 - val_true_loss: 1.0866\n",
      "Epoch 1622/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.0944 - reconstruction_loss: 1900.8486 - kl_loss: 105.9192 - false_loss: 0.0736 - true_loss: 1.0252 - val_loss: 5111.0068 - val_reconstruction_loss: 1895.3086 - val_kl_loss: 100.0487 - val_false_loss: 10.0233 - val_true_loss: 1.0865\n",
      "Epoch 1623/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.0703 - reconstruction_loss: 1900.5177 - kl_loss: 105.7741 - false_loss: 0.0736 - true_loss: 1.0252 - val_loss: 5110.7593 - val_reconstruction_loss: 1895.3088 - val_kl_loss: 100.0494 - val_false_loss: 10.0225 - val_true_loss: 1.0865\n",
      "Epoch 1624/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.6831 - reconstruction_loss: 1900.2988 - kl_loss: 106.5710 - false_loss: 0.0735 - true_loss: 1.0252 - val_loss: 5110.5142 - val_reconstruction_loss: 1895.3090 - val_kl_loss: 100.0500 - val_false_loss: 10.0217 - val_true_loss: 1.0864\n",
      "Epoch 1625/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.0058 - reconstruction_loss: 1900.0321 - kl_loss: 104.9182 - false_loss: 0.0735 - true_loss: 1.0251 - val_loss: 5110.2661 - val_reconstruction_loss: 1895.3090 - val_kl_loss: 100.0504 - val_false_loss: 10.0209 - val_true_loss: 1.0864\n",
      "Epoch 1626/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.2920 - reconstruction_loss: 1900.8232 - kl_loss: 106.1948 - false_loss: 0.0735 - true_loss: 1.0251 - val_loss: 5110.0220 - val_reconstruction_loss: 1895.3093 - val_kl_loss: 100.0510 - val_false_loss: 10.0200 - val_true_loss: 1.0864\n",
      "Epoch 1627/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2203.4356 - reconstruction_loss: 1900.2491 - kl_loss: 105.7853 - false_loss: 0.0735 - true_loss: 1.0250 - val_loss: 5109.7734 - val_reconstruction_loss: 1895.3093 - val_kl_loss: 100.0519 - val_false_loss: 10.0192 - val_true_loss: 1.0863\n",
      "Epoch 1628/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.2795 - reconstruction_loss: 1900.0265 - kl_loss: 107.2154 - false_loss: 0.0735 - true_loss: 1.0250 - val_loss: 5109.5249 - val_reconstruction_loss: 1895.3092 - val_kl_loss: 100.0525 - val_false_loss: 10.0184 - val_true_loss: 1.0863\n",
      "Epoch 1629/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2200.1429 - reconstruction_loss: 1899.8900 - kl_loss: 106.8934 - false_loss: 0.0735 - true_loss: 1.0250 - val_loss: 5109.2764 - val_reconstruction_loss: 1895.3093 - val_kl_loss: 100.0533 - val_false_loss: 10.0176 - val_true_loss: 1.0862\n",
      "Epoch 1630/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2199.2617 - reconstruction_loss: 1900.8320 - kl_loss: 106.5998 - false_loss: 0.0735 - true_loss: 1.0249 - val_loss: 5109.0244 - val_reconstruction_loss: 1895.3093 - val_kl_loss: 100.0539 - val_false_loss: 10.0168 - val_true_loss: 1.0862\n",
      "Epoch 1631/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2198.9117 - reconstruction_loss: 1900.1309 - kl_loss: 105.6202 - false_loss: 0.0735 - true_loss: 1.0249 - val_loss: 5108.7764 - val_reconstruction_loss: 1895.3094 - val_kl_loss: 100.0543 - val_false_loss: 10.0160 - val_true_loss: 1.0861\n",
      "Epoch 1632/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2199.6051 - reconstruction_loss: 1900.2798 - kl_loss: 104.7531 - false_loss: 0.0735 - true_loss: 1.0248 - val_loss: 5108.5244 - val_reconstruction_loss: 1895.3094 - val_kl_loss: 100.0550 - val_false_loss: 10.0151 - val_true_loss: 1.0861\n",
      "Epoch 1633/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2202.0131 - reconstruction_loss: 1900.3231 - kl_loss: 104.8938 - false_loss: 0.0735 - true_loss: 1.0248 - val_loss: 5108.2710 - val_reconstruction_loss: 1895.3096 - val_kl_loss: 100.0557 - val_false_loss: 10.0143 - val_true_loss: 1.0861\n",
      "Epoch 1634/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2198.1533 - reconstruction_loss: 1900.1688 - kl_loss: 107.3463 - false_loss: 0.0735 - true_loss: 1.0248 - val_loss: 5108.0205 - val_reconstruction_loss: 1895.3103 - val_kl_loss: 100.0564 - val_false_loss: 10.0135 - val_true_loss: 1.0860\n",
      "Epoch 1635/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2202.0916 - reconstruction_loss: 1901.6110 - kl_loss: 105.3092 - false_loss: 0.0735 - true_loss: 1.0247 - val_loss: 5107.7690 - val_reconstruction_loss: 1895.3103 - val_kl_loss: 100.0571 - val_false_loss: 10.0126 - val_true_loss: 1.0860\n",
      "Epoch 1636/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2195.9870 - reconstruction_loss: 1900.2217 - kl_loss: 107.0237 - false_loss: 0.0735 - true_loss: 1.0247 - val_loss: 5107.5166 - val_reconstruction_loss: 1895.3102 - val_kl_loss: 100.0580 - val_false_loss: 10.0118 - val_true_loss: 1.0859\n",
      "Epoch 1637/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.6273 - reconstruction_loss: 1899.7720 - kl_loss: 108.8212 - false_loss: 0.0735 - true_loss: 1.0246 - val_loss: 5107.2656 - val_reconstruction_loss: 1895.3103 - val_kl_loss: 100.0589 - val_false_loss: 10.0110 - val_true_loss: 1.0859\n",
      "Epoch 1638/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2196.2759 - reconstruction_loss: 1899.6229 - kl_loss: 108.1845 - false_loss: 0.0735 - true_loss: 1.0246 - val_loss: 5107.0146 - val_reconstruction_loss: 1895.3102 - val_kl_loss: 100.0596 - val_false_loss: 10.0102 - val_true_loss: 1.0858\n",
      "Epoch 1639/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2193.6565 - reconstruction_loss: 1899.6300 - kl_loss: 107.6214 - false_loss: 0.0735 - true_loss: 1.0246 - val_loss: 5106.7656 - val_reconstruction_loss: 1895.3102 - val_kl_loss: 100.0606 - val_false_loss: 10.0093 - val_true_loss: 1.0858\n",
      "Epoch 1640/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2197.3662 - reconstruction_loss: 1900.4308 - kl_loss: 108.1466 - false_loss: 0.0735 - true_loss: 1.0245 - val_loss: 5106.5127 - val_reconstruction_loss: 1895.3103 - val_kl_loss: 100.0616 - val_false_loss: 10.0085 - val_true_loss: 1.0858\n",
      "Epoch 1641/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2193.7578 - reconstruction_loss: 1900.1060 - kl_loss: 107.3913 - false_loss: 0.0735 - true_loss: 1.0245 - val_loss: 5106.2603 - val_reconstruction_loss: 1895.3103 - val_kl_loss: 100.0623 - val_false_loss: 10.0077 - val_true_loss: 1.0857\n",
      "Epoch 1642/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2192.3002 - reconstruction_loss: 1899.7203 - kl_loss: 108.0330 - false_loss: 0.0734 - true_loss: 1.0244 - val_loss: 5106.0034 - val_reconstruction_loss: 1895.3102 - val_kl_loss: 100.0629 - val_false_loss: 10.0068 - val_true_loss: 1.0857\n",
      "Epoch 1643/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2194.2712 - reconstruction_loss: 1899.5836 - kl_loss: 105.5687 - false_loss: 0.0734 - true_loss: 1.0244 - val_loss: 5105.7441 - val_reconstruction_loss: 1895.3103 - val_kl_loss: 100.0637 - val_false_loss: 10.0060 - val_true_loss: 1.0856\n",
      "Epoch 1644/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2267.9106 - reconstruction_loss: 1901.8496 - kl_loss: 95.9582 - false_loss: 0.0734 - true_loss: 1.0244 - val_loss: 5105.9502 - val_reconstruction_loss: 1895.3118 - val_kl_loss: 100.0612 - val_false_loss: 10.0052 - val_true_loss: 1.0900\n",
      "Epoch 1645/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 14311.8456 - reconstruction_loss: 2026.4147 - kl_loss: 1151.1257 - false_loss: 0.0745 - true_loss: 1.0265 - val_loss: 5106.5825 - val_reconstruction_loss: 1895.3198 - val_kl_loss: 100.2733 - val_false_loss: 10.0062 - val_true_loss: 1.0912\n",
      "Epoch 1646/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 8321.3759 - reconstruction_loss: 1966.3043 - kl_loss: 1010.2142 - false_loss: 0.0767 - true_loss: 1.0286 - val_loss: 5106.6372 - val_reconstruction_loss: 1895.3253 - val_kl_loss: 100.2764 - val_false_loss: 10.0060 - val_true_loss: 1.0922\n",
      "Epoch 1647/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 5459.5790 - reconstruction_loss: 1951.8129 - kl_loss: 120.9143 - false_loss: 0.0771 - true_loss: 1.0296 - val_loss: 5106.5469 - val_reconstruction_loss: 1895.3301 - val_kl_loss: 100.2753 - val_false_loss: 10.0055 - val_true_loss: 1.0930\n",
      "Epoch 1648/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 4490.9190 - reconstruction_loss: 1935.2616 - kl_loss: 88.3089 - false_loss: 0.0773 - true_loss: 1.0303 - val_loss: 5106.3716 - val_reconstruction_loss: 1895.3330 - val_kl_loss: 100.2737 - val_false_loss: 10.0047 - val_true_loss: 1.0935\n",
      "Epoch 1649/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 4035.2934 - reconstruction_loss: 1929.8906 - kl_loss: 72.6507 - false_loss: 0.0774 - true_loss: 1.0309 - val_loss: 5106.2002 - val_reconstruction_loss: 1895.3362 - val_kl_loss: 100.2691 - val_false_loss: 10.0039 - val_true_loss: 1.0940\n",
      "Epoch 1650/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3776.8132 - reconstruction_loss: 1926.6627 - kl_loss: 56.7743 - false_loss: 0.0774 - true_loss: 1.0314 - val_loss: 5106.0361 - val_reconstruction_loss: 1895.3386 - val_kl_loss: 100.2649 - val_false_loss: 10.0033 - val_true_loss: 1.0945\n",
      "Epoch 1651/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 3614.1958 - reconstruction_loss: 1924.5096 - kl_loss: 55.7831 - false_loss: 0.0775 - true_loss: 1.0318 - val_loss: 5105.8789 - val_reconstruction_loss: 1895.3412 - val_kl_loss: 100.2604 - val_false_loss: 10.0026 - val_true_loss: 1.0949\n",
      "Epoch 1652/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 3482.1901 - reconstruction_loss: 1923.0680 - kl_loss: 54.5258 - false_loss: 0.0775 - true_loss: 1.0322 - val_loss: 5105.7329 - val_reconstruction_loss: 1895.3433 - val_kl_loss: 100.2558 - val_false_loss: 10.0020 - val_true_loss: 1.0952\n",
      "Epoch 1653/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 3382.2277 - reconstruction_loss: 1921.3151 - kl_loss: 54.5457 - false_loss: 0.0776 - true_loss: 1.0326 - val_loss: 5105.5942 - val_reconstruction_loss: 1895.3456 - val_kl_loss: 100.2512 - val_false_loss: 10.0014 - val_true_loss: 1.0956\n",
      "Epoch 1654/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3299.1846 - reconstruction_loss: 1920.6840 - kl_loss: 55.2361 - false_loss: 0.0776 - true_loss: 1.0329 - val_loss: 5105.4458 - val_reconstruction_loss: 1895.3478 - val_kl_loss: 100.2467 - val_false_loss: 10.0008 - val_true_loss: 1.0959\n",
      "Epoch 1655/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3232.1388 - reconstruction_loss: 1920.2982 - kl_loss: 55.4667 - false_loss: 0.0777 - true_loss: 1.0333 - val_loss: 5105.3130 - val_reconstruction_loss: 1895.3499 - val_kl_loss: 100.2421 - val_false_loss: 10.0003 - val_true_loss: 1.0961\n",
      "Epoch 1656/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3172.9866 - reconstruction_loss: 1919.4902 - kl_loss: 55.6930 - false_loss: 0.0777 - true_loss: 1.0336 - val_loss: 5105.1709 - val_reconstruction_loss: 1895.3519 - val_kl_loss: 100.2375 - val_false_loss: 9.9998 - val_true_loss: 1.0964\n",
      "Epoch 1657/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3123.1219 - reconstruction_loss: 1918.8242 - kl_loss: 55.8116 - false_loss: 0.0777 - true_loss: 1.0338 - val_loss: 5105.0298 - val_reconstruction_loss: 1895.3539 - val_kl_loss: 100.2330 - val_false_loss: 9.9992 - val_true_loss: 1.0967\n",
      "Epoch 1658/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3082.2777 - reconstruction_loss: 1918.4175 - kl_loss: 55.8806 - false_loss: 0.0777 - true_loss: 1.0341 - val_loss: 5104.8872 - val_reconstruction_loss: 1895.3558 - val_kl_loss: 100.2285 - val_false_loss: 9.9987 - val_true_loss: 1.0969\n",
      "Epoch 1659/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3045.2243 - reconstruction_loss: 1917.9796 - kl_loss: 55.9603 - false_loss: 0.0778 - true_loss: 1.0343 - val_loss: 5104.7153 - val_reconstruction_loss: 1895.3575 - val_kl_loss: 100.2240 - val_false_loss: 9.9980 - val_true_loss: 1.0972\n",
      "Epoch 1660/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 3015.2482 - reconstruction_loss: 1917.1948 - kl_loss: 56.3503 - false_loss: 0.0778 - true_loss: 1.0346 - val_loss: 5104.5225 - val_reconstruction_loss: 1895.3594 - val_kl_loss: 100.2195 - val_false_loss: 9.9973 - val_true_loss: 1.0974\n",
      "Epoch 1661/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2988.3238 - reconstruction_loss: 1916.7025 - kl_loss: 56.8726 - false_loss: 0.0778 - true_loss: 1.0348 - val_loss: 5104.3032 - val_reconstruction_loss: 1895.3611 - val_kl_loss: 100.2151 - val_false_loss: 9.9965 - val_true_loss: 1.0976\n",
      "Epoch 1662/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2960.2314 - reconstruction_loss: 1916.5963 - kl_loss: 57.1099 - false_loss: 0.0778 - true_loss: 1.0350 - val_loss: 5104.0615 - val_reconstruction_loss: 1895.3628 - val_kl_loss: 100.2107 - val_false_loss: 9.9957 - val_true_loss: 1.0978\n",
      "Epoch 1663/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2936.5504 - reconstruction_loss: 1917.0410 - kl_loss: 57.0038 - false_loss: 0.0779 - true_loss: 1.0353 - val_loss: 5103.8120 - val_reconstruction_loss: 1895.3647 - val_kl_loss: 100.2064 - val_false_loss: 9.9948 - val_true_loss: 1.0980\n",
      "Epoch 1664/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2914.7613 - reconstruction_loss: 1917.4644 - kl_loss: 57.4511 - false_loss: 0.0779 - true_loss: 1.0355 - val_loss: 5103.5483 - val_reconstruction_loss: 1895.3665 - val_kl_loss: 100.2020 - val_false_loss: 9.9938 - val_true_loss: 1.0982\n",
      "Epoch 1665/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2893.2400 - reconstruction_loss: 1916.6100 - kl_loss: 57.6065 - false_loss: 0.0779 - true_loss: 1.0357 - val_loss: 5103.2856 - val_reconstruction_loss: 1895.3684 - val_kl_loss: 100.1977 - val_false_loss: 9.9929 - val_true_loss: 1.0984\n",
      "Epoch 1666/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2861.8389 - reconstruction_loss: 1917.2467 - kl_loss: 57.0748 - false_loss: 0.0779 - true_loss: 1.0358 - val_loss: 5103.0181 - val_reconstruction_loss: 1895.3699 - val_kl_loss: 100.1933 - val_false_loss: 9.9920 - val_true_loss: 1.0986\n",
      "Epoch 1667/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2839.1185 - reconstruction_loss: 1917.7936 - kl_loss: 57.0280 - false_loss: 0.0779 - true_loss: 1.0360 - val_loss: 5102.7495 - val_reconstruction_loss: 1895.3717 - val_kl_loss: 100.1889 - val_false_loss: 9.9910 - val_true_loss: 1.0988\n",
      "Epoch 1668/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2823.1284 - reconstruction_loss: 1918.8737 - kl_loss: 57.5756 - false_loss: 0.0780 - true_loss: 1.0362 - val_loss: 5102.4927 - val_reconstruction_loss: 1895.3739 - val_kl_loss: 100.1848 - val_false_loss: 9.9901 - val_true_loss: 1.0989\n",
      "Epoch 1669/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2819.0121 - reconstruction_loss: 1916.9791 - kl_loss: 58.1212 - false_loss: 0.0780 - true_loss: 1.0364 - val_loss: 5102.2231 - val_reconstruction_loss: 1895.3754 - val_kl_loss: 100.1805 - val_false_loss: 9.9892 - val_true_loss: 1.0991\n",
      "Epoch 1670/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2786.4850 - reconstruction_loss: 1915.7867 - kl_loss: 58.0203 - false_loss: 0.0780 - true_loss: 1.0365 - val_loss: 5101.9512 - val_reconstruction_loss: 1895.3771 - val_kl_loss: 100.1762 - val_false_loss: 9.9882 - val_true_loss: 1.0992\n",
      "Epoch 1671/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2765.6929 - reconstruction_loss: 1914.3522 - kl_loss: 58.1942 - false_loss: 0.0780 - true_loss: 1.0367 - val_loss: 5101.6812 - val_reconstruction_loss: 1895.3784 - val_kl_loss: 100.1719 - val_false_loss: 9.9873 - val_true_loss: 1.0994\n",
      "Epoch 1672/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2757.2933 - reconstruction_loss: 1914.4645 - kl_loss: 58.5103 - false_loss: 0.0780 - true_loss: 1.0369 - val_loss: 5101.4155 - val_reconstruction_loss: 1895.3799 - val_kl_loss: 100.1679 - val_false_loss: 9.9863 - val_true_loss: 1.0995\n",
      "Epoch 1673/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2750.9289 - reconstruction_loss: 1914.1406 - kl_loss: 59.2909 - false_loss: 0.0780 - true_loss: 1.0370 - val_loss: 5101.1401 - val_reconstruction_loss: 1895.3811 - val_kl_loss: 100.1636 - val_false_loss: 9.9854 - val_true_loss: 1.0997\n",
      "Epoch 1674/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2730.7607 - reconstruction_loss: 1912.6987 - kl_loss: 59.4058 - false_loss: 0.0781 - true_loss: 1.0372 - val_loss: 5100.8721 - val_reconstruction_loss: 1895.3824 - val_kl_loss: 100.1596 - val_false_loss: 9.9845 - val_true_loss: 1.0998\n",
      "Epoch 1675/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2723.2644 - reconstruction_loss: 1910.6915 - kl_loss: 59.8990 - false_loss: 0.0781 - true_loss: 1.0373 - val_loss: 5100.6021 - val_reconstruction_loss: 1895.3833 - val_kl_loss: 100.1555 - val_false_loss: 9.9835 - val_true_loss: 1.1000\n",
      "Epoch 1676/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2714.1494 - reconstruction_loss: 1919.3971 - kl_loss: 60.3035 - false_loss: 0.0781 - true_loss: 1.0374 - val_loss: 5100.3252 - val_reconstruction_loss: 1895.3867 - val_kl_loss: 100.1513 - val_false_loss: 9.9826 - val_true_loss: 1.1001\n",
      "Epoch 1677/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2728.3410 - reconstruction_loss: 1919.2191 - kl_loss: 60.6417 - false_loss: 0.0781 - true_loss: 1.0376 - val_loss: 5100.0488 - val_reconstruction_loss: 1895.3882 - val_kl_loss: 100.1472 - val_false_loss: 9.9816 - val_true_loss: 1.1002\n",
      "Epoch 1678/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2707.8949 - reconstruction_loss: 1913.4796 - kl_loss: 60.8510 - false_loss: 0.0781 - true_loss: 1.0377 - val_loss: 5099.7739 - val_reconstruction_loss: 1895.3893 - val_kl_loss: 100.1432 - val_false_loss: 9.9806 - val_true_loss: 1.1004\n",
      "Epoch 1679/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2685.5693 - reconstruction_loss: 1910.1906 - kl_loss: 61.2018 - false_loss: 0.0781 - true_loss: 1.0378 - val_loss: 5099.4966 - val_reconstruction_loss: 1895.3901 - val_kl_loss: 100.1393 - val_false_loss: 9.9797 - val_true_loss: 1.1005\n",
      "Epoch 1680/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2686.4688 - reconstruction_loss: 1910.4987 - kl_loss: 60.9717 - false_loss: 0.0781 - true_loss: 1.0380 - val_loss: 5099.2183 - val_reconstruction_loss: 1895.3918 - val_kl_loss: 100.1352 - val_false_loss: 9.9787 - val_true_loss: 1.1006\n",
      "Epoch 1681/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2687.0912 - reconstruction_loss: 1911.6527 - kl_loss: 61.4549 - false_loss: 0.0782 - true_loss: 1.0381 - val_loss: 5098.9404 - val_reconstruction_loss: 1895.3929 - val_kl_loss: 100.1314 - val_false_loss: 9.9778 - val_true_loss: 1.1007\n",
      "Epoch 1682/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2657.9004 - reconstruction_loss: 1909.3536 - kl_loss: 62.1146 - false_loss: 0.0782 - true_loss: 1.0382 - val_loss: 5098.6592 - val_reconstruction_loss: 1895.3938 - val_kl_loss: 100.1275 - val_false_loss: 9.9768 - val_true_loss: 1.1008\n",
      "Epoch 1683/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2650.2206 - reconstruction_loss: 1908.2544 - kl_loss: 62.0008 - false_loss: 0.0782 - true_loss: 1.0384 - val_loss: 5098.3794 - val_reconstruction_loss: 1895.3947 - val_kl_loss: 100.1238 - val_false_loss: 9.9758 - val_true_loss: 1.1010\n",
      "Epoch 1684/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2643.8967 - reconstruction_loss: 1908.5400 - kl_loss: 62.0799 - false_loss: 0.0782 - true_loss: 1.0385 - val_loss: 5098.0977 - val_reconstruction_loss: 1895.3954 - val_kl_loss: 100.1199 - val_false_loss: 9.9749 - val_true_loss: 1.1011\n",
      "Epoch 1685/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2637.9813 - reconstruction_loss: 1908.7230 - kl_loss: 62.0370 - false_loss: 0.0782 - true_loss: 1.0386 - val_loss: 5097.8145 - val_reconstruction_loss: 1895.3964 - val_kl_loss: 100.1160 - val_false_loss: 9.9739 - val_true_loss: 1.1012\n",
      "Epoch 1686/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2641.6941 - reconstruction_loss: 1909.5861 - kl_loss: 61.9445 - false_loss: 0.0782 - true_loss: 1.0387 - val_loss: 5097.5312 - val_reconstruction_loss: 1895.3975 - val_kl_loss: 100.1120 - val_false_loss: 9.9729 - val_true_loss: 1.1013\n",
      "Epoch 1687/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2634.3096 - reconstruction_loss: 1910.3242 - kl_loss: 62.5937 - false_loss: 0.0782 - true_loss: 1.0388 - val_loss: 5097.2466 - val_reconstruction_loss: 1895.3984 - val_kl_loss: 100.1082 - val_false_loss: 9.9720 - val_true_loss: 1.1014\n",
      "Epoch 1688/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2623.5259 - reconstruction_loss: 1908.2736 - kl_loss: 63.0828 - false_loss: 0.0782 - true_loss: 1.0389 - val_loss: 5096.9609 - val_reconstruction_loss: 1895.3990 - val_kl_loss: 100.1044 - val_false_loss: 9.9710 - val_true_loss: 1.1015\n",
      "Epoch 1689/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2613.3283 - reconstruction_loss: 1908.0078 - kl_loss: 63.0053 - false_loss: 0.0783 - true_loss: 1.0390 - val_loss: 5096.6748 - val_reconstruction_loss: 1895.3999 - val_kl_loss: 100.1006 - val_false_loss: 9.9700 - val_true_loss: 1.1016\n",
      "Epoch 1690/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2625.1048 - reconstruction_loss: 1907.8060 - kl_loss: 62.6416 - false_loss: 0.0783 - true_loss: 1.0391 - val_loss: 5096.3882 - val_reconstruction_loss: 1895.4008 - val_kl_loss: 100.0968 - val_false_loss: 9.9690 - val_true_loss: 1.1017\n",
      "Epoch 1691/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2594.3992 - reconstruction_loss: 1907.4639 - kl_loss: 63.6527 - false_loss: 0.0783 - true_loss: 1.0392 - val_loss: 5096.1016 - val_reconstruction_loss: 1895.4017 - val_kl_loss: 100.0930 - val_false_loss: 9.9681 - val_true_loss: 1.1018\n",
      "Epoch 1692/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2617.0179 - reconstruction_loss: 1908.3555 - kl_loss: 62.1642 - false_loss: 0.0783 - true_loss: 1.0393 - val_loss: 5095.8188 - val_reconstruction_loss: 1895.4026 - val_kl_loss: 100.0894 - val_false_loss: 9.9671 - val_true_loss: 1.1019\n",
      "Epoch 1693/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2603.0226 - reconstruction_loss: 1907.6190 - kl_loss: 63.2108 - false_loss: 0.0783 - true_loss: 1.0395 - val_loss: 5095.5322 - val_reconstruction_loss: 1895.4032 - val_kl_loss: 100.0856 - val_false_loss: 9.9661 - val_true_loss: 1.1020\n",
      "Epoch 1694/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2596.5214 - reconstruction_loss: 1907.9312 - kl_loss: 63.7768 - false_loss: 0.0783 - true_loss: 1.0396 - val_loss: 5095.2510 - val_reconstruction_loss: 1895.4042 - val_kl_loss: 100.0819 - val_false_loss: 9.9651 - val_true_loss: 1.1021\n",
      "Epoch 1695/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2599.6185 - reconstruction_loss: 1907.3024 - kl_loss: 63.3436 - false_loss: 0.0783 - true_loss: 1.0397 - val_loss: 5094.9653 - val_reconstruction_loss: 1895.4048 - val_kl_loss: 100.0782 - val_false_loss: 9.9642 - val_true_loss: 1.1022\n",
      "Epoch 1696/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2574.2579 - reconstruction_loss: 1907.0919 - kl_loss: 64.2044 - false_loss: 0.0783 - true_loss: 1.0397 - val_loss: 5094.6797 - val_reconstruction_loss: 1895.4056 - val_kl_loss: 100.0746 - val_false_loss: 9.9632 - val_true_loss: 1.1023\n",
      "Epoch 1697/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2566.7550 - reconstruction_loss: 1906.9615 - kl_loss: 64.9042 - false_loss: 0.0783 - true_loss: 1.0398 - val_loss: 5094.3955 - val_reconstruction_loss: 1895.4064 - val_kl_loss: 100.0709 - val_false_loss: 9.9622 - val_true_loss: 1.1024\n",
      "Epoch 1698/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2562.6984 - reconstruction_loss: 1906.7832 - kl_loss: 64.9684 - false_loss: 0.0783 - true_loss: 1.0399 - val_loss: 5094.1113 - val_reconstruction_loss: 1895.4069 - val_kl_loss: 100.0674 - val_false_loss: 9.9613 - val_true_loss: 1.1025\n",
      "Epoch 1699/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2560.8739 - reconstruction_loss: 1906.7931 - kl_loss: 64.3944 - false_loss: 0.0784 - true_loss: 1.0400 - val_loss: 5093.8276 - val_reconstruction_loss: 1895.4077 - val_kl_loss: 100.0637 - val_false_loss: 9.9603 - val_true_loss: 1.1025\n",
      "Epoch 1700/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2560.3483 - reconstruction_loss: 1906.7665 - kl_loss: 64.7168 - false_loss: 0.0784 - true_loss: 1.0401 - val_loss: 5093.5444 - val_reconstruction_loss: 1895.4083 - val_kl_loss: 100.0602 - val_false_loss: 9.9593 - val_true_loss: 1.1026\n",
      "Epoch 1701/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2547.7447 - reconstruction_loss: 1906.7308 - kl_loss: 65.9929 - false_loss: 0.0784 - true_loss: 1.0402 - val_loss: 5093.2617 - val_reconstruction_loss: 1895.4091 - val_kl_loss: 100.0567 - val_false_loss: 9.9584 - val_true_loss: 1.1027\n",
      "Epoch 1702/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2552.4365 - reconstruction_loss: 1906.8187 - kl_loss: 65.7836 - false_loss: 0.0784 - true_loss: 1.0403 - val_loss: 5092.9785 - val_reconstruction_loss: 1895.4097 - val_kl_loss: 100.0531 - val_false_loss: 9.9574 - val_true_loss: 1.1028\n",
      "Epoch 1703/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2541.0091 - reconstruction_loss: 1906.7692 - kl_loss: 65.9011 - false_loss: 0.0784 - true_loss: 1.0404 - val_loss: 5092.6958 - val_reconstruction_loss: 1895.4104 - val_kl_loss: 100.0497 - val_false_loss: 9.9565 - val_true_loss: 1.1029\n",
      "Epoch 1704/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2537.0496 - reconstruction_loss: 1906.5869 - kl_loss: 66.3300 - false_loss: 0.0784 - true_loss: 1.0404 - val_loss: 5092.4111 - val_reconstruction_loss: 1895.4110 - val_kl_loss: 100.0463 - val_false_loss: 9.9555 - val_true_loss: 1.1029\n",
      "Epoch 1705/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2532.1978 - reconstruction_loss: 1906.6055 - kl_loss: 66.4730 - false_loss: 0.0784 - true_loss: 1.0405 - val_loss: 5092.1279 - val_reconstruction_loss: 1895.4117 - val_kl_loss: 100.0430 - val_false_loss: 9.9545 - val_true_loss: 1.1030\n",
      "Epoch 1706/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2529.4374 - reconstruction_loss: 1906.9355 - kl_loss: 66.8606 - false_loss: 0.0784 - true_loss: 1.0406 - val_loss: 5091.8438 - val_reconstruction_loss: 1895.4124 - val_kl_loss: 100.0396 - val_false_loss: 9.9536 - val_true_loss: 1.1031\n",
      "Epoch 1707/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2526.3068 - reconstruction_loss: 1906.5670 - kl_loss: 66.8254 - false_loss: 0.0784 - true_loss: 1.0407 - val_loss: 5091.5605 - val_reconstruction_loss: 1895.4131 - val_kl_loss: 100.0363 - val_false_loss: 9.9526 - val_true_loss: 1.1032\n",
      "Epoch 1708/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2527.5119 - reconstruction_loss: 1906.7211 - kl_loss: 66.7111 - false_loss: 0.0784 - true_loss: 1.0407 - val_loss: 5091.2764 - val_reconstruction_loss: 1895.4137 - val_kl_loss: 100.0328 - val_false_loss: 9.9516 - val_true_loss: 1.1032\n",
      "Epoch 1709/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2528.6518 - reconstruction_loss: 1907.0902 - kl_loss: 66.4826 - false_loss: 0.0784 - true_loss: 1.0408 - val_loss: 5090.9922 - val_reconstruction_loss: 1895.4148 - val_kl_loss: 100.0295 - val_false_loss: 9.9507 - val_true_loss: 1.1033\n",
      "Epoch 1710/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2525.8154 - reconstruction_loss: 1907.5621 - kl_loss: 67.4063 - false_loss: 0.0785 - true_loss: 1.0409 - val_loss: 5090.7080 - val_reconstruction_loss: 1895.4155 - val_kl_loss: 100.0262 - val_false_loss: 9.9497 - val_true_loss: 1.1034\n",
      "Epoch 1711/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2508.2304 - reconstruction_loss: 1906.6143 - kl_loss: 68.4105 - false_loss: 0.0785 - true_loss: 1.0410 - val_loss: 5090.4233 - val_reconstruction_loss: 1895.4161 - val_kl_loss: 100.0230 - val_false_loss: 9.9488 - val_true_loss: 1.1034\n",
      "Epoch 1712/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2507.7260 - reconstruction_loss: 1906.5006 - kl_loss: 68.3583 - false_loss: 0.0785 - true_loss: 1.0410 - val_loss: 5090.1372 - val_reconstruction_loss: 1895.4169 - val_kl_loss: 100.0198 - val_false_loss: 9.9478 - val_true_loss: 1.1035\n",
      "Epoch 1713/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2510.9759 - reconstruction_loss: 1906.4720 - kl_loss: 67.8537 - false_loss: 0.0785 - true_loss: 1.0411 - val_loss: 5089.8530 - val_reconstruction_loss: 1895.4175 - val_kl_loss: 100.0167 - val_false_loss: 9.9468 - val_true_loss: 1.1036\n",
      "Epoch 1714/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2508.2363 - reconstruction_loss: 1906.2281 - kl_loss: 68.6399 - false_loss: 0.0785 - true_loss: 1.0412 - val_loss: 5089.5684 - val_reconstruction_loss: 1895.4182 - val_kl_loss: 100.0136 - val_false_loss: 9.9459 - val_true_loss: 1.1036\n",
      "Epoch 1715/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2498.6078 - reconstruction_loss: 1906.6641 - kl_loss: 68.6704 - false_loss: 0.0785 - true_loss: 1.0413 - val_loss: 5089.2827 - val_reconstruction_loss: 1895.4188 - val_kl_loss: 100.0104 - val_false_loss: 9.9449 - val_true_loss: 1.1037\n",
      "Epoch 1716/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2501.8901 - reconstruction_loss: 1906.4121 - kl_loss: 69.2041 - false_loss: 0.0785 - true_loss: 1.0413 - val_loss: 5088.9985 - val_reconstruction_loss: 1895.4196 - val_kl_loss: 100.0072 - val_false_loss: 9.9439 - val_true_loss: 1.1038\n",
      "Epoch 1717/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2500.6203 - reconstruction_loss: 1906.3193 - kl_loss: 69.0789 - false_loss: 0.0785 - true_loss: 1.0414 - val_loss: 5088.7134 - val_reconstruction_loss: 1895.4202 - val_kl_loss: 100.0041 - val_false_loss: 9.9430 - val_true_loss: 1.1038\n",
      "Epoch 1718/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2497.6662 - reconstruction_loss: 1906.4630 - kl_loss: 68.7105 - false_loss: 0.0785 - true_loss: 1.0415 - val_loss: 5088.4277 - val_reconstruction_loss: 1895.4209 - val_kl_loss: 100.0009 - val_false_loss: 9.9420 - val_true_loss: 1.1039\n",
      "Epoch 1719/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2498.0473 - reconstruction_loss: 1907.7319 - kl_loss: 69.1713 - false_loss: 0.0785 - true_loss: 1.0415 - val_loss: 5088.1421 - val_reconstruction_loss: 1895.4218 - val_kl_loss: 99.9979 - val_false_loss: 9.9411 - val_true_loss: 1.1040\n",
      "Epoch 1720/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2493.1437 - reconstruction_loss: 1907.5443 - kl_loss: 69.5786 - false_loss: 0.0785 - true_loss: 1.0416 - val_loss: 5087.8560 - val_reconstruction_loss: 1895.4224 - val_kl_loss: 99.9946 - val_false_loss: 9.9401 - val_true_loss: 1.1040\n",
      "Epoch 1721/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2490.0498 - reconstruction_loss: 1906.5088 - kl_loss: 69.8845 - false_loss: 0.0785 - true_loss: 1.0416 - val_loss: 5087.5703 - val_reconstruction_loss: 1895.4231 - val_kl_loss: 99.9916 - val_false_loss: 9.9391 - val_true_loss: 1.1041\n",
      "Epoch 1722/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2490.5895 - reconstruction_loss: 1906.3998 - kl_loss: 69.0757 - false_loss: 0.0785 - true_loss: 1.0417 - val_loss: 5087.2842 - val_reconstruction_loss: 1895.4237 - val_kl_loss: 99.9887 - val_false_loss: 9.9382 - val_true_loss: 1.1041\n",
      "Epoch 1723/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2484.5685 - reconstruction_loss: 1906.2728 - kl_loss: 70.3849 - false_loss: 0.0785 - true_loss: 1.0418 - val_loss: 5086.9980 - val_reconstruction_loss: 1895.4246 - val_kl_loss: 99.9858 - val_false_loss: 9.9372 - val_true_loss: 1.1042\n",
      "Epoch 1724/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2479.0921 - reconstruction_loss: 1906.0729 - kl_loss: 70.2115 - false_loss: 0.0785 - true_loss: 1.0418 - val_loss: 5086.7119 - val_reconstruction_loss: 1895.4250 - val_kl_loss: 99.9828 - val_false_loss: 9.9362 - val_true_loss: 1.1043\n",
      "Epoch 1725/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2476.7520 - reconstruction_loss: 1905.9921 - kl_loss: 70.7388 - false_loss: 0.0785 - true_loss: 1.0419 - val_loss: 5086.4243 - val_reconstruction_loss: 1895.4258 - val_kl_loss: 99.9799 - val_false_loss: 9.9353 - val_true_loss: 1.1043\n",
      "Epoch 1726/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2485.4210 - reconstruction_loss: 1906.6475 - kl_loss: 69.6339 - false_loss: 0.0786 - true_loss: 1.0420 - val_loss: 5086.1387 - val_reconstruction_loss: 1895.4264 - val_kl_loss: 99.9769 - val_false_loss: 9.9343 - val_true_loss: 1.1044\n",
      "Epoch 1727/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2489.6123 - reconstruction_loss: 1907.5956 - kl_loss: 69.3585 - false_loss: 0.0786 - true_loss: 1.0420 - val_loss: 5085.8516 - val_reconstruction_loss: 1895.4272 - val_kl_loss: 99.9738 - val_false_loss: 9.9333 - val_true_loss: 1.1044\n",
      "Epoch 1728/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2497.7245 - reconstruction_loss: 1908.5479 - kl_loss: 68.0914 - false_loss: 0.0786 - true_loss: 1.0421 - val_loss: 5085.5635 - val_reconstruction_loss: 1895.4277 - val_kl_loss: 99.9707 - val_false_loss: 9.9324 - val_true_loss: 1.1045\n",
      "Epoch 1729/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2472.8011 - reconstruction_loss: 1906.4635 - kl_loss: 71.1127 - false_loss: 0.0786 - true_loss: 1.0421 - val_loss: 5085.2769 - val_reconstruction_loss: 1895.4285 - val_kl_loss: 99.9678 - val_false_loss: 9.9314 - val_true_loss: 1.1045\n",
      "Epoch 1730/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2476.3474 - reconstruction_loss: 1906.1323 - kl_loss: 71.2211 - false_loss: 0.0786 - true_loss: 1.0422 - val_loss: 5084.9902 - val_reconstruction_loss: 1895.4291 - val_kl_loss: 99.9649 - val_false_loss: 9.9304 - val_true_loss: 1.1046\n",
      "Epoch 1731/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2471.7471 - reconstruction_loss: 1905.9916 - kl_loss: 71.5412 - false_loss: 0.0786 - true_loss: 1.0423 - val_loss: 5084.7026 - val_reconstruction_loss: 1895.4299 - val_kl_loss: 99.9619 - val_false_loss: 9.9295 - val_true_loss: 1.1047\n",
      "Epoch 1732/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2466.0000 - reconstruction_loss: 1905.8348 - kl_loss: 71.2502 - false_loss: 0.0786 - true_loss: 1.0423 - val_loss: 5084.4160 - val_reconstruction_loss: 1895.4304 - val_kl_loss: 99.9591 - val_false_loss: 9.9285 - val_true_loss: 1.1047\n",
      "Epoch 1733/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2468.1997 - reconstruction_loss: 1905.7728 - kl_loss: 71.8878 - false_loss: 0.0786 - true_loss: 1.0424 - val_loss: 5084.1289 - val_reconstruction_loss: 1895.4312 - val_kl_loss: 99.9564 - val_false_loss: 9.9275 - val_true_loss: 1.1048\n",
      "Epoch 1734/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2465.9943 - reconstruction_loss: 1905.7426 - kl_loss: 71.4612 - false_loss: 0.0786 - true_loss: 1.0424 - val_loss: 5083.8418 - val_reconstruction_loss: 1895.4318 - val_kl_loss: 99.9537 - val_false_loss: 9.9265 - val_true_loss: 1.1048\n",
      "Epoch 1735/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2460.0220 - reconstruction_loss: 1905.8550 - kl_loss: 72.2132 - false_loss: 0.0786 - true_loss: 1.0425 - val_loss: 5083.5557 - val_reconstruction_loss: 1895.4325 - val_kl_loss: 99.9509 - val_false_loss: 9.9256 - val_true_loss: 1.1049\n",
      "Epoch 1736/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2459.0954 - reconstruction_loss: 1905.7821 - kl_loss: 72.3281 - false_loss: 0.0786 - true_loss: 1.0425 - val_loss: 5083.2695 - val_reconstruction_loss: 1895.4329 - val_kl_loss: 99.9481 - val_false_loss: 9.9246 - val_true_loss: 1.1049\n",
      "Epoch 1737/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2461.4601 - reconstruction_loss: 1906.0299 - kl_loss: 71.9044 - false_loss: 0.0786 - true_loss: 1.0426 - val_loss: 5082.9829 - val_reconstruction_loss: 1895.4336 - val_kl_loss: 99.9453 - val_false_loss: 9.9237 - val_true_loss: 1.1050\n",
      "Epoch 1738/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2459.1220 - reconstruction_loss: 1905.8776 - kl_loss: 71.7064 - false_loss: 0.0786 - true_loss: 1.0426 - val_loss: 5082.6958 - val_reconstruction_loss: 1895.4342 - val_kl_loss: 99.9426 - val_false_loss: 9.9227 - val_true_loss: 1.1050\n",
      "Epoch 1739/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2461.1137 - reconstruction_loss: 1905.9404 - kl_loss: 71.8623 - false_loss: 0.0786 - true_loss: 1.0427 - val_loss: 5082.4102 - val_reconstruction_loss: 1895.4349 - val_kl_loss: 99.9399 - val_false_loss: 9.9217 - val_true_loss: 1.1051\n",
      "Epoch 1740/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2456.2293 - reconstruction_loss: 1905.9298 - kl_loss: 72.6555 - false_loss: 0.0786 - true_loss: 1.0427 - val_loss: 5082.1235 - val_reconstruction_loss: 1895.4354 - val_kl_loss: 99.9372 - val_false_loss: 9.9208 - val_true_loss: 1.1051\n",
      "Epoch 1741/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2453.4148 - reconstruction_loss: 1905.9999 - kl_loss: 72.3956 - false_loss: 0.0786 - true_loss: 1.0428 - val_loss: 5081.8374 - val_reconstruction_loss: 1895.4360 - val_kl_loss: 99.9346 - val_false_loss: 9.9198 - val_true_loss: 1.1052\n",
      "Epoch 1742/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2450.1101 - reconstruction_loss: 1905.8226 - kl_loss: 73.0553 - false_loss: 0.0786 - true_loss: 1.0428 - val_loss: 5081.5527 - val_reconstruction_loss: 1895.4365 - val_kl_loss: 99.9318 - val_false_loss: 9.9188 - val_true_loss: 1.1052\n",
      "Epoch 1743/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2448.7834 - reconstruction_loss: 1905.7728 - kl_loss: 72.9204 - false_loss: 0.0786 - true_loss: 1.0429 - val_loss: 5081.2666 - val_reconstruction_loss: 1895.4371 - val_kl_loss: 99.9292 - val_false_loss: 9.9179 - val_true_loss: 1.1053\n",
      "Epoch 1744/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2449.3080 - reconstruction_loss: 1906.1284 - kl_loss: 72.6719 - false_loss: 0.0787 - true_loss: 1.0429 - val_loss: 5080.9814 - val_reconstruction_loss: 1895.4379 - val_kl_loss: 99.9265 - val_false_loss: 9.9169 - val_true_loss: 1.1053\n",
      "Epoch 1745/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2448.1395 - reconstruction_loss: 1905.7340 - kl_loss: 72.9484 - false_loss: 0.0787 - true_loss: 1.0430 - val_loss: 5080.6938 - val_reconstruction_loss: 1895.4385 - val_kl_loss: 99.9238 - val_false_loss: 9.9159 - val_true_loss: 1.1054\n",
      "Epoch 1746/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2443.0973 - reconstruction_loss: 1905.8900 - kl_loss: 72.3612 - false_loss: 0.0787 - true_loss: 1.0430 - val_loss: 5080.4072 - val_reconstruction_loss: 1895.4390 - val_kl_loss: 99.9212 - val_false_loss: 9.9150 - val_true_loss: 1.1054\n",
      "Epoch 1747/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2443.5106 - reconstruction_loss: 1906.1041 - kl_loss: 72.9787 - false_loss: 0.0787 - true_loss: 1.0431 - val_loss: 5080.1201 - val_reconstruction_loss: 1895.4398 - val_kl_loss: 99.9184 - val_false_loss: 9.9140 - val_true_loss: 1.1055\n",
      "Epoch 1748/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2450.5238 - reconstruction_loss: 1906.2980 - kl_loss: 72.3685 - false_loss: 0.0787 - true_loss: 1.0431 - val_loss: 5079.8379 - val_reconstruction_loss: 1895.4403 - val_kl_loss: 99.9157 - val_false_loss: 9.9131 - val_true_loss: 1.1055\n",
      "Epoch 1749/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2528.1116 - reconstruction_loss: 1908.3658 - kl_loss: 66.2376 - false_loss: 0.0787 - true_loss: 1.0432 - val_loss: 5079.5518 - val_reconstruction_loss: 1895.4409 - val_kl_loss: 99.9124 - val_false_loss: 9.9121 - val_true_loss: 1.1056\n",
      "Epoch 1750/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2494.0287 - reconstruction_loss: 1907.6603 - kl_loss: 71.4614 - false_loss: 0.0787 - true_loss: 1.0433 - val_loss: 5079.2622 - val_reconstruction_loss: 1895.4417 - val_kl_loss: 99.9096 - val_false_loss: 9.9111 - val_true_loss: 1.1057\n",
      "Epoch 1751/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2458.3546 - reconstruction_loss: 1906.5109 - kl_loss: 73.1294 - false_loss: 0.0787 - true_loss: 1.0433 - val_loss: 5078.9756 - val_reconstruction_loss: 1895.4423 - val_kl_loss: 99.9070 - val_false_loss: 9.9102 - val_true_loss: 1.1057\n",
      "Epoch 1752/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2462.5334 - reconstruction_loss: 1906.4927 - kl_loss: 72.7462 - false_loss: 0.0787 - true_loss: 1.0434 - val_loss: 5078.6904 - val_reconstruction_loss: 1895.4430 - val_kl_loss: 99.9044 - val_false_loss: 9.9092 - val_true_loss: 1.1058\n",
      "Epoch 1753/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2459.6164 - reconstruction_loss: 1906.0179 - kl_loss: 73.1906 - false_loss: 0.0787 - true_loss: 1.0434 - val_loss: 5078.4023 - val_reconstruction_loss: 1895.4434 - val_kl_loss: 99.9019 - val_false_loss: 9.9082 - val_true_loss: 1.1058\n",
      "Epoch 1754/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2486.2803 - reconstruction_loss: 1905.7811 - kl_loss: 73.0270 - false_loss: 0.0787 - true_loss: 1.0435 - val_loss: 5078.1162 - val_reconstruction_loss: 1895.4438 - val_kl_loss: 99.8992 - val_false_loss: 9.9073 - val_true_loss: 1.1059\n",
      "Epoch 1755/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2483.6913 - reconstruction_loss: 1905.6627 - kl_loss: 73.6927 - false_loss: 0.0787 - true_loss: 1.0435 - val_loss: 5077.8286 - val_reconstruction_loss: 1895.4447 - val_kl_loss: 99.8964 - val_false_loss: 9.9063 - val_true_loss: 1.1059\n",
      "Epoch 1756/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2462.7278 - reconstruction_loss: 1905.8043 - kl_loss: 73.3551 - false_loss: 0.0787 - true_loss: 1.0436 - val_loss: 5077.5415 - val_reconstruction_loss: 1895.4452 - val_kl_loss: 99.8939 - val_false_loss: 9.9053 - val_true_loss: 1.1060\n",
      "Epoch 1757/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2461.1662 - reconstruction_loss: 1905.7550 - kl_loss: 73.1950 - false_loss: 0.0787 - true_loss: 1.0437 - val_loss: 5077.2534 - val_reconstruction_loss: 1895.4459 - val_kl_loss: 99.8910 - val_false_loss: 9.9043 - val_true_loss: 1.1060\n",
      "Epoch 1758/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2469.0987 - reconstruction_loss: 1905.4928 - kl_loss: 73.0444 - false_loss: 0.0787 - true_loss: 1.0437 - val_loss: 5076.9683 - val_reconstruction_loss: 1895.4463 - val_kl_loss: 99.8882 - val_false_loss: 9.9034 - val_true_loss: 1.1061\n",
      "Epoch 1759/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2507.1116 - reconstruction_loss: 1905.7211 - kl_loss: 71.5623 - false_loss: 0.0788 - true_loss: 1.0438 - val_loss: 5076.6826 - val_reconstruction_loss: 1895.4470 - val_kl_loss: 99.8852 - val_false_loss: 9.9024 - val_true_loss: 1.1062\n",
      "Epoch 1760/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2512.3016 - reconstruction_loss: 1905.6167 - kl_loss: 70.4779 - false_loss: 0.0788 - true_loss: 1.0438 - val_loss: 5076.3955 - val_reconstruction_loss: 1895.4476 - val_kl_loss: 99.8825 - val_false_loss: 9.9014 - val_true_loss: 1.1063\n",
      "Epoch 1761/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2498.2712 - reconstruction_loss: 1905.6714 - kl_loss: 71.4188 - false_loss: 0.0788 - true_loss: 1.0439 - val_loss: 5076.1074 - val_reconstruction_loss: 1895.4481 - val_kl_loss: 99.8799 - val_false_loss: 9.9005 - val_true_loss: 1.1063\n",
      "Epoch 1762/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2487.5991 - reconstruction_loss: 1905.5582 - kl_loss: 72.3900 - false_loss: 0.0788 - true_loss: 1.0440 - val_loss: 5075.8208 - val_reconstruction_loss: 1895.4489 - val_kl_loss: 99.8772 - val_false_loss: 9.8995 - val_true_loss: 1.1064\n",
      "Epoch 1763/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2482.9413 - reconstruction_loss: 1905.7051 - kl_loss: 72.2236 - false_loss: 0.0788 - true_loss: 1.0440 - val_loss: 5075.5342 - val_reconstruction_loss: 1895.4492 - val_kl_loss: 99.8743 - val_false_loss: 9.8985 - val_true_loss: 1.1064\n",
      "Epoch 1764/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2488.9358 - reconstruction_loss: 1905.5792 - kl_loss: 70.9778 - false_loss: 0.0788 - true_loss: 1.0441 - val_loss: 5075.2476 - val_reconstruction_loss: 1895.4500 - val_kl_loss: 99.8715 - val_false_loss: 9.8976 - val_true_loss: 1.1065\n",
      "Epoch 1765/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2484.1851 - reconstruction_loss: 1905.4492 - kl_loss: 70.9514 - false_loss: 0.0788 - true_loss: 1.0442 - val_loss: 5074.9600 - val_reconstruction_loss: 1895.4506 - val_kl_loss: 99.8688 - val_false_loss: 9.8966 - val_true_loss: 1.1065\n",
      "Epoch 1766/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2473.3977 - reconstruction_loss: 1905.3877 - kl_loss: 72.0731 - false_loss: 0.0788 - true_loss: 1.0442 - val_loss: 5074.6729 - val_reconstruction_loss: 1895.4510 - val_kl_loss: 99.8660 - val_false_loss: 9.8956 - val_true_loss: 1.1066\n",
      "Epoch 1767/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2470.1923 - reconstruction_loss: 1905.6754 - kl_loss: 72.0341 - false_loss: 0.0788 - true_loss: 1.0443 - val_loss: 5074.3857 - val_reconstruction_loss: 1895.4517 - val_kl_loss: 99.8632 - val_false_loss: 9.8947 - val_true_loss: 1.1067\n",
      "Epoch 1768/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2472.3942 - reconstruction_loss: 1905.5688 - kl_loss: 71.1377 - false_loss: 0.0788 - true_loss: 1.0443 - val_loss: 5074.0986 - val_reconstruction_loss: 1895.4521 - val_kl_loss: 99.8604 - val_false_loss: 9.8937 - val_true_loss: 1.1067\n",
      "Epoch 1769/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2469.0510 - reconstruction_loss: 1905.3698 - kl_loss: 71.8174 - false_loss: 0.0788 - true_loss: 1.0444 - val_loss: 5073.8101 - val_reconstruction_loss: 1895.4529 - val_kl_loss: 99.8576 - val_false_loss: 9.8927 - val_true_loss: 1.1068\n",
      "Epoch 1770/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2464.7929 - reconstruction_loss: 1905.6891 - kl_loss: 71.6167 - false_loss: 0.0788 - true_loss: 1.0444 - val_loss: 5073.5244 - val_reconstruction_loss: 1895.4535 - val_kl_loss: 99.8548 - val_false_loss: 9.8917 - val_true_loss: 1.1068\n",
      "Epoch 1771/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2484.7070 - reconstruction_loss: 1906.8950 - kl_loss: 69.0632 - false_loss: 0.0788 - true_loss: 1.0445 - val_loss: 5073.2373 - val_reconstruction_loss: 1895.4546 - val_kl_loss: 99.8519 - val_false_loss: 9.8908 - val_true_loss: 1.1069\n",
      "Epoch 1772/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2485.4134 - reconstruction_loss: 1907.4263 - kl_loss: 69.9491 - false_loss: 0.0788 - true_loss: 1.0446 - val_loss: 5072.9502 - val_reconstruction_loss: 1895.4554 - val_kl_loss: 99.8488 - val_false_loss: 9.8898 - val_true_loss: 1.1069\n",
      "Epoch 1773/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2469.9713 - reconstruction_loss: 1906.3893 - kl_loss: 71.5338 - false_loss: 0.0788 - true_loss: 1.0446 - val_loss: 5072.6621 - val_reconstruction_loss: 1895.4559 - val_kl_loss: 99.8461 - val_false_loss: 9.8888 - val_true_loss: 1.1070\n",
      "Epoch 1774/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2455.7735 - reconstruction_loss: 1905.8999 - kl_loss: 72.4771 - false_loss: 0.0788 - true_loss: 1.0447 - val_loss: 5072.3745 - val_reconstruction_loss: 1895.4565 - val_kl_loss: 99.8434 - val_false_loss: 9.8879 - val_true_loss: 1.1070\n",
      "Epoch 1775/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2455.1344 - reconstruction_loss: 1905.5743 - kl_loss: 72.2434 - false_loss: 0.0788 - true_loss: 1.0447 - val_loss: 5072.0859 - val_reconstruction_loss: 1895.4570 - val_kl_loss: 99.8408 - val_false_loss: 9.8869 - val_true_loss: 1.1071\n",
      "Epoch 1776/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2453.8573 - reconstruction_loss: 1905.6051 - kl_loss: 71.7291 - false_loss: 0.0788 - true_loss: 1.0448 - val_loss: 5071.7979 - val_reconstruction_loss: 1895.4576 - val_kl_loss: 99.8381 - val_false_loss: 9.8859 - val_true_loss: 1.1071\n",
      "Epoch 1777/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2449.5655 - reconstruction_loss: 1905.4727 - kl_loss: 72.5933 - false_loss: 0.0789 - true_loss: 1.0448 - val_loss: 5071.5083 - val_reconstruction_loss: 1895.4581 - val_kl_loss: 99.8354 - val_false_loss: 9.8850 - val_true_loss: 1.1072\n",
      "Epoch 1778/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2445.7841 - reconstruction_loss: 1905.3495 - kl_loss: 72.1146 - false_loss: 0.0789 - true_loss: 1.0449 - val_loss: 5071.2197 - val_reconstruction_loss: 1895.4587 - val_kl_loss: 99.8326 - val_false_loss: 9.8840 - val_true_loss: 1.1072\n",
      "Epoch 1779/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2444.5610 - reconstruction_loss: 1905.2565 - kl_loss: 72.3302 - false_loss: 0.0789 - true_loss: 1.0449 - val_loss: 5070.9316 - val_reconstruction_loss: 1895.4592 - val_kl_loss: 99.8299 - val_false_loss: 9.8830 - val_true_loss: 1.1073\n",
      "Epoch 1780/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2443.5374 - reconstruction_loss: 1905.3599 - kl_loss: 72.6720 - false_loss: 0.0789 - true_loss: 1.0450 - val_loss: 5070.6426 - val_reconstruction_loss: 1895.4600 - val_kl_loss: 99.8272 - val_false_loss: 9.8820 - val_true_loss: 1.1073\n",
      "Epoch 1781/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2435.9502 - reconstruction_loss: 1905.6084 - kl_loss: 72.4309 - false_loss: 0.0789 - true_loss: 1.0450 - val_loss: 5070.3535 - val_reconstruction_loss: 1895.4603 - val_kl_loss: 99.8244 - val_false_loss: 9.8811 - val_true_loss: 1.1073\n",
      "Epoch 1782/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2427.2668 - reconstruction_loss: 1905.4321 - kl_loss: 72.9988 - false_loss: 0.0789 - true_loss: 1.0451 - val_loss: 5070.0649 - val_reconstruction_loss: 1895.4611 - val_kl_loss: 99.8217 - val_false_loss: 9.8801 - val_true_loss: 1.1074\n",
      "Epoch 1783/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2435.9310 - reconstruction_loss: 1905.2477 - kl_loss: 72.9357 - false_loss: 0.0789 - true_loss: 1.0451 - val_loss: 5069.7754 - val_reconstruction_loss: 1895.4617 - val_kl_loss: 99.8189 - val_false_loss: 9.8791 - val_true_loss: 1.1074\n",
      "Epoch 1784/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2436.5853 - reconstruction_loss: 1905.8644 - kl_loss: 71.9879 - false_loss: 0.0789 - true_loss: 1.0452 - val_loss: 5069.4883 - val_reconstruction_loss: 1895.4625 - val_kl_loss: 99.8163 - val_false_loss: 9.8782 - val_true_loss: 1.1075\n",
      "Epoch 1785/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2436.1197 - reconstruction_loss: 1908.7894 - kl_loss: 72.6827 - false_loss: 0.0789 - true_loss: 1.0452 - val_loss: 5069.2007 - val_reconstruction_loss: 1895.4633 - val_kl_loss: 99.8136 - val_false_loss: 9.8772 - val_true_loss: 1.1075\n",
      "Epoch 1786/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2434.7151 - reconstruction_loss: 1906.5323 - kl_loss: 72.0224 - false_loss: 0.0789 - true_loss: 1.0452 - val_loss: 5068.9146 - val_reconstruction_loss: 1895.4639 - val_kl_loss: 99.8106 - val_false_loss: 9.8762 - val_true_loss: 1.1076\n",
      "Epoch 1787/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2470.5050 - reconstruction_loss: 1906.5576 - kl_loss: 69.5602 - false_loss: 0.0789 - true_loss: 1.0453 - val_loss: 5068.6289 - val_reconstruction_loss: 1895.4644 - val_kl_loss: 99.8079 - val_false_loss: 9.8753 - val_true_loss: 1.1076\n",
      "Epoch 1788/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2423.3327 - reconstruction_loss: 1905.6263 - kl_loss: 72.1134 - false_loss: 0.0789 - true_loss: 1.0453 - val_loss: 5068.3374 - val_reconstruction_loss: 1895.4650 - val_kl_loss: 99.8053 - val_false_loss: 9.8743 - val_true_loss: 1.1077\n",
      "Epoch 1789/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2396.4893 - reconstruction_loss: 1905.8021 - kl_loss: 74.7700 - false_loss: 0.0789 - true_loss: 1.0454 - val_loss: 5068.0483 - val_reconstruction_loss: 1895.4655 - val_kl_loss: 99.8029 - val_false_loss: 9.8733 - val_true_loss: 1.1077\n",
      "Epoch 1790/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2397.8762 - reconstruction_loss: 1905.4918 - kl_loss: 75.5763 - false_loss: 0.0789 - true_loss: 1.0454 - val_loss: 5067.7603 - val_reconstruction_loss: 1895.4662 - val_kl_loss: 99.8004 - val_false_loss: 9.8724 - val_true_loss: 1.1077\n",
      "Epoch 1791/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2394.4002 - reconstruction_loss: 1905.8555 - kl_loss: 75.3855 - false_loss: 0.0789 - true_loss: 1.0454 - val_loss: 5067.4707 - val_reconstruction_loss: 1895.4666 - val_kl_loss: 99.7981 - val_false_loss: 9.8714 - val_true_loss: 1.1078\n",
      "Epoch 1792/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2390.5045 - reconstruction_loss: 1905.5702 - kl_loss: 75.5075 - false_loss: 0.0789 - true_loss: 1.0455 - val_loss: 5067.1821 - val_reconstruction_loss: 1895.4670 - val_kl_loss: 99.7958 - val_false_loss: 9.8704 - val_true_loss: 1.1078\n",
      "Epoch 1793/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2395.1420 - reconstruction_loss: 1905.2003 - kl_loss: 75.6053 - false_loss: 0.0789 - true_loss: 1.0455 - val_loss: 5066.8921 - val_reconstruction_loss: 1895.4677 - val_kl_loss: 99.7931 - val_false_loss: 9.8695 - val_true_loss: 1.1078\n",
      "Epoch 1794/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2402.5970 - reconstruction_loss: 1905.5645 - kl_loss: 74.8681 - false_loss: 0.0789 - true_loss: 1.0455 - val_loss: 5066.6025 - val_reconstruction_loss: 1895.4681 - val_kl_loss: 99.7910 - val_false_loss: 9.8685 - val_true_loss: 1.1078\n",
      "Epoch 1795/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2389.1365 - reconstruction_loss: 1905.3730 - kl_loss: 76.8156 - false_loss: 0.0789 - true_loss: 1.0456 - val_loss: 5066.3130 - val_reconstruction_loss: 1895.4689 - val_kl_loss: 99.7887 - val_false_loss: 9.8675 - val_true_loss: 1.1079\n",
      "Epoch 1796/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2390.3633 - reconstruction_loss: 1905.8541 - kl_loss: 76.3688 - false_loss: 0.0789 - true_loss: 1.0456 - val_loss: 5066.0234 - val_reconstruction_loss: 1895.4692 - val_kl_loss: 99.7865 - val_false_loss: 9.8666 - val_true_loss: 1.1079\n",
      "Epoch 1797/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2381.4508 - reconstruction_loss: 1905.8510 - kl_loss: 76.9874 - false_loss: 0.0789 - true_loss: 1.0456 - val_loss: 5065.7339 - val_reconstruction_loss: 1895.4701 - val_kl_loss: 99.7841 - val_false_loss: 9.8656 - val_true_loss: 1.1079\n",
      "Epoch 1798/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2385.9019 - reconstruction_loss: 1905.8949 - kl_loss: 77.0989 - false_loss: 0.0789 - true_loss: 1.0456 - val_loss: 5065.4448 - val_reconstruction_loss: 1895.4709 - val_kl_loss: 99.7819 - val_false_loss: 9.8646 - val_true_loss: 1.1079\n",
      "Epoch 1799/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2385.1544 - reconstruction_loss: 1906.2173 - kl_loss: 77.6451 - false_loss: 0.0789 - true_loss: 1.0457 - val_loss: 5065.1553 - val_reconstruction_loss: 1895.4714 - val_kl_loss: 99.7798 - val_false_loss: 9.8637 - val_true_loss: 1.1080\n",
      "Epoch 1800/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2379.7457 - reconstruction_loss: 1905.4523 - kl_loss: 77.8332 - false_loss: 0.0789 - true_loss: 1.0457 - val_loss: 5064.8652 - val_reconstruction_loss: 1895.4722 - val_kl_loss: 99.7776 - val_false_loss: 9.8627 - val_true_loss: 1.1080\n",
      "Epoch 1801/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2377.5912 - reconstruction_loss: 1905.7939 - kl_loss: 78.3241 - false_loss: 0.0789 - true_loss: 1.0457 - val_loss: 5064.5757 - val_reconstruction_loss: 1895.4728 - val_kl_loss: 99.7754 - val_false_loss: 9.8617 - val_true_loss: 1.1080\n",
      "Epoch 1802/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2378.1969 - reconstruction_loss: 1905.3871 - kl_loss: 77.6040 - false_loss: 0.0789 - true_loss: 1.0457 - val_loss: 5064.2866 - val_reconstruction_loss: 1895.4733 - val_kl_loss: 99.7731 - val_false_loss: 9.8608 - val_true_loss: 1.1080\n",
      "Epoch 1803/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2408.2818 - reconstruction_loss: 1907.9614 - kl_loss: 73.7999 - false_loss: 0.0789 - true_loss: 1.0458 - val_loss: 5063.9980 - val_reconstruction_loss: 1895.4747 - val_kl_loss: 99.7708 - val_false_loss: 9.8598 - val_true_loss: 1.1081\n",
      "Epoch 1804/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2393.9275 - reconstruction_loss: 1910.1693 - kl_loss: 77.4382 - false_loss: 0.0789 - true_loss: 1.0458 - val_loss: 5063.7085 - val_reconstruction_loss: 1895.4753 - val_kl_loss: 99.7687 - val_false_loss: 9.8588 - val_true_loss: 1.1081\n",
      "Epoch 1805/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2383.2594 - reconstruction_loss: 1907.4562 - kl_loss: 78.1716 - false_loss: 0.0789 - true_loss: 1.0458 - val_loss: 5063.4189 - val_reconstruction_loss: 1895.4762 - val_kl_loss: 99.7668 - val_false_loss: 9.8578 - val_true_loss: 1.1081\n",
      "Epoch 1806/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2380.8032 - reconstruction_loss: 1905.9518 - kl_loss: 78.8528 - false_loss: 0.0789 - true_loss: 1.0458 - val_loss: 5063.1294 - val_reconstruction_loss: 1895.4769 - val_kl_loss: 99.7648 - val_false_loss: 9.8569 - val_true_loss: 1.1081\n",
      "Epoch 1807/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2378.4753 - reconstruction_loss: 1906.2471 - kl_loss: 78.5821 - false_loss: 0.0789 - true_loss: 1.0459 - val_loss: 5062.8403 - val_reconstruction_loss: 1895.4773 - val_kl_loss: 99.7628 - val_false_loss: 9.8559 - val_true_loss: 1.1082\n",
      "Epoch 1808/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2377.2907 - reconstruction_loss: 1905.6542 - kl_loss: 78.2325 - false_loss: 0.0789 - true_loss: 1.0459 - val_loss: 5062.5513 - val_reconstruction_loss: 1895.4780 - val_kl_loss: 99.7607 - val_false_loss: 9.8549 - val_true_loss: 1.1082\n",
      "Epoch 1809/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2381.7893 - reconstruction_loss: 1905.2213 - kl_loss: 77.4690 - false_loss: 0.0789 - true_loss: 1.0459 - val_loss: 5062.2617 - val_reconstruction_loss: 1895.4783 - val_kl_loss: 99.7584 - val_false_loss: 9.8540 - val_true_loss: 1.1082\n",
      "Epoch 1810/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2470.6940 - reconstruction_loss: 1907.0045 - kl_loss: 68.5716 - false_loss: 0.0790 - true_loss: 1.0460 - val_loss: 5061.9731 - val_reconstruction_loss: 1895.4789 - val_kl_loss: 99.7549 - val_false_loss: 9.8530 - val_true_loss: 1.1083\n",
      "Epoch 1811/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2477.7226 - reconstruction_loss: 1907.7471 - kl_loss: 73.5594 - false_loss: 0.0790 - true_loss: 1.0460 - val_loss: 5061.6836 - val_reconstruction_loss: 1895.4797 - val_kl_loss: 99.7520 - val_false_loss: 9.8520 - val_true_loss: 1.1083\n",
      "Epoch 1812/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2397.8882 - reconstruction_loss: 1906.1869 - kl_loss: 78.3878 - false_loss: 0.0790 - true_loss: 1.0461 - val_loss: 5061.3940 - val_reconstruction_loss: 1895.4805 - val_kl_loss: 99.7499 - val_false_loss: 9.8511 - val_true_loss: 1.1083\n",
      "Epoch 1813/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2380.9341 - reconstruction_loss: 1905.3652 - kl_loss: 78.9162 - false_loss: 0.0790 - true_loss: 1.0461 - val_loss: 5061.1060 - val_reconstruction_loss: 1895.4808 - val_kl_loss: 99.7481 - val_false_loss: 9.8501 - val_true_loss: 1.1083\n",
      "Epoch 1814/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2370.7897 - reconstruction_loss: 1905.1776 - kl_loss: 79.7912 - false_loss: 0.0790 - true_loss: 1.0461 - val_loss: 5060.8188 - val_reconstruction_loss: 1895.4813 - val_kl_loss: 99.7462 - val_false_loss: 9.8491 - val_true_loss: 1.1084\n",
      "Epoch 1815/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2373.4520 - reconstruction_loss: 1905.5615 - kl_loss: 80.5236 - false_loss: 0.0790 - true_loss: 1.0461 - val_loss: 5060.5293 - val_reconstruction_loss: 1895.4818 - val_kl_loss: 99.7442 - val_false_loss: 9.8482 - val_true_loss: 1.1084\n",
      "Epoch 1816/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2366.8587 - reconstruction_loss: 1905.2451 - kl_loss: 80.4733 - false_loss: 0.0790 - true_loss: 1.0462 - val_loss: 5060.2397 - val_reconstruction_loss: 1895.4824 - val_kl_loss: 99.7424 - val_false_loss: 9.8472 - val_true_loss: 1.1084\n",
      "Epoch 1817/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2365.5325 - reconstruction_loss: 1905.2841 - kl_loss: 80.5348 - false_loss: 0.0790 - true_loss: 1.0462 - val_loss: 5059.9502 - val_reconstruction_loss: 1895.4829 - val_kl_loss: 99.7406 - val_false_loss: 9.8463 - val_true_loss: 1.1084\n",
      "Epoch 1818/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2365.8182 - reconstruction_loss: 1905.8573 - kl_loss: 80.3566 - false_loss: 0.0790 - true_loss: 1.0462 - val_loss: 5059.6606 - val_reconstruction_loss: 1895.4834 - val_kl_loss: 99.7387 - val_false_loss: 9.8453 - val_true_loss: 1.1084\n",
      "Epoch 1819/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2367.8312 - reconstruction_loss: 1905.1886 - kl_loss: 80.7189 - false_loss: 0.0790 - true_loss: 1.0462 - val_loss: 5059.3721 - val_reconstruction_loss: 1895.4838 - val_kl_loss: 99.7368 - val_false_loss: 9.8443 - val_true_loss: 1.1084\n",
      "Epoch 1820/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2376.6457 - reconstruction_loss: 1905.2196 - kl_loss: 78.0319 - false_loss: 0.0790 - true_loss: 1.0462 - val_loss: 5059.0830 - val_reconstruction_loss: 1895.4845 - val_kl_loss: 99.7346 - val_false_loss: 9.8434 - val_true_loss: 1.1085\n",
      "Epoch 1821/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2377.9769 - reconstruction_loss: 1905.6801 - kl_loss: 78.7726 - false_loss: 0.0790 - true_loss: 1.0463 - val_loss: 5058.7935 - val_reconstruction_loss: 1895.4850 - val_kl_loss: 99.7324 - val_false_loss: 9.8424 - val_true_loss: 1.1085\n",
      "Epoch 1822/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2369.3172 - reconstruction_loss: 1905.2150 - kl_loss: 80.1159 - false_loss: 0.0790 - true_loss: 1.0463 - val_loss: 5058.5034 - val_reconstruction_loss: 1895.4856 - val_kl_loss: 99.7305 - val_false_loss: 9.8414 - val_true_loss: 1.1085\n",
      "Epoch 1823/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2361.4208 - reconstruction_loss: 1905.1865 - kl_loss: 81.8485 - false_loss: 0.0790 - true_loss: 1.0463 - val_loss: 5058.2144 - val_reconstruction_loss: 1895.4861 - val_kl_loss: 99.7287 - val_false_loss: 9.8405 - val_true_loss: 1.1085\n",
      "Epoch 1824/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2363.6504 - reconstruction_loss: 1905.5682 - kl_loss: 80.8505 - false_loss: 0.0790 - true_loss: 1.0463 - val_loss: 5057.9253 - val_reconstruction_loss: 1895.4865 - val_kl_loss: 99.7270 - val_false_loss: 9.8395 - val_true_loss: 1.1085\n",
      "Epoch 1825/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2363.8172 - reconstruction_loss: 1905.4554 - kl_loss: 81.4719 - false_loss: 0.0790 - true_loss: 1.0463 - val_loss: 5057.6353 - val_reconstruction_loss: 1895.4872 - val_kl_loss: 99.7253 - val_false_loss: 9.8385 - val_true_loss: 1.1085\n",
      "Epoch 1826/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2359.4577 - reconstruction_loss: 1905.0034 - kl_loss: 80.9998 - false_loss: 0.0790 - true_loss: 1.0464 - val_loss: 5057.3467 - val_reconstruction_loss: 1895.4878 - val_kl_loss: 99.7234 - val_false_loss: 9.8376 - val_true_loss: 1.1085\n",
      "Epoch 1827/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2380.1589 - reconstruction_loss: 1905.8304 - kl_loss: 77.3257 - false_loss: 0.0790 - true_loss: 1.0464 - val_loss: 5057.0596 - val_reconstruction_loss: 1895.4883 - val_kl_loss: 99.7209 - val_false_loss: 9.8366 - val_true_loss: 1.1086\n",
      "Epoch 1828/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2407.6884 - reconstruction_loss: 1905.2349 - kl_loss: 75.1170 - false_loss: 0.0790 - true_loss: 1.0464 - val_loss: 5056.7705 - val_reconstruction_loss: 1895.4889 - val_kl_loss: 99.7186 - val_false_loss: 9.8356 - val_true_loss: 1.1086\n",
      "Epoch 1829/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2370.0727 - reconstruction_loss: 1904.8927 - kl_loss: 80.6711 - false_loss: 0.0790 - true_loss: 1.0464 - val_loss: 5056.4800 - val_reconstruction_loss: 1895.4894 - val_kl_loss: 99.7168 - val_false_loss: 9.8347 - val_true_loss: 1.1086\n",
      "Epoch 1830/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2357.3623 - reconstruction_loss: 1908.8793 - kl_loss: 81.8648 - false_loss: 0.0790 - true_loss: 1.0465 - val_loss: 5056.1943 - val_reconstruction_loss: 1895.4900 - val_kl_loss: 99.7153 - val_false_loss: 9.8337 - val_true_loss: 1.1086\n",
      "Epoch 1831/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2365.1906 - reconstruction_loss: 1908.3848 - kl_loss: 83.1479 - false_loss: 0.0790 - true_loss: 1.0465 - val_loss: 5055.9067 - val_reconstruction_loss: 1895.4908 - val_kl_loss: 99.7135 - val_false_loss: 9.8328 - val_true_loss: 1.1087\n",
      "Epoch 1832/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2378.0474 - reconstruction_loss: 1906.8217 - kl_loss: 82.5662 - false_loss: 0.0790 - true_loss: 1.0465 - val_loss: 5055.6196 - val_reconstruction_loss: 1895.4916 - val_kl_loss: 99.7117 - val_false_loss: 9.8318 - val_true_loss: 1.1087\n",
      "Epoch 1833/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2409.8762 - reconstruction_loss: 1905.5692 - kl_loss: 80.5978 - false_loss: 0.0790 - true_loss: 1.0465 - val_loss: 5055.3325 - val_reconstruction_loss: 1895.4919 - val_kl_loss: 99.7097 - val_false_loss: 9.8308 - val_true_loss: 1.1087\n",
      "Epoch 1834/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2423.6362 - reconstruction_loss: 1905.3413 - kl_loss: 80.5615 - false_loss: 0.0790 - true_loss: 1.0466 - val_loss: 5055.0488 - val_reconstruction_loss: 1895.4924 - val_kl_loss: 99.7078 - val_false_loss: 9.8299 - val_true_loss: 1.1088\n",
      "Epoch 1835/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2435.4125 - reconstruction_loss: 1905.6337 - kl_loss: 79.3349 - false_loss: 0.0790 - true_loss: 1.0466 - val_loss: 5054.7642 - val_reconstruction_loss: 1895.4932 - val_kl_loss: 99.7059 - val_false_loss: 9.8289 - val_true_loss: 1.1088\n",
      "Epoch 1836/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2428.3731 - reconstruction_loss: 1906.7255 - kl_loss: 78.9272 - false_loss: 0.0790 - true_loss: 1.0466 - val_loss: 5054.4785 - val_reconstruction_loss: 1895.4938 - val_kl_loss: 99.7038 - val_false_loss: 9.8280 - val_true_loss: 1.1089\n",
      "Epoch 1837/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2420.5460 - reconstruction_loss: 1905.4738 - kl_loss: 77.5248 - false_loss: 0.0790 - true_loss: 1.0467 - val_loss: 5054.1919 - val_reconstruction_loss: 1895.4943 - val_kl_loss: 99.7016 - val_false_loss: 9.8270 - val_true_loss: 1.1089\n",
      "Epoch 1838/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2412.1375 - reconstruction_loss: 1904.6715 - kl_loss: 77.3840 - false_loss: 0.0790 - true_loss: 1.0467 - val_loss: 5053.9043 - val_reconstruction_loss: 1895.4946 - val_kl_loss: 99.6995 - val_false_loss: 9.8260 - val_true_loss: 1.1089\n",
      "Epoch 1839/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2408.7536 - reconstruction_loss: 1904.5566 - kl_loss: 78.1630 - false_loss: 0.0790 - true_loss: 1.0468 - val_loss: 5053.6177 - val_reconstruction_loss: 1895.4951 - val_kl_loss: 99.6974 - val_false_loss: 9.8251 - val_true_loss: 1.1090\n",
      "Epoch 1840/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2403.9416 - reconstruction_loss: 1905.3525 - kl_loss: 78.7341 - false_loss: 0.0790 - true_loss: 1.0468 - val_loss: 5053.3306 - val_reconstruction_loss: 1895.4957 - val_kl_loss: 99.6952 - val_false_loss: 9.8241 - val_true_loss: 1.1090\n",
      "Epoch 1841/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2399.7903 - reconstruction_loss: 1906.4532 - kl_loss: 78.3904 - false_loss: 0.0790 - true_loss: 1.0468 - val_loss: 5053.0449 - val_reconstruction_loss: 1895.4965 - val_kl_loss: 99.6931 - val_false_loss: 9.8231 - val_true_loss: 1.1090\n",
      "Epoch 1842/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2408.1814 - reconstruction_loss: 1905.5653 - kl_loss: 77.8289 - false_loss: 0.0790 - true_loss: 1.0469 - val_loss: 5052.7607 - val_reconstruction_loss: 1895.4971 - val_kl_loss: 99.6907 - val_false_loss: 9.8222 - val_true_loss: 1.1091\n",
      "Epoch 1843/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2462.3134 - reconstruction_loss: 1906.8304 - kl_loss: 69.2696 - false_loss: 0.0790 - true_loss: 1.0469 - val_loss: 5052.4863 - val_reconstruction_loss: 1895.4977 - val_kl_loss: 99.6870 - val_false_loss: 9.8212 - val_true_loss: 1.1092\n",
      "Epoch 1844/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2558.4549 - reconstruction_loss: 1908.1149 - kl_loss: 65.7254 - false_loss: 0.0791 - true_loss: 1.0470 - val_loss: 5052.2065 - val_reconstruction_loss: 1895.4984 - val_kl_loss: 99.6841 - val_false_loss: 9.8203 - val_true_loss: 1.1092\n",
      "Epoch 1845/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2453.9234 - reconstruction_loss: 1906.7686 - kl_loss: 71.4860 - false_loss: 0.0791 - true_loss: 1.0470 - val_loss: 5051.9209 - val_reconstruction_loss: 1895.4993 - val_kl_loss: 99.6820 - val_false_loss: 9.8193 - val_true_loss: 1.1093\n",
      "Epoch 1846/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2398.1595 - reconstruction_loss: 1906.0011 - kl_loss: 78.7960 - false_loss: 0.0791 - true_loss: 1.0471 - val_loss: 5051.6338 - val_reconstruction_loss: 1895.4999 - val_kl_loss: 99.6801 - val_false_loss: 9.8184 - val_true_loss: 1.1093\n",
      "Epoch 1847/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2386.3761 - reconstruction_loss: 1907.1201 - kl_loss: 81.1655 - false_loss: 0.0791 - true_loss: 1.0471 - val_loss: 5051.3481 - val_reconstruction_loss: 1895.5006 - val_kl_loss: 99.6783 - val_false_loss: 9.8174 - val_true_loss: 1.1093\n",
      "Epoch 1848/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2375.7788 - reconstruction_loss: 1906.1274 - kl_loss: 81.6270 - false_loss: 0.0791 - true_loss: 1.0471 - val_loss: 5051.0630 - val_reconstruction_loss: 1895.5010 - val_kl_loss: 99.6766 - val_false_loss: 9.8165 - val_true_loss: 1.1094\n",
      "Epoch 1849/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2396.4727 - reconstruction_loss: 1905.1234 - kl_loss: 80.3588 - false_loss: 0.0791 - true_loss: 1.0471 - val_loss: 5050.7754 - val_reconstruction_loss: 1895.5015 - val_kl_loss: 99.6748 - val_false_loss: 9.8155 - val_true_loss: 1.1094\n",
      "Epoch 1850/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2384.9214 - reconstruction_loss: 1904.4691 - kl_loss: 81.1178 - false_loss: 0.0791 - true_loss: 1.0472 - val_loss: 5050.4912 - val_reconstruction_loss: 1895.5020 - val_kl_loss: 99.6729 - val_false_loss: 9.8146 - val_true_loss: 1.1094\n",
      "Epoch 1851/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2425.5495 - reconstruction_loss: 1904.8114 - kl_loss: 80.1866 - false_loss: 0.0791 - true_loss: 1.0472 - val_loss: 5050.2065 - val_reconstruction_loss: 1895.5023 - val_kl_loss: 99.6711 - val_false_loss: 9.8136 - val_true_loss: 1.1095\n",
      "Epoch 1852/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2414.3922 - reconstruction_loss: 1904.7035 - kl_loss: 79.3534 - false_loss: 0.0791 - true_loss: 1.0472 - val_loss: 5049.9194 - val_reconstruction_loss: 1895.5028 - val_kl_loss: 99.6688 - val_false_loss: 9.8126 - val_true_loss: 1.1095\n",
      "Epoch 1853/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2427.4132 - reconstruction_loss: 1904.6971 - kl_loss: 72.3263 - false_loss: 0.0791 - true_loss: 1.0473 - val_loss: 5049.6455 - val_reconstruction_loss: 1895.5033 - val_kl_loss: 99.6657 - val_false_loss: 9.8117 - val_true_loss: 1.1096\n",
      "Epoch 1854/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2603.7665 - reconstruction_loss: 1905.8340 - kl_loss: 65.9033 - false_loss: 0.0791 - true_loss: 1.0473 - val_loss: 5049.3633 - val_reconstruction_loss: 1895.5037 - val_kl_loss: 99.6629 - val_false_loss: 9.8107 - val_true_loss: 1.1097\n",
      "Epoch 1855/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2484.5749 - reconstruction_loss: 1905.4795 - kl_loss: 68.3268 - false_loss: 0.0791 - true_loss: 1.0474 - val_loss: 5049.0762 - val_reconstruction_loss: 1895.5044 - val_kl_loss: 99.6605 - val_false_loss: 9.8098 - val_true_loss: 1.1097\n",
      "Epoch 1856/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2397.8196 - reconstruction_loss: 1904.9033 - kl_loss: 76.7783 - false_loss: 0.0791 - true_loss: 1.0474 - val_loss: 5048.7881 - val_reconstruction_loss: 1895.5050 - val_kl_loss: 99.6583 - val_false_loss: 9.8088 - val_true_loss: 1.1098\n",
      "Epoch 1857/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2359.3052 - reconstruction_loss: 1904.3140 - kl_loss: 79.9408 - false_loss: 0.0791 - true_loss: 1.0475 - val_loss: 5048.5005 - val_reconstruction_loss: 1895.5052 - val_kl_loss: 99.6566 - val_false_loss: 9.8078 - val_true_loss: 1.1098\n",
      "Epoch 1858/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2347.6541 - reconstruction_loss: 1904.8096 - kl_loss: 82.1921 - false_loss: 0.0791 - true_loss: 1.0475 - val_loss: 5048.2134 - val_reconstruction_loss: 1895.5055 - val_kl_loss: 99.6550 - val_false_loss: 9.8069 - val_true_loss: 1.1098\n",
      "Epoch 1859/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2371.6293 - reconstruction_loss: 1905.0361 - kl_loss: 82.6719 - false_loss: 0.0791 - true_loss: 1.0475 - val_loss: 5047.9263 - val_reconstruction_loss: 1895.5063 - val_kl_loss: 99.6533 - val_false_loss: 9.8059 - val_true_loss: 1.1098\n",
      "Epoch 1860/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2386.9517 - reconstruction_loss: 1905.0189 - kl_loss: 82.7284 - false_loss: 0.0791 - true_loss: 1.0475 - val_loss: 5047.6396 - val_reconstruction_loss: 1895.5068 - val_kl_loss: 99.6516 - val_false_loss: 9.8050 - val_true_loss: 1.1098\n",
      "Epoch 1861/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2389.1011 - reconstruction_loss: 1904.2184 - kl_loss: 81.7135 - false_loss: 0.0791 - true_loss: 1.0476 - val_loss: 5047.3564 - val_reconstruction_loss: 1895.5073 - val_kl_loss: 99.6499 - val_false_loss: 9.8040 - val_true_loss: 1.1099\n",
      "Epoch 1862/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2405.2434 - reconstruction_loss: 1904.2568 - kl_loss: 81.6712 - false_loss: 0.0791 - true_loss: 1.0476 - val_loss: 5047.0708 - val_reconstruction_loss: 1895.5079 - val_kl_loss: 99.6481 - val_false_loss: 9.8030 - val_true_loss: 1.1099\n",
      "Epoch 1863/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2394.7193 - reconstruction_loss: 1905.8519 - kl_loss: 80.7287 - false_loss: 0.0791 - true_loss: 1.0476 - val_loss: 5046.7852 - val_reconstruction_loss: 1895.5084 - val_kl_loss: 99.6464 - val_false_loss: 9.8021 - val_true_loss: 1.1099\n",
      "Epoch 1864/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2385.4234 - reconstruction_loss: 1904.8217 - kl_loss: 81.0892 - false_loss: 0.0791 - true_loss: 1.0476 - val_loss: 5046.4980 - val_reconstruction_loss: 1895.5090 - val_kl_loss: 99.6447 - val_false_loss: 9.8011 - val_true_loss: 1.1099\n",
      "Epoch 1865/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2381.3672 - reconstruction_loss: 1904.5490 - kl_loss: 80.7367 - false_loss: 0.0791 - true_loss: 1.0477 - val_loss: 5046.2119 - val_reconstruction_loss: 1895.5095 - val_kl_loss: 99.6430 - val_false_loss: 9.8002 - val_true_loss: 1.1100\n",
      "Epoch 1866/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2380.4328 - reconstruction_loss: 1904.2006 - kl_loss: 80.0233 - false_loss: 0.0791 - true_loss: 1.0477 - val_loss: 5045.9253 - val_reconstruction_loss: 1895.5099 - val_kl_loss: 99.6412 - val_false_loss: 9.7992 - val_true_loss: 1.1100\n",
      "Epoch 1867/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2377.0498 - reconstruction_loss: 1904.6681 - kl_loss: 80.5687 - false_loss: 0.0791 - true_loss: 1.0477 - val_loss: 5045.6396 - val_reconstruction_loss: 1895.5104 - val_kl_loss: 99.6393 - val_false_loss: 9.7983 - val_true_loss: 1.1100\n",
      "Epoch 1868/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2381.7335 - reconstruction_loss: 1904.8179 - kl_loss: 80.3482 - false_loss: 0.0791 - true_loss: 1.0477 - val_loss: 5045.3540 - val_reconstruction_loss: 1895.5109 - val_kl_loss: 99.6374 - val_false_loss: 9.7973 - val_true_loss: 1.1100\n",
      "Epoch 1869/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2380.3679 - reconstruction_loss: 1904.5541 - kl_loss: 80.2925 - false_loss: 0.0791 - true_loss: 1.0478 - val_loss: 5045.0679 - val_reconstruction_loss: 1895.5112 - val_kl_loss: 99.6356 - val_false_loss: 9.7963 - val_true_loss: 1.1101\n",
      "Epoch 1870/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2378.0281 - reconstruction_loss: 1904.2910 - kl_loss: 80.9463 - false_loss: 0.0791 - true_loss: 1.0478 - val_loss: 5044.7817 - val_reconstruction_loss: 1895.5117 - val_kl_loss: 99.6339 - val_false_loss: 9.7954 - val_true_loss: 1.1101\n",
      "Epoch 1871/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2378.3329 - reconstruction_loss: 1904.0563 - kl_loss: 78.3186 - false_loss: 0.0791 - true_loss: 1.0478 - val_loss: 5044.4951 - val_reconstruction_loss: 1895.5122 - val_kl_loss: 99.6316 - val_false_loss: 9.7944 - val_true_loss: 1.1101\n",
      "Epoch 1872/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2435.8665 - reconstruction_loss: 1904.8602 - kl_loss: 69.1986 - false_loss: 0.0791 - true_loss: 1.0478 - val_loss: 5044.2114 - val_reconstruction_loss: 1895.5127 - val_kl_loss: 99.6279 - val_false_loss: 9.7935 - val_true_loss: 1.1102\n",
      "Epoch 1873/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2538.7920 - reconstruction_loss: 1905.1348 - kl_loss: 69.3479 - false_loss: 0.0792 - true_loss: 1.0479 - val_loss: 5043.9258 - val_reconstruction_loss: 1895.5131 - val_kl_loss: 99.6254 - val_false_loss: 9.7925 - val_true_loss: 1.1102\n",
      "Epoch 1874/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2412.2948 - reconstruction_loss: 1904.4293 - kl_loss: 73.6517 - false_loss: 0.0792 - true_loss: 1.0480 - val_loss: 5043.6396 - val_reconstruction_loss: 1895.5135 - val_kl_loss: 99.6235 - val_false_loss: 9.7916 - val_true_loss: 1.1102\n",
      "Epoch 1875/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2388.2208 - reconstruction_loss: 1904.6475 - kl_loss: 80.1746 - false_loss: 0.0792 - true_loss: 1.0480 - val_loss: 5043.3530 - val_reconstruction_loss: 1895.5140 - val_kl_loss: 99.6217 - val_false_loss: 9.7906 - val_true_loss: 1.1103\n",
      "Epoch 1876/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2390.0693 - reconstruction_loss: 1904.2760 - kl_loss: 81.9240 - false_loss: 0.0792 - true_loss: 1.0480 - val_loss: 5043.0664 - val_reconstruction_loss: 1895.5144 - val_kl_loss: 99.6201 - val_false_loss: 9.7896 - val_true_loss: 1.1103\n",
      "Epoch 1877/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2366.2941 - reconstruction_loss: 1903.8180 - kl_loss: 82.3005 - false_loss: 0.0792 - true_loss: 1.0480 - val_loss: 5042.7812 - val_reconstruction_loss: 1895.5151 - val_kl_loss: 99.6186 - val_false_loss: 9.7887 - val_true_loss: 1.1103\n",
      "Epoch 1878/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2386.8111 - reconstruction_loss: 1904.5167 - kl_loss: 82.3214 - false_loss: 0.0792 - true_loss: 1.0481 - val_loss: 5042.4951 - val_reconstruction_loss: 1895.5155 - val_kl_loss: 99.6168 - val_false_loss: 9.7877 - val_true_loss: 1.1103\n",
      "Epoch 1879/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2382.0955 - reconstruction_loss: 1903.9785 - kl_loss: 81.6108 - false_loss: 0.0792 - true_loss: 1.0481 - val_loss: 5042.2104 - val_reconstruction_loss: 1895.5160 - val_kl_loss: 99.6149 - val_false_loss: 9.7868 - val_true_loss: 1.1104\n",
      "Epoch 1880/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2390.4479 - reconstruction_loss: 1903.9733 - kl_loss: 81.4406 - false_loss: 0.0792 - true_loss: 1.0481 - val_loss: 5041.9258 - val_reconstruction_loss: 1895.5165 - val_kl_loss: 99.6132 - val_false_loss: 9.7858 - val_true_loss: 1.1104\n",
      "Epoch 1881/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2389.7635 - reconstruction_loss: 1903.9960 - kl_loss: 80.4779 - false_loss: 0.0792 - true_loss: 1.0481 - val_loss: 5041.6401 - val_reconstruction_loss: 1895.5168 - val_kl_loss: 99.6116 - val_false_loss: 9.7849 - val_true_loss: 1.1104\n",
      "Epoch 1882/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2376.5728 - reconstruction_loss: 1903.6294 - kl_loss: 81.2849 - false_loss: 0.0792 - true_loss: 1.0482 - val_loss: 5041.3555 - val_reconstruction_loss: 1895.5173 - val_kl_loss: 99.6098 - val_false_loss: 9.7839 - val_true_loss: 1.1104\n",
      "Epoch 1883/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2380.1956 - reconstruction_loss: 1904.5580 - kl_loss: 81.2252 - false_loss: 0.0792 - true_loss: 1.0482 - val_loss: 5041.0703 - val_reconstruction_loss: 1895.5178 - val_kl_loss: 99.6080 - val_false_loss: 9.7830 - val_true_loss: 1.1105\n",
      "Epoch 1884/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2374.9785 - reconstruction_loss: 1903.8707 - kl_loss: 81.4556 - false_loss: 0.0792 - true_loss: 1.0482 - val_loss: 5040.7856 - val_reconstruction_loss: 1895.5181 - val_kl_loss: 99.6062 - val_false_loss: 9.7820 - val_true_loss: 1.1105\n",
      "Epoch 1885/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2372.6369 - reconstruction_loss: 1903.7627 - kl_loss: 81.2163 - false_loss: 0.0792 - true_loss: 1.0482 - val_loss: 5040.5015 - val_reconstruction_loss: 1895.5184 - val_kl_loss: 99.6044 - val_false_loss: 9.7811 - val_true_loss: 1.1105\n",
      "Epoch 1886/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2377.2128 - reconstruction_loss: 1904.2305 - kl_loss: 80.1916 - false_loss: 0.0792 - true_loss: 1.0482 - val_loss: 5040.2173 - val_reconstruction_loss: 1895.5189 - val_kl_loss: 99.6028 - val_false_loss: 9.7801 - val_true_loss: 1.1105\n",
      "Epoch 1887/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2373.0147 - reconstruction_loss: 1904.2695 - kl_loss: 80.7144 - false_loss: 0.0792 - true_loss: 1.0483 - val_loss: 5039.9331 - val_reconstruction_loss: 1895.5194 - val_kl_loss: 99.6011 - val_false_loss: 9.7792 - val_true_loss: 1.1106\n",
      "Epoch 1888/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2373.2285 - reconstruction_loss: 1906.3046 - kl_loss: 81.2136 - false_loss: 0.0792 - true_loss: 1.0483 - val_loss: 5039.6484 - val_reconstruction_loss: 1895.5203 - val_kl_loss: 99.5993 - val_false_loss: 9.7782 - val_true_loss: 1.1106\n",
      "Epoch 1889/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2368.6998 - reconstruction_loss: 1905.2168 - kl_loss: 79.8313 - false_loss: 0.0792 - true_loss: 1.0483 - val_loss: 5039.3633 - val_reconstruction_loss: 1895.5206 - val_kl_loss: 99.5973 - val_false_loss: 9.7773 - val_true_loss: 1.1106\n",
      "Epoch 1890/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2376.0330 - reconstruction_loss: 1906.1396 - kl_loss: 80.5175 - false_loss: 0.0792 - true_loss: 1.0483 - val_loss: 5039.0776 - val_reconstruction_loss: 1895.5214 - val_kl_loss: 99.5951 - val_false_loss: 9.7763 - val_true_loss: 1.1106\n",
      "Epoch 1891/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2366.9527 - reconstruction_loss: 1904.5137 - kl_loss: 79.0776 - false_loss: 0.0792 - true_loss: 1.0483 - val_loss: 5038.7915 - val_reconstruction_loss: 1895.5216 - val_kl_loss: 99.5934 - val_false_loss: 9.7753 - val_true_loss: 1.1106\n",
      "Epoch 1892/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2357.8744 - reconstruction_loss: 1903.6398 - kl_loss: 81.7550 - false_loss: 0.0792 - true_loss: 1.0484 - val_loss: 5038.5073 - val_reconstruction_loss: 1895.5220 - val_kl_loss: 99.5916 - val_false_loss: 9.7744 - val_true_loss: 1.1107\n",
      "Epoch 1893/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2370.3387 - reconstruction_loss: 1903.9941 - kl_loss: 78.7042 - false_loss: 0.0792 - true_loss: 1.0484 - val_loss: 5038.2222 - val_reconstruction_loss: 1895.5228 - val_kl_loss: 99.5887 - val_false_loss: 9.7734 - val_true_loss: 1.1107\n",
      "Epoch 1894/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2412.9320 - reconstruction_loss: 1904.9579 - kl_loss: 72.9395 - false_loss: 0.0792 - true_loss: 1.0484 - val_loss: 5037.9390 - val_reconstruction_loss: 1895.5233 - val_kl_loss: 99.5857 - val_false_loss: 9.7725 - val_true_loss: 1.1108\n",
      "Epoch 1895/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2413.8521 - reconstruction_loss: 1904.7916 - kl_loss: 74.0312 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5037.6519 - val_reconstruction_loss: 1895.5238 - val_kl_loss: 99.5837 - val_false_loss: 9.7715 - val_true_loss: 1.1108\n",
      "Epoch 1896/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2323.1148 - reconstruction_loss: 1904.1108 - kl_loss: 81.1576 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5037.3643 - val_reconstruction_loss: 1895.5242 - val_kl_loss: 99.5822 - val_false_loss: 9.7706 - val_true_loss: 1.1108\n",
      "Epoch 1897/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2315.0428 - reconstruction_loss: 1903.9957 - kl_loss: 84.5315 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5037.0781 - val_reconstruction_loss: 1895.5247 - val_kl_loss: 99.5810 - val_false_loss: 9.7696 - val_true_loss: 1.1108\n",
      "Epoch 1898/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2313.6527 - reconstruction_loss: 1903.5687 - kl_loss: 85.6013 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5036.7910 - val_reconstruction_loss: 1895.5251 - val_kl_loss: 99.5797 - val_false_loss: 9.7687 - val_true_loss: 1.1108\n",
      "Epoch 1899/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2309.2933 - reconstruction_loss: 1904.3955 - kl_loss: 86.6628 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5036.5039 - val_reconstruction_loss: 1895.5255 - val_kl_loss: 99.5784 - val_false_loss: 9.7677 - val_true_loss: 1.1108\n",
      "Epoch 1900/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2311.5190 - reconstruction_loss: 1903.6661 - kl_loss: 85.3707 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5036.2178 - val_reconstruction_loss: 1895.5258 - val_kl_loss: 99.5768 - val_false_loss: 9.7668 - val_true_loss: 1.1108\n",
      "Epoch 1901/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2318.2546 - reconstruction_loss: 1903.8075 - kl_loss: 82.5994 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5035.9307 - val_reconstruction_loss: 1895.5262 - val_kl_loss: 99.5754 - val_false_loss: 9.7658 - val_true_loss: 1.1108\n",
      "Epoch 1902/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2312.8320 - reconstruction_loss: 1903.8365 - kl_loss: 87.6210 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5035.6436 - val_reconstruction_loss: 1895.5267 - val_kl_loss: 99.5743 - val_false_loss: 9.7649 - val_true_loss: 1.1108\n",
      "Epoch 1903/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2311.3472 - reconstruction_loss: 1903.6354 - kl_loss: 86.6013 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5035.3569 - val_reconstruction_loss: 1895.5270 - val_kl_loss: 99.5726 - val_false_loss: 9.7639 - val_true_loss: 1.1108\n",
      "Epoch 1904/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2427.4498 - reconstruction_loss: 1905.8130 - kl_loss: 69.6046 - false_loss: 0.0792 - true_loss: 1.0485 - val_loss: 5035.0723 - val_reconstruction_loss: 1895.5276 - val_kl_loss: 99.5687 - val_false_loss: 9.7630 - val_true_loss: 1.1108\n",
      "Epoch 1905/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2487.4428 - reconstruction_loss: 1905.4850 - kl_loss: 71.3299 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5034.7905 - val_reconstruction_loss: 1895.5281 - val_kl_loss: 99.5656 - val_false_loss: 9.7620 - val_true_loss: 1.1109\n",
      "Epoch 1906/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2397.3466 - reconstruction_loss: 1904.3617 - kl_loss: 75.7144 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5034.5049 - val_reconstruction_loss: 1895.5283 - val_kl_loss: 99.5640 - val_false_loss: 9.7611 - val_true_loss: 1.1109\n",
      "Epoch 1907/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2355.4851 - reconstruction_loss: 1903.8623 - kl_loss: 82.2832 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5034.2173 - val_reconstruction_loss: 1895.5289 - val_kl_loss: 99.5625 - val_false_loss: 9.7601 - val_true_loss: 1.1109\n",
      "Epoch 1908/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2331.9884 - reconstruction_loss: 1903.7881 - kl_loss: 86.2082 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5033.9321 - val_reconstruction_loss: 1895.5294 - val_kl_loss: 99.5617 - val_false_loss: 9.7591 - val_true_loss: 1.1109\n",
      "Epoch 1909/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2324.6484 - reconstruction_loss: 1908.4886 - kl_loss: 87.8162 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5033.6470 - val_reconstruction_loss: 1895.5304 - val_kl_loss: 99.5606 - val_false_loss: 9.7582 - val_true_loss: 1.1109\n",
      "Epoch 1910/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2326.0340 - reconstruction_loss: 1907.5707 - kl_loss: 89.8143 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5033.3613 - val_reconstruction_loss: 1895.5311 - val_kl_loss: 99.5595 - val_false_loss: 9.7572 - val_true_loss: 1.1109\n",
      "Epoch 1911/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2319.4926 - reconstruction_loss: 1904.5648 - kl_loss: 88.6535 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5033.0767 - val_reconstruction_loss: 1895.5315 - val_kl_loss: 99.5586 - val_false_loss: 9.7563 - val_true_loss: 1.1109\n",
      "Epoch 1912/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2315.9914 - reconstruction_loss: 1907.0532 - kl_loss: 89.6145 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5032.7920 - val_reconstruction_loss: 1895.5323 - val_kl_loss: 99.5577 - val_false_loss: 9.7554 - val_true_loss: 1.1109\n",
      "Epoch 1913/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2315.1071 - reconstruction_loss: 1905.4791 - kl_loss: 89.5037 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5032.5063 - val_reconstruction_loss: 1895.5328 - val_kl_loss: 99.5568 - val_false_loss: 9.7544 - val_true_loss: 1.1109\n",
      "Epoch 1914/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2310.7842 - reconstruction_loss: 1904.0236 - kl_loss: 89.7760 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5032.2222 - val_reconstruction_loss: 1895.5332 - val_kl_loss: 99.5560 - val_false_loss: 9.7535 - val_true_loss: 1.1109\n",
      "Epoch 1915/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2310.5149 - reconstruction_loss: 1903.5951 - kl_loss: 90.0477 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5031.9375 - val_reconstruction_loss: 1895.5334 - val_kl_loss: 99.5552 - val_false_loss: 9.7525 - val_true_loss: 1.1109\n",
      "Epoch 1916/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2312.4582 - reconstruction_loss: 1903.4878 - kl_loss: 90.5152 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5031.6523 - val_reconstruction_loss: 1895.5339 - val_kl_loss: 99.5542 - val_false_loss: 9.7516 - val_true_loss: 1.1109\n",
      "Epoch 1917/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2331.8739 - reconstruction_loss: 1903.8258 - kl_loss: 89.7030 - false_loss: 0.0792 - true_loss: 1.0486 - val_loss: 5031.3696 - val_reconstruction_loss: 1895.5344 - val_kl_loss: 99.5532 - val_false_loss: 9.7506 - val_true_loss: 1.1109\n",
      "Epoch 1918/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2380.3788 - reconstruction_loss: 1903.3184 - kl_loss: 86.7426 - false_loss: 0.0792 - true_loss: 1.0487 - val_loss: 5031.0874 - val_reconstruction_loss: 1895.5348 - val_kl_loss: 99.5521 - val_false_loss: 9.7497 - val_true_loss: 1.1109\n",
      "Epoch 1919/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2368.9817 - reconstruction_loss: 1903.4869 - kl_loss: 88.2692 - false_loss: 0.0792 - true_loss: 1.0487 - val_loss: 5030.8037 - val_reconstruction_loss: 1895.5353 - val_kl_loss: 99.5509 - val_false_loss: 9.7487 - val_true_loss: 1.1109\n",
      "Epoch 1920/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2366.1085 - reconstruction_loss: 1903.9580 - kl_loss: 86.4117 - false_loss: 0.0792 - true_loss: 1.0487 - val_loss: 5030.5200 - val_reconstruction_loss: 1895.5355 - val_kl_loss: 99.5497 - val_false_loss: 9.7478 - val_true_loss: 1.1109\n",
      "Epoch 1921/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2360.8687 - reconstruction_loss: 1903.6520 - kl_loss: 85.8202 - false_loss: 0.0792 - true_loss: 1.0487 - val_loss: 5030.2368 - val_reconstruction_loss: 1895.5360 - val_kl_loss: 99.5485 - val_false_loss: 9.7468 - val_true_loss: 1.1110\n",
      "Epoch 1922/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2357.6006 - reconstruction_loss: 1903.5273 - kl_loss: 85.5183 - false_loss: 0.0792 - true_loss: 1.0487 - val_loss: 5029.9531 - val_reconstruction_loss: 1895.5363 - val_kl_loss: 99.5473 - val_false_loss: 9.7459 - val_true_loss: 1.1110\n",
      "Epoch 1923/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2357.3803 - reconstruction_loss: 1903.4381 - kl_loss: 83.1617 - false_loss: 0.0792 - true_loss: 1.0487 - val_loss: 5029.6685 - val_reconstruction_loss: 1895.5366 - val_kl_loss: 99.5453 - val_false_loss: 9.7449 - val_true_loss: 1.1110\n",
      "Epoch 1924/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2443.3945 - reconstruction_loss: 1906.0365 - kl_loss: 68.7132 - false_loss: 0.0792 - true_loss: 1.0488 - val_loss: 5029.3960 - val_reconstruction_loss: 1895.5375 - val_kl_loss: 99.5420 - val_false_loss: 9.7440 - val_true_loss: 1.1111\n",
      "Epoch 1925/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 15s 1s/step - loss: 2519.4781 - reconstruction_loss: 1905.3258 - kl_loss: 69.6146 - false_loss: 0.0792 - true_loss: 1.0489 - val_loss: 5029.1143 - val_reconstruction_loss: 1895.5380 - val_kl_loss: 99.5394 - val_false_loss: 9.7431 - val_true_loss: 1.1111\n",
      "Epoch 1926/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2398.3288 - reconstruction_loss: 1904.0433 - kl_loss: 77.1929 - false_loss: 0.0793 - true_loss: 1.0489 - val_loss: 5028.8345 - val_reconstruction_loss: 1895.5385 - val_kl_loss: 99.5372 - val_false_loss: 9.7421 - val_true_loss: 1.1112\n",
      "Epoch 1927/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2390.7151 - reconstruction_loss: 1903.5531 - kl_loss: 82.8666 - false_loss: 0.0793 - true_loss: 1.0489 - val_loss: 5028.5503 - val_reconstruction_loss: 1895.5387 - val_kl_loss: 99.5357 - val_false_loss: 9.7412 - val_true_loss: 1.1112\n",
      "Epoch 1928/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2371.7560 - reconstruction_loss: 1903.3116 - kl_loss: 83.1274 - false_loss: 0.0793 - true_loss: 1.0489 - val_loss: 5028.2671 - val_reconstruction_loss: 1895.5391 - val_kl_loss: 99.5345 - val_false_loss: 9.7402 - val_true_loss: 1.1112\n",
      "Epoch 1929/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2360.0223 - reconstruction_loss: 1903.1136 - kl_loss: 84.5042 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5027.9839 - val_reconstruction_loss: 1895.5393 - val_kl_loss: 99.5333 - val_false_loss: 9.7393 - val_true_loss: 1.1112\n",
      "Epoch 1930/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2358.8183 - reconstruction_loss: 1903.8866 - kl_loss: 86.3163 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5027.6992 - val_reconstruction_loss: 1895.5398 - val_kl_loss: 99.5318 - val_false_loss: 9.7383 - val_true_loss: 1.1112\n",
      "Epoch 1931/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2348.2080 - reconstruction_loss: 1903.0581 - kl_loss: 86.0454 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5027.4165 - val_reconstruction_loss: 1895.5400 - val_kl_loss: 99.5305 - val_false_loss: 9.7374 - val_true_loss: 1.1112\n",
      "Epoch 1932/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2348.6555 - reconstruction_loss: 1903.6698 - kl_loss: 86.0289 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5027.1338 - val_reconstruction_loss: 1895.5403 - val_kl_loss: 99.5293 - val_false_loss: 9.7364 - val_true_loss: 1.1112\n",
      "Epoch 1933/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2345.8280 - reconstruction_loss: 1903.3043 - kl_loss: 85.9379 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5026.8516 - val_reconstruction_loss: 1895.5408 - val_kl_loss: 99.5279 - val_false_loss: 9.7355 - val_true_loss: 1.1112\n",
      "Epoch 1934/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2345.7591 - reconstruction_loss: 1903.1273 - kl_loss: 84.6817 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5026.5684 - val_reconstruction_loss: 1895.5411 - val_kl_loss: 99.5264 - val_false_loss: 9.7346 - val_true_loss: 1.1113\n",
      "Epoch 1935/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2347.0217 - reconstruction_loss: 1903.0498 - kl_loss: 83.9259 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5026.2847 - val_reconstruction_loss: 1895.5413 - val_kl_loss: 99.5249 - val_false_loss: 9.7336 - val_true_loss: 1.1113\n",
      "Epoch 1936/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2346.2157 - reconstruction_loss: 1903.7422 - kl_loss: 83.0502 - false_loss: 0.0793 - true_loss: 1.0490 - val_loss: 5026.0020 - val_reconstruction_loss: 1895.5416 - val_kl_loss: 99.5234 - val_false_loss: 9.7327 - val_true_loss: 1.1113\n",
      "Epoch 1937/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2347.2394 - reconstruction_loss: 1903.2003 - kl_loss: 84.3909 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5025.7197 - val_reconstruction_loss: 1895.5421 - val_kl_loss: 99.5221 - val_false_loss: 9.7317 - val_true_loss: 1.1113\n",
      "Epoch 1938/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2339.7093 - reconstruction_loss: 1903.1388 - kl_loss: 85.5130 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5025.4375 - val_reconstruction_loss: 1895.5424 - val_kl_loss: 99.5208 - val_false_loss: 9.7308 - val_true_loss: 1.1113\n",
      "Epoch 1939/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2345.5034 - reconstruction_loss: 1903.6407 - kl_loss: 84.3905 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5025.1543 - val_reconstruction_loss: 1895.5427 - val_kl_loss: 99.5195 - val_false_loss: 9.7298 - val_true_loss: 1.1113\n",
      "Epoch 1940/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2338.4936 - reconstruction_loss: 1903.0338 - kl_loss: 85.1260 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5024.8716 - val_reconstruction_loss: 1895.5430 - val_kl_loss: 99.5181 - val_false_loss: 9.7289 - val_true_loss: 1.1113\n",
      "Epoch 1941/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2337.3587 - reconstruction_loss: 1903.1338 - kl_loss: 84.7969 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5024.5889 - val_reconstruction_loss: 1895.5432 - val_kl_loss: 99.5166 - val_false_loss: 9.7280 - val_true_loss: 1.1113\n",
      "Epoch 1942/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2339.7111 - reconstruction_loss: 1902.9883 - kl_loss: 85.0307 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5024.3062 - val_reconstruction_loss: 1895.5437 - val_kl_loss: 99.5153 - val_false_loss: 9.7270 - val_true_loss: 1.1113\n",
      "Epoch 1943/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2340.3876 - reconstruction_loss: 1903.9860 - kl_loss: 84.2547 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5024.0229 - val_reconstruction_loss: 1895.5442 - val_kl_loss: 99.5137 - val_false_loss: 9.7261 - val_true_loss: 1.1114\n",
      "Epoch 1944/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2401.8451 - reconstruction_loss: 1905.1307 - kl_loss: 71.1114 - false_loss: 0.0793 - true_loss: 1.0491 - val_loss: 5023.7422 - val_reconstruction_loss: 1895.5450 - val_kl_loss: 99.5101 - val_false_loss: 9.7251 - val_true_loss: 1.1114\n",
      "Epoch 1945/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2418.8783 - reconstruction_loss: 1907.0243 - kl_loss: 80.7813 - false_loss: 0.0793 - true_loss: 1.0492 - val_loss: 5023.4614 - val_reconstruction_loss: 1895.5454 - val_kl_loss: 99.5074 - val_false_loss: 9.7242 - val_true_loss: 1.1114\n",
      "Epoch 1946/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2376.2643 - reconstruction_loss: 1904.5898 - kl_loss: 76.6918 - false_loss: 0.0793 - true_loss: 1.0492 - val_loss: 5023.1812 - val_reconstruction_loss: 1895.5459 - val_kl_loss: 99.5064 - val_false_loss: 9.7233 - val_true_loss: 1.1114\n",
      "Epoch 1947/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2352.7699 - reconstruction_loss: 1903.6515 - kl_loss: 83.6542 - false_loss: 0.0793 - true_loss: 1.0492 - val_loss: 5022.8975 - val_reconstruction_loss: 1895.5461 - val_kl_loss: 99.5048 - val_false_loss: 9.7223 - val_true_loss: 1.1114\n",
      "Epoch 1948/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2340.8084 - reconstruction_loss: 1903.2852 - kl_loss: 87.8381 - false_loss: 0.0793 - true_loss: 1.0492 - val_loss: 5022.6152 - val_reconstruction_loss: 1895.5466 - val_kl_loss: 99.5037 - val_false_loss: 9.7214 - val_true_loss: 1.1115\n",
      "Epoch 1949/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2343.8958 - reconstruction_loss: 1903.1996 - kl_loss: 86.8174 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5022.3335 - val_reconstruction_loss: 1895.5470 - val_kl_loss: 99.5026 - val_false_loss: 9.7204 - val_true_loss: 1.1115\n",
      "Epoch 1950/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2342.5322 - reconstruction_loss: 1904.7675 - kl_loss: 87.7738 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5022.0513 - val_reconstruction_loss: 1895.5479 - val_kl_loss: 99.5013 - val_false_loss: 9.7195 - val_true_loss: 1.1115\n",
      "Epoch 1951/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2341.2567 - reconstruction_loss: 1905.4816 - kl_loss: 87.2509 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5021.7690 - val_reconstruction_loss: 1895.5483 - val_kl_loss: 99.5002 - val_false_loss: 9.7185 - val_true_loss: 1.1115\n",
      "Epoch 1952/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2330.8127 - reconstruction_loss: 1903.9108 - kl_loss: 87.3813 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5021.4868 - val_reconstruction_loss: 1895.5486 - val_kl_loss: 99.4991 - val_false_loss: 9.7176 - val_true_loss: 1.1115\n",
      "Epoch 1953/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2333.9689 - reconstruction_loss: 1903.3219 - kl_loss: 86.7490 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5021.2051 - val_reconstruction_loss: 1895.5488 - val_kl_loss: 99.4979 - val_false_loss: 9.7167 - val_true_loss: 1.1115\n",
      "Epoch 1954/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2333.4361 - reconstruction_loss: 1903.1206 - kl_loss: 86.2268 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5020.9238 - val_reconstruction_loss: 1895.5492 - val_kl_loss: 99.4968 - val_false_loss: 9.7157 - val_true_loss: 1.1115\n",
      "Epoch 1955/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2333.1019 - reconstruction_loss: 1902.9609 - kl_loss: 86.8227 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5020.6416 - val_reconstruction_loss: 1895.5493 - val_kl_loss: 99.4957 - val_false_loss: 9.7148 - val_true_loss: 1.1115\n",
      "Epoch 1956/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2325.8348 - reconstruction_loss: 1902.8273 - kl_loss: 87.3512 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5020.3594 - val_reconstruction_loss: 1895.5497 - val_kl_loss: 99.4946 - val_false_loss: 9.7138 - val_true_loss: 1.1115\n",
      "Epoch 1957/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2322.3916 - reconstruction_loss: 1902.8920 - kl_loss: 87.5073 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5020.0767 - val_reconstruction_loss: 1895.5502 - val_kl_loss: 99.4935 - val_false_loss: 9.7129 - val_true_loss: 1.1115\n",
      "Epoch 1958/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2321.4900 - reconstruction_loss: 1902.8278 - kl_loss: 86.9894 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5019.7954 - val_reconstruction_loss: 1895.5507 - val_kl_loss: 99.4920 - val_false_loss: 9.7120 - val_true_loss: 1.1115\n",
      "Epoch 1959/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2329.9288 - reconstruction_loss: 1904.9219 - kl_loss: 84.9486 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5019.5146 - val_reconstruction_loss: 1895.5514 - val_kl_loss: 99.4907 - val_false_loss: 9.7110 - val_true_loss: 1.1115\n",
      "Epoch 1960/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2331.2272 - reconstruction_loss: 1905.9908 - kl_loss: 86.4257 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5019.2349 - val_reconstruction_loss: 1895.5519 - val_kl_loss: 99.4895 - val_false_loss: 9.7101 - val_true_loss: 1.1115\n",
      "Epoch 1961/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2332.2994 - reconstruction_loss: 1904.5367 - kl_loss: 86.0918 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5018.9541 - val_reconstruction_loss: 1895.5521 - val_kl_loss: 99.4883 - val_false_loss: 9.7092 - val_true_loss: 1.1115\n",
      "Epoch 1962/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2334.4750 - reconstruction_loss: 1904.6154 - kl_loss: 83.0740 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5018.6729 - val_reconstruction_loss: 1895.5526 - val_kl_loss: 99.4857 - val_false_loss: 9.7082 - val_true_loss: 1.1116\n",
      "Epoch 1963/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2351.9822 - reconstruction_loss: 1903.9459 - kl_loss: 78.8869 - false_loss: 0.0793 - true_loss: 1.0493 - val_loss: 5018.3984 - val_reconstruction_loss: 1895.5529 - val_kl_loss: 99.4840 - val_false_loss: 9.7073 - val_true_loss: 1.1116\n",
      "Epoch 1964/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2342.9341 - reconstruction_loss: 1903.2799 - kl_loss: 84.4517 - false_loss: 0.0793 - true_loss: 1.0494 - val_loss: 5018.1201 - val_reconstruction_loss: 1895.5532 - val_kl_loss: 99.4830 - val_false_loss: 9.7064 - val_true_loss: 1.1116\n",
      "Epoch 1965/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2344.9219 - reconstruction_loss: 1903.5049 - kl_loss: 82.0199 - false_loss: 0.0793 - true_loss: 1.0494 - val_loss: 5017.8413 - val_reconstruction_loss: 1895.5533 - val_kl_loss: 99.4810 - val_false_loss: 9.7055 - val_true_loss: 1.1116\n",
      "Epoch 1966/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2347.9368 - reconstruction_loss: 1903.2152 - kl_loss: 82.7915 - false_loss: 0.0793 - true_loss: 1.0494 - val_loss: 5017.5698 - val_reconstruction_loss: 1895.5537 - val_kl_loss: 99.4795 - val_false_loss: 9.7045 - val_true_loss: 1.1116\n",
      "Epoch 1967/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2479.0390 - reconstruction_loss: 1906.5375 - kl_loss: 69.8225 - false_loss: 0.0793 - true_loss: 1.0494 - val_loss: 5017.3047 - val_reconstruction_loss: 1895.5546 - val_kl_loss: 99.4785 - val_false_loss: 9.7037 - val_true_loss: 1.1117\n",
      "Epoch 1968/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2387.1534 - reconstruction_loss: 1905.8556 - kl_loss: 85.8153 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5017.0225 - val_reconstruction_loss: 1895.5551 - val_kl_loss: 99.4763 - val_false_loss: 9.7027 - val_true_loss: 1.1117\n",
      "Epoch 1969/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2341.6650 - reconstruction_loss: 1904.0348 - kl_loss: 84.3356 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5016.7402 - val_reconstruction_loss: 1895.5554 - val_kl_loss: 99.4755 - val_false_loss: 9.7018 - val_true_loss: 1.1117\n",
      "Epoch 1970/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2321.3207 - reconstruction_loss: 1903.8434 - kl_loss: 88.2684 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5016.4570 - val_reconstruction_loss: 1895.5557 - val_kl_loss: 99.4745 - val_false_loss: 9.7008 - val_true_loss: 1.1117\n",
      "Epoch 1971/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2325.8500 - reconstruction_loss: 1903.1080 - kl_loss: 89.9426 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5016.1758 - val_reconstruction_loss: 1895.5559 - val_kl_loss: 99.4736 - val_false_loss: 9.6999 - val_true_loss: 1.1117\n",
      "Epoch 1972/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2330.8376 - reconstruction_loss: 1902.8633 - kl_loss: 89.1503 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5015.8945 - val_reconstruction_loss: 1895.5562 - val_kl_loss: 99.4725 - val_false_loss: 9.6990 - val_true_loss: 1.1117\n",
      "Epoch 1973/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2327.3854 - reconstruction_loss: 1903.6431 - kl_loss: 89.5356 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5015.6143 - val_reconstruction_loss: 1895.5564 - val_kl_loss: 99.4718 - val_false_loss: 9.6980 - val_true_loss: 1.1117\n",
      "Epoch 1974/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2350.1296 - reconstruction_loss: 1903.0133 - kl_loss: 87.4850 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5015.3330 - val_reconstruction_loss: 1895.5569 - val_kl_loss: 99.4705 - val_false_loss: 9.6971 - val_true_loss: 1.1117\n",
      "Epoch 1975/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2347.2501 - reconstruction_loss: 1903.3033 - kl_loss: 85.6955 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5015.0522 - val_reconstruction_loss: 1895.5571 - val_kl_loss: 99.4691 - val_false_loss: 9.6962 - val_true_loss: 1.1117\n",
      "Epoch 1976/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2343.4223 - reconstruction_loss: 1903.0674 - kl_loss: 86.9763 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5014.7715 - val_reconstruction_loss: 1895.5576 - val_kl_loss: 99.4678 - val_false_loss: 9.6952 - val_true_loss: 1.1117\n",
      "Epoch 1977/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2345.3063 - reconstruction_loss: 1902.8712 - kl_loss: 84.0730 - false_loss: 0.0793 - true_loss: 1.0495 - val_loss: 5014.4917 - val_reconstruction_loss: 1895.5580 - val_kl_loss: 99.4655 - val_false_loss: 9.6943 - val_true_loss: 1.1117\n",
      "Epoch 1978/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2377.3571 - reconstruction_loss: 1904.3754 - kl_loss: 74.0890 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5014.2188 - val_reconstruction_loss: 1895.5585 - val_kl_loss: 99.4636 - val_false_loss: 9.6934 - val_true_loss: 1.1117\n",
      "Epoch 1979/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2363.4044 - reconstruction_loss: 1903.4594 - kl_loss: 80.2681 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5013.9380 - val_reconstruction_loss: 1895.5587 - val_kl_loss: 99.4615 - val_false_loss: 9.6924 - val_true_loss: 1.1117\n",
      "Epoch 1980/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2358.7471 - reconstruction_loss: 1903.0680 - kl_loss: 84.1449 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5013.6587 - val_reconstruction_loss: 1895.5590 - val_kl_loss: 99.4604 - val_false_loss: 9.6915 - val_true_loss: 1.1117\n",
      "Epoch 1981/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2341.5556 - reconstruction_loss: 1902.8065 - kl_loss: 86.2919 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5013.3784 - val_reconstruction_loss: 1895.5593 - val_kl_loss: 99.4593 - val_false_loss: 9.6906 - val_true_loss: 1.1117\n",
      "Epoch 1982/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2334.6586 - reconstruction_loss: 1902.8096 - kl_loss: 88.8284 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5013.0967 - val_reconstruction_loss: 1895.5596 - val_kl_loss: 99.4583 - val_false_loss: 9.6896 - val_true_loss: 1.1117\n",
      "Epoch 1983/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2328.2282 - reconstruction_loss: 1903.8843 - kl_loss: 88.5299 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5012.8159 - val_reconstruction_loss: 1895.5601 - val_kl_loss: 99.4574 - val_false_loss: 9.6887 - val_true_loss: 1.1117\n",
      "Epoch 1984/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2330.4255 - reconstruction_loss: 1903.2340 - kl_loss: 87.7226 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5012.5352 - val_reconstruction_loss: 1895.5603 - val_kl_loss: 99.4561 - val_false_loss: 9.6878 - val_true_loss: 1.1117\n",
      "Epoch 1985/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2329.2484 - reconstruction_loss: 1902.8981 - kl_loss: 86.1233 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5012.2549 - val_reconstruction_loss: 1895.5605 - val_kl_loss: 99.4549 - val_false_loss: 9.6869 - val_true_loss: 1.1117\n",
      "Epoch 1986/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2326.8774 - reconstruction_loss: 1902.9562 - kl_loss: 87.4696 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5011.9751 - val_reconstruction_loss: 1895.5608 - val_kl_loss: 99.4537 - val_false_loss: 9.6859 - val_true_loss: 1.1118\n",
      "Epoch 1987/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2325.0465 - reconstruction_loss: 1903.2919 - kl_loss: 87.0577 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5011.6958 - val_reconstruction_loss: 1895.5610 - val_kl_loss: 99.4528 - val_false_loss: 9.6850 - val_true_loss: 1.1118\n",
      "Epoch 1988/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2324.1489 - reconstruction_loss: 1902.9098 - kl_loss: 86.5335 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5011.4155 - val_reconstruction_loss: 1895.5614 - val_kl_loss: 99.4517 - val_false_loss: 9.6841 - val_true_loss: 1.1118\n",
      "Epoch 1989/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2320.9291 - reconstruction_loss: 1902.6979 - kl_loss: 88.7263 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5011.1362 - val_reconstruction_loss: 1895.5616 - val_kl_loss: 99.4506 - val_false_loss: 9.6831 - val_true_loss: 1.1118\n",
      "Epoch 1990/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2321.9169 - reconstruction_loss: 1903.2725 - kl_loss: 88.7601 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5010.8555 - val_reconstruction_loss: 1895.5619 - val_kl_loss: 99.4495 - val_false_loss: 9.6822 - val_true_loss: 1.1118\n",
      "Epoch 1991/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2318.3346 - reconstruction_loss: 1902.7988 - kl_loss: 88.1444 - false_loss: 0.0793 - true_loss: 1.0496 - val_loss: 5010.5762 - val_reconstruction_loss: 1895.5624 - val_kl_loss: 99.4486 - val_false_loss: 9.6813 - val_true_loss: 1.1118\n",
      "Epoch 1992/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2319.0189 - reconstruction_loss: 1903.0304 - kl_loss: 87.7772 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5010.2959 - val_reconstruction_loss: 1895.5626 - val_kl_loss: 99.4474 - val_false_loss: 9.6803 - val_true_loss: 1.1118\n",
      "Epoch 1993/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2317.4559 - reconstruction_loss: 1903.2428 - kl_loss: 87.8561 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5010.0161 - val_reconstruction_loss: 1895.5629 - val_kl_loss: 99.4464 - val_false_loss: 9.6794 - val_true_loss: 1.1118\n",
      "Epoch 1994/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2317.6628 - reconstruction_loss: 1902.7679 - kl_loss: 87.9701 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5009.7383 - val_reconstruction_loss: 1895.5634 - val_kl_loss: 99.4452 - val_false_loss: 9.6785 - val_true_loss: 1.1118\n",
      "Epoch 1995/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2320.3021 - reconstruction_loss: 1902.7003 - kl_loss: 86.0317 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5009.4600 - val_reconstruction_loss: 1895.5636 - val_kl_loss: 99.4442 - val_false_loss: 9.6776 - val_true_loss: 1.1118\n",
      "Epoch 1996/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2317.6319 - reconstruction_loss: 1903.7006 - kl_loss: 88.0591 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5009.1816 - val_reconstruction_loss: 1895.5638 - val_kl_loss: 99.4431 - val_false_loss: 9.6766 - val_true_loss: 1.1118\n",
      "Epoch 1997/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2314.8427 - reconstruction_loss: 1903.2645 - kl_loss: 88.3086 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5008.9033 - val_reconstruction_loss: 1895.5641 - val_kl_loss: 99.4420 - val_false_loss: 9.6757 - val_true_loss: 1.1118\n",
      "Epoch 1998/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2317.2236 - reconstruction_loss: 1902.9707 - kl_loss: 85.4767 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5008.6260 - val_reconstruction_loss: 1895.5645 - val_kl_loss: 99.4409 - val_false_loss: 9.6748 - val_true_loss: 1.1118\n",
      "Epoch 1999/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2316.0680 - reconstruction_loss: 1902.8569 - kl_loss: 88.3551 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5008.3481 - val_reconstruction_loss: 1895.5647 - val_kl_loss: 99.4398 - val_false_loss: 9.6739 - val_true_loss: 1.1118\n",
      "Epoch 2000/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2317.2769 - reconstruction_loss: 1902.7441 - kl_loss: 86.9252 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5008.0698 - val_reconstruction_loss: 1895.5652 - val_kl_loss: 99.4386 - val_false_loss: 9.6729 - val_true_loss: 1.1118\n",
      "Epoch 2001/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2316.1428 - reconstruction_loss: 1903.1110 - kl_loss: 87.8665 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5007.7920 - val_reconstruction_loss: 1895.5654 - val_kl_loss: 99.4376 - val_false_loss: 9.6720 - val_true_loss: 1.1118\n",
      "Epoch 2002/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2314.0008 - reconstruction_loss: 1902.6655 - kl_loss: 88.4192 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5007.5142 - val_reconstruction_loss: 1895.5657 - val_kl_loss: 99.4368 - val_false_loss: 9.6711 - val_true_loss: 1.1118\n",
      "Epoch 2003/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2312.4194 - reconstruction_loss: 1903.2806 - kl_loss: 88.5723 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5007.2349 - val_reconstruction_loss: 1895.5660 - val_kl_loss: 99.4357 - val_false_loss: 9.6702 - val_true_loss: 1.1118\n",
      "Epoch 2004/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2316.0264 - reconstruction_loss: 1905.1351 - kl_loss: 87.4110 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5006.9570 - val_reconstruction_loss: 1895.5665 - val_kl_loss: 99.4347 - val_false_loss: 9.6692 - val_true_loss: 1.1117\n",
      "Epoch 2005/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2309.7711 - reconstruction_loss: 1904.7887 - kl_loss: 89.7574 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5006.6792 - val_reconstruction_loss: 1895.5668 - val_kl_loss: 99.4337 - val_false_loss: 9.6683 - val_true_loss: 1.1117\n",
      "Epoch 2006/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2308.9728 - reconstruction_loss: 1903.3431 - kl_loss: 89.0627 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5006.4009 - val_reconstruction_loss: 1895.5670 - val_kl_loss: 99.4326 - val_false_loss: 9.6674 - val_true_loss: 1.1117\n",
      "Epoch 2007/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2309.7030 - reconstruction_loss: 1903.9551 - kl_loss: 88.6826 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5006.1230 - val_reconstruction_loss: 1895.5674 - val_kl_loss: 99.4316 - val_false_loss: 9.6665 - val_true_loss: 1.1117\n",
      "Epoch 2008/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2311.7803 - reconstruction_loss: 1903.2679 - kl_loss: 87.3938 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5005.8447 - val_reconstruction_loss: 1895.5676 - val_kl_loss: 99.4297 - val_false_loss: 9.6655 - val_true_loss: 1.1117\n",
      "Epoch 2009/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2320.0459 - reconstruction_loss: 1903.0605 - kl_loss: 85.8038 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5005.5684 - val_reconstruction_loss: 1895.5681 - val_kl_loss: 99.4288 - val_false_loss: 9.6646 - val_true_loss: 1.1117\n",
      "Epoch 2010/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2307.2146 - reconstruction_loss: 1902.6871 - kl_loss: 89.4435 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5005.2915 - val_reconstruction_loss: 1895.5684 - val_kl_loss: 99.4279 - val_false_loss: 9.6637 - val_true_loss: 1.1117\n",
      "Epoch 2011/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2312.3206 - reconstruction_loss: 1903.1063 - kl_loss: 87.0858 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5005.0146 - val_reconstruction_loss: 1895.5686 - val_kl_loss: 99.4267 - val_false_loss: 9.6628 - val_true_loss: 1.1117\n",
      "Epoch 2012/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2309.0557 - reconstruction_loss: 1902.9238 - kl_loss: 89.4484 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5004.7368 - val_reconstruction_loss: 1895.5690 - val_kl_loss: 99.4258 - val_false_loss: 9.6619 - val_true_loss: 1.1117\n",
      "Epoch 2013/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2308.4176 - reconstruction_loss: 1902.7168 - kl_loss: 89.1215 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5004.4595 - val_reconstruction_loss: 1895.5692 - val_kl_loss: 99.4247 - val_false_loss: 9.6609 - val_true_loss: 1.1117\n",
      "Epoch 2014/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2305.7819 - reconstruction_loss: 1902.6421 - kl_loss: 90.0287 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5004.1821 - val_reconstruction_loss: 1895.5697 - val_kl_loss: 99.4236 - val_false_loss: 9.6600 - val_true_loss: 1.1117\n",
      "Epoch 2015/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2312.6931 - reconstruction_loss: 1903.5028 - kl_loss: 87.9168 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5003.9067 - val_reconstruction_loss: 1895.5697 - val_kl_loss: 99.4226 - val_false_loss: 9.6591 - val_true_loss: 1.1117\n",
      "Epoch 2016/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2311.3297 - reconstruction_loss: 1902.6489 - kl_loss: 87.2900 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5003.6313 - val_reconstruction_loss: 1895.5702 - val_kl_loss: 99.4216 - val_false_loss: 9.6582 - val_true_loss: 1.1117\n",
      "Epoch 2017/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2305.6662 - reconstruction_loss: 1902.5674 - kl_loss: 89.9223 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5003.3535 - val_reconstruction_loss: 1895.5704 - val_kl_loss: 99.4207 - val_false_loss: 9.6573 - val_true_loss: 1.1117\n",
      "Epoch 2018/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2304.2188 - reconstruction_loss: 1903.5450 - kl_loss: 89.9434 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5003.0767 - val_reconstruction_loss: 1895.5709 - val_kl_loss: 99.4197 - val_false_loss: 9.6564 - val_true_loss: 1.1117\n",
      "Epoch 2019/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2307.0738 - reconstruction_loss: 1902.8429 - kl_loss: 89.5476 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5002.7998 - val_reconstruction_loss: 1895.5710 - val_kl_loss: 99.4189 - val_false_loss: 9.6554 - val_true_loss: 1.1117\n",
      "Epoch 2020/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2305.5306 - reconstruction_loss: 1902.7833 - kl_loss: 90.5554 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5002.5239 - val_reconstruction_loss: 1895.5713 - val_kl_loss: 99.4181 - val_false_loss: 9.6545 - val_true_loss: 1.1117\n",
      "Epoch 2021/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2302.0477 - reconstruction_loss: 1903.6416 - kl_loss: 90.0996 - false_loss: 0.0793 - true_loss: 1.0497 - val_loss: 5002.2520 - val_reconstruction_loss: 1895.5718 - val_kl_loss: 99.4171 - val_false_loss: 9.6536 - val_true_loss: 1.1117\n",
      "Epoch 2022/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2880.7096 - reconstruction_loss: 1919.1543 - kl_loss: 65.5209 - false_loss: 0.0793 - true_loss: 1.0498 - val_loss: 5001.9971 - val_reconstruction_loss: 1895.5732 - val_kl_loss: 99.4132 - val_false_loss: 9.6527 - val_true_loss: 1.1118\n",
      "Epoch 2023/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2594.7310 - reconstruction_loss: 1914.1693 - kl_loss: 67.9130 - false_loss: 0.0793 - true_loss: 1.0499 - val_loss: 5001.7339 - val_reconstruction_loss: 1895.5745 - val_kl_loss: 99.4102 - val_false_loss: 9.6518 - val_true_loss: 1.1119\n",
      "Epoch 2024/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2474.8085 - reconstruction_loss: 1909.9438 - kl_loss: 72.4066 - false_loss: 0.0793 - true_loss: 1.0499 - val_loss: 5001.4644 - val_reconstruction_loss: 1895.5753 - val_kl_loss: 99.4082 - val_false_loss: 9.6509 - val_true_loss: 1.1119\n",
      "Epoch 2025/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2363.0944 - reconstruction_loss: 1906.8668 - kl_loss: 80.1365 - false_loss: 0.0793 - true_loss: 1.0499 - val_loss: 5001.1958 - val_reconstruction_loss: 1895.5757 - val_kl_loss: 99.4065 - val_false_loss: 9.6501 - val_true_loss: 1.1119\n",
      "Epoch 2026/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2345.5078 - reconstruction_loss: 1904.9360 - kl_loss: 85.4070 - false_loss: 0.0793 - true_loss: 1.0500 - val_loss: 5000.9233 - val_reconstruction_loss: 1895.5762 - val_kl_loss: 99.4054 - val_false_loss: 9.6491 - val_true_loss: 1.1119\n",
      "Epoch 2027/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2339.9464 - reconstruction_loss: 1904.3130 - kl_loss: 86.7596 - false_loss: 0.0794 - true_loss: 1.0500 - val_loss: 5000.6499 - val_reconstruction_loss: 1895.5768 - val_kl_loss: 99.4043 - val_false_loss: 9.6482 - val_true_loss: 1.1119\n",
      "Epoch 2028/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2340.7911 - reconstruction_loss: 1903.9185 - kl_loss: 89.0106 - false_loss: 0.0794 - true_loss: 1.0500 - val_loss: 5000.3750 - val_reconstruction_loss: 1895.5770 - val_kl_loss: 99.4033 - val_false_loss: 9.6473 - val_true_loss: 1.1119\n",
      "Epoch 2029/2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 2332.8780 - reconstruction_loss: 1903.7310 - kl_loss: 88.6073 - false_loss: 0.0794 - true_loss: 1.0500 - val_loss: 5000.0996 - val_reconstruction_loss: 1895.5774 - val_kl_loss: 99.4025 - val_false_loss: 9.6464 - val_true_loss: 1.1119\n",
      "Epoch 2030/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2325.9912 - reconstruction_loss: 1903.8246 - kl_loss: 90.0828 - false_loss: 0.0794 - true_loss: 1.0500 - val_loss: 4999.8232 - val_reconstruction_loss: 1895.5776 - val_kl_loss: 99.4015 - val_false_loss: 9.6455 - val_true_loss: 1.1119\n",
      "Epoch 2031/2700\n",
      "12/12 [==============================] - 16s 1s/step - loss: 2320.5411 - reconstruction_loss: 1903.6774 - kl_loss: 90.0784 - false_loss: 0.0794 - true_loss: 1.0500 - val_loss: 4999.5459 - val_reconstruction_loss: 1895.5781 - val_kl_loss: 99.4008 - val_false_loss: 9.6446 - val_true_loss: 1.1119\n",
      "Epoch 2032/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2314.8794 - reconstruction_loss: 1903.6210 - kl_loss: 90.6210 - false_loss: 0.0794 - true_loss: 1.0500 - val_loss: 4999.2690 - val_reconstruction_loss: 1895.5786 - val_kl_loss: 99.4001 - val_false_loss: 9.6436 - val_true_loss: 1.1119\n",
      "Epoch 2033/2700\n",
      "12/12 [==============================] - 15s 1s/step - loss: 2317.9644 - reconstruction_loss: 1904.1776 - kl_loss: 90.8153 - false_loss: 0.0794 - true_loss: 1.0500 - val_loss: 4998.9912 - val_reconstruction_loss: 1895.5789 - val_kl_loss: 99.3993 - val_false_loss: 9.6427 - val_true_loss: 1.1119\n",
      "Epoch 2034/2700\n",
      "11/12 [==========================>...] - ETA: 1s - loss: 2309.0452 - reconstruction_loss: 1903.1932 - kl_loss: 91.3480 - false_loss: 0.0794 - true_loss: 1.0500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1c845b5418fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m model.fit(x = [data,true_data,false_data ],y= data[:,:,:,:], epochs=2700, batch_size=5000, \n\u001b[0;32m----> 9\u001b[0;31m           validation_data=([data_test,true_data_test,false_data_test ], data_test),validation_batch_size=6000)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"vae_best_model.h5\",\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(x = [data,true_data,false_data ],y= data[:,:,:,:], epochs=2700, batch_size=5000, \n",
    "          validation_data=([data_test,true_data_test,false_data_test ], data_test),validation_batch_size=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee2c1464e4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VAE-ENCODERv38.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VAE-DECODERv14.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.encoder.save(\"VAE-ENCODERv38.h5\")\n",
    "model.decoder.save(\"VAE-DECODERv14.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAABTCAYAAABOIAlxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAArq0lEQVR4nO2de7TtVXXfv9MLaiTIFiEoV8NBvCWlWI8MY9D6wBR8FUWNQ4VaNOpAUzEBMSnaNFpNE8owOmo0REooUKvGKggxGCXGRxw+CuJRHpGAeFSIgAa3oiiP6+ofe334fc88+5x7eNzz4M7vGGfMs/dev99vrjXnWr81v+sVrTUVCoVCoVAoFLY/7rPWChQKhUKhUCjsKKiOV6FQKBQKhcIqoTpehUKhUCgUCquE6ngVCoVCoVAorBKq41UoFAqFQqGwSqiOV6FQKBQKhcIqYU06XhHxjIi4IiKuiogT10KHQqFQKBQKhdVGrPY+XhGxSdI/SjpM0jWSLpR0ZGvt8lVVpFAoFAqFQmGVsRaM1+MkXdVau7q1dqukD0g6Yg30KBQKhUKhUFhV7LQGz9ws6Tv2+RpJv7bcBbtGtAdLul//fIv9dt8ux13u1uXNXd4/ffbvHpB+u61L741y/1u7RAeet/sUfX/W5c7pvlu73KXLsGvgHW9K196edPb7oMuP0zXcaxcNoMwipf1+l7taWtLwnF9Iz6FMbtOATSntj7qkjN1m3HfXlBadKOufacAoPWec7sFz0NGfubMWgjJ9gH23NUnKjnvgE84Pk9efJ33R9SeWFr149i91+YN0X7dzvv8N6XsHaSgfdEAn9Me/pCFvD5pyP7+X35+y5D7oe1tKJw35f2iX2JlGh3t53dw5SfRG11stLeWAD1P3uT9593rG/ag76PvTLj3PSmnwe3TJ9dCf/Ytd/iRJR24HyBu+kNsAafDZBxzIwx8xkdddLUn6p2sX68T9cj54ntePTSktfvvgLrHVtIida3I7Oq1MATqQx9GU+/PM3P7neicN/ohvUO73Td878v0AeqObX8t9sTP+k+uDtLj94b4/TmkfaGnQJduO5/3I0nJ9zhs67pLSTdMTnciHdwy4Dz5wfZd7dYl9tmoAfsq1tNPYyn2CZ2EHdKA+j7sk79JQZyif/F7m87QODnpSBrcm6aDsbuyStvK2JKXF769rpO+31vaccts16XitCBFxjKRjpInB/0DSTP9t3tLt3eVHu3xWl3Nd7tflJXbN/l0e1OVFXV7Xpb/89unyW11u6fLcLl80RfevJ91w1HGX9DK9QuJ0f98l1uKa/SwtlQ5dPp+uoZI+1q65Oj1zc5fv6fLXLW1+uT6qy890SZn8k10z6vLRXX48ff6WpR2nZ16Q9Oe+PvYMJUoFxt5P6ZK8fkYDyPNDuqSy/3OXj7K05BXdntDllV3iE964kDcaHvRF1y9Z2i92iS/8dpcfSvfdogH5/u/s8kAtBmlGXT6nyyu6pCH8lF1D+Tyvy/yC9M44DSY+zX0e2SX58g4G9eo/d4lP0IA/LKWTBlvxHHTADu5HlM9pXVL38SPs4fWM+810Sb5oH0aWFptQtg/vcr5LfIb6IA15e2KX+MDFXfrLPbcDRKM05rkNkIY2a/a8/s++J0/kf3+BJOm/9hmzM3YNL4KcD+qZvxl42VEun+vypV2SDw9aAPfP7ehoSlo6VuT5e11Sdzxo5Jm9i3mHL9ycPktD/cE3KH/yPK3uUA9uTt9TFrx0vb3gvo/vEl/7lS6dWcCXqV/4IG09efc2OHdm8DXau49bWuxI3njOhV3iM9drAO9AbDXq8tIunVDgPvhA9zid0OVXuxzbNbPpWvLGu9HbFvzvqi6pi9Tnv+ryYLuGOpPbTd7L+MqDtRjoeUCX811+a1HK4T3wvi5f0CVl7mVKPrD9706/paS16Xhdq6EeSJP299qcqLV2qqRTJWmfiHabhpfqIy0dTvurXfIS3yX9/kq7hoKhsvCyGHd5rKXFqajINJzcj8blPRpA5riWykjlQSd/0eE4vHh4Hk7oDR3OTOeJvPOSPaZLjwTJMw0GTjejxeDZH+tyvksqMPpzD3/2FVoIPvvLDwelwbwm6UKZ+vjzuEtsRmNIA0FZEtk6MsNGo+8NNnnmJfW/unxaur/nmXcfDSv5olM4trT44+FdUrY0ZuhysQZQqYnejuwSn3iIpUU/OgHv7pKXxy7pd2loVLg/z+NF9FRL+70k0Xe39P2cXfOSLrHZqEsaezqj1A9p6IxR18kXvne1FgM/uSml4eUyY2nPTb99o0taSLcv3xHZzyWduIe/sLHNd1LaaUwItqAsuZYXzN916Y3l7Kv7P/u+uf/zcknST3uHa9y/3Xu45I7ypu1CF2zmnWV8mPrKC4x2Nbdt0vASwrcJbEZdenuNbfA17ndYl7RPrhP6zndJPebavaakHXdJ3cdPsal3jGhD8J/c2aET7Z0FvqPTP+qSNvcJlpbAGH3RjU4B7bfrRD54JnahXPzdwTPRF9tgD671upPLeaZLfMIZNeon7x2CRvwptw3S0K6Rp7kuaZ//1tLSoaVMM1v2O11+XgPIM+3C5elzDrKlobypVzmY9mE32olsT9ol8vchDSCvTngshbWY43WhpC0RsW9E3FfSizW8wwqFQqFQKBTutVh1xqu1dntEHKsJW7pJ0umttcuWu+ZmTXprMFHe86VnS490vksiNqJSZxLobRPRExEwbPgWS0s0TVRKVEHERrTkQ470oBmOISKjR39mlx7pvzfpRPRANOlM0tO7hKVhCIr7n9+lR0WzWggYEKKWG+03KF8itKWYOo8miGqJ0CgDIua/tLREt0Tiv5muIWJzuptnwwwSJRHpoKMPKRPx4S8zXRJReYSZh1VJO+7yh+mz3yf7GEzk8yztO5K+lAvUOxS/D3Nn5olnTxtuyMNSBy3xvTMhRH73TWm51oclGcagHrywSyJAfPkRGkBU/VtdwiIepIWYNkcnzxei3A63tPjETSkNjC8+7cPP5JHol3k1MF3OCmBX6josN/6P7Zx5JC+Xp7TYzFkTfDVPEaAeMNSyvwx/xD+jiThiwk1QZ47qct4uoe3ANpmd/ANLy9Biv/si9hnWgzorDawP9cl9QBoYYGlxHcRv0Ik67+XE/+MuyQ++7FMesBE6PbNL7AFD8Xq7BjtgO9q9L3SJb/hzeL/A6sKk0ab5+yaztqd2iV15H/kcI9ohyg4fh01xn0PfPDxP+4BffV0Dnt8l7yYYHt4LzrKiP/WI9wNtAvnwcTXyBGvF+3kai8uQK/ehnMddYh/aYNcbJhNdsC/l5zqRj9zO5ak60mBzhlUZbWDI9G1dztg1MGbOai+FNZnj1Vo7X0P/oFAoFAqFQmGHQO1cXygUCoVCobBK2OYGqhGxlyYE996ttWdGxAGSHt9a+4vVUFCS/kVEe6cG2nBsv2V6FYoQOhR61VfJQAUyNPf59L3ToHkyep7IeED6LA0rBWa7nEs6MQTl1Cb0KlQ1dDq6PMbSMhyCvlC05PH9XfoKHsoOahwqnCEKHx5gyIChRCb7UpY81+luqGqGeaBd0XVkaRlWxWZPSjpRlkdP0Z/J0L6aRBqGQnxS6Fe6hJbOk059UjRDaJQ/VDXDPgwtfE4DnpJ+w2aZMvf7sJAgLwogAvKhRmzPtZQ7w7bPt7RQ+tguD6FxDx+KZdj2nC6h08dduk/zbIY9qfzoja4+DQD98AGGffKK4FM1gKEUhtEZ3piZoj/PZEiUa/A9hjvctxkqY/gFW+HLrj92PSD9llf5PloDvJ2RhiE1/PeJ9hvfcV908dVzknTYK+zDaX/e/3mdJGlrTLyY6RG0KY+3S/KKO+wx7tInp2NnhmnRifpBOfnwcF4RzLWU/0ssrbdj0jB8hN9OYwLwU+ovOjC9wYcyGT6ibqNTXok9bYsL0lL+LP5AR2+v90pp/0uXPhQOGNphkjh1Ebugm7dp+B4+Qrlhn7GlpU2h7tCu0h5Na+Np5xg6Y5iT8vGJ8gy3/V66Bh84V4uBHfLKYGx53ZS03l5Ki6f3uG8wVYD7MVzJEDjtk78DWcRAvSXP3MOfnxfVXZk+k9YXjVHetBevkL7cWps6134ljNcZmgwX08f5R0nHreC6QqFQKBQKhYJhJXO89mitfTAi3iDdMTl+67YuuidxiyZRGpGO98ZHXY67hJGgxwq75BPeiJphWIh+pkUGRDbzXdI7JmpEF5+0THRyVpd58mN+nutPFJH303F2ht4+0TSRElFEjqikgVViWTiRWt4IUxqYrhzZEM3D6PmkX6IhnslEaiZVeoRDdPsCLQSsDeXv7EZeBg5jRD4yi+b6oT+hB5GJRx15QueoS6IjmApfJp73Ucv7n3klwXex3XyXREfkxyeQws7gw6d0iS1d/zxp/OykA8/zTRopB5g76gPl5UwF5QsDTOTHPahfx9s1eQEK1850iY/4Mm7qE3t7kS908zKFWcGPxl3SBqCj12f0hDnFdiyIGFla/IXnUG9nuqROet3nGnTIeyA5i0jeKOe8oIZFNPpTu4gm+/jJ09njCCaScvJFAjDtPO/W9Pkrlpayoh69N6WFXfS6mzegpjxe06UvpuA37Es7B6MwbRPrzAzRDv1Jl86M54nrlCE64hPOeOGX3J9n81zy6mwmPk0bTvtAOXl7N+qSPO6c0tCOuB/B4tG+US7Yxdv2vHEzE9hz2+ssKD49Tvfdkr6XhvyjN/6J7Xi/TdtMHDuTN9pTrwd5lIH8UJa0T85IcX32ZeyMPXzLIHyZ+1MGoy7HlhZ9d06fqaM8x983sJ0+YrYUVsJ4/SQiHqy+SWxEHKyF74dCoVAoFAqFwgqwkjleB2kScx2oyar3PSW9oLX2te2v3gT7RrS3aIjGfKdrmBp690T69ESnzdvK48JE5jBIM5aWeQQwCUSw9JpZiu9bExA5EemxlQD3JWof2TUwIrA+9LS5v7M/h3ZJr5tryCtl4jrlJa5ECOhyqP3Gpmp5B+qj0+++2SRMGnOtiCbo2fuO7ERz5JnIiaXAsCYe1RGVMk5PJJO3S/BtMbAntic/RFC+XUI+PgJmCCbhj9PzpSF65tk/T5+nzZvblNIQxRGho5s0jOczFyofo+Ms5Y3pOyTsJAyIR+2US94ZnHL/PUsLe0t5wwSjPz7vfjbukjkolCWRJxGuMyL8hq9xogMMle/8ThRKhE/ZkVcY21M0gC1pxkliH49gc53JfkSb41u9cD/yhk9Ttj7Hi7mYedsWGMBfZdLd+04aLrp1slPqt++38Nm0D9zDd+yGgcf3sFnetV8a6jRtLFE8/v9nXV6oAdmPqNf467QRCtqd2aTLtK12qOu0IbR3bLcxtrTclzY91xngczVhdHgOduVelNc7NIC5RHkTUezsbS9tFzu9/0aXr+oS3z5KA3g2980ngYwsLTaHccpbmdAW+Ka0/IatKB/K3dk3np3bB+oKoxFej2lHYQRpN9DV2yHaaXw5nwYAvO3N8y3JG+0gNnMWjt9oq7jW53UC3oe8I/KGtkjfUmmUnn3cMnO8tjnU2Fq7OCKeosm7ISRd0VpbyVYVhUKhUCgUCgXDShivTZL+nSaEzR0dtdba27erZobdI9phGiIcP1+IuRn0tjlTid4sPVVffcBqGwLKvHJxWg+Y6Pmm9D1Rnq9sIgKgV0z0Q6+cCNFXBuU5FNyPa/yQaaIgInx68EQX5NWjayK8fDwGEc6bLC3RHGWXIx6iFR9zR1/yik7cw+eoUWaUKVEDduA5XtbkleiceSmwMnNTriEaJZqb7RL/8U0OKYe8eStR9nyXvvKITURZ9cNGoUQlHulznz/skojqxiQ9gqIcWFWK3kSCvmkvLAybPsLU3ph+95VZ+B91BX2JPJ9uaWGHX5Q+wwxSlj5fi2dSH/CFvPGlz4eZ7zIf0ZQZYWmwGfUVdgb98UU/sgaf4Dn5mCGf14Zeu6a0M12Snzm7JrNgXDvq0tkl8pgP530jpwFzgvpObxt+fOlk68+/7BQk5QFDQjl9bLjijpVd2HekhfC2izKjjsNAYfd85qu0kCWUBp+b9jx8mHLCB6gz+P+0DTwz45LnzDooZ+bWUYKwJtOOU8tzc2Di8UFvg2Fm8S30h2n0MsnnCWa2HubTGSNWkFOfsCvtk7e9tEM8E5YV/8zzSl0XWOhztBA+ckAeaXPxpzwq4/MvM6MJ60wdHVta7El54I/olNtgaSgr2mnqW95Ye9pIEW0VvkF/wFk+ypczb2GA83xnZzYZBeB+Z90dxkuT+Zs/0yQP+QD3QqFQKBQKhcIKsRLG62uttX+9SvpMxZaI9j80RJZ+DEA+vJoeLivBYMScJWNlBVHEqMt8uKs0MDVEv0QgRBcc9eKHWNNbJkImQoCNYD6PX8NqBaJfosXZKWnzygp0oyzo7Tv7gC6scOIw4lGXHjVemL6DUWBfJiIDH28mAoRlo2ynLX8l4iACIT/YEDs8SQNI864uYStnupw2R4f/iciIjth3xufmsMcUkQwsH8wddnYWCFD+eQ8n37MINg+bEd2NuuSgai/TvFcZkSd59TlePBvbw/JRhjBUfog40Vv2H/zX92lDT2yXo2Ds4Wyx6yctXvGFT3rUyHOIaNHx6vRZGvxnqUOCKRPfpwr9YD5ggrG/Mwnoy/2pt5Qh9cR9bqZLmPfZLrGHs6DM6cE2+P+xNF5n97ldt594xzWf7jQDfoKOlCEsxHs1gHmXmYmnns1aWtgS5thdnOSzu/yiBsBeEelTz2a6dEYTf6R+UaYwdLSVz9Ji0G7jC9QZZ4qwVa47lHs+0kwa7ImNsAP+5XMEAf6e2x3aeJ9bNN8lzDU2gmHLe2j5b5Td5SmNt42UGeXCOxCmi3z4Kvq8lxt1H3/ytox6zH5k6E9Zo8vZGsDRTcznZcQCOzijBqM43+WuKS32cOYaX+YafJw2fdxlPr5KGnwD2zGn7BOW5t93SZnluXzYzFcZ0t6TtxPv5j5eH4uIp60gXaFQKBQKhUJhGaxkqPGLks6JiPtoEmiFpNZae+Dyl91zuI8mjM+01RlErIxV0xv/apLObhABEPUQzc106RHabJe7pbR51STPl4Yxe9LAHBDdESH6HiPoCZuUx3SdFdi8jTQ8z/NMOcGCEQ0R9fq9YAPyfls5WvRd4oloYA5e1iVj+tPmaxE9EPGgL7q9XwN4Fisec4RPlOGRJmXK/SnbUZfHWFryTyQOw5j3avJIBRaMiBOGEF18ng16cn90IsLEj3y+Dc/KrA/14CpLe2D6DaaO5xFBu/78z7wIojfs4PN40IsVhJQX9QJb+c7duS7mw2hHWgyiZ+pGPgjbmV98mjkgMFBEudPmhcHa5nlJsAQz9h1paA9gdCgffN2j93GX1CHmMWKHkaWd6/IOpou5XWfjHf2L44ZreDb2oAzwT3zk2RrANTx7n/T57y0teYJRyKwGNnSWiRWvaM3KURiSV1pamBsYA/SmbcynM0gDmwHjsWeSflg8bcvm9Bv5YD6U1x10ghklb8yzYj8yZ4yo63un35yRBcxFpA3br0tsNd+lz0ea7ZL2mpctc+0+ZGkZvcgr+PF/mMKRXYNvUzeoZ+g/a2n5Dp9D70elz4fZNRelNLTLmY2Thndq3osQdo/8+EgXdW5L+pxXTXrd5L1L+8C7j/s6NXVj+o0+A20aZT1j10w7VWAprKTj9XZN2LhL2rbGJQuFQqFQKBQKS2IlQ43fkXTpne10RcTpEXFDRFxq3+0eERdExJVdPujOKlwoFAqFQqGwUbGSyfVnaMLOfUy2onZb20lExJMl/VjSWa21A/t3J0u6sbV2UkScKOlBrbX/tC0lHxnRTtZAr+5jv0H5Mvw10yW0H/Tx2K65f0oDTQyd6JMcGdrIE3ehOKFffSIyE/mhK6Fz82TjaRsLcr+LUxpPmzcshF6nLMiXD7HkTVUZNoF+9aXUULFQ7dz/c+n3X9cAyiVvncH2GH68EMNIDCHkId+8TYA0LP0lDfnJQ6V+KCrPyZuucn+n66G589EQeUK+Tzploj3X5omk7qdQ1vjTu7tkki42m7drGA5gmCdv6OhbT+TNEvNGkqR1/XdOkiGFPBFZGoYesu/lTWn/m11zePoNHRh+YMGBb+uBLgw3MCSFfX14Ph8TwkRUhr7e2qVvxEje8GWG0dk2wevxr6W0TMLN+vtE7Tz8z1As93Wf5tlMyD6Ww7BP60cu3zDJwSW2OoBho7wFAs/Jx/dIixfb4IOUtR8ZlIchkdyD4UQfFmOYmfYTn8ZWX7C0B6Xf8tAN9c+ne+DD+6fPtJVe/l/SQozTZ/SfNimasuQoq7yZqG8ai3/S3lB3KEufeoLNuR9DWhzkjN/6dhXcjzYqH0n0t5aWdpT3Tt7Gg7L0Y6TycW20C/iXTzPgPUbZYYdxlyzk8LlH2IZ3COUF03OwpWWom/Zmpkv8tdeGBUOBeYuXPPSOrv7eZNjZ31vS4uke0uItS2i7eB5D2T7dhjzx7nvO3Zxc/01Jn9Rk8ceu9rcsWmuf1cIhVmniI7RxZ0p67gqeXygUCoVCoXCvwDYZr7t184gZSR81xmvcWhv1/0PSD/i8HB4a0V6moZfpG53Nd0kEQ88UhoRerk/uJhqBhSBieE+XzgrkTVCfkL6nR+3REIwQEQaRP4e6Eln5Bqfcj4iViJBe/6WWluiWCaJEqUQ23N+jujy5EbaGCN3ZsXwsAuwMUQQMxpkaQMSRj1CifDyv5A0WgDwTGWIfZw8yy8PzZrtkA9jftmsof/R+Z5fkfWxp84HR+bgTfvclzUTvTCSFSRila6XFm5QSncJQwRj6IdxERfmw6ZkunRUg6idqQzdYOGzpjABECtEoLG6O9vz+2Iy85k17fXL9pek3WDnqIpOCM0vhafO2Cc60EJ3DsGA7fO+H6bM0+Dn5oFzypo3S4iNqqFdEk5Sf17O5LomqyTtl6u0Q9zsK2uSSJy+8+og3S5KuPW+4Bnvm435YNAB76M+B3SAftInkb8bScr882R39KTf3Pf6HWaYec39n07kvNj+ty9d3Sf129gRGhLKEOaJ++FY41K8902fYOHzSRx8ofmxPnjkGbdqoAHUDe/AcysBZVtq+XAe5H+2T2wwWKR+8PN+lH5vH7iO0kWx/weIhyss36mXhz6jLvJWSj1CwzQLtMnremNK6TuSJusezKUtnufmO90Bue7GHL1yg/PHpmXQN72BnBvNCCPwT3aYdd4YfkVf8n+1i/Cg83ivUhxPuygaqEfGu1tqxEfFX6gdkO1prz5ly2YrRWmsRsWSvLyKOUfedVVs+WSgUCoVCobAdsSTjFRE/aq09sJ/TuAittc9M+z7dY0YLGa8rJB3SWvtuRDxU0qdba/svdw9JelhEe62GyMbZE5gIWKB8OCq9cN86gF4x0UqO5n3OAL1s5inAWhHR0Ev3a/I2BvS+89E7flArR9+M02989rkn+UgaDDTXJWXgG0fSc4c1pFdO/jxqpHx5DlsIwIxwX5+vklkTIh3s4tGEzx+QFjMJeYmzNERz+QgWnnN4+iwNhzPDGhLVeVkCol3m8XAfbEnU6JuiZl+DkaIsXRdsDjuC/1DWMA3Tjj+BXYKJhcnz+8NwwX5CkhClUk88aszHMKEbefRDxClDbJTLnc0TZ+2acZfYnjqSNzX0fOALlC2sGOynb31AeeQNGMnH3ul3aahX+BabcOITXv7UGXyOLQ5gkChL37YF25AP2Ag2/t3P0mKrlzOJ5S39QKlv/74k6e96gnm7Bh9jPhDlQR7xRdcpMyvMYcqb1LpOMBKwEZQPdvaNhLEvdsR21H0fQaAt4dm0Q5Q7Zf0oDchlulv63uezYPO8zQaMJvXZWVZGPCg7/JTn8Z5w34DGyHMq8StnQWkvKYe5LvGFcZc+f5FycNZZGphNn4fMe4UyhU2H7YGF86120JNyhj3MGwxLA8OV503nsvbjyGjfuD86UQb+vszs87jLfKSYlz95waeZW0dnAj/brAHojZ/SpvNe8PvPd8m8LVjRK1NanzdHPWIk7ZS7eGTQN6SVdbDuBM7TZBTwpC7PXT55oVAoFAqFwr0HyzFe12iyh9dUrGBV4/slHSJpD02CoDdJ+oikD0r6ZU06hi9sreUJ+Ivw6Ih2voYe8Uftt7yqgaiUlWBELV/XADZ649gLeudEd75RG2wDERLRLkHqCV161O7HsriOsANv6fKFloZn5pWEsDa+Wi/PLyOKIMIhiveVI0QN9HRhqIjIvUyJDPJcCiITomHPM/qe2iURMVHLbpYWxoO8ETnNdwmL6KsCR+m3vIEq+fONHZnPQXmQH+zhzFs+uJvIj7khrJRzFpH7wAaRL/Ls8zxgIPAfnkce84aV0uAvRLSzXVJePk+CCJLrGZ6n3KetFM3zwgBl7Ju5jtP9KVsYNcod+0vDZpxExJQLh7BTPj6/cJSel9lbn/eXj0KBuXMfkBauXkVf/J/n5MOhXS90oqGa7/IJ6Xe/hryhI5GxbxxJng5pv9z/6zMUD5/MeJr768lHZ0IoQ3TxdkEaytrnC+2TvqNNJGqfdog4+XDmbKnvYYyuSxJGx+vxuMs8F4vy4vm+KpC01BHsC1OxeUpaGBZ8O8/X89VhmTmjPmddHTA5XJMPevZr8pFT/EZ7Cms5a9fQZuURFe7voyVPTGlpr3kPTTsmKa+KhTmijH0uJWU37pJ2M6829flUvFcyW4nP+WpA2CpYLNq3PNfUWVDeV5Qh5ULer06/S0M5YA/yjI/4O5CRj9w5odyhsdyPuP63hnvcJcZrkyZbJ8cyaZZEa+3IJX76t3flfoVCoVAoFAobHcsxXhe31nLwuCb4lxHtLEnv6J89GoK9YkVinotCT9gjwLxK4uEpzbSDeImq57qc7TLP65GGeRBLHQzqET5AByIRorg850JavApkPulAb99745n5w7B5LzBHPpiYCIH7+jwDovK8txJRvR+3QcTEQbjnayGIlH2fKnSAMaBc2EOIqM/tnA9ZhYFBf18pysqWPI8t76fmcx8oHyLC+2khnDnNByzPdYldPpfSSYM9P5PSIp2RIk22Lz5H+fkeNsyDgKnzspMWz8WThqiO+1Du2HdkaZn/Mp+ew7xL2BqfD4MdYFQod8JGZ7yYq3RS0gE/xa9eYtfkeUjYGVtNm0eSV05hd5gdn+9E3r7RJaur8/EwkvQ6lp+9+iMTecNzJUn/3JXCln68TV7dRn6oS9jZ2VbykY9woo76MUyjLqnbtLXYEnu4b2A/nkP7xLw2Zx3w2ZkuadNzmwIrKg3lQNniczzHD7GmbXcWz78fdelzXPDlfCwVPkK99hXH2JM8017Drj7T0uLL3J9VadgVG/p8Lsp73CVMNe2Hz5PkehitvIcVbZqPOgD8CR15rjP7+AvviHwMGSswj9IAyow8027SfvjKvJO7xObsbwbjz3vgZg2gXYM5yweQU5bOYFMn0I0RF+qM5znPd+V5rIynPfL3Zj566LF3cR+vu8R0FQqFQqFQKBSmY7mOVw0JFgqFQqFQKNyD2K4bqN5T4Mgg6FWf2MlwCae2Q6cyGZohKR9iYfgI6pGhgk3pd2mgIRly/FJKCxXpOuUjV6Co2XAUXaYdMwQ1CoUNFf8iSwudymRDhqmgUGe6ZKGBg6FA6GjoWx8KhCYfdwmFCqXNMNY0avyr6XPeDsDvy7ADwwsM2WFTJoRLw3AD+s51Odsl5eWTWil3qHCGKNBt2sn1pGXIOg8/+DD0KN3PFxtIw/CPNAw9sUUD9+M53MuHP7Envob/501dpcHP81J+ypR8+fAzejN8kRcheD2g7PD/mS7xI4aV2BbFrydPDKPiI+jsQ43owNAQPs5Q9rNtPPddfU8FyiWXD/nzoTTuwzAPfoNPjywtG2iiA8NL1CGGdnxYj/vgp9RrbPhyHwO7ktJ7+UQcNZlU/5E+fs4CiQvsktxWkZ88rOtzRPJCAtoPrn2SpSUSZ/schll5Ln7k7RH1l7qO3gx/+7AbdQSfoD5RDxi+9aFMbEV7gX0ZfvOh3nGX1AOGs/Ow2LSNL/HXvEEuOrqfMn5EPhgOww4+xJUXaFEPntF/+L/dWUZ2DX55U5Jb02e/Djvk48+wsy/soO5xDTqSHy+fuS4pQ56HjtQLHwrERuSVITneSb6gh/cgvoH+eWGWbwvDs/ZPaVkUkDf+dR2wDfnJx1e5TvgE7398Li9U8fuiw3F388igQqFQKBQKhcI9gA3BeD32IdEuOlpDmD1vPzK7fq5LZszRNWVmLSeRStKHuxx3SfeVdaC+lpYuLTM4WTvNtYRqTj+gH9dyPgPdZsJIX79KiEFXO89s9tmgrBdF75ku8wnSvocGYW0+HyHPOvU03J9ZzMx2nLbraj5bifCCcnF6ifujN2EJ4SkhD7aUhpCSMI5yh47La7T9OXxHXgn3/PRe311QWrxiYdSllyl6H98lYRdhqfvEoek7yot7EM67TrAj0IXQTlCCvr6a++LD7JWSd1H0sJGwiz0gxl2+oUvfxwAfZp01NEQ+l8lXjuTzhcjbW7ukLN2P2MmWHY/xeyhJ1wlfgN6AYiEMxn9Hdk3eS8TPvnGdpYG+g3aGWqZNmbY7MMhnsuBzx1uaOw7uOHoiPvu/JxLagfrsYTXljN/k9e5PnfL91SkN5YPPX2+/5Z2ouZY8cu20HaNHKQ1l7fYlT5ztRT64B77idDfPgsajPaKdc/qH/X3e2CXUHO0StvtDu4Y2BJ+gjc/nMo3sGl/ZIg3+iv4+65pn/m6X2DDvwvonGpDbOcoUH/fjXLAZz6SeoTdtzREa8LouGX6B3ssrYKSh/GnDsCflRjviQyD4D/bl3UF9c0oQYEfKA/+kbfMVBXkVQ16BBLy9y7ueowvtqA9n0I6hE35EmeZ9XaShj9H1jROK8SoUCoVCoVBYc2wIxisivqdJH/T7a61L4U5hD5XNNhrKZhsPZbONh7LZxsOdtdk+rbU9p/2wITpekhQRFy1F2xXWJ8pmGw9ls42HstnGQ9ls4+GetFkNNRYKhUKhUCisEqrjVSgUCoVCobBK2Egdr1O3naSwzlA223gom208lM02HspmGw/3mM02zByvQqFQKBQKhY2OjcR4FQqFQqFQKGxorPuOV0Q8IyKuiIirIuLEtdanMB0RMR8Rl0TEXERc1L/bPSIuiIgru3zQWuu5oyMiTo+IGyLiUvtuqp1ignf2uve1iDho6TsXtgeWsNebI+LaXtfmIuJZ9tsbur2uiIinT79rYXsiIh4eEZ+KiMsj4rKI+J3+fdWzdYplbLZd6tq67nhFxCZJ79Zkf9oDJB0ZEQcsf1VhDfHU1tqsLbk9UdInW2tbJH2yfy6sLc6Q9Iz03VJ2eqYmZyps0WRv7lNUWG2cocX2kqR39Lo221o7X5J62/hiSf+qX/NnvQ0trC5ul3RCa+0ASQdLek23TdWz9YulbCZth7q2rjtekh4n6arW2tWttVslfUALDz4orG8coeFs8DMlPXftVClIUmvts1p80MxSdjpC0lltgi9KGkXEQ1dF0YKkJe21FI6Q9IHW2i2ttW9qcrDT47abcoWpaK19t7V2cf//Jkn/IGmzqp6tWyxjs6Vwt+raeu94bdZwypY0Ob1vucIorB2apE9ExJcjgpPL9mqtfbf/f52GE8EK6wtL2anq3/rFsX1Y6nQbwi97rTNExIykx0j6kqqebQgkm0nboa6t945XYePgia21gzShzV8TEU/2H9tk+WwtoV3nKDttCJwiaT9Js5K+q4XHKxfWCSLiFyV9WNJxrbUf+W9Vz9Ynpthsu9S19d7xulYLzxt/WP+usM7QWru2yxsknaMJ7Xo9lHmXN6ydhoVlsJSdqv6tQ7TWrm+tbW2t/VzS/9QwxFH2WieIiJ01eYH/n9ba2f3rqmfrGNNstr3q2nrveF0oaUtE7BsR99VkMtt5a6xTISEidomIXflf0tMkXaqJrV7ak71U0rlro2FhG1jKTudJOrqvujpY0g9tqKSwRkjzf56nSV2TJvZ6cUTcLyL21WSy9v9bbf12dERESPoLSf/QWnu7/VT1bJ1iKZttr7q2091XefuhtXZ7RBwr6eOSNkk6vbV22RqrVViMvSSdM/Fd7STpfa21v4mICyV9MCJeIelbkl64hjoWJEXE+yUdImmPiLhG0psknaTpdjpf0rM0mTh6s6TfXHWFd3AsYa9DImJWk6GqeUmvkqTW2mUR8UFJl2uySus1rbWta6D2jo5/I+k/SLokIub6d29U1bP1jKVsduT2qGu1c32hUCgUCoXCKmG9DzUWCoVCoVAo3GtQHa9CoVAoFAqFVUJ1vAqFQqFQKBRWCdXxKhQKhUKhUFglVMerUCgUCoVCYZVQHa9CobAhERFbI2LO/maWSTsfEXusonqFQqEwFet6H69CoVBYBj9trc2utRKFQqFwZ1CMV6FQuNcgIjZFxNsi4tJ+sO1r7efXRsTFEXFJRPxKT/+4iPhCRHwlIj4fEfv3718WEWdHxN9ExJURcbLd/4x+/0si4vg1yGahUNjAKMarUChsVPyC7TL9zdba8yQdI2lG0mw/+WJ3S//91tpBEfEfJb1e0islfV3Sk3raQyX9kaTf6OlnJT1G0i2SroiIP5X0S5I2t9YOlKSIGG3H/BUKhXshquNVKBQ2KqYNNR4q6c9ba7dLUmvtRvuNw4q/LOn5/f/dJJ0ZEVs0ORZkZ0v/ydbaDyUpIi6XtI+kyyQ9onfC/lrSJ+657BQKhR0BNdRYKBR2FNzS5VYNQedbJX2qM1jPlnT/KenvuKa19gNJj5b0aUmvlnTa9lS4UCjc+1Adr0KhcG/CBZJeFRE7SVIaapyG3SRd2/9/2bZu3ldG3qe19mFJvy/poLuuaqFQ2BFRHa9CoXBvwmmSvi3paxHxVUlHbSP9yZL+OCK+opVNvdgs6dN9btl7Jb3hbuhaKBR2QERrba11KBQKhUKhUNghUIxXoVAoFAqFwiqhOl6FQqFQKBQKq4TqeBUKhUKhUCisEqrjVSgUCoVCobBKqI5XoVAoFAqFwiqhOl6FQqFQKBQKq4TqeBUKhUKhUCisEqrjVSgUCoVCobBK+P8TExbbeyHUswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAABgCAYAAADMznxyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUdUlEQVR4nO3dfbAkVXnH8e9vd1lRIcK6iLwYEEVTaOlK1IAhhiQGBTWrSUTR+EpcrYilUaNoJaXRRImlWIVRU0RXUBOUKjRiRAUplRLfUAQXUGAVENblzQXCiwvs3id/9Gm3abp7emZ6embu/X2qbs1M95mep+d0933m9OnTigjMzMzMbPKWTTsAMzMzs6XCiZeZmZlZT5x4mZmZmfXEiZeZmZlZT5x4mZmZmfXEiZeZmZlZT5x4mZlNkKSXSDp72nGY2WyQx/Eys6VEUgAHRsTGCSx7f+AqYKeI2Nb18s1s/rnFy8wmStKKaccwjHmL18zmixMvM+ucpKslvU3ST4A7JR0m6TuSbpV0saTDC2VXSfqkpF9JukXS/xTmvVrSRklbJJ0pae/CvJD0WklXpuV+RJLSvEdL+pak2yTdLOlzafp56e0XS7pD0gslHS7puhTv9cAnJb1C0rdL6xSSHp2eP1DSByVdkz7j25IeCOTLvzUt/9DysiQ9TdIF6X0XSHpaYd43Jb1H0vmSbpd0tqTVXdSJmc0GJ15mNinHAM8GDgC+CPwLsAp4C3CGpD1SuU8DDwIeBzwM+BCApD8F3gccDewFXAN8tvQZzwGeAjwhlXtmmv4e4Gxgd2Bf4MMAEfH0NP+JEbFLRHwuvX54im0/YF2LdfsA8PvA09L73gosAPnyd0vL/27xTZJWAV8GTgIeCpwIfFnSQwvFXgy8Mn0XK8m+LzNbJJx4mdmknBQR1wJ/A5wVEWdFxEJEnAP8EDhK0l7AkcBrI+KWiLg3Ir6V3v8SYH1EXBgRdwNvBw5N/ahyJ0TErRHxS+AbwJo0/V6yJGrviNgaEfdpvaqwALwzIu6OiN80FZS0DHgV8IaI2BQR2yPiOynGQZ4NXBkRn46IbRFxGvAz4LmFMp+MiCtSHKcX1snMFgEnXmY2Kdemx/2AF6TTgbdKuhU4jKwV6xHAloi4peL9e5O1cgEQEXcAvwb2KZS5vvD8LmCX9PytgIAfSLpU0qsGxHpTRGxtt1qsBnYGft6yfNF91im5hnbrZGaLgDuRmtmk5JdMXwt8OiJeXS6QWrxWSdotIm4tzf4VWdKWl30w2em5TQM/OOJ64NXpfYcBX5d0XsOVjOXLu+8kO/2Zf/bDC/NuBrYCjwIuHrCcsvusU/K7wFcHvM/MFgm3eJnZpH0GeK6kZ0paLmnn1KF934jYDHwF+Kik3SXtJCnvJ3Ua8EpJayQ9AHgv8P2IuHrQB0p6gaR908tbyBKihfT6BrJ+Z00uBh6XPntn4F35jIhYANYDJ0raO63ToSnGm9Ln1C3/LOAxkl4saYWkFwIHAf87aJ3MbHFw4mVmE5X6ea0F3kGWmFwL/AM7jj8vJeuT9TPgRuCN6X1fB/4JOAPYTNbC9KKWH/sU4PuS7gDOJOuP9Ys0713Aqem059E1MV8BvBv4OnAlUO4j9hZgA3ABsAX4N2BZRNwF/Ctwflr+IaXl/prsgoA3k502fSvwnIi4ueV6mdmc8wCqZmZmZj1xi5eZmZlZT5x4mZmZmfVkKomXpGdJujyNSH38NGIwMzMz61vvfbwkLQeuAP4cuI6sc+oxEXFZr4GYmZmZ9WwaLV5PBTZGxC8i4h6yW4CsnUIcZmZmZr2axgCq+7BjRGvIWr3+oOkNy6RwZzRrQ9MOwMxszuTHzSi9rpvGgPnzMFbCpGPcDjdHxB5V82Z25HpJ60g3qxXj3zNjeeH59jGX1ZWmmJZjo1jM31v+42Oh9HqWLAwuYjb3ZnHfG0d+3Nxeel03jQHzJ/0/tovjTFOMg/4fD/pOALbc/9ZgvzWNxGsT2f3ZcvtScQuQiDgZOBlghRSwYyWbNop7KsrUadrY+raYE4aypbSuuS4P1LN80J/l2IrqktemA3o58R21jN1f0/c2L9vUtJT/j5Wnj7KsYZYzynvaaEqM2m4TTfthU4zlfKKcI+ycHos3d83n7dQirmls0xcAB0p6pKSVZCNRnzmFOMzMzMx61XuLV0Rsk3Qc8DWyJHF9RFza5r33pseqTLg87d6KMnXqfjFYd4q/Lga1Ss5CC2Qbg7abYvz3Vkyz/pW3rYXS9Cp52bpjSlU915VZSseYNutc990Wv9NyHXkfuq9yq07emrK9NH9eWg67bC0edX+r++7a5BVbBxeZTh+viDiL7GaxZmZmZkvGvCTBZmZmZnNvYIuXpD2B9wJ7R8SRkg4CDo2IT0w8uiTImvzaZIl1zZRN721qwp7nUwNNFyG0abZvezXLoOU0xTXK/HFVnQIZ50KLYS7ksOmqq4eu6nCUbXuWTqFNIpa+vtt5UXd18kJFmbJRThvOW+tK3QUvyyqmDdJmm6n6H1++kC8vU+44X4xjZXpsczqyTZ2cQtYfa+/0+grgjS3eZ2ZmZmYFbRKv1RFxOim5i4ht9NwQJLJAF6jPdJenv53ZcaknZBlqOUtdXvO3nepLcgdddtrmV+64ZZYPWaZcrjytr5hmQTnGvJ6r4p+H9enKMpoPAMuGKGOjm6VtbpZimQdttv9lDLcvLYb9rcvtqGmdu/g+qnKBujLbS39F96S/qpyjrE3Md0p6KGmgV0mHALe1eJ+ZmZmZFbS5qvFNZONsPUrS+cAewF9PNKoKxSx0ZeF5eYCzukHkitPzc7BVLWGjxFN+XddPok0/oqXU12GQppGQ60YSbiozD99bUz+GNoN9jtI3pM2I+IPKjNJPparcoD6aHrzU2hi0LYy7zQ3a/tu0aMxiy1XTECCDjrlN/8+67kfd5vgzrDYj2Tf1+SoPutpkYOIVERdK+mPgsWRn/S6PiGGGyTIzMzMz2l3VuBw4Ctg/lT9CEhFx4oRju49iNnpn4XmecS6UXue2VkzPy3aZPbbJtIfJxudt0LtJGOUXyLwbZj3alB3le2naTgctb5j7n7V5zzADnS6WbcC6M8o2N0yZUcrOslH+R/VRpq1x6qHNcSgvk+cOxdjLg642aXOq8Utk+cuGlss0MzMzswptEq99I+IJE4+kQT6OV5W6fjx5Rlo11H/e+lV3m6HiMuvOHU+qRWqUXwjz2io2zC13RvklU9evYJrjJo2zzpMae61NX41RWrrafs/jrnN5OcP8ch0mFpsNXbRyt6nnps8Z5RjSxU2sxzFuv7ZB//Pa9O8cxij9tpr6lA3aXqrK5v3Jy7e5qzrDlr+nq/59X5F0RItyZmZmZtagTYvX94AvSFpG1igkICLidyYaWYVlpUcYfLVB3YizcP8Mvk2ZQbFNo0xfv/Tb/JqoK9M0yv0wV3sOumK0jfKoxOX42i53nJH9+1rnUcpU/dIcptVqkmW6vnp43DLF+W3KDLM9tdnPuvicUWKZ1DoPU6bvY0ubz2nSZj8rG2aU+7oy41yl3LZMnWHKjHLFdNszYcVpddtyU8tmrjwiQlMrWZM2ideJwKHAhoiIFuXNzMzMrEKbhPRa4JJhky5J6yXdKOmSwrRVks6RdGV63H3YgM3MzMzmlQblU5JOAQ4AvgLcnU8fNJyEpKcDdwCfiojHp2nvB7ZExAmSjgd2j4i3DQpyhRS70Nzpt9wJLr9t0NbSa7h/J/q+OtEOc0ow12Ygu3LZcZv2B5mlm/oOo+lXRtuOo/N6IUMbXQye6A7p7XWxzXVRZlI3Z7b7GmUA0nLZSR/b582gC6hGNWj4mvzzivtDOde4AX4UEU+uen+b/egq4Fyy3GbXwl+jiDgP2FKavBY4NT0/FXhei883MzMzWxTajFz/zx1+3p4RsTk9vx7Ys82bRJb15a1ZxazvrlLZPNtcKL0uqht0dZxOjsP84qwq28WtWNrM7/Iy32kaZSiEpl+CXXQenwVd3Cqlzf5QV6bNUCxt5y92s3jBwjhllpK6bbfp2F4uM6nbDE3r+DzuEB1l47Syjru9VrVoFVXddrCcezSpTbwk/XtEHCfpS6QbZBdFxF+0WH6tiAhJtec5Ja0D1sFs/KM3MzMzG1dTi9fLgOOAD3T4eTdI2isiNkvaC7ixrmBEnAycDPAAKXZlxznU4mCou6XH8gBn5Yy06vZAVcNHFJcB7W/O3Obce90yhvmcrmLpYpiE4vy6S3Obhm6oKzNOH7hRW7ymdZl+3fxxYymbVOtSl30Gm5Yzb99/F9tl1+tcF8sw69xUrsvj3LzUc9kwLV5189uU6etzmso0NYgMajGq+k6HWee2x7E29VzOHYrqBlvPyxbPqOX5SX5G7qaGuJoSr58DRMS3GsoM60zg5cAJ6fGLHS7bzMzMbKY1JV57SHpT3cwWVzWeBhwOrJZ0HfBOsoTrdEnHAtcAR7cJUmSZZ55dFjPfvCVr19LrsmLrVl1r2CgD2o1apgvD9OfJDXO7ob5vEdGFYfoZFLW9wmhSv5StO9Ns+R2mTBfbXN+t6eN8TlXZcfazxWwSLV5VZWfhuF0XSxctXkV1/w92bZhfPgtTjrW4bT4oPe6WHjc2xNKUeC0HdiHLe4YWEcfUzPqzUZZnZmZmNu+aEq/NEfHu3iJp8Biyc5S3p9dVLV7lq6zK/YiKw/iPcoViXUta1fy6W/pUXQmRK2fUdf3PimVnqT/MytK0/D33lOZXlenyFibz2jck1+ZWHeX5TWW60vZXaZMuvpdRxpwateV5FvezacfSlWE+p4uxxaY5ztygY1Sblpauj3OzpG4dc12NZ1dW/r/c1KJWPjuWt25tLZQp5x5PavjspjhHaukyMzMzs2pNiZdPCZqZmZl1qPZUY0SUR52fmpUHwP4nAKvShNsLM/OecXm0eSqZtwnmPfKr2nPL5/XatEe3afsd1HZKaf6gzxxkULt0+bOKmuJv+zl108bVVQ/bUWJrW4d9Gma8jXG2ub7XedxzpuPE2+a85CjX048zgm0X5876rOe+jnNdxjLOPjRMHOPGMoxh+ibkZmFsi7bxTqo/RdX9gerGw3hwesxzkGKfoF+lxzznOLb+I2fhogYzMzOzJWHgLYNmwu4HwwvOZ0dXtl0KM8u3plxRmp6/3lZ4T/686oZCxfcsVfn3U/7u6l4P855hltv0nrJB87ssYzuMUs91y2gqY7PB+1A/+j6ednVsL+s7/mEME385n2jKK9K8Y+svkXOLl5mZmVlPFFF7u8SZIekm4E7g5mnHYkNZjets3rjO5o/rbP64zubPsHW2X0TsUTVjLhIvAEk/jIgnTzsOa891Nn9cZ/PHdTZ/XGfzp8s686lGMzMzs5448TIzMzPryTwlXidPOwAbmuts/rjO5o/rbP64zuZPZ3U2N328zMzMzObdPLV4mZmZmc21mU+8JD1L0uWSNko6ftrxWDVJV0vaIOkiST9M01ZJOkfSlelx92nHudRJWi/pRkmXFKZV1pMyJ6V97yeSDp5e5EtTTX29S9KmtK9dJOmowry3p/q6XNIzpxP10ibpEZK+IekySZdKekOa7v1sRjXU2UT2tZlOvCQtBz4CHAkcBBwj6aDpRmUN/iQi1hQuuT0eODciDgTOTa9tuk4BnlWaVldPRwIHpr91wMd6itF2OIX71xfAh9K+tiYizgJIx8YXAY9L7/loOoZav7YBb46Ig4BDgNeluvF+Nrvq6gwmsK/NdOIFPBXYGBG/iIh7gM8Ca6cck7W3Fjg1PT8VeN70QjGAiDiPHbeUz9XV01rgU5H5HrCbpL16CdSA2vqqsxb4bETcHRFXARvJjqHWo4jYHBEXpue3Az8F9sH72cxqqLM6Y+1rs5547QNcW3h9Hc1fhk1PAGdL+pGkdWnanhGxOT2/HthzOqHZAHX15P1vdh2XTkutL5zCd33NGEn7A08Cvo/3s7lQqjOYwL4264mXzY/DIuJgsmbz10l6enFmZJfP+hLaGed6mgsfAx4FrAE2Ax+cajRWSdIuwBnAGyPi/4rzvJ/Npoo6m8i+NuuJ1ybgEYXX+6ZpNmMiYlN6vBH4Almz6w15k3l6vHF6EVqDunry/jeDIuKGiNgeEQvAf7LjFIfra0ZI2onsH/h/RcTn02TvZzOsqs4mta/NeuJ1AXCgpEdKWknWme3MKcdkJZIeLGnX/DlwBHAJWV29PBV7OfDF6URoA9TV05nAy9JVV4cAtxVOldiUlPr/PJ9sX4Osvl4k6QGSHknWWfsHfce31EkS8AngpxFxYmGW97MZVVdnk9rXVowf8uRExDZJxwFfA5YD6yPi0imHZfe3J/CFbNtlBfDfEfFVSRcAp0s6FrgGOHqKMRog6TTgcGC1pOuAdwInUF1PZwFHkXUcvQt4Ze8BL3E19XW4pDVkp6quBl4DEBGXSjoduIzsKq3XRcT2KYS91P0h8FJgg6SL0rR34P1sltXV2TGT2Nc8cr2ZmZlZT2b9VKOZmZnZouHEy8zMzKwnTrzMzMzMeuLEy8zMzKwnTrzMzMzMeuLEy8zmkqTtki4q/O3fUPZqSat7DM/MrNJMj+NlZtbgNxGxZtpBmJkNwy1eZrZoSFou6QOSLkk3tn19YfbrJV0oaYOk30vlnyrpu5J+LOk7kh6bpr9C0uclfVXSlZLeX1j+KWn5GyT9/RRW08zmmFu8zGxePbAwyvRVEfF8YB2wP7Am3fliVaH8zRFxsKS/A94C/C3wM+CPUtlnAO8F/iqVXwM8CbgbuFzSh4GHAftExOMBJO02wfUzs0XIiZeZzauqU43PAP4jIrYBRMSWwrz8ZsU/Av4yPX8IcKqkA8luC7JTofy5EXEbgKTLgP2AS4EDUhL2ZeDs7lbHzJYCn2o0s6Xi7vS4nR0/Ot8DfCO1YD0X2Lmi/G/fExG3AE8Evgm8Fvj4JAM2s8XHiZeZLSbnAK+RtAKgdKqxykOATen5KwYtPF0ZuSwizgD+ETh49FDNbCly4mVmi8nHgV8CP5F0MfDiAeXfD7xP0o9p1/ViH+CbqW/ZZ4C3jxGrmS1Biohpx2BmZma2JLjFy8zMzKwnTrzMzMzMeuLEy8zMzKwnTrzMzMzMeuLEy8zMzKwnTrzMzMzMeuLEy8zMzKwnTrzMzMzMevL/YJ/WW7XWIjwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAABgCAYAAADMznxyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ7klEQVR4nO2de/AeVXnHv98kQICgEBK5F7xQO4gaqVqw1NLWqqA22lYUrfcanYqjrVbBaUerLVJHcUardqxG8FKUGbSiooKMyHgHEUhAuchFEhMhQhCIEJI8/WN3yeHJOWfPvu++t/y+n5nf7G/3PHvOc67vs+dKM4MQQgghhBg98yatgBBCCCHEXEGGlxBCCCHEmJDhJYQQQggxJmR4CSGEEEKMCRleQgghhBBjQoaXEEIIIcSYkOElhBAjhORLSV4waT2EENMBtY+XEGIuQdIAHG5mN4zA78MA3ARgFzPb0rf/QojZRz1eQoiRQnLBpHXowqzpK4SYLWR4CSF6h+TNJN9O8ioA95I8luT3SW4keSXJ4wLZxSQ/RfJXJO8k+X+B22tJ3kDyDpLnkTwwcDOSryd5fe3vR0iydnsMye+QvIvkBpJfqJ9fUr9+Jcl7SL6I5HEk19T6rgfwKZKvJPldFycj+Zj6/91JfoDkLXUY3yW5O4DG/421/8d4v0g+jeSl9XuXknxa4HYxyfeQ/B7Ju0leQHJJH3kihJgOZHgJIUbFSQCeA+BRAL4M4N8BLAbwVgDnklxay30GwB4AHgfgEQA+CAAk/xzAewGcCOAAALcA+LwL47kAngLgCbXcs+rn7wFwAYB9ABwM4MMAYGZPr92faGaLzOwL9f3+tW6HAlhRELf3A/hDAE+r33sbgG0AGv/3rv3/QfgSycUAvgbgQwD2BXAGgK+R3DcQewmAV9VpsSuq9BJC7CTI8BJCjIoPmdmtAP4OwPlmdr6ZbTOzCwFcBuAEkgcAOB7A683sTjN7wMy+U7//UgArzexyM7sfwKkAjqnnUTWcbmYbzeyXAL4NYFn9/AFURtSBZnafmT2k9yrCNgDvNLP7zex3OUGS8wC8GsCbzGytmW01s+/XOrbxHADXm9lnzGyLmZ0N4OcAnhfIfMrMrqv1OCeIkxBiJ0CGlxBiVNxaXw8F8MJ6OHAjyY0AjkXVi3UIgDvM7M7I+wei6uUCAJjZPQB+A+CgQGZ98P8mAIvq/98GgAB+TPJqkq9u0fV2M7uvLFpYAmAhgF8Uyoc8JE41t6AsTkKInQBNIhVCjIpmyfStAD5jZq/1AnWP12KSe5vZRuf8K1RGWyO7J6rhubWtAZutB/Da+r1jAXyL5CWZlYx+efe9qIY/m7D3D9w2ALgPwKMBXNnij+chcar5PQDfaHlPCLGToB4vIcSo+SyA55F8Fsn5JBfWE9oPNrN1AL4O4KMk9yG5C8lmntTZAF5FchnJ3QCcBuBHZnZzW4AkX0jy4Pr2TlQG0bb6/teo5p3luBLA4+qwFwJ4V+NgZtsArARwBskD6zgdU+t4ex1Oyv/zAfw+yZeQXEDyRQCOAPDVtjgJIXYOZHgJIUZKPc9rOYB3oDJMbgXwz9je/rwM1ZysnwO4DcCb6/e+BeBfAZwLYB2qHqYXFwb7FAA/InkPgPNQzce6sXZ7F4Cz6mHPExM6Xwfg3QC+BeB6AH6O2FsBrAJwKYA7APwngHlmtgnAfwD4Xu3/0c7f36BaEPAWVMOmbwPwXDPbUBgvIcSMow1UhRBCCCHGhHq8hBBCCCHGhAwvIYQQQogxMRHDi+SzSV5b70h9yiR0EEIIIYQYN2Of40VyPoDrAPwlgDWoJqeeZGbXjFURIYQQQogxM4ker6cCuMHMbjSzzaiOAFk+AT2EEEIIIcbKJDZQPQjbd7QGql6vP8q9MI+0+cF92EdHd43JeHeLPBPjI5VX486PWHgqG7NPrg+fBTLD0OZ/rsyNQo+ScGJt4yBhDRPncdW3Lvmfk+3yezNpusSjb/oo2138GPX43TZ3z4zbVmCDmS1FhKnduZ7kCtSH1c5DddJtw9bg/13qa2iYAdWmQM273r1x2wXtNO/7RJ0mfLdlTNdpWkXh82pr4vmo/YilybaMWxtN2FszbkjIxPQeJE6TIhbnSZGrq6Ouz23+58rcKPQoCWdegUxJWMPEua/2qa1dyNXRlF991edRkWr//W9fSTz6piSd28pczA+fr819l/I7SJvlzxSbH3Fr/L1rx6PBHmQShtdaVOezNRyMyBEgZvZxAB8HgAWkbcX2SMYMJp+IXiaWyE3B9IZYmHmDNERtlbDkB7XLj26qEYvFo62S5vwfRiaXjqmGIWeMpOjSSG7NyJT8MPg453QbRu9B0qXth6FEpks4XX7QupSnhi5Gct/GVVtd7NKAD6tTabvQJZyY7KjiPM9dt7nrIEZal7YlF6/Uj3mMLvW5z3pWGj5QlrZ9fACWtC25PGyrr41fmzP+d6FLnO9zMgvdfeiXN3TvyugwiY6QSwEcTvKRJHdFtRP1eRPQQwghhBBirIy9x8vMtpA8GcA3URmHK83s6pJ3N0ee+S/uzYnnsS+Qbe7+AbQzyFCU9zfXQ9KlFyVFly81nxY5RiWT+hraGpEZJF1SsvM7yMTKRpe0G4RUuuTKaZtMWG7bynvJkF1JnWnzP5eXXepmwzA9FSX+5r6YxzXkOk3h9FEXhwkvTP9xty0ltLUtsd81L5PrsWvTN1aHfC9Prj6XpkuXkaJh67OfShSZX1XkT+q5tw0aNtXXPZweoS5+ODLGROZ4mdn5qA6LFUIIIYSYM0zTnGshhBBCiJ2a1h4vkvsBOA3AgWZ2PMkjABxjZp8cuXaO2LBhMyG+6fLbq77e7dxzFmbjn/cL2HE4pI/hpb6G7Bq6TGj3sl0mdXehDz9ilCwk8G5tfgzKIHFrS5dBh61KZXNx77Loo8R9kAnBXWT7GDbsg9hwQ58LRoaly+KeUejS1yKiFH1Nuh7Fis5Sma66dGm3Bxme7KJLjkHqfEke+jRN1bPcMKL3KxdOU8d3c/fhsGJs+LHN3xxnopqPdWB9fx2ANxe8J4QQQgghAkrmeC0xs3NIngo8ODl+rNv2zENlTTYT2/YM3FKKNMs+Y1tP7Fpfmy8lb32G73jruGSbitQXZuNXbjuMlExsMmibLrl9ynwvX0hbnGNfGSmZnC7en5y+o46zl9k18TwWVmpi5zBpO6yMl23cc1+AfeiSi3NTL3LbAXRJfy/jZVP5E5LrlfO6pHoSFmJHvGxMV/+FX7LtSSpdUulWokusl7JNl1w4w+iS0yklk/IjlBmkbHdpt2P7RZbK5NqWlF/D5nMqnL7TpaFLnfe9TKkyGQunpG2P1VfgoT2nqXTxCzFCvx6IPEtR0uN1L8l9UW8KS/Jo5LeoEEIIIYQQEVoPySZ5FIAPAzgSwGoASwH8rZldNXr1KhaSdgi2W5vhuGpqWWljve5dX2M9RgudrO8JCxlkGwn/zjBj5bHdpb2/o1op4cfLu8yj6DK/YJBwhtGtC7E8bEvvWJxT+nbpQs5tkdIHuTzrM72HnXvSMKryP+rTKlL1t892IxduCdOkS5/03bZMc33OkUr/WPiD5FVJefFpNcxvbcrP8JnfXiNXtr0t0LzTjLrFRn2akblfAT8xsyfH9G0dajSzy0n+KYDHojqa6FozG2b7HiGEEEKIOUnJqsb5AE4AcFgt/0ySMLMzRqzbg2xD1cvV9EjFVhH58dXGUm2sz92wncZKvdeFk9skM7eBXfg89m5jSXsLO0aJtZ/SJbch5TBni6U2GCxZSejHxktkSjY59MTmw4ziqKa+VgMNc1RKLP37OBIqFU4o00dZKAknRUk9y+VhaqPIUR9PVVLmUuF1WeFZ0lPSZVVjSdsyCl26zPEapD53WQXdpW0ZJG1j/relyyA9YiU9y7H64etp3yt2U3V+kN+zXPr43+GS33A/j6159zf1NZxvvrG+lszxKplc/xVUds8qtLeLQgghhBAiQYnhdbCZPWHkmmQwVJZmY6HGVi40z+52z5terdhRKQvdfQ7/pZ8bH07JpPwsCXcQXWJxTsnEvnAa/Jh4bk5CSib8umiTiX2R+JVBqaNBcnH2dPl6L3knF+eUPyVx7pL+bWWqyzFAg+iSy2dPSTgleeSPCfOU5FnMj0F0GaTMtYUTy+dBeuO8HyVx9jKDzMvL6Z/TJefPoDI5/YdpW0ra00F+QwbpYSwpt13KXOkh1sP0bqXCjoUTyvjy4nWJhZfqaYyVU59Xe7r7sEw09oS3QWKUzF/7OslnFsgJIYQQQogMJT1ePwTwJZLzUBl6BGBm9rCRahZAVBZos5oxtHKbHq3G2vQrFhvZcCWk35enbS5KTKare5tMlxUcfeoS+8IsnT/QZWXQqGWGXR01i3HOuQ9THgcpE32twkr50/fKr9SX8iC6DBv3YdK2r7I2Ll3aZEt6T0YV51RvzLBte6lMzr3PtB3Gj9CtS++/J7ZKv4sODW29bF3CifnlbYWmZ3av+hraFduc2yakKTG8zgBwDIBV1rb3hBBCCCGESFJiqN8KYHVXo4vkSpK3kVwdPFtM8kKS19fXfboqLIQQQggxq5RsoHomgEcB+DqA+5vnbdtJkHw6gHsAfNrMjqyfvQ/AHWZ2OslTAOxjZm9vU3IBaYsQPyZhD3fvhyObLsJwQn4z+c0PTzaE1miXpbNtDNM1m5vM2ueSY6B9MuWoN6rs4n8u3QbpWh8mn7sc2F0S51GlSxeZPuhj8m1fhxEPshFo2zYAMfqQGXc4JQyyVU2JLn3VszaZUbUtfQ0796lLyj1GSbr0nUcNpe1Prl0t2UDVu3VpA5pwGvuimVwf2hWNcdT4f0dmA9WS9L4JwEWo7J69gr8sZnZJFfZDWA7grPr/swA8vyB8IYQQQoidgpKd6/+tx/D2M7N19f/rAexX8hJRWX2xg369ZesnvcUsy0bGL42PbVPRtty5eSecZNcmE/tySMn4Za0lMrFwUjKxXsSULn5CfizOKZlQlzaZ2MT/Rsbn0a7OPdZb6cPJbUdSmrZh2G1+lMjk4lyS/j5OvmzH6kGbzCC69JXPg9SzkrKd2zIjdA/98Wlbks/DlLmUe4mML7dAul0YddsyjC6TqGepfG56MmJtyzwnE8vnNhnvntOlSz1LtZXA9kVpjcx8dx9ODE/JNH7kfkNSMrkyB3efq0OptqWRDcPx6e83R421p942aOLRxCvUudlqovHH9zqFJA0vkv9lZieT/ArqA7JDzOyvMv62YmZGMjnOSXIFgBXA5M7zEkIIIYTok+QcL5K/NbOH1ec07oCZfafVc/IwAF8N5nhdC+A4M1tH8gAAF5vZY9v8mU/aQmy3OsMt+ee7Z5vdfW7zu7ZN2HL+NWx17uEzH97ChHtMxvdChBvypfwpCcdb+bmNL0vDick09345bheZ8N6ni++JTOVP6I//0sltqut1ad4Jj57yG+96mZguD7TIhOF6fb1M+AXYJpNLl9RGwoPo0iX9G8JwU+ni082/F76zW8K9RGaQehYLpy1tS2RibUuqXejStqTiUyIzTDglMr59ysmMq54N0p52kfFbIAE7Hs7sZfpqTwf5PSvRJXWEn3cPZVLl3/c+xWR8nJtr+I7vkfK6hG2LP66o6QH0vW7hHPNGpvH/lgEPyf4FUGZgdeA8AK8AcHp9/XKPfgshhBBCTDU5w2spyX9KORasajwbwHEAlpBcA+CdqAyuc0i+BsAtAE4sVXJpcB9a443Fucm5+S/a0FJNzW2J9YSkDhkumR/WULLipU2mZOPIYXqZYr18sbH71DspmZKekNQ8m/BrJdVb5dM/duxGl16+VD52iXMs/X0PXSr9u+RzX+nf9sXfly5dyrZ/J1Ym22Ry5X+YeubLSq6Xo+Rw8rYjxWK9P6n2Jxa/VBnzfuT8ycW5T12msZ6VtC195HPo7lfr53rNStMu18uXaitj/nYZKWqe+fiU6N92/FYok1r1GWv3/CHWJasq962vzdyuxt64O5DxxwnlyBle8wEsQjW3vTNmdlLC6S8G8U8IIYQQYtbJGV7rzOzdY9Mkw+4AHh/cx1YfNCsVN7n73FdAyX4eqf2XpnHCfxfdUl8IMRlPH70cXSndW6xLXsZoS5dcOSqR8au4StK/b108g+xt5cMbRJdYvNpkYr0nKT+69HgNokuM1L5Rw+wtltvjra0XJZTx6RLzo7TMDVNuu4QTMkjZHpUunr7zeZCykJPxpOIcW4makhmkzS3ZiysVXvi8TabLXoq5EZ7mnbvq65H19fb6GvYM+h7fGyP+pXQJGainSwghhBBCxMkZXhoSFEIIIYTokeRQo5nl9v8aK3uiOqW7USi2oWDTzbd/ffUbt8UszMaf1DLT0N893H1DbPmt7zLtc2l5iUxfy9z9ZEEfnz2xnTaZMJw2Ge+e8gfY3k2cm9iYWha+LSLj89nnZThJtE0mposvT/7dUKe2rRViujR0iXOTdpudTKzMeX/a6keJTHjfJpOLcyqcrQUyXeKc28LEL2PvI13COLe1LbF45Ooi8NCl/qX1LPTfh9ml/fFpm6tn/t7XoZh/vg6V1DMv0yUPc/WsLc6xLRy8jK+rMV18HsV08rqk4hzTIVXmQlLlxdehUMbX11z98DJtW0XE/PGLJ8I4+41ZGztiqbuGQ7J+2tPnkGYapyoJIYQQQuyUtB6SPQ08+cn722WXvRzACRHXRe7+MfW1sce31NfQFm7c1rv7mJ9r6mvTObjF3W+I+LHAPbvH3S9w1xKZjYFsm4x3j8n4dAv1T8m0+RH6M4yMd/f6xWS8e5dwuugSum9pkdkSyDYyGxIyuXz24Xg/cv6k0q1E5p7IM1+2U37EZHycY/nclv65cGLp4t9J+bPIuZfoUlK2fR6G77Tp2yWcVNrGwkm1YTF929I2pktJmevStgxSz1Lh5Mpcn/U5V+Z8WcjV55wM3DOvr9c1rM9e35wf97XI5OKckgnLXEqX9e4+pLTOx9owf78m4t7osrfTZYmTXR2802x5Ws3SIh8/1CHZQgghhBCiB2aix4vk7aimbW1okxVTxRIoz2YN5dnsoTybPZRns0fXPDvUzJbGHGbC8AIAkpeluu3EdKI8mz2UZ7OH8mz2UJ7NHn3mmYYahRBCCCHGhAwvIYQQQogxMUuG18cnrYDojPJs9lCezR7Ks9lDeTZ79JZnMzPHSwghhBBi1pmlHi8hhBBCiJlm6g0vks8meS3JG0ieMml9RBySN5NcRfIKkpfVzxaTvJDk9fV1n0nrOdchuZLkbSRXB8+i+cSKD9V17yqSR01O87lJIr/eRXJtXdeuIHlC4HZqnV/XknzWZLSe25A8hOS3SV5D8mqSb6qfq55NKZk8G0ldm2rDi+R8AB8BcDyAIwCcRPKIyWolMvyZmS0LltyeAuAiMzscwEX1vZgsZwJ4tnuWyqfjARxe/60A8LEx6Si2cyZ2zC8A+GBd15aZ2fkAULeNLwbwuPqdj9ZtqBgvWwC8xcyOAHA0gDfUeaN6Nr2k8gwYQV2basMLwFMB3GBmN5rZZgCfB7B8wjqJcpYDOKv+/ywAz5+cKgIAzOwSbD9vviGVT8sBfNoqfghgb5IHjEVRASCZXymWA/i8md1vZjcBuAFVGyrGiJmtM7PL6//vBvAzAAdB9WxqyeRZiqHq2rQbXgcBuDW4X4N8YojJYQAuIPkTkivqZ/uZ2br6//UA9puMaqKFVD6p/k0vJ9fDUiuDIXzl15RB8jAATwLwI6iezQQuz4AR1LVpN7zE7HCsmR2Fqtv8DSSfHjpatXxWS2inHOXTTPAxAI8GsAzAOgAfmKg2IgrJRQDOBfBmM/tt6KZ6Np1E8mwkdW3aDa+1AA4J7g+un4kpw8zW1tfbAHwJVbfrr5su8/p62+Q0FBlS+aT6N4WY2a/NbKuZbQPwP9g+xKH8mhJI7oLqB/xzZvbF+rHq2RQTy7NR1bVpN7wuBXA4yUeS3BXVZLbzJqyTcJDck+Rezf8AnglgNaq8ekUt9goAX56MhqKFVD6dB+Dl9aqrowHcFQyViAnh5v+8AFVdA6r8ejHJ3Ug+EtVk7R+PW7+5DkkC+CSAn5nZGYGT6tmUksqzUdW1BcOrPDrMbAvJkwF8E8B8ACvN7OoJqyV2ZD8AX6rKLhYA+F8z+wbJSwGcQ/I1AG4BcOIEdRQASJ4N4DgAS0iuAfBOAKcjnk/nAzgB1cTRTQBeNXaF5ziJ/DqO5DJUQ1U3A3gdAJjZ1STPAXANqlVabzCzrRNQe67zxwBeBmAVySvqZ++A6tk0k8qzk0ZR17RzvRBCCCHEmJj2oUYhhBBCiJ0GGV5CCCGEEGNChpcQQgghxJiQ4SWEEEIIMSZkeAkhhBBCjAkZXkKImYTkVpJXBH+HZWRvJrlkjOoJIUSUqd7HSwghMvzOzJZNWgkhhOiCeryEEDsNJOeTfD/J1fXBtm8MnN9I8nKSq0j+QS3/VJI/IPlTkt8n+dj6+StJfpHkN0heT/J9gf9n1v6vIvmPE4imEGKGUY+XEGJW2T3YZfomM3sBgBUADgOwrD75YnEgv8HMjiL5DwDeCuDvAfwcwJ/Uss8AcBqAv6nllwF4EoD7AVxL8sMAHgHgIDM7EgBI7j3C+AkhdkJkeAkhZpXYUOMzAPy3mW0BADO7I3BrDiv+CYC/rv9/OICzSB6O6liQXQL5i8zsLgAgeQ2AQwFcDeBRtRH2NQAX9BcdIcRcQEONQoi5wv31dSu2f3S+B8C36x6s5wFYGJF/8B0zuxPAEwFcDOD1AD4xSoWFEDsfMryEEDsTFwJ4HckFAOCGGmM8HMDa+v9Xtnler4ycZ2bnAvgXAEcNrqoQYi4iw0sIsTPxCQC/BHAVySsBvKRF/n0A3kvypyibenEQgIvruWWfBXDqELoKIeYgNLNJ6yCEEEIIMSdQj5cQQgghxJiQ4SWEEEIIMSZkeAkhhBBCjAkZXkIIIYQQY0KGlxBCCCHEmJDhJYQQQggxJmR4CSGEEEKMCRleQgghhBBj4v8BvZGcVu7o/rUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAABTCAYAAABOIAlxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoOklEQVR4nO2de7BlR3Xev8VoBonR4+iFMILoglChyBANQmCwsA02sYFUIhOnbHAlwXZSIjE4tuNUAkmqTFVSmKJsUkUSO3GACEICpYpxjBNeMgEcP7D1YGQ9rEGyuBgJRkIaHY0QSCPNdP44/Zu97nf2uXP1mPvQrK/qVt+zd+/eq1ev7t1r9erV0VpToVAoFAqFQuHo4ykbTUChUCgUCoXCsYKaeBUKhUKhUCisE2riVSgUCoVCobBOqIlXoVAoFAqFwjqhJl6FQqFQKBQK64SaeBUKhUKhUCisEzZk4hURr4mIPRFxa0S8bSNoKBQKhUKhUFhvxHrH8YqIbZK+LOmvS7pd0lWS3thau2ldCSkUCoVCoVBYZ2yExeulkm5trd3WWjsg6aOSLt0AOgqFQqFQKBTWFcdtwDvPlvS19Pt2Sd+z2gM7ItoJkrDNRbrn9rpm6Y6ePpLyPLWnD/b04IKyJGlnTx+2vGH5MiO5d6Cnh3rKLHfbyHucbvIeGslLucdbef6eB9IzJ/X0oZ5SjxPs9xgOWUpdD6Q80AJPva4573GWh2d22PVvp2dO7unDlm6330/VAG+rZnlPTHl5F7RRV2/L4zWAPMgWdFNGbueHLS+gzt52+Zmwe97e0lBX8vCeHVqJLLfw/bSenkX5/QX7k1Dc01P4AG1Ps3If0gDvVzvst/NCmuf/anXmed693a6PPQMNBywvZTwt5W2W1+XfZSPncZr4/XDKyzWXn+Pteh6XuMZ7qI/zLT/D/7THU+13BjRRnvezA5oH5fi4NqbV+weH8lxut6c8h+yaj8W5TGhADimXcY5ns0x4XX1sHxuDHf5M7ncPWh7nC78zb6nrQfs9lpc6P2x5aPexjzz82W55V3vmoKX+3jw2Uj6yxvhKOzi/crn+nff65Gv+rH9vcjt4P/P3jPUZ708+tq8mG/dLd7fWzhy7txETrzUhIi6TdJk0a9BLNC9Y0sqBTBoYgbA/u6fTlOe5Pd3T0/0LypKkl/T0jp7e31MalAbP3KVRmF36R/skzQO6fQLx7ZG8lPv8njIpoc6859r0zCt6eltPmZSdb7/HaHrQ8lDXr6a85/X0lp7yAaOuX095J5aHdqCteCbT/2or55s9fYZdf1565r6eIi/wlme/N+XlXdSNutLO8DyXT9vs6yn1YSIzSXnv7Ok9WgnqjFzlDz90Ik+0K+U+mPJOLQ+/n62VyB/Hm3v6kz39pZ6efMos/dS+Ie+He0qbQ9sLe4q83prKp07I/5LRPdU8JpYHxecUKzM/T52QBWjjmdyH4AfyQnvwAdqV8kL37T1FJmhfl41MN+Wdab+/mfJus2vIPX0J9o+1M3w4p6enW978DGMU/YHx7367P0b3nfabuuYxmHJ2aiWoTy7fv0LIE3JPnc9KeR6ya9A07elpKe+kp4xzlHtBT+F1lgmeRybyBEIaHxsBY6Q/86z0P+Pbdsvr/foODYBPtNkze0p98tg76enentIOyC9l5UkC/KFc5IUxMrcTbQ0tfC/57vDe8zSA8hkvr+7pC3rqCqE0yJF/x55m16VBtqjT/XYdOT1HA5AbynPlLn//+d+NM5OeIjN5PHJ8bmUzrcBG+Hi9XNI7Wms/0n+/XZJaa7+y6JlTI9qrNHTK/PGa9PQB+w3D6GC5c+6zvHw0EIblERpoUISBRqNBcqMxQPBup3FsQHUNh/fwMUnfwLkBiHLoLHSE/JHdbvcYqBHCacrLu8/u6bKVxzM3pGfoYK6djg1a1Am6kc7T7Hru/NC7XyvBQDrWkeETncMnSPkZrl3XUwYR6kEZz9SAaU9p51O0Epn/tCvvZGByucqg/NMsD2mWCQZZt2y69TBPxGizfwu9vSN8rD/83pSXPgIffMILskyfOXJNGvoK9cofZmSaOsJv5Oi6lJc2ci3XJ+UZvMvHAN6T+zEfQmQP3lI+vMhtR53oZ/Qh6M8y4TKF0sJ7oD+X7x9X2pe+SFnZYuQKJTTwUcrOtVPLA4/hLXzL4ymy5R8r6pFpWeqpK7L+sc2TOLem8ww8HVNkfVJDXqdVGsYJ8jqP4dOfpGd2WbnQRF3vTHkZWyiPZ3xikUHeZcsL3bnObgncZ9dpq2yN5nnqSl8d+8aSd8nyMN4xluX+xsQHuinfJ0bSMCbRN/mG+HcsT6Ko69Ro+0RPmWhnPnl/9T6alSJkApmDJt5HffLEy2X4D6RrWmsXawQb4eN1laTzIuI5EbFD0hskfXwD6CgUCoVCoVBYV6z7UmNr7ZGIeKukT2s2mf1Aa+3GtTyLppBNmt+0PA/a9V09zVodGgDloc2hvS+NvJNZMRYXzK68J09r0VyxbjA7ZxY9pjX6ksqXrIxsFUDDQKPhGdf0s1bh1hhocQuVNMzYeR5+L/cUPmXHPN7tZls0g6xt0UYTy+Mac8bU8lAfykUrGrOe0L5oTGi9WdOkTiw/fs3ykGat9/l2z2nI2hbyh/UEjYz3uMVTGvgz7am3a5Yf6ob1EDmlLTHxn68B/wS6u7Pbf/vWLP2v/XruW1i8qKPLMDQ9VwN8mQot2i0XWVOmfNqDJWDe87qU1y1EaLBLdj1bBunPaNluvcp1RpZpG+pIX530NMsRfZPyseyMachuQXNLly+X5XK2WR6sl8h2Xlaa9hTZg5fIZJZT2s+tViyXUX62wvEM7ZHHEqcFHrqLBv0aml6iAbQr76Q/P9OuSwNfeAbeLrIaZ1rc8k75q1nVoXvS0+We5qVG6u9uBrQrY1i25vN9cQsg8nN6ygv98BZa3F0lt8ttlge+ed2loY7koRz61YU9zSsgvsTuY3r+Dd1ePt8d+JbX7eAD3wFkj2fc+iTNu84A+mi2RtPmSz31by79Ij/D2LIWn8AN8fFqrX1Cg1WwUCgUCoVC4ZhARa4vFAqFQqFQWCcc0eIVEWdJeqekZ7bWXhsRF0h6eWvt/Ueduo4Dmpkjx3YGYfIbMy1Kg/kvzzAxg057iimVHVrLKS/l7e4pSzW+FR9TpDTs9gAHR/JI486ImD0xp2NKvS/l5Z377B60jjn9YqpmCYRn3SFfGurGcthyTyc9Pd+uZ/gOM/JkWjCTs5xEfXwZKy+xuMka/rBkOrWyc174z3IJ5WYHW57H3E87UAbvyQ6emJR5xnd1Zcdz33XGM+6MfW565h67dr2Vn3k6tnwtDf2DJdSfyR2hM/w/9yXG3zMax5Y9WbaAfnjpzr/S0Ea+QxG+IXu3aAD89aVY+vH/S3ndAZ+6QoMvPUrzmqZvoshjy32W15e6QF6q8+Xs0+133k3HEh07Qcd2JDqgCX7Af+h2Z35pqBvy5DsL8/toC9oIufcdoxn0K8Yd2o5lw9xnpj29yPLAF98dnemFTnjKUnbeMOJtBv2TnjIGj+0Wd5cB+i/tm3daTu3eck/zEh2AbtrGd3r7xhtpfuc67UlZebx21wbfnHS73c9Y6ilji++olQb5YUz075vvFpSGuiHjvsEjuyRQ7z/qKW4R1IOy8vh6oeWhzVzG81KghzuZ9pTvfv4+e2QC75PQlPk0tot3EdZi8bpcM38sZOrLkn5hDc8VCoVCoVAoFBLW4uN1RmvtihT24ZGIWMuk7glDaDbrZmaaHZyZ2bpG5rP7bF3yLfDMKPeO5KX8r1tegBY8Hbl20O5RLu8ZqwczbdfqsiWDOlK+x21xJ8UMaPGtzVmbcGfiQ5aH63nLNHxhJo8GhWaTNUy0Emih7mi/rvFkGrxOlDvm+OoB/5AfrDV7Ul74y3s8/tVYvB74jEVq2lPaNztZ5sCu0nyAQdp7mvLA7909zVqitFK7X+So/dqe/kyv4HeSivabncAv9N/wA168cMg6t9kASyzFrRazCTp5xkONZAsMDrS+xRycnf7HkkKdpz2ln/mmmXyNPB4OIFtnkD/qSHu4xTlbwJBHaFnq6aSnWX6xRCyK9TVmEfR4fOTFykRdx6zpyM9yT5Hf3M+QQywUHrfQxzZpaHvfaIGs5A0FyAJ18lARYKJ5+GqG05hp2Wt53MF8KT3DeARPXeZ4JltMoG+v/abPZ4sjdfZNMavFFmPjkoePYIzM3wOPBQidjC2+KiANco4M06/G4glCw5KVT3ljYT0WhTAZs4zDF6yg3ieR5bw5gXe7THj4n9yWSz2Fhy4/05SX/3fZb6clb6LwcWI1rMXi9UBEnK4evDUiXqZ5i26hUCgUCoVC4QhYi8Xrn2oWZ+vciPhDzRSxv3NUqTI0zWanzFTzWjsanm/z9Fn4ND2DdoWmwKx5TFtxixDb2ymX2XJec/ftsPdbOmYF2m6pW2ByVGO0z0UB+cZ8WzwoIBrI2Pq/Bz2d9BQtFU08z/ax4KApoUFRx2wpRDOgbr7Vm1l91lbcikcbUu519lsa2hz6qRcyk8OScA9NBs1mn93PWi/0/kVP3XKRrXC0vQdwdP+VLNsAK4RbTLPWRP15/u/29Cd6qAgsXTko6qd76hbUB+y6NGjI7m/hAXgn6Rnq7KEU4Bu+IjnsCc979PmlnuawMN43kUE/wsS14ky3b2UfC3Dq/ooexTr7efAuxhZkG0te1trvtzzOJ8rPlk76BrLL+7Jvo7SST/DDNXE/8UKa98vzAKTUa8wHizzIP7KYwwDQnu4/5WNZro+Pb2AsAO/U7jG+MVZB63J6hnGIdoZf7guaLbNu0XE/rmzZ5BptT9gFeIC/Uh6DkSna8eWWJ/OCPPiDQQu+g9OeYmGThv4FnR4QfCwALM94SB/Gufw9g5fZGimNHznl7Yq8eGiTMf6Twku3suYx3v123VI4SXl5jvLhk4dLyuOFBzVeDUeceLXWro2IH9CsXUPSntaay12hUCgUCoVC4Qg44pFBEbFN0t/QTOk8PFFrrb3nqFKWcGJEe0H6ndeffVcDKbNzNJ3sb+O7h9COmE1mDY3AhPssj+/mGvNhQmvzY4DGginyDHQy20fbG9uFAy3MsH23TNYQ3LLi/gBjWqP7O021EtlHigCy0ER9sEKMHXFBefAFLQP6s3Y06Sl+GFhgnP9jO8I8WKMHWZQGS8KLeooFiXZAq8w85V3u/zLmW+dWT8rxY5KyBkX93T/Fd/BIA+/e3NMfPGOW7r97lmLpyjsjvR9gHcA3JPsJTY1+aHHftPwM5SKf3ocoK1v5XPOmjZDBbEV0PlMOMjJ2FAh1cyuQH4kjzftlufUT62qmya3F7tOS+xn8cR8491fMgTXpc1hJsExQd+ozdlSKWwjdyp7L86CoPkaO+V/SRvCS92ZL227Li/y4tSxr9u63Mxa8EkCvryowXlO/sT4KnT5ej1lO3deK8nlf5r+fRYs85nNfpfHjZ6BpauX6ztScxy2bfi5jzoMVyHddj2x+Ptwf/NitsYgCvsLilqLMH/cZgw/4fMGvsbHdj1vy3frZmr7UU18NG/PfzStM0rCTn+t813I7UC78+cwqRwatZanxdzWr8/VaW1DWQqFQKBQKhcII1jLxelZr7a8ddUpWwTbNtEE/nkEaZtauzWG5YD19bLcSGoj7iY3FavJdGb7zImtQPstnVoyFwv2JpEE7f4rlmfQ0H7nDLB6NCV8NynNrljRoelgAfRdcBnX0XYxej2yFdE0TuuFLpn9sZ5E0f3B01opoZz9Z3nd9Zk3Nj3XynaLZoubWwok9S72yNunWVSwWY0cSuU8aPHaLYy4f+qY9pc74auSdlz/d0+/rjNjbLV0cgE37ZJmATj/KZFdPs58Q9LrGvVrMKdrC4zthUUYOxnywaCv3/8uWX99h5wdf43u32i6j3VZW5unU7vlO6bHjeTyWErQxdmVNGo3eeUo/cEuqNBylg+XukKXwKx8mzu5UrGJYNmmXsRiH/tutTrkdsLbutzzIWj6ubFdPkTk/6uUqozmXBw+hP/ssAZ5zq7nvus3jNffc+uY+j2N+vLSN70zMlk3GAdoMuuGX7xrP2G73fHzK7/bVEfc1zpZljyvnUQHG/JTcOryav5Ov6jDu8S2Zpry8G15OFuTNfTNbsqT5o/3cnzrTx/jzfK3EF9P/yBH8oE/6Nz3Tsdp45liLH9gnI+KH15CvUCgUCoVCobAK1uLj9XpJH9ZskvawZg72rbXmAWyPGk6KaC/WoDnlHReuYaLxeTTovNCKZsysk1ntmFbNjJlnPMYLz4zF2fJdS2gMaE7ZlwNtyHd+7bPf0qBxoGmgqS331NeupUHLwscHbdujJ2f6odt9K5jtj8XBGvNVklbS73GFfPdY3jHl5VOO75aBt1mL8XgtaCRoX9la4+W5hj+m1aGBob27D1PW9Gkj2t61Uo+aLc1bV2lP6vjPU97v7j5dX+6Wrnf361f31HfJSoP8+44s5Cv7OkIfbeQxrtCm82603T1FzimX92DdyFppjtMlDVarsXb3mHq8m/ZwK0F+Hhn2WG+ZP1yDdx6h22OY5WfOXJAn56WfwR/qysBKn819k75D3Xzc8DFGGmSK8qY9HfMb5R5t4lbosV1VyAL18cOlsxXN/cuA7ybOUcS5tmh3XYbHWOPdyDpylL8h8Mp30dEu7vMlDfxGppd6iqxl65KPiVMrj3bIVpCxuH7SUOd83a2U8NZj4o35bXl8Stoh19XbBB57dPqxyO/wB0vtsubh4+aZltI+ub/DU/oK76F/jPnlQRM08A28bSQvtLCqRMxN6ur9O9OEbN30OH283qPZbtbr25FmaYVCoVAoFAqFhVjLUuPXJN3waCddEfGBiLgrIm5I106LiCsj4paenvpoCS4UCoVCoVDYqljLUuPlmlnYPqnkI32kcBIR8f2SviXpQ63NokFExLsl7WutvSsi3ibp1NbavzgSkSdFtF0azH95WW/R0hYmR8ys2dGZ5QTfBkveL6S8mBrvtzzQstzT7BjJbHaRqXosIB/mcw/MOnb0AeZODhVleYb6+PKVNDiksukAMzTPZLM95WPipXx4Co3ZKRvB8EOCoSWboaELp0+WLFkK8aULaeCdOxVP7T15+dadoTFHY57O2/QpD3771n7ek5fFfNmQJUHKz+/37eaLQkPkpa5T7Bqy+PM9XUod4cZu8/5Q/40Ttx8xkc31yz1lKcEdVnOf8mUdX4amfrnO0M2ztCdtSF8aW9LkWd8Ekvs+ckP5yB718WDHufxFS4F5+dmXN7dZHg+xIM0feDw12nJduedLaSyRb7Pr0sAzaKDN/FDr7Afimz94ZmJ05HJ4hqNrfBNIDpsBL5E1l4kx/rgj+167nmlyOn3z0tgSEfxZtGSal1n9yDjq6kGT8zK3L5VCo4c3kMYP85YGXowdR+djLXAHd2nemdu/az4+5XLhlx9cn+FBZwll8sc99YDC0jD+8KyH+8nfS65RJ9/MAt/HQkK5u4GHfsntgXy6Yzz051A4iwKVInO+2S7TRJ7VwkmsxeL1FUmf1WwsOSn9rYrW2u9r5RKoJF0q6YP9/w9K+tE1vL9QKBQKhULhSYEjWrweV+ERS5L+d7J4TVtrk/5/SLqX36thZ0S7QMNsL8/m3GnYj5Hw4HU5jwe7Y8aaNQPXdn0W7s60mT53qEWLnPZ0SfNw50nXEKX5YzfGgqBmGjN9ey2Ph6KQBi2Ce26pGDtaybVQtw5kDQL+nGN50FZ439juDd+e7w7/2ZHaLX9YIbB0ZZmAhi/19DTLc3NPs4bD/2hOOGti1cjt4daRSU9pI+qcnXKpE5rYL/b07O5If83dQ96P9PT/Gt2u+eW+s83y+nEeY6Ei7rN7yMqkp1mOkBM/bshlIz/jMuf9OVs0fXMAKZZU2iFbyTz0hFuh84YI33RD3dncsGzvk+adez3g8q0pr8vnTvs96Wnux1zj3W5V940A0mD18Y00pLkf8K5pTz0wNdfHwvMA+Ea52VLhKxHInFuVsqUi1yWDumbrk1uz+e1hJLI11531pz2lnT1MiTTwf9Gmn2nKSxt5kFuX8bwqAL3UHVrGQhZ4QOKxILTSyjrzTg8nNLaJgm/GktE27Sn1y9YY6PN2WLb7uTzK94C/1Cdb750P/u0mHAQ05jyA8miXTBMbvJBTDzcku57LR95/77E410fEf2itvTUiflf9gOyM1trfWvTsWtBaaxGxcNYXEZdJukyaj+RcKBQKhUKhsBWx0OIVEftbayf3cxrn0Fr7wth1K2NJKy1eeyS9srX2jYj4Lkmfb615HLM5nBzRLtYwY8/aFrNjD6S53NNJT7NvDr4fWJFcu8h5d/eUGTRWMvyRbrbr0rxvDlqFW8eyVoFVY9l+u3Yhza8vM/t3zSmvWaNB+hZgNPC85uw+AR700w+4lYbZvlv3zrPf0sBneOj+Eu77IM1b7JiMY4VDe8n1OGTX+D0WKJfnqaP7ZI2FPkBzRWMiaCV8n6a8brE5x/IgC1nrwoL2j3t6ulm63p/ywl8sCFh6PWxCtsySZ2LvvseuS0O7YrFY6intDr+yVkqwXvwL4bsHVh0L30JeD3Y75ovolhw/+iVb+XjG6zEW+sCPtiIUC/0P/6ex422wtvEs/SBbnJF/DxGx3a7nQKHuh+dhJMaOSHP/Jrcaj1lxPTAozzIWTNMz7m/p4QYmKa9bKqgPHwHGo7GjWBZZxjP/3QeK3/AA/6Rs/YA+t9T5UTX5PW5pwf/SQwnl8qc99dWZMV8+yl1kYc5jplutoM1XaXKYHg+f4r7SeWwnUDY89NUGaBk71oZ7yD3PZJnzUDuTnsJDaMsrCPABmuDB+T1lDMtWPvf/yuN/fl+G+w67D980/U9b0a6ffIzhJP5CWtsE61Hg45LeJOldPf2dJ7DsQqFQKBQKhU2N1Sxet2sWw2sUa9jV+BFJr5R0hmaK6y9L+l+SrpD0VzRTCn+8teYO+HM4NaK9SsPMd5LuMfvG8oSm5Ltjsoaz6MiasfV5DwzJTBotntlt1tB43i0ulOGBEqVhJs2sHisAZU1S3kU7zHwXYtYQvBysHWgK2ew4tltLGrQHrmd/JDRXyvOAplkrc83IDxwn7yTlcWuGB8lkF0228k2N3on9ztoLmtOiI1MQ0jFfONoK/tAOY7tv0aZpoyt7+r0j7ydAanRGX9nNP+/r17NWuigIofMtHwPE867FuW9Tph8ZRqYpF6vE2DPuW0GeMf9LLBXIiAfjzDz1IJBnWl5ozOWjlbo/5JjFDvlGtnmfWzQn6ZndPYV+1F1i6mReu2XCd+k5b6V5yxx155mn2PVc/iK/qozJgvcgN/TnaXrm3J7CJywJ9Kk8wDP2whdkwK19mX7klHdO7Hq2cvth9oyxPqblfkz/fbbdcz/A7Mu33/K471jmLbIGvdBCcOMz7b4031+RxWlPz0154TvfL/g/6SmWk0w/NJxkeaBl50he3u2WUrdAZlrggwen9f4nzR+3BG30JfdBlebHdOA7O6Wh79EXoRefqexj5/5+u3rqh6NzP78L3v3Px2jx2ibpRM0i1T9qtNbeuODWDz2W8gqFQqFQKBS2OlazeF3bWrto9OY64+Lt0a6eaP7sEWmYJvfp5oGugviRBSekRfF7H175KBrstu6cdZcHP5L09D7FfWDfynJ5z8lPHfK2HtQKbc79VqY9za/xGC9ouWgOOV5JdDof6AVg7cGKsnNkOv6drjagCZwKvb0CB5KjzQ7uQXCvz37n24mJqMksubebAqnbkp8qKh2u1P5e0MnudNVVkb2JQRTzdJxYenvf0Z1C0I5OTu2MQ0e7WisQHsxJ0gPdKWen8XZn96u6p/tVnZ7U6wOdpzu6OnqwW6S2df7tTyeDn9zLcTPo4XK5/yOJUPJ+utPUZW/niKPNwW+vKFbxnFnavtJ/U+fMH98uhHMiQj1JeVEHffucmbMOfGv4f4dvg+00HOjv20FbZvMGnTGbeaRB6LIcWeCcg52X26DNnY2kQVAmK2k6XL9sqnCHsJMsD+Vn5xnfFtZNhPu7A+DJfzXlha5uRrr5T2fp+b3tHuhttzP1s3s6f0/vsn3vdStJwgKzlOT0nkMryY1+b/+hlaRmIOfIuPtWZssj78SC8ELe3eUr94Ovep7O/wd6vab98iSVj7zf9fWV9MLqsZhQbgGMTgtjfyJpznLmvDz8nlTpv7TvzNn94XsPrbyeaeLa6cZ/aB1b+nHLNX3qjlQBj1kWuY8n3DXS0B6/y/0vpeHbdm9/56Rfp8uc2x3c7kpbdr2uh8f2Pka29L1BHg874HVGMCZz+4RXJKJsieU7vbwTKAOGZadKD8aJ4ExXvk9Kvl1naAX2373y/gnZUay/82D/Bh73GON4PSZLV6FQKBQKhUJhHKtNvGpJsFAoFAqFQuEJxFENoPpE4eLnRrv6nRrsotkzEpsfSxS+B3jS0+zN57Zq9+rOJlmWIljH491+VHuOcMo1TJeUy55j7PV5mYby3AM229EB9LGUgwkV70mWPvKyDKZZ4mKwNx6eZi9EPDkxHbPs4+uhmU/LPYUPlDG2Y4F3Uh7Tf2IHjHl9e5RA35+PHOzRAEzTLOm4Lf8F6X9o4hwm2hB+8d7snT7t6Q/2FI9b2jKvZ/Cu4y0PMgCtub2JYcFSoHuoZvmhjjgHQAsmfd/PLQ3y4bsmQF5voP+wzIkMU673qfw81+g79CV4meMl8AwygQy+wu5Lg1z+SU/zMm2m6fp07SU99ciO0Jb7wcTeAy/pz7RplglbvjhcNz+jSxr4T19hxw60IeOZJupPH2dpxaNy5uVV+hFtRz/wc3oyfb5f3yNu5mfgs58PBt05Ki388PNmGAuo8xfTMxMrn7HeY6ZI86YEjzM0Fo0TwPdn2HV4PhY3xNcCH7bf0tBXPLIp/FnuaY5VQzvssbwsXOW4IrdaHmQCGfAxUhraz5fjPaaDNMgCcj7t6ZLdz+dhAdwJkBs/C0waliEpn3dDL+MFY3N+J3xyHsOL7AbANersfSaPLcjsYR+Wni73lD6UvyEWFyNe//iODCoUCoVCoVAoPAHYGhavi5/Xrr761zRMtbPHG968qI24mp9o9zMe6SmbOjl7hWeuS3lRHyiHd7MB9wfsujSoroBpP+9BrTg/5WHaj/qO+vDinma1kToy3ffwq9/d03zYhpfPSvI1Pb0w5UXNgqc8w/T+W5ZKQ51RK5YWXM+AL5R/ieWdprzw+9Ke0obwEpov0QBv+xt7Ck/zAS7QCz/8YBjaOcsGdNJWhNSEtuWU17w03dv08O/sVY68UB6byO+x+7l81Dj4QT3GTC7IP/JynV3Puyf4n3dS90lP2aRNm2a6oY1dDrQR7Z77Ae3JM7QhNGX6ofcSy8t7qXP2gH2x5aUvLff0X6W8u3u6x/K8uae32n1pPhzttKfU63tSXue3jwuU/2INgF7K55klrUTesA7dz7B78ODmlNfLgZfTnp5o13O55KHcidHqdEnz45KH3ZWkn+jpe3uKifmKnv5syuvl3Gq/oR9apcFUcaPlhQba4wYNoByCAzE+IONLKe+Nlofjin+sp6uNd4zLyI3LawbtgImIsQxaM+8ZF6DN+93zUt69lk7sfXvttzS/5PQHPeW7c9xI3j+0PH5Y1HL6/0LL42GsqXOmiW8o/ZX23WW/M93TniITn7X3+7guMW5EvKMsXoVCoVAoFAobjS1h8YqIb2pmCrj7SHkLmwpnqNpsq6HabOuh2mzrodps6+HRttk5rTWPyS1pi0y8JCkirl5ktitsTlSbbT1Um209VJttPVSbbT08kW1WS42FQqFQKBQK64SaeBUKhUKhUCisE7bSxOs3N5qAwqNGtdnWQ7XZ1kO12dZDtdnWwxPWZlvGx6tQKBQKhUJhq2MrWbwKhUKhUCgUtjQ2/cQrIl4TEXsi4taIeNtG01MYR0QsR8T1EbE7Iq7u106LiCsj4paenrrRdB7riIgPRMRdEXFDujbaTjHDe3vf+7OIuGhxyYWjgQXt9Y6IuKP3td0R8bp07+29vfZEhB+iVFgHRMSzI+JzEXFTRNwYET/fr1c/26RYpc2OSl/b1BOviNgm6T9Keq1mp3y9MSIuWP2pwgbiVa21XWnL7dskfba1dp5mIX9r4rzxuFzSa+zaonZ6rWan550n6TJJv7FONBYGXK759pKkf9f72q7W2ickqY+Nb9DsKILXSPr1PoYW1hePSPql1toFkl4m6S29baqfbV4sajPpKPS1TT3xkvRSSbe21m5rrR2Q9FENZ8YUNj8u1XA+xgcl/ejGkVKQpNba72v+uPBF7XSppA+1Gb4oaRIR37UuhBYkLWyvRbhU0kdbaw+11r6i2Xk5Lz1qxBVG0Vr7Rmvt2v7//ZL+XLNzfKqfbVKs0maL8Lj62mafeJ2tleew367VmVHYODRJn4mIayLisn7trNbaN/r/ezUcqFXYXFjUTtX/Ni/e2pelPpCW8Ku9NhkiYknSizQ7RLL62RaAtZl0FPraZp94FbYOXtFau0gzs/lbIuL788022z5bW2g3OaqdtgR+Q7MT03dJ+oakX9tQagqjiIgTJf2WpF9ore3P96qfbU6MtNlR6WubfeJ1h6Rnp9/P0nA8e2ETobV2R0/vkvTbmpld78Rk3tO7No7CwipY1E7V/zYhWmt3ttYOttYOSfovGpY4qr02CSJiu2Yf8P/eWvtYv1z9bBNjrM2OVl/b7BOvqySdFxHPiYgdmjmzfXyDaSoYImJnRJzE/5J+WNINmrXVm3q2N0n6nY2hsHAELGqnj0v6+33X1csk3ZeWSgobBPP/eb1mfU2atdcbIuKpEfEczZy1/3S96TvWEREh6f2S/ry19p50q/rZJsWiNjtafe24x0/y0UNr7ZGIeKukT0vaJukDrbUbN5iswjzOkvTbM9nVcZL+R2vtUxFxlaQrIuIfSPqqpB/fQBoLkiLiI5JeKemMiLhd0i9LepfG2+kTkl6nmePotyX99LoTfIxjQXu9MiJ2abZUtSzpzZLUWrsxIq6QdJNmu7Te0lo7uAFkH+u4RNLfk3R9ROzu1/6lqp9tZixqszcejb5WkesLhUKhUCgU1gmbfamxUCgUCoVC4UmDmngVCoVCoVAorBNq4lUoFAqFQqGwTqiJV6FQKBQKhcI6oSZehUKhUCgUCuuEmngVCoUtiYg4GBG709/SKnmXI+KMdSSvUCgURrGp43gVCoXCKvhOa23XRhNRKBQKjwZl8SoUCk8aRMS2iPjViLihH2z7c+n2z0XEtRFxfUSc3/O/NCL+OCK+FBF/FBHP79d/KiI+FhGfiohbIuLdqfzLe/nXR8QvbkA1C4XCFkZZvAqFwlbFCSnK9Fdaa6+XdJmkJUm7+skXp6X8d7fWLoqIn5X0zyT9Q0k3S/q+nvfVkt4p6cd6/l2SXiTpIUl7IuLfS3q6pLNbay+QpIiYHMX6FQqFJyFq4lUoFLYqxpYaXy3pP7XWHpGk1tq+dI/Diq+R9Lf7/6dI+mBEnKfZsSDbU/7Pttbuk6SIuEnSOZJulPTcPgn7P5I+88RVp1AoHAuopcZCoXCs4KGeHtSgdP4bSZ/rFqy/Ken4kfyHn2mt3SvpQkmfl/SPJL3vaBJcKBSefKiJV6FQeDLhSklvjojjJMmWGsdwiqQ7+v8/daTC+87Ip7TWfkvSv5Z00WMntVAoHIuoiVehUHgy4X2S/lLSn0XEdZJ+8gj53y3pVyLiS1qb68XZkj7ffcs+LOntj4PWQqFwDCJaaxtNQ6FQKBQKhcIxgbJ4FQqFQqFQKKwTauJVKBQKhUKhsE6oiVehUCgUCoXCOqEmXoVCoVAoFArrhJp4FQqFQqFQKKwTauJVKBQKhUKhsE6oiVehUCgUCoXCOqEmXoVCoVAoFArrhP8PbKXjI/nMTNcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAABTCAYAAABOIAlxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqKklEQVR4nO2de9DuVXXfv4vDQUTRB0RBuT1iiAS0OYIaFS/YGAVbJSZplE6rybTFtJLWpp1WO5mJbWeMcdR00qQmJlpwTLROE4skGEWqJkW03I7hIsjFVwW5iX2QiAgcdv949uf81vt9f897Dsh5L7C+M2fWeX+//dt77bXX3s9ea6+9d7TWVCgUCoVCoVDY89hrvRkoFAqFQqFQeLSgJl6FQqFQKBQKa4SaeBUKhUKhUCisEWriVSgUCoVCobBGqIlXoVAoFAqFwhqhJl6FQqFQKBQKa4R1mXhFxMkRcU1EXBcRb1sPHgqFQqFQKBTWGrHW53hFxBZJX5P0M5JulHSRpNNaa1etKSOFQqFQKBQKa4z18Hg9X9J1rbUbWmv3SvqYpFPXgY9CoVAoFAqFNcXe61DmoZK+lf6+UdJPrfbB3hFtq6R9+98PpHc7On1sp/jvtnZ6Z6f7agBp+DYs3/tz2cbLfp1+3/LdJ6W5w76939I2e595uKfTrZZ2q1bi3k4fY8/5JtdjS6d72bv77BtpkOX99u4H9j63A2nhZYulGeNlEU/QXGfP5zH2nHrspwHOP/L+YaeR0jZ7RntS570tnX+f/ybNA6u8Q/e2Gr1HA9AX+HVd/EH6/+OtTHSDfJHxfRpAHXfYO3+evwfeDndrJUhDfvACb7R/rhf8UzYycN2Qhra+x95RDvnmepAmt400rtPk430EWdxt6aShneHte50igzwOMYb4mgP5j/EELz5O8PcTLW9JekKn6Iv3pSx/2tN1jra6155LK/uO6/+WlJZ8H6vl4BvXQWmlnMgPWWbd4xlyoT7kS/ljPHnd+QZec3+njbyO/puS0+wwSr6UMzYega2WJsvvyTB+QKffnZNbe2Mhv6xHd3WKvvjvTe4zlEnbM9agT2O/UdSJfB7XKf0h/2Z5X4dfZEq+ue8j/7B3Pl7kcQv+F43FWee22jvygSf6W/7Gfx9vl77TWnuyRrAeE6/dQkScLul0aS6EoyQ9s7/LgwoK9OxOEcjTOv10p0enb1AKvkXIdOA7UtondUoDHN/pRZbvNH3zkU4P7PT2TuGfDjBJ38DDtZ0eYuWOtR6z16M6daX4bkq7f6f72btvWzmSdKyl4d3lnSLruzSAtD9m5d1t76Whs9MZnSfowekb6nSrlUP+t3R6vAaQ1mWIjMcGCjou+sP6t+uBtHzwzvmRV9ZT8qUeyI5y4O2a9A3tcK2lQX+uTmlfZPnSrsiQ8m/XAMr2bw6359LyCa00tBG6d6lWgrKmncL/TZ1OOqWfSEN7zjo9xvLKffN5nV5taeg7lJd1j3z9x+gn7XnOB91yHflKp1lPebet0/M6PbTTY1NaxhD/kaLvjPUz2gidoOzrOn2V5S1Jr+j0ik6p46zTSUpLe97QKXpPn2XMyeMR/Lv+o+v7p7Tw+SwtB9/Qhk9L7y62NPCCbmTdYzzme+pDvvSvJ2rADZb2G53S7rRZHi980ocOzzrNP8i0n8ud9qVNx8YjfvCRN+U+O6V987T/5xc6/ZM5ec/X5/TL/fG9wyf6XKc/3elhVu4spWWco+1f0im/B2O/UYy91B3PCr/HR6W0lIWc4XfSKTqexy5+O7baO/Kg/Kx7S50iQ6/r4SntIfZuf6Po0ZHpG8YDxpLfG1RpBdZj4nWTltfxMA1j8U601j4g6QOSdGBEO1ZDA+cfPNYo+YFEMHRGBo78DYXTaVAoBJYHuqUFlWAgpdPckN4x0O23IA0Kmgds+OXH5HZLmy2ECztFyfDq0XmQU1YKfmCu7xQr+IWd5gA7tAX+GEDhBR6X0jeUdWOnDDzIPQ+0s05RXupBHpNOc0fzH1EoedFRslWHdeWTViZnl6dnpKEjowPkC0+5nRlsGVAZ2Kj7k1Ja8kX3mCzcquXIAwU/rsibAQn9yj8eyAOZMWCTH+2QDRDgE/hLR9LSVkzw4JtykVPmnwHOf5T4wURel6Vv/AfzDqOHpLT8MNLmfIPcKffLGvDiTqkzAziDsLeHtHKcwIDyyWgum35GXdGnrNPwR5nwQlsxkOfJPmPUzNJSd3QeHcl8g2mnyC9PcsiPdkQHn9sp+ptlSpug47Q7eeQ+SZtTV3TtSHuex2A3HibGW64rY8lnO2XshRfkk39wkB1jOjpN+9KmeeLCGMm4weQQWWbP5qxTNw6XLP/s7cawpN8hlyx3sNQTTc0L8aw+8fpCf5z75imdMp6hY8gi/0CTLXX9607RlaVO/276hvEefmmrn7K/JellWs4ndUWGTNafqQHOE21GfQ6359Kgp+gcdc36D+CPccG99OSf2wwdzrq7COsR43WRpKMj4ukRsY+kN0j65DrwUSgUCoVCobCmWHOPV2vt/og4Q3Ov4xZJH2qtXbnaN1s0tw7xyrwsvTu7U6wVrC5mzViV2erC6sQaYsbLLHea0jKzxVqYGWVWnr1XzIrx/jC7PcT+vkIDmDljiWEFw1O2VphZUzbeADxf5P9tDZh0ihcDGVDONKX1JZsvdorcWcbIM3ssD6wSyobH7HPNlmMGViP1y54q5ANP5OHek+9pgMd1YA2hG1mmeAWO0XLAP/lnCweLGGsR+cNj9rLi4XKPGvrlcXrSYK3hmcOjeZVRadBh2v7okTTOExafL4P6srQ06NiXOqVtkPek0zFrjzJpV/oi9ctLLMgJXp5tNHt/8AbAP7rs+jtL3+BF2mJp3OstDX0PDyZ64+2c68z/GQ8oj3bOy6qA/PBg0nfgMbeDL7v5sgnfZp7oe3iD0GVvd2nlEg3eGfds5n7iMTnwcrf9LUmv6ZR2pG7IgLwyT8hu2umfd/rPO70+pf0/nXqsF/pLW2bPYy5LGnSZb2mXr6Q0viyPbKlXzpO+OesUWb6gUzww2QvCbwc6B794bPPYzm/G1FzXLAl+otPshXM98ZWEPPYiO2/f7H3OeeU0lIm378lGpcEr5mMiuoD8chgGz9BTxjtEQPnZs0kaZIhMySN7uz3kxJ/zW5L789h4tgjrEuPVWjtX0rnrUXahUCgUCoXCeqFOri8UCoVCoVBYI+zS4xURB0t6p6SntdZOiYhjJb2wtfbBPc5dwg4NO3Y+m54TrIebEHcwbtCxHX6TTvOygjQEDp+VnuES9WBclmlwf+YdZgRDzzrFHenuy7GlOlyYuOBx9efdVu7m9uUwX0aRBncqy1bU/Sp7nvn3oGt482VXaZAp73DPT41naaiLL9U81/6+UwNYusEtTR09uDK7+Cnbl4PHdvi5a5q/qQ9LK2PB17zb3ilu9cNH0vgGEd+4cIsG8I5vZ8ZbdoPzf5aVaDt0msDVUzSApaClTqkryyZ5I8HrO6Ud4Re92Wp/S8PGFz/yALmjZ/kb0lIfljmQS94wQh/xpWNfbpilb97UKfJAF48aSeu7zVi6YWlobPmQb9BH8p90upTSEjRM2SzBTjv1JVNp0B/0EF2mP1NuLod+RXkEbqNXOfie8WbWKXpKe1Du2BIOy6BsrmMZOi818h26R19HN9C9PF4A2uEdnaLreWx3Pj2gHR5fpAF+5AHy4Bv6QV6mz3ooreybeWxnaQteGKcJUqed85lKlEW+jF3+OyQNY+KJxIT0eI/H9Qj3p/WYljx20TbozZPseR57kYOPa1+w97kd/OgMH//yxiPqOu101ilymXSaw3mAb6obCwkB5Av/viSe8/dlQx+vJ/ZcGkJxGLM+NcID2B2P15max2Oh01+T9Nbd+K5QKBQKhUKhkLDLK4Mi4qLW2vMi4rLW2nP6s+2ttW1rwaAkHRTRXqvB8jgsveNYBGaiWIDu2fEzl6RhtkxAOBZUDo5b6vRF9o7ZPkH9fi6NNMzYH7C/mZ1n7wYWAJaUn4WTPV7kQ9lYkb4tN3t0CDB/jv39mJG0k06ZaROQirUF3znAlkBkD/z/hv2d4VYj5eK1zO2AV8Etvq32PJ8Pw7Eb1Jk6wvcXU1q8L9SN8rBcZ51m74MHX1MfeMpWuwfvkxb5kD/eCWnwpmJ9PdH+HjtaYaLlwINA/rkfIA90DGuUQPZ8FhTydg8w/eImSyet9Gz6Jg0/ryfzifzRU/rxmEz9+IK77H3eho5163pPvcb4hwcsYvdwZp787DI/2yp7x/wIFvj3YOaxs9d4lr1Jmed8FAj5sFJAf2A8zWdCwQNjIzruXo0cHE39kSntjXcpb4hwbwNeHt/in3UbGeLhhO/77G9p5ZE0fkYaz/OmEz9HkPL8GIl8UKufdQj/L7dy8zv3KgF4yl4adJjfDryUeC2z/BkXfr3T6a8sZ/jcD89pHu/YhIDnBb0nrzxeOy877Dk6M3ZuIWMjdfMz0zLuMUpbHm3PpWFjmm+i8N+JvKmO/Gh78oXvLFM/EPouo/S/sXP/0I3fkS5preUhfSd2x+P1/Yh4kvpBrxHxAi33RBYKhUKhUCgUdgO7s6vx1zQ/Z+sZEXGB5hPDX1j9k4cfO7QyVkoaPFJYtT4Ld8+INHhUyAfL+/CRtDybdYr1O7H3easxFv11Wg6sVT/GQhosJD88kXKy9wErcalTZvXdsNkZxzPm3cDD8kr7JnsFqD+WATL04zC+pAFTKwe5YB2Nea9mnWIV+an92ZKddOrxbe5hyJYmlj2WN3Xkmxzjd7tR8sfCQMb5WAzkgrcJqxS5Z0v/EHvm5XmcT07rJ77zd/YY+hEB7hkZA+2I1eb94cdSWvcc4P3JOiAN/UMavHf/u1MsTHR7LJZs2qnHK3oflVYeooi17h68HHvixy9g2eKNyP0Y/fHjHfCmjx00Szu7FU08Tz7C5LP2DA8n/YO6jh3wSH/iW+oML/mgTfQcfcHDhadtbJw43N4ha4/xk4a2IpaJcWPMqwHgm5PMGdPQiexJwLsBD8hjqdPc52nPSafolsfa5TqTL/n4Cfb8nXX7f3ZKnZEtnqTc74hNJg4YHnyVJo8trKAwxqCXeBWzx45DsJc6ndr1AJT/Ba3ExOjMeJIGXSMNer+tU8bt/I17+OmLY4eU02+RIfmxmsX4PXZMAzJ0udAP8hhM/f2YGdo3/17fYmkZC+hX6Gm+SePOkWeLsMuJV2vt0oh4mea/WyHpmtaae7gLhUKhUCgUCrvA7uxq3CLp1Zobo3tLemVEqLX2vj3M2048oLkl41fwSCtjcZgdY5Eze56lb5jhkg9WBfmPHQSHJ8KvYsGazx4jLFe3zLC63OshDRYm6/Dwwix/bP2ZuCS8YR4Hk+Xk8UdYu8gv3y3m97SRBksfXrMFSBq/S26ilcCyI27kf1geWDF5dr/U6bRTrAqsLCyd7D3BCqIc6oi8svcE0GZYNrQz7Z6tLpcpOoLl84yUFv6wtJEB7Yw3K1v66CnWLp4K5JItZN8x6B4qvD45nodnfg1GthI9fyiyRBfHvFe0DbGI5Atv6NMkfcMz33nq8VvSIP/b7R0xoMhymr5BP+mj9Fu3nKWVOoCc0G36R7b0qX++zkkav3IKjyI8ES+Hbs9WyR/dgEc8Rsgix5AgF8Y5dlvhVckeQT8MFW8WeWD5576JHCjbr1IaG+c8Ls+9EBySmtNOjF/Kzbsy8Sq595xvyYtypKHP4xFhHMLrQf551yFp6IOuI9lLSdmMC/BN36FPTtM3jBeUzfhPH8p3frJbkd+Oky5dnmhLV7Qjk0vnvE59F/GYfEjjsWr+u5P11Fd3ljo9eiStH2hOP8B7iK7nsRGe+BZ+0VP6d46jRmZ+lRjtkPXWx31Ex7hHvxjT7dyfFmF3lhrP0XxculzLV0IKhUKhUCgUCg8CuzPxOqy19nf2OCerYC/NZ6B4BbKnZdIplofHZHkMkDTMXj12gjwm6Rkza/Lz62F8F400WF1Y+r670eOUpMFThyWAdYqFO01pmbH3S+h3Xj2BlcSafp6Nw6+fdUR52dLHwmDm7nX12Jqc1uOnKGeS0mLRw6+fHUT+Y3FhWDJYiegEcQ75Oim8J3wzsTQ5zgNrDh6eYH+TNns20SM8LO6dyWv9eFT2srR8i9U15iXDwvQdNcentDctSItHFms9X9eETPGoYR2SR9YJ3+WDdYhH4RatBBYxuoFcfLds5ok2R06U4zuQpKGP0G+RMd4O90JIQ99j9xly+minr0tpp516nJBfcpy9cH7OlnsssjWMXpL/pFPqBa9jO7MohzHEL22epW/o477zmDEne8f4Hp1ATtRjLMYLuaCXvsM2734mH+L/8JzxLTzmC5f9SjT3NuSdoh5fiefRz+jKOoF80Rd0HZ2j/OythBd0gbakP2ePIOOQXxDt/S97XODT46v8qqX8DP6u7Ep2HB2iu5CelzxexNahG3j70M+/n/LnHWMu8iC+bWznOvVHT2DFvcbSIAfayC9On3Waf8/cm40MGJ/3sb9zGmRL3/Hfa2nlGYEHW1p0Ou+0JO3YCQqO3dnV+KmIeOWukxUKhUKhUCgUVsPunOP1Okkf0XySdp/mAfattfaEVT98GLFfRPtxrdzJJg3emUmnPiMdOz3ZZ+FYCrNOT01peYeFQHnbOvXdZNJgATCr9cs/x85cwrLBUsaqmBrP0spzwHwnx1jsA2X7BdqzTl+S0nqcDdYFVgR55PzxfPiusXzCNaBtfNaP1Yhlki0Q2sp3NiEn91BlHvC+IbelTvNJznyH9UV+V2s58vlCWEUeX0U7ZO8G1i76RLwB1i6yHDsPbtGZMneMpMECd7ljjWVLc7IgX57nWC+sXWRI/lj+8J8tceRAmR67NxbvQZkze4dssyyQlZ/yDdCfbJW6VwaLmHrkQ3fO7nTSKW2GntJnM//0KyxkeEM+eVejewX4mzHFd9VJQx3hiXgY77NZ9+hn7hUjj3wuop8TRDtTD/rShSkN+bnHF12YprTIm12B8EC/gNcsU8Yz2tF3RedT0OkTfukzni90IntOGRvdOzmzv8dOQ3f9pB7PS2lmlpayPd4t509boafInTEr/x74xevI+J+xDID78A+GNL/1nTl9f/+bcYN+/ukh6YqzvXwHLTzNRnjgme/cnKS0viPxyUZp3zEvGfpKOfRRP39RWtnfADqT9chjY/mWtnPvaM4X+Xx2lXO8dmep8X2ar+Rc3nY1SysUCoVCoVAoLMTuLDV+S9IVD3bSFREfiojbIuKK9OzAiDgvIq7t9IAHy3ChUCgUCoXCZsXuLDWeqbm3+1NKce27Ok4iIl4q6W8lfbi19qz+7N2Svttae1dEvE3SAa21f78rJg+IaC/XsMyzlN7hAsStjeuRAGpchjn4F5cybuF/1Gm+UgHgIsUNyRZUXL++3VQalkB82Q33pC8LSINrlGcsQeGyzVeZ4KLG9UrdWMJb0krwPS5a5MXyYZYPrlLqzLKJX8CbXbYsefz3TlkK9Os3ctm4aX154R57Lw2uaep8lKXl/Sx94wcUIlO+zUvWtKcf1oe8qGteiuGdX0OD6z1vnsjLstJQZ3TaA8OlwZWPniJT8sq8+PVLyPv6TuE/B2qjpxwt4kspY4Hs3lbkx3JVbud8GKk0LCX4MQpZj1jycP3nCIR8qKsH7dOvfIkiy8YPAuXbiT2XhjohZ+Th4Q2UKw1LWbTRXpY2b+hB13wZ2o/zyEvi6Bz5fcueU78c0L5o6z15jI1D1NWD30+x59IQfI1c0FvfyJPzudX+ZjmLpaJPpG8I4ma5068OyhdeozfInR8sZDq2ROSbYZAdsoC3HDQ96xQdnBhvs5SWutLf/Gq6sSMc0GF0BB7yhhpZGsbpbZ3+Fkrxy52y00bSOy+b005WjJVZB/0aKj+UGZ3Omw8YF5Y6fUWn1D1vSEEOjDGMo349VR4nbjCKjnjITuaJ76kjYUjTTvN4R59H7n7IN+2Q6+EXdq+21Lg7Hq+vSzq/l71/+rcqWmt/pZVHWpwq6az+/7Mk/exulF8oFAqFQqHwiMDunFz/Hx/G8g5urd3c/3+Lhkn6qtiq+ax61v/Oh0ByFYcHeHKVyTX2Xhq8DK/u9GxLk3cN4DFgxotVBy9+UKU0WA9u2fgxDGPH/2OkYOn71uZcFvni3ZtYHnl2DL945pj1L3U6TWn9cFgH5WWPC1YXFitWLkGmOdgbq5DjBnLZ0vKrfABbjD0QFviWcGml9YYMx+SPhYT15gHtfsioNMjOr7JAqbMHya1FZAC/5JEPRvTNJPw96TR7Wmzn+E7d46gRv25IGrw7zj95Za8JfM4sDZ5SLOd8NARtgqVP30Huk06z1YhFiUWIFYlMc5uhJ35kDLzS7tlTgVzoI4wFYwfkohO0iXtq77N00jBOuPdkbHOAX6l0uKWhzvlwYz+6wS1g6np9ekY/oO3hjW/z9TPoP7LzsYTxNHsGsf7hjW/wUo4dTEk56Ms24+209A06wbgPD3g082Gr5Es5tA26Qr3GrsTZ3qlfc+PHxkiDblN3xrKxDRd+qK57XuibeRMF3zDW0s+8PtLgMZ11ivwv6W6PE/yMH0mv6R3WD2qFp+yZRZbed9BTdC5vhkIOS53CQvYqAR+P+V0hXz/ANfOHp2vR1VNZ975tzzyAPvd9vzjdvetjB4STHzrxWS3GwolXRPxua+2MiDhH/YLsjNbaa1fJd5dorbWIWLjOGRGnSzpdkh7/oxRUKBQKhUKhsEGwmsfrjZLOkPSeh7G8WyPiqa21myPiqZJuW5SwtfYBSR+QpIMi2t1aHj8CfP0XKxErGmsxW4YXWVrAGnP2ChAf4le8rHa9yl3296TTaaesLeejCbAe8OAxa8ZSyBZIvipGGvhe6pSYnbFLjnnmlwOvFm8G/Fqg2cg3rOX7tSGT9H8sGawT+MfiIE4jtwNW6Hb7lvgSPGtjR4241xOarS+/XJe6U+dpp0vpG9qPcrBK4T8f5gpfHE/hnhaQPZvIyb2G8JY9jq/plDhF9BNd96txpKHOeBm2jaQByMwPf8Sy9MtjpZWxUKQhf6xtdEYa9NTjXh5n7/P/aV/ij9BFj3OTBi8T+brXIbeZx9ZRDl4axpZ8lYx7MskfnvJ4Qfux2x8dwbODxfxiDfADWr2tGDfOTc88how037X3+dmsU2/3nxkp1w+tZgWBeuR+NjFe3JOK/mbvCWOwx+XBW/b+0PfgyWOuKD97N+iL1A3PlPfN7K1E//HCMD5RTvaM46HwK8Bob7zUO3ehaWWboSNLnY55iRkv8KBS3gl8lM4MenYXzKm9UvRN8lgakq7wypOG/OkPecznN4qDWOm/9Mkce+WeKNr1KEubY/mQO/lyaLj/NmU9AhNL48erSMNY7r9Nz7P32QvHCprHwI1htYnX9ZLUWhu71Pyh4pOS3iTpXZ2evXryQqFQKBQKhUcOFu5qjIgbNT/DaxS7savxo5JOknSQ5gbab0j6X5I+LukIzSfFv9ha2+WdkgdFtNdq5cXI0uAhwHqedOoHhs7SN6zZ+249rIh8zQAzdMomH652Weo0W7K+A84vEMZCyDsV+QbLw+Nh8qW7fsghHjS39LPV5QchMmPHIsjXw7jXAYsKiw8PRY4NwRI4p1OsXb5ZSmmnnc6sHOQEb3gYpKEdFx1ISXn5MEFiP7AWsbyxcPMBpFhKyN0P4BuzirD64ROLDev3opSWfO+0v31XWraWvD09Vi3Ln7bOFljmyfmQVnr5yG+p03xtC20y63TaqccK5ngqjyki7d32Pnuj/Rop5DJm/VEWMWT0HfLFK5R1gj7nuoAnMnsc7zIKn4wPyDp7oOkbs059cMtjCx4Oj0mjvckjxzNOO0VOnJHpMU253eGBOhPDOub5Rf8oE28SMU18k8eWP7d3tDeyzWPjt+wdfNOX3KsirfRq++7Y7H2DT8q829LibcoHRgO8bYx/eGt8t5o09AfkQLwl5Y95EZc6nXZKXSmPcVwa6n+gpfHdh9Kgn1ssDZ7C36Sgt6aPeqXO/Ys5/d3+GBnng6MnndK+7r1Fj7leSloZM0a/Q25Zloy91BGdRhepV94lTT9Fd/2QcuSWd4kDPwiccvOOUS7o9gPSH1jwPPOJh/y9D/EA1S2ah1fFKmkWorV22oJXP/1Q8isUCoVCoVDY7FjN43Vpa23s2JA1x7aIdr4GKy5bQ/sQed9Nm+/3KSkz0gP6+zv+dvjGz3hhJr8FF9hsSHtbT4QVcUR3DbX+nN0UJ6eAsdu62cnsGIvt9b3ge/uLpVQPZv1YSnyL1yR7x7CasTioB1bKSb3Ol6Q6T+ybH++m7AXdjMjxC3hFsBqY1eMp3M/SZX796pindLlcn7Z+YYBh9RzwE3N60VfndOzamyN6nVqv0+f6c6y6aafZC+QWOFbS2PUteC9O7swt3be8HrThP0iux6u7+2qp/z3p1OMzpJVn0MEbvIydkeO70dA1LKp8JhdthXXt8Yv3GZUG2cHncb1u19+5vHxpsFRP6Gnu6Gme1P/+Uv/7BSl45pu9sCN6QTu6a2hLr8BNXekPTTbhHRcvrw+8PcP6nSRF709LXRDTXukLuq7hOTomu38m/ZteNjKI/p9vJvcVVjRVoh0O6Pxf0PM48aDhm8v7VSzP7vldaQGZuX1P6t/9oH+DlU0527qb5rZ0SKDHK1K1I7osvtRlMeblO7SnuaCnoX1PSAGkP+h18ovHt9nYlT0J7sGEbu80NdlOvTyubxFsPSAVWY/FtKLTvpOWPpO9ocTowZOf8cY3OcbrKV23zumMElOHh+WkXvfPpw7n8Ue05V/3tpyk/PFkndgLvb73C37H8Nocl4Jyz+ltzliPlxL5XTwkXbGTEp1myJ2yHfPt6SN+CP7TnHyz802feVxaArmky4VxGQ8XbUTbTdO2z9tuXM4DxbmnXxrGHcZTjyt8Af0ruY+/2duCdj6mM3PRt5eXM0vluHfyhP6b8rX+mzJ2B+IhXQ7Xdxk8o+vCJb38bSktZdEOj3+I53g9JE9XoVAoFAqFQmEcq028akmwUCgUCoVC4WHELq8M2gh47tHRLv4vGtbj8robflb3ZX7F3mcQUY7PEX/9AyNp/d4Ij5xf6nSavnFfKfnjgyS6L6874LclQhgHJeWPRY0TIUrd8cWzNPET6RvqdpWlJd8cVUyaqeUPjxd2miNIWdulHL/yfexkTab9+IApl/WwXGd4IQIWGaML8Jajy5G3R+Ajv3zeBjyxVkG0KfrDXuYsJz9h1ve3X5jekQ9rRaxnsFaBLHI0NnzntXVp0Lm8v5r2ZB3A1x2QaY6k5pnvvacd8nkngO/Rf/J4qX2beeDZq+1vP2lTGq43Yd2cutPuOSqafJA3fd5P0czrq/cYZUcHaxZ5DY2yifa91J4jr3yGBmtAfnor/fmylBadIB/6iu9Hz9HjvtvGTzYdW2vOkfDSUI+jtBisD9JvqcfYzg7K8tM3addczsTKucrSoBN5iZY+wrqb85DdBzvXaTvlfB6ixhnzs24z5nLuA21IOehE7m888/M8fFeUNPxu0XeQD21Fn32hBvidO34uSV7A4nvkwHlC5Me3uR3QG3i41mg+IZdx008rnXTqUeXScF4B5zyQL+2TI+VfZmm830LzOMj44L8Dq50Mzpovuu33MOVxiD7DujZ1/0ynHocjrTgPKd77o10ZVCgUCoVCoVB4GLA5PF7PPaRdfPEbJd3fn5yY3jL1JYzvuE6nnV4wkiPTYzb+YzJgktyf0lIWpk2PQty5IXQ2kj9h4Rw6gfmGaUgU4lL6Bn4xJzADqE82Aakz5fya8YI7gouTJOn1nbIbwc2WfD8AZsofdIoMMA1P6DQf+IA5emWnuBXHLolALtNOMY/gZdZpPs7ykk4xQWiHv2e83KgBmCO0FTKEt3wJCEBfqCO80A6fTGlx+fEN/BLum81h+IZf+MT07vu6d7aTtPzqdWmoB3r75fTOtxmAi+15bmf0/Dp7h9wmKS06h7n4HS0HkQn5GEjSkj91J392f3xaA37e8oUHZPyM9A5XF3yfv4CnrBPoALI81b69JaXl6NV/2ekiHcyu0/uNPt7o9pSWtt/XqOtgHo9IQ9tTR3hC507QAOpBH/14p/+u0z9OaX28IZ8Pd0rfyRviqdsl9jftk3WF/6PDPk5s7xRdkYY6USZtta3TLJ+r7Rl9/EotR746HT7pg34cKjqZw/iRpY/X6ELuB+daGmR6vtHT0zd+RC714hKwrNPwwu8B8l/qlHEqywm5uN7AS440QnZ+pDaYWR65zDvtHTL8uZR2X0uDfiIn+nzWOR/vX2XPkUEeQykHOXAQzQc7naa06CX59F0IO8cC8srHM1PWnO+Id5THq1AoFAqFQmG9sSk8XhFxu+YmkZvZhY2Ng1RtttlQbbb5UG22+VBttvnwYNvsyNbak8debIqJlyRFxMWL3HaFjYlqs82HarPNh2qzzYdqs82Hh7PNaqmxUCgUCoVCYY1QE69CoVAoFAqFNcJmmnh9YL0ZKDxoVJttPlSbbT5Um20+VJttPjxsbbZpYrwKhUKhUCgUNjs2k8erUCgUCoVCYVNjw0+8IuLkiLgmIq6LiLetNz+FcUTEUkRcHhHbI+Li/uzAiDgvIq7t9ID15vPRjoj4UETcFhFXpGej7RRz/E7ve38TEccvzrmwJ7Cgvd4RETf1vrY9Il6d3r29t9c1EfGq8VwLexIRcXhEfC4iroqIKyPiX/Xn1c82KFZpsz3S1zb0xCsitkj6PUmnaH4j2mkRcezqXxXWES9vrW1LW27fJun81trRmh+JXBPn9ceZkk62Z4va6RTNb6w7WvNjtd+/RjwWBpyple0lSb/d+9q21tq5ktTHxjdofvz8yZL+Wx9DC2uL+yX9m9basZofNf+W3jbVzzYuFrWZtAf62oaeeEl6vqTrWms3tNbulfQxDXd8FDY+TpV0Vv//WZJ+dv1YKUhSa+2vtPwqbmlxO50q6cNtji9JmkTEU9eE0YKkhe21CKdK+lhr7Yetta9rfofJ8/cYc4VRtNZubq1d2v9/l6Svan4HTfWzDYpV2mwRfqS+ttEnXodK+lb6+0atLozC+qFJ+kxEXBIRXDp2cGvt5v7/WzRcVlnYWFjUTtX/Ni7O6MtSH0pL+NVeGwwRMZX0HM0v16x+tglgbSbtgb620Sdehc2DF7fWjtfcbf6WiHhpftnm22drC+0GR7XTpsD7Nb85eJukmyW9d125KYwiIh4v6U8lvbW19r38rvrZxsRIm+2RvrbRJ143STo8/X2YhivYCxsIrbWbOr1N0ic0d7veisu809vWj8PCKljUTtX/NiBaa7e21na01h6Q9IcaljiqvTYIImKr5j/gf9xa+7P+uPrZBsZYm+2pvrbRJ14XSTo6Ip4eEftoHsz2yXXmqWCIiMdFxP78X9IrJV2heVu9qSd7k6Sz14fDwi6wqJ0+KemNfdfVCyTdmZZKCusEi/95neZ9TZq31xsi4jER8XTNg7X/71rz92hHRISkD0r6amvtfelV9bMNikVttqf62t4/Ost7Dq21+yPiDEmflrRF0odaa1euM1uFlThY0ifmuqu9Jf1Ja+0vI+IiSR+PiH8i6RuSfnEdeSxIioiPSjpJ0kERcaOk35D0Lo2307mSXq154Ojdkn55zRl+lGNBe50UEds0X6pakvRmSWqtXRkRH5d0lea7tN7SWtuxDmw/2nGipH8s6fKI2N6f/QdVP9vIWNRmp+2JvlYn1xcKhUKhUCisETb6UmOhUCgUCoXCIwY18SoUCoVCoVBYI9TEq1AoFAqFQmGNUBOvQqFQKBQKhTVCTbwKhUKhUCgU1gg18SoUCpsSEbEjIranf9NV0i5FxEFryF6hUCiMYkOf41UoFAqr4AettW3rzUShUCg8GJTHq1AoPGIQEVsi4j0RcUW/2PZX0+tfjYhLI+LyiDimp39+RFwYEZdFxBcj4pn9+S9FxJ9FxF9GxLUR8e6U/5k9/8sj4l+vQzULhcImRnm8CoXCZsVj0ynTX2+tvU7S6ZKmkrb1my8OTOm/01o7PiL+haR/K+mfSrpa0kt62ldIeqekn+/pt0l6jqQfSromIv6rpKdIOrS19ixJiojJHqxfoVB4BKImXoVCYbNibKnxFZJ+v7V2vyS11r6b3nFZ8SWSfq7//4mSzoqIozW/FmRrSn9+a+1OSYqIqyQdKelKSUf1SdhfSPrMw1edQqHwaEAtNRYKhUcLftjpDg1G53+W9LnuwXqNpH1H0u/8prX2/yT9pKTPS/oVSX+0JxkuFAqPPNTEq1AoPJJwnqQ3R8TekmRLjWN4oqSb+v9/aVeZ952Re7XW/lTSr0s6/qGzWigUHo2oiVehUHgk4Y8kfVPS30TEVyT9w12kf7ek34yIy7R7oReHSvp8jy37iKS3/wi8FgqFRyGitbbePBQKhUKhUCg8KlAer0KhUCgUCoU1Qk28CoVCoVAoFNYINfEqFAqFQqFQWCPUxKtQKBQKhUJhjVATr0KhUCgUCoU1Qk28CoVCoVAoFNYINfEqFAqFQqFQWCPUxKtQKBQKhUJhjfD/ASp33wPr2Mz4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random \n",
    "for i in range(10):\n",
    "    index = int(random.random()*1000)\n",
    "    plot_data = data[index:index+1,:,:]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel(\"Fchans\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.imshow(plot_data[0,:,:,0], interpolation='nearest', cmap=plt.get_cmap('hot'))\n",
    "    plt.show()\n",
    "  \n",
    "    stuff = model.encoder.predict(plot_data)\n",
    "    sample = sample_creation(stuff)\n",
    "    reconstruction = model.decoder.predict(sample)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(\"reconstruction\")\n",
    "    plt.xlabel(\"Fchans\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.imshow(reconstruction[0,:,:,0], interpolation='nearest', cmap=plt.get_cmap('hot'))\n",
    "#     print(\"-----------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
