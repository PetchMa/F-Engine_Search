{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pma/.local/lib/python3.6/site-packages/numba/core/decorators.py:255: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, prange, njit\n",
    "from blimpy import Waterfall\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from synthetic_real import create_true, create_full_cadence, create_false, create_true_single_shot, create_true_faster\n",
    "from scipy import spatial\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.insert(1, '../ML_Training')\n",
    "sys.path.insert(2, '../GBT_pipeline')\n",
    "from preprocess import get_data\n",
    "from single_search import search_model_eval, combine\n",
    "\n",
    "@jit(nopython=True)\n",
    "def pre_proc(data):\n",
    "    data = np.log(data)\n",
    "    data= data - data.min()\n",
    "    data = data/data.max()\n",
    "    return data\n",
    "\n",
    "@jit(parallel=True)\n",
    "def load_data_ED(data):\n",
    "    print(data.shape)\n",
    "    data_transform =  np.zeros((data.shape[0],6, 16,256,1))\n",
    "    for i in prange(data.shape[0]):\n",
    "        data_transform[i,:,:,:,0]  = pre_proc(data[i,:,:,:] )\n",
    "    return data_transform\n",
    "\n",
    "def combine(data):\n",
    "    new_data = np.zeros((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],data.shape[4]))\n",
    "    for i in prange(data.shape[0]):\n",
    "        new_data[i*data.shape[1] : (i+1)*data.shape[1],:,:,:] = data[i,:,:,:,:]\n",
    "    return new_data\n",
    "# tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77687, 6, 16, 256)\n",
      "Creating True\n",
      "(20000, 6, 16, 256)\n",
      "Creating False\n",
      "(120000, 6, 16, 256)\n",
      "Creating True\n",
      "(120000, 6, 16, 256)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "NUM_SAMPLES = 20000\n",
    "plate = np.load('../../real_filtered.npy')[:77687]\n",
    "\n",
    "print(plate.shape)\n",
    "print(\"Creating True\")\n",
    "data = create_full_cadence(create_true_faster, plate = plate, samples = NUM_SAMPLES,  snr_base=10, snr_range=30, factor =0.1)\n",
    "data = combine(load_data_ED(data))\n",
    "\n",
    "print(\"Creating False\")\n",
    "false_data = abs(create_full_cadence(create_false, plate = plate, samples = NUM_SAMPLES*6, snr_base=10, snr_range=30))\n",
    "false_data = load_data_ED(false_data)\n",
    "\n",
    "print(\"Creating True\")\n",
    "true_data = create_full_cadence(create_true_faster, plate = plate, samples = NUM_SAMPLES*6,  snr_base=10, snr_range=30, factor =0.1)\n",
    "true_data = load_data_ED(true_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77687, 6, 16, 256)\n",
      "Creating True\n",
      "(1000, 6, 16, 256)\n",
      "Creating False\n",
      "(6000, 6, 16, 256)\n",
      "Creating True\n",
      "(6000, 6, 16, 256)\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 1000\n",
    "\n",
    "print(plate.shape)\n",
    "print(\"Creating True\")\n",
    "data_test = create_full_cadence(create_true_faster, plate = plate, samples = NUM_SAMPLES,  snr_base=10, snr_range=30, factor =0.1)\n",
    "data_test = combine(load_data_ED(data_test))\n",
    "\n",
    "print(\"Creating False\")\n",
    "false_data_test = abs(create_full_cadence(create_false, plate = plate, samples = NUM_SAMPLES*6, snr_base=10, snr_range=30))\n",
    "false_data_test = load_data_ED(false_data_test)\n",
    "\n",
    "\n",
    "print(\"Creating True\")\n",
    "true_data_test  = create_full_cadence(create_true_faster, plate = plate, samples = NUM_SAMPLES*6,  snr_base=10, snr_range=30, factor =0.1)\n",
    "true_data_test = load_data_ED(true_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder,  **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.true_loss_tracker = keras.metrics.Mean(name=\"true_loss\")\n",
    "        self.false_loss_tracker = keras.metrics.Mean(name=\"false_loss\")\n",
    "        \n",
    "        self.total_loss_tracker_validation = keras.metrics.Mean(name=\"val_total_loss\")\n",
    "        self.reconstruction_loss_tracker_validation = keras.metrics.Mean(\n",
    "            name=\"val_reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker_validation = keras.metrics.Mean(name=\"val_kl_loss\")\n",
    "        self.false_loss_tracker_validation = keras.metrics.Mean(name=\"val_false_loss\")\n",
    "        self.true_loss_tracker_validation = keras.metrics.Mean(name=\"val_true_loss\")\n",
    "        \n",
    "        alpha=2\n",
    "        beta=2\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.count=1\n",
    "\n",
    "    @tf.function\n",
    "    def loss_diff(self, a,b):\n",
    "        return 1/ self.loss_same(a,b)\n",
    "   \n",
    "    @tf.function\n",
    "    def loss_same(self, a,b):\n",
    "        return tf.math.reduce_mean(tf.math.reduce_euclidean_norm(a-b, axis=1))\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def true_clustering(self, true_data,training=True):\n",
    "        similarity = 0\n",
    "        difference = 0\n",
    "        same = 0\n",
    "        a1 = self.encoder(true_data[:,0,:,:,:], training)[2]\n",
    "        b = self.encoder(true_data[:,1,:,:,:], training)[2]\n",
    "        a2 = self.encoder(true_data[:,2,:,:,:],training)[2]\n",
    "        c = self.encoder(true_data[:,3,:,:,:], training)[2]\n",
    "        a3 = self.encoder(true_data[:,4,:,:,:], training)[2]\n",
    "        d = self.encoder(true_data[:,5,:,:,:], training)[2]\n",
    "\n",
    "        difference += self.loss_diff(a1,b)\n",
    "        difference += self.loss_diff(a1,c)\n",
    "        difference += self.loss_diff(a1,d)\n",
    "\n",
    "        difference += self.loss_diff(a2,b)\n",
    "        difference += self.loss_diff(a2,c)\n",
    "        difference += self.loss_diff(a2,d)\n",
    "\n",
    "        difference += self.loss_diff(a3,b)\n",
    "        difference += self.loss_diff(a3,c)\n",
    "        difference += self.loss_diff(a3,d)\n",
    "\n",
    "        same += self.loss_same(a1,a2)\n",
    "        same += self.loss_same(a1,a3)\n",
    "        same += self.loss_same(a2,a3)\n",
    "        \n",
    "        same += self.loss_same(b,c)\n",
    "        same += self.loss_same(c,d)\n",
    "        same += self.loss_same(b,d)\n",
    "        \n",
    "\n",
    "        similarity += same+difference\n",
    "        return similarity\n",
    "    \n",
    "    @tf.function\n",
    "    def false_clustering(self, false_data, training=True):\n",
    "\n",
    "        similarity = 0\n",
    "        difference = 0\n",
    "        same = 0\n",
    "        a1 = self.encoder(false_data[:,0,:,:,:], training)[2]\n",
    "        b = self.encoder(false_data[:,1,:,:,:], training)[2]\n",
    "        a2 = self.encoder(false_data[:,2,:,:,:],training)[2]\n",
    "        c = self.encoder(false_data[:,3,:,:,:], training)[2]\n",
    "        a3 = self.encoder(false_data[:,4,:,:,:], training)[2]\n",
    "        d = self.encoder(false_data[:,5,:,:,:], training)[2]\n",
    "\n",
    "        difference += self.loss_same(a1,b)\n",
    "        difference += self.loss_same(a1,c)\n",
    "        difference += self.loss_same(a1,d)\n",
    "\n",
    "        difference += self.loss_same(a2,b)\n",
    "        difference += self.loss_same(a2,c)\n",
    "        difference += self.loss_same(a2,d)\n",
    "\n",
    "        difference += self.loss_same(a3,b)\n",
    "        difference += self.loss_same(a3,c)\n",
    "        difference += self.loss_same(a3,d)\n",
    "\n",
    "        same += self.loss_same(a1,a2)\n",
    "        same += self.loss_same(a1,a3)\n",
    "        same += self.loss_same(a2,a3)\n",
    "        \n",
    "        same += self.loss_same(b,c)\n",
    "        same += self.loss_same(c,d)\n",
    "        same += self.loss_same(b,d)\n",
    "        \n",
    "        similarity += same+difference\n",
    "        return similarity\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        self.count+=1\n",
    "        cluster_loss =0\n",
    "        x, y = data\n",
    "        true_data = x[1]\n",
    "        false_data = x[2]\n",
    "        x= x[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(y, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "\n",
    "            false_loss = self.false_clustering(false_data)\n",
    "            true_loss = self.true_clustering(true_data)\n",
    "            total_loss = reconstruction_loss + self.beta*kl_loss +self.alpha*(30*true_loss+false_loss)\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.false_loss_tracker.update_state(false_loss)\n",
    "        self.true_loss_tracker.update_state(true_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"false_loss\": self.false_loss_tracker.result(),\n",
    "            \"true_loss\": self.true_loss_tracker.result()\n",
    "        }\n",
    "    \n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        true_data = x[1]\n",
    "        false_data = x[2]\n",
    "        x= x[0]\n",
    "        z_mean, z_log_var, z = self.encoder(x, training=False)\n",
    "        reconstruction = self.decoder(z, training=False)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(y, reconstruction), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        false_loss = self.false_clustering(false_data, False)\n",
    "        true_loss = self.true_clustering(true_data, False)\n",
    "        total_loss = reconstruction_loss + self.beta*kl_loss +self.alpha*(30*true_loss+false_loss)\n",
    "        \n",
    "        \n",
    "        self.total_loss_tracker_validation.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker_validation.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker_validation.update_state(kl_loss)\n",
    "        self.false_loss_tracker_validation.update_state(false_loss)\n",
    "        self.true_loss_tracker_validation.update_state(true_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker_validation.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker_validation.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker_validation.result(),\n",
    "            \"false_loss\": self.false_loss_tracker_validation.result(),\n",
    "            \"true_loss\": self.true_loss_tracker_validation.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_creation(inputs):\n",
    "    z_mean = inputs[0]\n",
    "    z_log_var = inputs[1]\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "tensorflow      INFO     Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 16, 256, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 128, 16)   160         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 128, 16)   2320        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 64, 32)    4640        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 64, 32)    9248        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 64, 32)    9248        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 2, 32, 64)    18496       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 2, 32, 64)    36928       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 2, 32, 128)   73856       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 1, 16, 256)   295168      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          2097664     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 8)            4104        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 8)            4104        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sampling_1 (Sampling)           (None, 8)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,555,936\n",
      "Trainable params: 2,555,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               4608      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 16, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 2, 32, 256)        590080    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 4, 64, 128)        295040    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 4, 64, 64)         73792     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 4, 64, 64)         36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 4, 64, 32)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 4, 64, 32)         9248      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 8, 128, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 8, 128, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DT (None, 16, 256, 16)       2320      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DT (None, 16, 256, 1)        145       \n",
      "=================================================================\n",
      "Total params: 3,145,745\n",
      "Trainable params: 3,145,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    latent_dim = 8\n",
    "    dens_lay = 512\n",
    "    kernel = (3,3)\n",
    "    encoder_inputs = keras.Input(shape=(16, 256, 1))\n",
    "    x = layers.Conv2D(16, kernel, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "    x = layers.Conv2D(16, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, kernel, activation=\"relu\", strides=2,padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(128, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(256, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(dens_lay, activation=\"relu\")(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    encoder.summary()\n",
    "    \n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(dens_lay, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Dense(1* 16 * 256, activation=\"relu\")(x)\n",
    "    x = layers.Reshape((1,16, 256))(x)\n",
    "    x = layers.Conv2DTranspose(256, kernel, activation=\"relu\", strides=2,padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(128, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(64, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(32, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(32, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, kernel, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, kernel, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1, kernel, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    decoder.summary()\n",
    "\n",
    "    vae = VAE(encoder, decoder)\n",
    "    vae.compile(optimizer=keras.optimizers.Adam(lr=0.0005))\n",
    "    return vae\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "40/40 [==============================] - 78s 1s/step - loss: 4059.9436 - reconstruction_loss: 2786.6987 - kl_loss: 9.3861 - false_loss: 33.6449 - true_loss: 19.3563 - val_loss: 3649.9421 - val_reconstruction_loss: 2716.1973 - val_kl_loss: 7.3410 - val_false_loss: 13.9165 - val_true_loss: 14.8538\n",
      "Epoch 2/800\n",
      "40/40 [==============================] - 40s 989ms/step - loss: 3630.3243 - reconstruction_loss: 2684.0256 - kl_loss: 7.9643 - false_loss: 20.4646 - true_loss: 15.9894 - val_loss: 3621.8467 - val_reconstruction_loss: 2687.5835 - val_kl_loss: 8.1982 - val_false_loss: 14.3277 - val_true_loss: 14.8202\n",
      "Epoch 3/800\n",
      "40/40 [==============================] - 40s 996ms/step - loss: 3592.6524 - reconstruction_loss: 2658.5430 - kl_loss: 9.2321 - false_loss: 18.1442 - true_loss: 15.4858 - val_loss: 3610.1758 - val_reconstruction_loss: 2677.0828 - val_kl_loss: 8.8427 - val_false_loss: 14.2732 - val_true_loss: 14.7810\n",
      "Epoch 4/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3570.9440 - reconstruction_loss: 2693.8879 - kl_loss: 13.2153 - false_loss: 17.1896 - true_loss: 15.1456 - val_loss: 3575.6895 - val_reconstruction_loss: 2680.9827 - val_kl_loss: 11.2617 - val_false_loss: 14.2896 - val_true_loss: 14.0601\n",
      "Epoch 5/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3552.7969 - reconstruction_loss: 2816.4888 - kl_loss: 33.1999 - false_loss: 17.0715 - true_loss: 14.4382 - val_loss: 3532.1282 - val_reconstruction_loss: 2707.2812 - val_kl_loss: 21.0594 - val_false_loss: 14.1061 - val_true_loss: 12.5753\n",
      "Epoch 6/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3273.1808 - reconstruction_loss: 2773.5129 - kl_loss: 66.1219 - false_loss: 16.9814 - true_loss: 13.1210 - val_loss: 3475.7136 - val_reconstruction_loss: 2715.9031 - val_kl_loss: 29.6756 - val_false_loss: 14.2690 - val_true_loss: 11.1987\n",
      "Epoch 7/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3182.3538 - reconstruction_loss: 2756.8821 - kl_loss: 67.6024 - false_loss: 16.9725 - true_loss: 11.7807 - val_loss: 3431.7976 - val_reconstruction_loss: 2721.8113 - val_kl_loss: 36.0170 - val_false_loss: 14.4135 - val_true_loss: 10.1521\n",
      "Epoch 8/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3156.4693 - reconstruction_loss: 2756.2092 - kl_loss: 69.3973 - false_loss: 16.9807 - true_loss: 10.7372 - val_loss: 3398.3691 - val_reconstruction_loss: 2726.2014 - val_kl_loss: 41.7240 - val_false_loss: 14.6583 - val_true_loss: 9.3234\n",
      "Epoch 9/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.5589 - reconstruction_loss: 2755.7087 - kl_loss: 70.3901 - false_loss: 17.0168 - true_loss: 9.9154 - val_loss: 3371.8079 - val_reconstruction_loss: 2729.5044 - val_kl_loss: 45.0024 - val_false_loss: 14.6887 - val_true_loss: 8.7154\n",
      "Epoch 10/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3154.9275 - reconstruction_loss: 2755.2869 - kl_loss: 70.0682 - false_loss: 17.0542 - true_loss: 9.2669 - val_loss: 3350.4211 - val_reconstruction_loss: 2732.1201 - val_kl_loss: 48.0430 - val_false_loss: 14.7617 - val_true_loss: 8.2115\n",
      "Epoch 11/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3152.2822 - reconstruction_loss: 2755.1704 - kl_loss: 70.5835 - false_loss: 17.0847 - true_loss: 8.7380 - val_loss: 3332.8865 - val_reconstruction_loss: 2734.2698 - val_kl_loss: 50.6722 - val_false_loss: 14.8469 - val_true_loss: 7.7930\n",
      "Epoch 12/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3156.0073 - reconstruction_loss: 2755.1741 - kl_loss: 70.6108 - false_loss: 17.1156 - true_loss: 8.3012 - val_loss: 3318.2051 - val_reconstruction_loss: 2736.0505 - val_kl_loss: 52.3008 - val_false_loss: 14.8270 - val_true_loss: 7.4650\n",
      "Epoch 13/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3153.9562 - reconstruction_loss: 2755.1672 - kl_loss: 70.5795 - false_loss: 17.1311 - true_loss: 7.9344 - val_loss: 3305.8025 - val_reconstruction_loss: 2737.5647 - val_kl_loss: 53.6589 - val_false_loss: 14.8055 - val_true_loss: 7.1885\n",
      "Epoch 14/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3156.3405 - reconstruction_loss: 2755.1169 - kl_loss: 69.9855 - false_loss: 17.1493 - true_loss: 7.6222 - val_loss: 3295.5769 - val_reconstruction_loss: 2738.8550 - val_kl_loss: 54.7882 - val_false_loss: 14.7733 - val_true_loss: 6.9600\n",
      "Epoch 15/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3155.4075 - reconstruction_loss: 2755.1680 - kl_loss: 70.2389 - false_loss: 17.1482 - true_loss: 7.3578 - val_loss: 3286.4353 - val_reconstruction_loss: 2739.9751 - val_kl_loss: 56.1505 - val_false_loss: 14.8204 - val_true_loss: 6.7420\n",
      "Epoch 16/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3154.0047 - reconstruction_loss: 2755.1772 - kl_loss: 70.0163 - false_loss: 17.1772 - true_loss: 7.1208 - val_loss: 3278.3240 - val_reconstruction_loss: 2740.9604 - val_kl_loss: 57.2480 - val_false_loss: 14.8452 - val_true_loss: 6.5530\n",
      "Epoch 17/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3148.3143 - reconstruction_loss: 2755.1382 - kl_loss: 71.0693 - false_loss: 17.1889 - true_loss: 6.9117 - val_loss: 3271.2234 - val_reconstruction_loss: 2741.8203 - val_kl_loss: 58.5757 - val_false_loss: 14.9304 - val_true_loss: 6.3732\n",
      "Epoch 18/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3150.5181 - reconstruction_loss: 2755.1335 - kl_loss: 70.8137 - false_loss: 17.2075 - true_loss: 6.7271 - val_loss: 3264.8398 - val_reconstruction_loss: 2742.5850 - val_kl_loss: 59.1863 - val_false_loss: 14.9038 - val_true_loss: 6.2346\n",
      "Epoch 19/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3153.3777 - reconstruction_loss: 2755.1831 - kl_loss: 70.3272 - false_loss: 17.2103 - true_loss: 6.5640 - val_loss: 3259.2820 - val_reconstruction_loss: 2743.2759 - val_kl_loss: 60.3407 - val_false_loss: 14.9815 - val_true_loss: 6.0894\n",
      "Epoch 20/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3150.3601 - reconstruction_loss: 2755.1675 - kl_loss: 70.9307 - false_loss: 17.2251 - true_loss: 6.4151 - val_loss: 3254.1392 - val_reconstruction_loss: 2743.9006 - val_kl_loss: 60.9204 - val_false_loss: 14.9802 - val_true_loss: 5.9740\n",
      "Epoch 21/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3152.8871 - reconstruction_loss: 2755.1489 - kl_loss: 70.5281 - false_loss: 17.2265 - true_loss: 6.2817 - val_loss: 3249.4397 - val_reconstruction_loss: 2744.4587 - val_kl_loss: 61.5206 - val_false_loss: 14.9902 - val_true_loss: 5.8660\n",
      "Epoch 22/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3150.6848 - reconstruction_loss: 2755.1213 - kl_loss: 70.6809 - false_loss: 17.2365 - true_loss: 6.1604 - val_loss: 3245.2009 - val_reconstruction_loss: 2744.9670 - val_kl_loss: 61.9517 - val_false_loss: 14.9797 - val_true_loss: 5.7729\n",
      "Epoch 23/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3153.1884 - reconstruction_loss: 2755.1030 - kl_loss: 70.3780 - false_loss: 17.2441 - true_loss: 6.0496 - val_loss: 3241.2988 - val_reconstruction_loss: 2745.4294 - val_kl_loss: 62.5408 - val_false_loss: 15.0054 - val_true_loss: 5.6796\n",
      "Epoch 24/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3152.0093 - reconstruction_loss: 2755.1367 - kl_loss: 70.6047 - false_loss: 17.2505 - true_loss: 5.9484 - val_loss: 3237.7454 - val_reconstruction_loss: 2745.8557 - val_kl_loss: 63.1673 - val_false_loss: 15.0382 - val_true_loss: 5.5913\n",
      "Epoch 25/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.6489 - reconstruction_loss: 2755.1396 - kl_loss: 70.8468 - false_loss: 17.2575 - true_loss: 5.8547 - val_loss: 3234.5020 - val_reconstruction_loss: 2746.2476 - val_kl_loss: 63.4542 - val_false_loss: 15.0222 - val_true_loss: 5.5217\n",
      "Epoch 26/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.1827 - reconstruction_loss: 2755.1235 - kl_loss: 70.3959 - false_loss: 17.2658 - true_loss: 5.7696 - val_loss: 3231.4939 - val_reconstruction_loss: 2746.6133 - val_kl_loss: 63.9953 - val_false_loss: 15.0522 - val_true_loss: 5.4464\n",
      "Epoch 27/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 3154.3958 - reconstruction_loss: 2755.2151 - kl_loss: 70.7733 - false_loss: 17.2716 - true_loss: 5.6906 - val_loss: 3228.6641 - val_reconstruction_loss: 2746.9485 - val_kl_loss: 64.3716 - val_false_loss: 15.0610 - val_true_loss: 5.3808\n",
      "Epoch 28/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.2981 - reconstruction_loss: 2755.1265 - kl_loss: 70.7381 - false_loss: 17.2707 - true_loss: 5.6167 - val_loss: 3226.0620 - val_reconstruction_loss: 2747.2583 - val_kl_loss: 64.6955 - val_false_loss: 15.0645 - val_true_loss: 5.3214\n",
      "Epoch 29/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3151.3901 - reconstruction_loss: 2755.1277 - kl_loss: 70.7469 - false_loss: 17.2759 - true_loss: 5.5484 - val_loss: 3223.6423 - val_reconstruction_loss: 2747.5469 - val_kl_loss: 64.9456 - val_false_loss: 15.0545 - val_true_loss: 5.2683\n",
      "Epoch 30/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3146.3500 - reconstruction_loss: 2755.0928 - kl_loss: 70.5987 - false_loss: 17.2777 - true_loss: 5.4835 - val_loss: 3221.3572 - val_reconstruction_loss: 2747.8176 - val_kl_loss: 65.1689 - val_false_loss: 15.0494 - val_true_loss: 5.2184\n",
      "Epoch 31/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3148.8660 - reconstruction_loss: 2755.0994 - kl_loss: 70.1131 - false_loss: 17.2823 - true_loss: 5.4246 - val_loss: 3219.2566 - val_reconstruction_loss: 2748.0701 - val_kl_loss: 65.5985 - val_false_loss: 15.0795 - val_true_loss: 5.1638\n",
      "Epoch 32/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3153.7486 - reconstruction_loss: 2755.0273 - kl_loss: 70.5795 - false_loss: 17.2867 - true_loss: 5.3689 - val_loss: 3217.2493 - val_reconstruction_loss: 2748.3015 - val_kl_loss: 65.8989 - val_false_loss: 15.0896 - val_true_loss: 5.1162\n",
      "Epoch 33/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3148.0514 - reconstruction_loss: 2755.1724 - kl_loss: 70.4258 - false_loss: 17.2905 - true_loss: 5.3157 - val_loss: 3215.3879 - val_reconstruction_loss: 2748.5227 - val_kl_loss: 66.1466 - val_false_loss: 15.0947 - val_true_loss: 5.0730\n",
      "Epoch 34/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3152.0249 - reconstruction_loss: 2755.1555 - kl_loss: 70.9632 - false_loss: 17.2980 - true_loss: 5.2671 - val_loss: 3213.6240 - val_reconstruction_loss: 2748.7322 - val_kl_loss: 66.2800 - val_false_loss: 15.0840 - val_true_loss: 5.0361\n",
      "Epoch 35/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3145.4237 - reconstruction_loss: 2755.1294 - kl_loss: 70.5850 - false_loss: 17.2959 - true_loss: 5.2204 - val_loss: 3211.9497 - val_reconstruction_loss: 2748.9316 - val_kl_loss: 66.4971 - val_false_loss: 15.0900 - val_true_loss: 4.9974\n",
      "Epoch 36/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3146.0501 - reconstruction_loss: 2754.9346 - kl_loss: 70.4969 - false_loss: 17.3031 - true_loss: 5.1764 - val_loss: 3210.4075 - val_reconstruction_loss: 2749.1025 - val_kl_loss: 66.7505 - val_false_loss: 15.1044 - val_true_loss: 4.9599\n",
      "Epoch 37/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3150.4171 - reconstruction_loss: 2754.8335 - kl_loss: 70.4248 - false_loss: 17.3074 - true_loss: 5.1362 - val_loss: 3208.9265 - val_reconstruction_loss: 2749.2620 - val_kl_loss: 67.0346 - val_false_loss: 15.1222 - val_true_loss: 4.9225\n",
      "Epoch 38/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.7360 - reconstruction_loss: 2754.9587 - kl_loss: 70.6403 - false_loss: 17.3083 - true_loss: 5.0980 - val_loss: 3207.5757 - val_reconstruction_loss: 2749.4260 - val_kl_loss: 67.3259 - val_false_loss: 15.1440 - val_true_loss: 4.8868\n",
      "Epoch 39/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3150.1107 - reconstruction_loss: 2754.8140 - kl_loss: 70.3620 - false_loss: 17.3136 - true_loss: 5.0606 - val_loss: 3206.1951 - val_reconstruction_loss: 2749.5413 - val_kl_loss: 67.5185 - val_false_loss: 15.1540 - val_true_loss: 4.8551\n",
      "Epoch 40/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3157.4299 - reconstruction_loss: 2759.6335 - kl_loss: 71.2402 - false_loss: 17.3181 - true_loss: 5.0269 - val_loss: 3205.0344 - val_reconstruction_loss: 2749.7683 - val_kl_loss: 67.6623 - val_false_loss: 15.1575 - val_true_loss: 4.8271\n",
      "Epoch 41/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3152.7864 - reconstruction_loss: 2756.6804 - kl_loss: 70.4001 - false_loss: 17.3225 - true_loss: 4.9941 - val_loss: 3203.8789 - val_reconstruction_loss: 2749.9492 - val_kl_loss: 67.8009 - val_false_loss: 15.1606 - val_true_loss: 4.8001\n",
      "Epoch 42/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.8381 - reconstruction_loss: 2756.0339 - kl_loss: 70.5146 - false_loss: 17.3253 - true_loss: 4.9620 - val_loss: 3202.7678 - val_reconstruction_loss: 2750.1147 - val_kl_loss: 68.0087 - val_false_loss: 15.1776 - val_true_loss: 4.7713\n",
      "Epoch 43/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3151.5632 - reconstruction_loss: 2755.8577 - kl_loss: 70.6648 - false_loss: 17.3305 - true_loss: 4.9318 - val_loss: 3201.6987 - val_reconstruction_loss: 2750.2693 - val_kl_loss: 68.1906 - val_false_loss: 15.1873 - val_true_loss: 4.7446\n",
      "Epoch 44/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3152.0962 - reconstruction_loss: 2755.1548 - kl_loss: 70.7180 - false_loss: 17.3325 - true_loss: 4.9027 - val_loss: 3200.5667 - val_reconstruction_loss: 2750.3010 - val_kl_loss: 68.3374 - val_false_loss: 15.1987 - val_true_loss: 4.7199\n",
      "Epoch 45/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.4818 - reconstruction_loss: 2756.1890 - kl_loss: 70.2023 - false_loss: 17.3375 - true_loss: 4.8755 - val_loss: 3199.6174 - val_reconstruction_loss: 2750.4263 - val_kl_loss: 68.5095 - val_false_loss: 15.2070 - val_true_loss: 4.6960\n",
      "Epoch 46/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3151.2495 - reconstruction_loss: 2755.2358 - kl_loss: 70.5522 - false_loss: 17.3410 - true_loss: 4.8498 - val_loss: 3198.6421 - val_reconstruction_loss: 2750.5403 - val_kl_loss: 68.6606 - val_false_loss: 15.2153 - val_true_loss: 4.6725\n",
      "Epoch 47/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.1967 - reconstruction_loss: 2755.1592 - kl_loss: 70.6718 - false_loss: 17.3414 - true_loss: 4.8238 - val_loss: 3197.7080 - val_reconstruction_loss: 2750.6487 - val_kl_loss: 68.8132 - val_false_loss: 15.2237 - val_true_loss: 4.6498\n",
      "Epoch 48/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3148.8966 - reconstruction_loss: 2755.1445 - kl_loss: 70.4727 - false_loss: 17.3444 - true_loss: 4.7990 - val_loss: 3196.9744 - val_reconstruction_loss: 2750.7546 - val_kl_loss: 69.0463 - val_false_loss: 15.2507 - val_true_loss: 4.6271\n",
      "Epoch 49/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3148.1593 - reconstruction_loss: 2754.8127 - kl_loss: 71.2305 - false_loss: 17.3462 - true_loss: 4.7755 - val_loss: 3196.0798 - val_reconstruction_loss: 2750.8218 - val_kl_loss: 69.1095 - val_false_loss: 15.2480 - val_true_loss: 4.6090\n",
      "Epoch 50/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.3936 - reconstruction_loss: 2755.3574 - kl_loss: 70.3641 - false_loss: 17.3503 - true_loss: 4.7534 - val_loss: 3195.2358 - val_reconstruction_loss: 2750.9109 - val_kl_loss: 69.2310 - val_false_loss: 15.2556 - val_true_loss: 4.5892\n",
      "Epoch 51/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.1404 - reconstruction_loss: 2755.2954 - kl_loss: 70.3132 - false_loss: 17.3508 - true_loss: 4.7327 - val_loss: 3194.5120 - val_reconstruction_loss: 2751.0063 - val_kl_loss: 69.3984 - val_false_loss: 15.2676 - val_true_loss: 4.5696\n",
      "Epoch 52/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.5199 - reconstruction_loss: 2755.2188 - kl_loss: 71.0033 - false_loss: 17.3574 - true_loss: 4.7119 - val_loss: 3193.7761 - val_reconstruction_loss: 2751.0950 - val_kl_loss: 69.5802 - val_false_loss: 15.2877 - val_true_loss: 4.5491\n",
      "Epoch 53/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 3151.3704 - reconstruction_loss: 2755.0305 - kl_loss: 70.7826 - false_loss: 17.3578 - true_loss: 4.6916 - val_loss: 3193.0200 - val_reconstruction_loss: 2751.1733 - val_kl_loss: 69.6277 - val_false_loss: 15.2798 - val_true_loss: 4.5339\n",
      "Epoch 54/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.3506 - reconstruction_loss: 2754.7598 - kl_loss: 70.1412 - false_loss: 17.3590 - true_loss: 4.6719 - val_loss: 3192.2998 - val_reconstruction_loss: 2751.2581 - val_kl_loss: 69.6831 - val_false_loss: 15.2740 - val_true_loss: 4.5188\n",
      "Epoch 55/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3150.2012 - reconstruction_loss: 2754.8228 - kl_loss: 70.8900 - false_loss: 17.3617 - true_loss: 4.6536 - val_loss: 3191.6858 - val_reconstruction_loss: 2751.3396 - val_kl_loss: 69.6860 - val_false_loss: 15.2635 - val_true_loss: 4.5075\n",
      "Epoch 56/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.7742 - reconstruction_loss: 2755.1829 - kl_loss: 70.5969 - false_loss: 17.3645 - true_loss: 4.6366 - val_loss: 3191.0156 - val_reconstruction_loss: 2751.4146 - val_kl_loss: 69.7762 - val_false_loss: 15.2687 - val_true_loss: 4.4919\n",
      "Epoch 57/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3151.7800 - reconstruction_loss: 2754.4763 - kl_loss: 70.6654 - false_loss: 17.3681 - true_loss: 4.6192 - val_loss: 3190.3662 - val_reconstruction_loss: 2751.4619 - val_kl_loss: 69.8282 - val_false_loss: 15.2691 - val_true_loss: 4.4785\n",
      "Epoch 58/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3162.9920 - reconstruction_loss: 2757.9629 - kl_loss: 72.2785 - false_loss: 17.3712 - true_loss: 4.6034 - val_loss: 3189.7844 - val_reconstruction_loss: 2751.5354 - val_kl_loss: 69.9886 - val_false_loss: 15.2829 - val_true_loss: 4.4618\n",
      "Epoch 59/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3150.8856 - reconstruction_loss: 2755.1978 - kl_loss: 70.8904 - false_loss: 17.3766 - true_loss: 4.5881 - val_loss: 3189.1902 - val_reconstruction_loss: 2751.6055 - val_kl_loss: 70.0837 - val_false_loss: 15.2876 - val_true_loss: 4.4474\n",
      "Epoch 60/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3155.6681 - reconstruction_loss: 2755.1611 - kl_loss: 70.6759 - false_loss: 17.3775 - true_loss: 4.5727 - val_loss: 3188.6038 - val_reconstruction_loss: 2751.6733 - val_kl_loss: 70.1732 - val_false_loss: 15.2911 - val_true_loss: 4.4334\n",
      "Epoch 61/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3145.1332 - reconstruction_loss: 2755.1326 - kl_loss: 70.2237 - false_loss: 17.3787 - true_loss: 4.5570 - val_loss: 3188.0764 - val_reconstruction_loss: 2751.7402 - val_kl_loss: 70.3237 - val_false_loss: 15.3054 - val_true_loss: 4.4180\n",
      "Epoch 62/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3150.0625 - reconstruction_loss: 2755.1548 - kl_loss: 71.0227 - false_loss: 17.3785 - true_loss: 4.5425 - val_loss: 3187.5349 - val_reconstruction_loss: 2751.8030 - val_kl_loss: 70.3308 - val_false_loss: 15.2981 - val_true_loss: 4.4079\n",
      "Epoch 63/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3153.6803 - reconstruction_loss: 2755.1321 - kl_loss: 70.5975 - false_loss: 17.3802 - true_loss: 4.5285 - val_loss: 3187.0076 - val_reconstruction_loss: 2751.8640 - val_kl_loss: 70.3587 - val_false_loss: 15.2915 - val_true_loss: 4.3974\n",
      "Epoch 64/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3146.6829 - reconstruction_loss: 2755.1230 - kl_loss: 70.9978 - false_loss: 17.3813 - true_loss: 4.5141 - val_loss: 3186.4856 - val_reconstruction_loss: 2751.9224 - val_kl_loss: 70.4008 - val_false_loss: 15.2904 - val_true_loss: 4.3863\n",
      "Epoch 65/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3147.2722 - reconstruction_loss: 2755.1328 - kl_loss: 70.5814 - false_loss: 17.3795 - true_loss: 4.5007 - val_loss: 3185.9924 - val_reconstruction_loss: 2751.9800 - val_kl_loss: 70.5016 - val_false_loss: 15.2972 - val_true_loss: 4.3736\n",
      "Epoch 66/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3145.8239 - reconstruction_loss: 2755.1377 - kl_loss: 69.8863 - false_loss: 17.3792 - true_loss: 4.4875 - val_loss: 3185.5496 - val_reconstruction_loss: 2752.0359 - val_kl_loss: 70.6946 - val_false_loss: 15.3253 - val_true_loss: 4.3579\n",
      "Epoch 67/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3150.1521 - reconstruction_loss: 2755.1379 - kl_loss: 67.5691 - false_loss: 17.3850 - true_loss: 4.4749 - val_loss: 3184.7922 - val_reconstruction_loss: 2752.0891 - val_kl_loss: 70.6338 - val_false_loss: 15.3466 - val_true_loss: 4.3457\n",
      "Epoch 68/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3153.8818 - reconstruction_loss: 2755.0857 - kl_loss: 62.2644 - false_loss: 17.4008 - true_loss: 4.4643 - val_loss: 3183.8677 - val_reconstruction_loss: 2752.1394 - val_kl_loss: 70.5226 - val_false_loss: 15.3751 - val_true_loss: 4.3322\n",
      "Epoch 69/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3117.0859 - reconstruction_loss: 2754.9573 - kl_loss: 60.3954 - false_loss: 17.4368 - true_loss: 4.4492 - val_loss: 3182.8936 - val_reconstruction_loss: 2752.1829 - val_kl_loss: 70.4565 - val_false_loss: 15.4173 - val_true_loss: 4.3161\n",
      "Epoch 70/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3110.5370 - reconstruction_loss: 2754.6704 - kl_loss: 60.8244 - false_loss: 17.4738 - true_loss: 4.4323 - val_loss: 3181.8755 - val_reconstruction_loss: 2752.2161 - val_kl_loss: 70.3587 - val_false_loss: 15.4529 - val_true_loss: 4.3006\n",
      "Epoch 71/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3109.7143 - reconstruction_loss: 2754.4722 - kl_loss: 60.6766 - false_loss: 17.5198 - true_loss: 4.4147 - val_loss: 3180.8672 - val_reconstruction_loss: 2752.2488 - val_kl_loss: 70.2231 - val_false_loss: 15.4787 - val_true_loss: 4.2869\n",
      "Epoch 72/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3106.9909 - reconstruction_loss: 2754.2478 - kl_loss: 60.5189 - false_loss: 17.5616 - true_loss: 4.3972 - val_loss: 3179.8425 - val_reconstruction_loss: 2752.2891 - val_kl_loss: 70.1093 - val_false_loss: 15.5149 - val_true_loss: 4.2718\n",
      "Epoch 73/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3108.8729 - reconstruction_loss: 2754.7546 - kl_loss: 60.7251 - false_loss: 17.6062 - true_loss: 4.3798 - val_loss: 3178.8352 - val_reconstruction_loss: 2752.3245 - val_kl_loss: 70.0366 - val_false_loss: 15.5583 - val_true_loss: 4.2553\n",
      "Epoch 74/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.3295 - reconstruction_loss: 2754.2434 - kl_loss: 61.0540 - false_loss: 17.6475 - true_loss: 4.3623 - val_loss: 3177.8440 - val_reconstruction_loss: 2752.3440 - val_kl_loss: 69.9149 - val_false_loss: 15.5841 - val_true_loss: 4.2417\n",
      "Epoch 75/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.5745 - reconstruction_loss: 2754.2524 - kl_loss: 60.5509 - false_loss: 17.6892 - true_loss: 4.3453 - val_loss: 3176.8928 - val_reconstruction_loss: 2752.3757 - val_kl_loss: 69.8356 - val_false_loss: 15.6259 - val_true_loss: 4.2266\n",
      "Epoch 76/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3102.9586 - reconstruction_loss: 2754.2520 - kl_loss: 60.8169 - false_loss: 17.7316 - true_loss: 4.3288 - val_loss: 3175.9771 - val_reconstruction_loss: 2752.4094 - val_kl_loss: 69.7640 - val_false_loss: 15.6649 - val_true_loss: 4.2118\n",
      "Epoch 77/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.9176 - reconstruction_loss: 2754.3628 - kl_loss: 60.9428 - false_loss: 17.7723 - true_loss: 4.3127 - val_loss: 3175.0547 - val_reconstruction_loss: 2752.4397 - val_kl_loss: 69.6876 - val_false_loss: 15.6973 - val_true_loss: 4.1974\n",
      "Epoch 78/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3103.5441 - reconstruction_loss: 2754.2197 - kl_loss: 61.1719 - false_loss: 17.8107 - true_loss: 4.2969 - val_loss: 3174.1658 - val_reconstruction_loss: 2752.4661 - val_kl_loss: 69.6106 - val_false_loss: 15.7279 - val_true_loss: 4.1837\n",
      "Epoch 79/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 3102.7110 - reconstruction_loss: 2753.9348 - kl_loss: 61.1495 - false_loss: 17.8492 - true_loss: 4.2814 - val_loss: 3173.2629 - val_reconstruction_loss: 2752.4727 - val_kl_loss: 69.5396 - val_false_loss: 15.7610 - val_true_loss: 4.1698\n",
      "Epoch 80/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3096.3358 - reconstruction_loss: 2754.2349 - kl_loss: 60.9736 - false_loss: 17.8850 - true_loss: 4.2660 - val_loss: 3172.4045 - val_reconstruction_loss: 2752.4956 - val_kl_loss: 69.4727 - val_false_loss: 15.7929 - val_true_loss: 4.1563\n",
      "Epoch 81/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3104.5017 - reconstruction_loss: 2754.2817 - kl_loss: 61.1765 - false_loss: 17.9241 - true_loss: 4.2516 - val_loss: 3171.5676 - val_reconstruction_loss: 2752.5215 - val_kl_loss: 69.3791 - val_false_loss: 15.8156 - val_true_loss: 4.1443\n",
      "Epoch 82/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3103.1322 - reconstruction_loss: 2754.0950 - kl_loss: 60.8735 - false_loss: 17.9601 - true_loss: 4.2371 - val_loss: 3170.7427 - val_reconstruction_loss: 2752.5317 - val_kl_loss: 69.3188 - val_false_loss: 15.8507 - val_true_loss: 4.1312\n",
      "Epoch 83/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.6511 - reconstruction_loss: 2754.0051 - kl_loss: 60.7678 - false_loss: 17.9928 - true_loss: 4.2230 - val_loss: 3169.9651 - val_reconstruction_loss: 2752.5579 - val_kl_loss: 69.2525 - val_false_loss: 15.8853 - val_true_loss: 4.1189\n",
      "Epoch 84/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.2620 - reconstruction_loss: 2754.2332 - kl_loss: 61.1734 - false_loss: 18.0287 - true_loss: 4.2094 - val_loss: 3169.1846 - val_reconstruction_loss: 2752.5823 - val_kl_loss: 69.1877 - val_false_loss: 15.9117 - val_true_loss: 4.1067\n",
      "Epoch 85/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3103.6007 - reconstruction_loss: 2754.2363 - kl_loss: 61.1328 - false_loss: 18.0612 - true_loss: 4.1960 - val_loss: 3168.4294 - val_reconstruction_loss: 2752.6047 - val_kl_loss: 69.1388 - val_false_loss: 15.9438 - val_true_loss: 4.0943\n",
      "Epoch 86/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.3571 - reconstruction_loss: 2753.8130 - kl_loss: 60.9269 - false_loss: 18.0935 - true_loss: 4.1827 - val_loss: 3167.6658 - val_reconstruction_loss: 2752.6013 - val_kl_loss: 69.0577 - val_false_loss: 15.9666 - val_true_loss: 4.0836\n",
      "Epoch 87/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.2238 - reconstruction_loss: 2753.9417 - kl_loss: 61.2281 - false_loss: 18.1273 - true_loss: 4.1701 - val_loss: 3166.9583 - val_reconstruction_loss: 2752.6248 - val_kl_loss: 68.9788 - val_false_loss: 15.9931 - val_true_loss: 4.0732\n",
      "Epoch 88/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.4007 - reconstruction_loss: 2755.1157 - kl_loss: 61.5928 - false_loss: 18.1598 - true_loss: 4.1576 - val_loss: 3166.2798 - val_reconstruction_loss: 2752.6548 - val_kl_loss: 68.9501 - val_false_loss: 16.0283 - val_true_loss: 4.0611\n",
      "Epoch 89/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.3434 - reconstruction_loss: 2754.3191 - kl_loss: 61.2302 - false_loss: 18.1915 - true_loss: 4.1454 - val_loss: 3165.6011 - val_reconstruction_loss: 2752.6809 - val_kl_loss: 68.9070 - val_false_loss: 16.0589 - val_true_loss: 4.0498\n",
      "Epoch 90/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.9496 - reconstruction_loss: 2754.1790 - kl_loss: 61.1908 - false_loss: 18.2225 - true_loss: 4.1332 - val_loss: 3164.9341 - val_reconstruction_loss: 2752.7002 - val_kl_loss: 68.8712 - val_false_loss: 16.0928 - val_true_loss: 4.0384\n",
      "Epoch 91/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3108.4573 - reconstruction_loss: 2750.2212 - kl_loss: 59.0465 - false_loss: 18.2538 - true_loss: 4.1225 - val_loss: 3165.8757 - val_reconstruction_loss: 2752.7581 - val_kl_loss: 69.0171 - val_false_loss: 16.0963 - val_true_loss: 4.0482\n",
      "Epoch 92/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3182.7275 - reconstruction_loss: 2757.9219 - kl_loss: 75.4761 - false_loss: 18.2571 - true_loss: 4.1203 - val_loss: 3166.4321 - val_reconstruction_loss: 2752.8528 - val_kl_loss: 69.1824 - val_false_loss: 16.1072 - val_true_loss: 4.0500\n",
      "Epoch 93/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3188.1907 - reconstruction_loss: 2755.8042 - kl_loss: 74.5291 - false_loss: 18.2491 - true_loss: 4.1178 - val_loss: 3166.3159 - val_reconstruction_loss: 2752.8828 - val_kl_loss: 69.2519 - val_false_loss: 16.1012 - val_true_loss: 4.0454\n",
      "Epoch 94/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3148.8271 - reconstruction_loss: 2755.1597 - kl_loss: 70.9957 - false_loss: 18.2409 - true_loss: 4.1133 - val_loss: 3166.1902 - val_reconstruction_loss: 2752.9124 - val_kl_loss: 69.2796 - val_false_loss: 16.0888 - val_true_loss: 4.0424\n",
      "Epoch 95/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3144.3217 - reconstruction_loss: 2755.1301 - kl_loss: 70.6723 - false_loss: 18.2324 - true_loss: 4.1080 - val_loss: 3166.0723 - val_reconstruction_loss: 2752.9419 - val_kl_loss: 69.2702 - val_false_loss: 16.0704 - val_true_loss: 4.0408\n",
      "Epoch 96/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.8944 - reconstruction_loss: 2755.1313 - kl_loss: 71.0945 - false_loss: 18.2247 - true_loss: 4.1032 - val_loss: 3165.9500 - val_reconstruction_loss: 2752.9695 - val_kl_loss: 69.3057 - val_false_loss: 16.0585 - val_true_loss: 4.0375\n",
      "Epoch 97/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.0194 - reconstruction_loss: 2755.1216 - kl_loss: 70.9948 - false_loss: 18.2171 - true_loss: 4.0984 - val_loss: 3165.8235 - val_reconstruction_loss: 2752.9971 - val_kl_loss: 69.3272 - val_false_loss: 16.0483 - val_true_loss: 4.0346\n",
      "Epoch 98/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3143.8385 - reconstruction_loss: 2755.1179 - kl_loss: 70.8339 - false_loss: 18.2104 - true_loss: 4.0935 - val_loss: 3165.7041 - val_reconstruction_loss: 2753.0239 - val_kl_loss: 69.3627 - val_false_loss: 16.0400 - val_true_loss: 4.0312\n",
      "Epoch 99/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3151.7238 - reconstruction_loss: 2755.1021 - kl_loss: 70.3118 - false_loss: 18.2036 - true_loss: 4.0892 - val_loss: 3165.5916 - val_reconstruction_loss: 2753.0498 - val_kl_loss: 69.4420 - val_false_loss: 16.0372 - val_true_loss: 4.0264\n",
      "Epoch 100/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3145.5313 - reconstruction_loss: 2755.1108 - kl_loss: 71.2221 - false_loss: 18.1960 - true_loss: 4.0843 - val_loss: 3165.4653 - val_reconstruction_loss: 2753.0752 - val_kl_loss: 69.4697 - val_false_loss: 16.0282 - val_true_loss: 4.0232\n",
      "Epoch 101/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3152.2298 - reconstruction_loss: 2755.1040 - kl_loss: 70.6320 - false_loss: 18.1892 - true_loss: 4.0801 - val_loss: 3165.3425 - val_reconstruction_loss: 2753.1008 - val_kl_loss: 69.5108 - val_false_loss: 16.0192 - val_true_loss: 4.0197\n",
      "Epoch 102/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3153.6180 - reconstruction_loss: 2755.0923 - kl_loss: 70.4287 - false_loss: 18.1823 - true_loss: 4.0757 - val_loss: 3165.2246 - val_reconstruction_loss: 2753.1257 - val_kl_loss: 69.5230 - val_false_loss: 16.0076 - val_true_loss: 4.0173\n",
      "Epoch 103/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.4886 - reconstruction_loss: 2755.0996 - kl_loss: 70.5398 - false_loss: 18.1745 - true_loss: 4.0712 - val_loss: 3165.1099 - val_reconstruction_loss: 2753.1499 - val_kl_loss: 69.5261 - val_false_loss: 15.9932 - val_true_loss: 4.0154\n",
      "Epoch 104/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3145.1787 - reconstruction_loss: 2755.0779 - kl_loss: 71.2664 - false_loss: 18.1654 - true_loss: 4.0669 - val_loss: 3164.9885 - val_reconstruction_loss: 2753.1736 - val_kl_loss: 69.5737 - val_false_loss: 15.9862 - val_true_loss: 4.0116\n",
      "Epoch 105/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 3147.4841 - reconstruction_loss: 2755.0652 - kl_loss: 70.2543 - false_loss: 18.1600 - true_loss: 4.0628 - val_loss: 3164.8789 - val_reconstruction_loss: 2753.1965 - val_kl_loss: 69.5927 - val_false_loss: 15.9752 - val_true_loss: 4.0091\n",
      "Epoch 106/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.6117 - reconstruction_loss: 2755.0837 - kl_loss: 69.7096 - false_loss: 18.1534 - true_loss: 4.0587 - val_loss: 3164.7551 - val_reconstruction_loss: 2753.2200 - val_kl_loss: 69.6333 - val_false_loss: 15.9716 - val_true_loss: 4.0054\n",
      "Epoch 107/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3149.8736 - reconstruction_loss: 2755.0815 - kl_loss: 67.5756 - false_loss: 18.1463 - true_loss: 4.0547 - val_loss: 3164.3792 - val_reconstruction_loss: 2753.2424 - val_kl_loss: 69.6125 - val_false_loss: 15.9841 - val_true_loss: 3.9991\n",
      "Epoch 108/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3118.6103 - reconstruction_loss: 2754.6052 - kl_loss: 60.8453 - false_loss: 18.1595 - true_loss: 4.0487 - val_loss: 3163.8604 - val_reconstruction_loss: 2753.2559 - val_kl_loss: 69.5769 - val_false_loss: 16.0091 - val_true_loss: 3.9905\n",
      "Epoch 109/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3104.1206 - reconstruction_loss: 2754.2185 - kl_loss: 60.6758 - false_loss: 18.1807 - true_loss: 4.0407 - val_loss: 3163.3235 - val_reconstruction_loss: 2753.2681 - val_kl_loss: 69.5158 - val_false_loss: 16.0293 - val_true_loss: 3.9828\n",
      "Epoch 110/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3106.0801 - reconstruction_loss: 2754.1453 - kl_loss: 60.8310 - false_loss: 18.2054 - true_loss: 4.0322 - val_loss: 3162.7888 - val_reconstruction_loss: 2753.2800 - val_kl_loss: 69.4560 - val_false_loss: 16.0485 - val_true_loss: 3.9750\n",
      "Epoch 111/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.4350 - reconstruction_loss: 2754.2202 - kl_loss: 60.8272 - false_loss: 18.2269 - true_loss: 4.0236 - val_loss: 3162.2612 - val_reconstruction_loss: 2753.2900 - val_kl_loss: 69.4040 - val_false_loss: 16.0685 - val_true_loss: 3.9671\n",
      "Epoch 112/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3104.6636 - reconstruction_loss: 2754.0034 - kl_loss: 60.4880 - false_loss: 18.2531 - true_loss: 4.0152 - val_loss: 3161.7405 - val_reconstruction_loss: 2753.2927 - val_kl_loss: 69.3405 - val_false_loss: 16.0866 - val_true_loss: 3.9599\n",
      "Epoch 113/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3102.5268 - reconstruction_loss: 2754.3677 - kl_loss: 61.2236 - false_loss: 18.2742 - true_loss: 4.0071 - val_loss: 3161.2412 - val_reconstruction_loss: 2753.3127 - val_kl_loss: 69.2902 - val_false_loss: 16.1060 - val_true_loss: 3.9523\n",
      "Epoch 114/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.1201 - reconstruction_loss: 2754.2849 - kl_loss: 60.8704 - false_loss: 18.2974 - true_loss: 3.9988 - val_loss: 3160.7363 - val_reconstruction_loss: 2753.3242 - val_kl_loss: 69.2438 - val_false_loss: 16.1261 - val_true_loss: 3.9445\n",
      "Epoch 115/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.3082 - reconstruction_loss: 2754.3008 - kl_loss: 61.2866 - false_loss: 18.3195 - true_loss: 3.9907 - val_loss: 3160.2441 - val_reconstruction_loss: 2753.3342 - val_kl_loss: 69.1999 - val_false_loss: 16.1437 - val_true_loss: 3.9370\n",
      "Epoch 116/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.5733 - reconstruction_loss: 2754.1812 - kl_loss: 61.4648 - false_loss: 18.3397 - true_loss: 3.9827 - val_loss: 3159.7678 - val_reconstruction_loss: 2753.3452 - val_kl_loss: 69.1687 - val_false_loss: 16.1670 - val_true_loss: 3.9292\n",
      "Epoch 117/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.8919 - reconstruction_loss: 2754.2507 - kl_loss: 61.0586 - false_loss: 18.3619 - true_loss: 3.9749 - val_loss: 3159.2830 - val_reconstruction_loss: 2753.3528 - val_kl_loss: 69.1350 - val_false_loss: 16.1881 - val_true_loss: 3.9214\n",
      "Epoch 118/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.1507 - reconstruction_loss: 2754.1184 - kl_loss: 60.9885 - false_loss: 18.3842 - true_loss: 3.9671 - val_loss: 3158.8245 - val_reconstruction_loss: 2753.3652 - val_kl_loss: 69.0837 - val_false_loss: 16.2028 - val_true_loss: 3.9148\n",
      "Epoch 119/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3104.1042 - reconstruction_loss: 2754.1570 - kl_loss: 61.5517 - false_loss: 18.4049 - true_loss: 3.9596 - val_loss: 3158.4143 - val_reconstruction_loss: 2753.3782 - val_kl_loss: 69.0787 - val_false_loss: 16.2232 - val_true_loss: 3.9072\n",
      "Epoch 120/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3103.3348 - reconstruction_loss: 2754.2314 - kl_loss: 61.4856 - false_loss: 18.4244 - true_loss: 3.9523 - val_loss: 3157.9578 - val_reconstruction_loss: 2753.3838 - val_kl_loss: 69.0411 - val_false_loss: 16.2419 - val_true_loss: 3.9001\n",
      "Epoch 121/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.4476 - reconstruction_loss: 2754.1919 - kl_loss: 60.9559 - false_loss: 18.4456 - true_loss: 3.9449 - val_loss: 3157.5081 - val_reconstruction_loss: 2753.3933 - val_kl_loss: 68.9934 - val_false_loss: 16.2568 - val_true_loss: 3.8936\n",
      "Epoch 122/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.4046 - reconstruction_loss: 2754.0952 - kl_loss: 61.0405 - false_loss: 18.4647 - true_loss: 3.9376 - val_loss: 3157.0686 - val_reconstruction_loss: 2753.4028 - val_kl_loss: 68.9674 - val_false_loss: 16.2757 - val_true_loss: 3.8863\n",
      "Epoch 123/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3103.8267 - reconstruction_loss: 2753.9868 - kl_loss: 61.2506 - false_loss: 18.4849 - true_loss: 3.9306 - val_loss: 3156.6301 - val_reconstruction_loss: 2753.4053 - val_kl_loss: 68.9241 - val_false_loss: 16.2907 - val_true_loss: 3.8799\n",
      "Epoch 124/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3098.7304 - reconstruction_loss: 2754.2139 - kl_loss: 61.4775 - false_loss: 18.5036 - true_loss: 3.9235 - val_loss: 3156.2046 - val_reconstruction_loss: 2753.4150 - val_kl_loss: 68.9019 - val_false_loss: 16.3099 - val_true_loss: 3.8728\n",
      "Epoch 125/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3105.5239 - reconstruction_loss: 2753.9878 - kl_loss: 61.3216 - false_loss: 18.5235 - true_loss: 3.9168 - val_loss: 3155.7649 - val_reconstruction_loss: 2753.4041 - val_kl_loss: 68.8476 - val_false_loss: 16.3211 - val_true_loss: 3.8671\n",
      "Epoch 126/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3107.5753 - reconstruction_loss: 2754.3130 - kl_loss: 61.2523 - false_loss: 18.5429 - true_loss: 3.9102 - val_loss: 3155.3577 - val_reconstruction_loss: 2753.4131 - val_kl_loss: 68.8119 - val_false_loss: 16.3352 - val_true_loss: 3.8608\n",
      "Epoch 127/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3099.0063 - reconstruction_loss: 2754.0532 - kl_loss: 61.2421 - false_loss: 18.5593 - true_loss: 3.9034 - val_loss: 3154.9448 - val_reconstruction_loss: 2753.4158 - val_kl_loss: 68.7765 - val_false_loss: 16.3499 - val_true_loss: 3.8546\n",
      "Epoch 128/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3103.0813 - reconstruction_loss: 2754.3613 - kl_loss: 61.1192 - false_loss: 18.5798 - true_loss: 3.8968 - val_loss: 3154.5476 - val_reconstruction_loss: 2753.4248 - val_kl_loss: 68.7445 - val_false_loss: 16.3659 - val_true_loss: 3.8484\n",
      "Epoch 129/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.9157 - reconstruction_loss: 2753.9517 - kl_loss: 61.2356 - false_loss: 18.5964 - true_loss: 3.8903 - val_loss: 3154.1462 - val_reconstruction_loss: 2753.4275 - val_kl_loss: 68.7052 - val_false_loss: 16.3801 - val_true_loss: 3.8425\n",
      "Epoch 130/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.0063 - reconstruction_loss: 2754.3262 - kl_loss: 61.5033 - false_loss: 18.6139 - true_loss: 3.8839 - val_loss: 3153.7668 - val_reconstruction_loss: 2753.4373 - val_kl_loss: 68.6669 - val_false_loss: 16.3939 - val_true_loss: 3.8368\n",
      "Epoch 131/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 3099.9583 - reconstruction_loss: 2754.1401 - kl_loss: 61.1912 - false_loss: 18.6315 - true_loss: 3.8776 - val_loss: 3153.3845 - val_reconstruction_loss: 2753.4470 - val_kl_loss: 68.6213 - val_false_loss: 16.4050 - val_true_loss: 3.8314\n",
      "Epoch 132/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.4817 - reconstruction_loss: 2754.3560 - kl_loss: 61.6513 - false_loss: 18.6483 - true_loss: 3.8714 - val_loss: 3153.0063 - val_reconstruction_loss: 2753.4551 - val_kl_loss: 68.5885 - val_false_loss: 16.4205 - val_true_loss: 3.8256\n",
      "Epoch 133/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.3311 - reconstruction_loss: 2753.9885 - kl_loss: 61.2420 - false_loss: 18.6648 - true_loss: 3.8653 - val_loss: 3152.6484 - val_reconstruction_loss: 2753.4639 - val_kl_loss: 68.5819 - val_false_loss: 16.4400 - val_true_loss: 3.8190\n",
      "Epoch 134/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.8039 - reconstruction_loss: 2754.0251 - kl_loss: 61.0105 - false_loss: 18.6803 - true_loss: 3.8593 - val_loss: 3152.2793 - val_reconstruction_loss: 2753.4651 - val_kl_loss: 68.5746 - val_false_loss: 16.4609 - val_true_loss: 3.8124\n",
      "Epoch 135/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.9259 - reconstruction_loss: 2753.9207 - kl_loss: 61.5316 - false_loss: 18.6968 - true_loss: 3.8535 - val_loss: 3151.9207 - val_reconstruction_loss: 2753.4734 - val_kl_loss: 68.5466 - val_false_loss: 16.4752 - val_true_loss: 3.8067\n",
      "Epoch 136/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3104.8914 - reconstruction_loss: 2754.2261 - kl_loss: 61.2083 - false_loss: 18.7137 - true_loss: 3.8477 - val_loss: 3151.5630 - val_reconstruction_loss: 2753.4807 - val_kl_loss: 68.5123 - val_false_loss: 16.4873 - val_true_loss: 3.8014\n",
      "Epoch 137/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3104.0138 - reconstruction_loss: 2754.1997 - kl_loss: 61.2230 - false_loss: 18.7289 - true_loss: 3.8418 - val_loss: 3151.2119 - val_reconstruction_loss: 2753.4897 - val_kl_loss: 68.4725 - val_false_loss: 16.4980 - val_true_loss: 3.7963\n",
      "Epoch 138/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3097.8745 - reconstruction_loss: 2754.1348 - kl_loss: 61.5089 - false_loss: 18.7447 - true_loss: 3.8359 - val_loss: 3150.8660 - val_reconstruction_loss: 2753.4978 - val_kl_loss: 68.4409 - val_false_loss: 16.5119 - val_true_loss: 3.7910\n",
      "Epoch 139/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3100.2266 - reconstruction_loss: 2754.1870 - kl_loss: 61.2481 - false_loss: 18.7604 - true_loss: 3.8303 - val_loss: 3150.5261 - val_reconstruction_loss: 2753.5032 - val_kl_loss: 68.4260 - val_false_loss: 16.5273 - val_true_loss: 3.7853\n",
      "Epoch 140/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3103.9710 - reconstruction_loss: 2754.8748 - kl_loss: 61.6361 - false_loss: 18.7756 - true_loss: 3.8248 - val_loss: 3150.1956 - val_reconstruction_loss: 2753.5117 - val_kl_loss: 68.4035 - val_false_loss: 16.5415 - val_true_loss: 3.7799\n",
      "Epoch 141/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3101.9736 - reconstruction_loss: 2754.0591 - kl_loss: 61.4294 - false_loss: 18.7901 - true_loss: 3.8193 - val_loss: 3149.8660 - val_reconstruction_loss: 2753.5229 - val_kl_loss: 68.3551 - val_false_loss: 16.5477 - val_true_loss: 3.7756\n",
      "Epoch 142/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3103.0679 - reconstruction_loss: 2754.1741 - kl_loss: 61.5275 - false_loss: 18.8041 - true_loss: 3.8140 - val_loss: 3149.5552 - val_reconstruction_loss: 2753.5332 - val_kl_loss: 68.3228 - val_false_loss: 16.5590 - val_true_loss: 3.7710\n",
      "Epoch 143/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3103.2148 - reconstruction_loss: 2754.1414 - kl_loss: 61.0228 - false_loss: 18.8199 - true_loss: 3.8087 - val_loss: 3149.2285 - val_reconstruction_loss: 2753.5383 - val_kl_loss: 68.2845 - val_false_loss: 16.5698 - val_true_loss: 3.7664\n",
      "Epoch 144/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3102.0674 - reconstruction_loss: 2754.2048 - kl_loss: 61.1174 - false_loss: 18.8346 - true_loss: 3.8035 - val_loss: 3148.9058 - val_reconstruction_loss: 2753.5388 - val_kl_loss: 68.2637 - val_false_loss: 16.5855 - val_true_loss: 3.7611\n",
      "Epoch 145/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3103.4601 - reconstruction_loss: 2753.7498 - kl_loss: 61.0060 - false_loss: 18.8482 - true_loss: 3.7983 - val_loss: 3148.6016 - val_reconstruction_loss: 2753.5447 - val_kl_loss: 68.2621 - val_false_loss: 16.6030 - val_true_loss: 3.7554\n",
      "Epoch 146/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3101.4084 - reconstruction_loss: 2754.1238 - kl_loss: 61.5836 - false_loss: 18.8623 - true_loss: 3.7933 - val_loss: 3148.3132 - val_reconstruction_loss: 2753.5581 - val_kl_loss: 68.2517 - val_false_loss: 16.6181 - val_true_loss: 3.7503\n",
      "Epoch 147/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3107.4463 - reconstruction_loss: 2754.4680 - kl_loss: 61.8529 - false_loss: 18.8764 - true_loss: 3.7885 - val_loss: 3148.0046 - val_reconstruction_loss: 2753.5652 - val_kl_loss: 68.2102 - val_false_loss: 16.6261 - val_true_loss: 3.7461\n",
      "Epoch 148/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3103.5669 - reconstruction_loss: 2754.0950 - kl_loss: 61.0415 - false_loss: 18.8897 - true_loss: 3.7835 - val_loss: 3147.6936 - val_reconstruction_loss: 2753.5676 - val_kl_loss: 68.1737 - val_false_loss: 16.6356 - val_true_loss: 3.7418\n",
      "Epoch 149/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3102.1997 - reconstruction_loss: 2754.6206 - kl_loss: 61.2644 - false_loss: 18.9041 - true_loss: 3.7787 - val_loss: 3147.3992 - val_reconstruction_loss: 2753.5735 - val_kl_loss: 68.1394 - val_false_loss: 16.6440 - val_true_loss: 3.7376\n",
      "Epoch 150/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3105.1343 - reconstruction_loss: 2753.4128 - kl_loss: 60.9736 - false_loss: 18.9184 - true_loss: 3.7740 - val_loss: 3147.1001 - val_reconstruction_loss: 2753.5625 - val_kl_loss: 68.0980 - val_false_loss: 16.6520 - val_true_loss: 3.7340\n",
      "Epoch 151/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3097.3849 - reconstruction_loss: 2748.8699 - kl_loss: 58.9706 - false_loss: 18.9297 - true_loss: 3.7698 - val_loss: 3147.8477 - val_reconstruction_loss: 2753.6519 - val_kl_loss: 68.0878 - val_false_loss: 16.6290 - val_true_loss: 3.7460\n",
      "Epoch 152/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3199.9782 - reconstruction_loss: 2759.1736 - kl_loss: 71.9548 - false_loss: 18.9315 - true_loss: 3.7717 - val_loss: 3147.9189 - val_reconstruction_loss: 2753.6758 - val_kl_loss: 68.0841 - val_false_loss: 16.6141 - val_true_loss: 3.7474\n",
      "Epoch 153/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3145.2497 - reconstruction_loss: 2756.2847 - kl_loss: 70.4574 - false_loss: 18.9220 - true_loss: 3.7711 - val_loss: 3147.9929 - val_reconstruction_loss: 2753.7021 - val_kl_loss: 68.1500 - val_false_loss: 16.6098 - val_true_loss: 3.7462\n",
      "Epoch 154/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3149.3923 - reconstruction_loss: 2756.2124 - kl_loss: 70.8516 - false_loss: 18.9129 - true_loss: 3.7707 - val_loss: 3148.0698 - val_reconstruction_loss: 2753.7261 - val_kl_loss: 68.2280 - val_false_loss: 16.6078 - val_true_loss: 3.7445\n",
      "Epoch 155/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3151.8839 - reconstruction_loss: 2755.8318 - kl_loss: 71.3386 - false_loss: 18.9044 - true_loss: 3.7697 - val_loss: 3148.1128 - val_reconstruction_loss: 2753.7424 - val_kl_loss: 68.2549 - val_false_loss: 16.5975 - val_true_loss: 3.7444\n",
      "Epoch 156/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3147.5334 - reconstruction_loss: 2755.2502 - kl_loss: 70.3961 - false_loss: 18.8953 - true_loss: 3.7689 - val_loss: 3148.1558 - val_reconstruction_loss: 2753.7551 - val_kl_loss: 68.2801 - val_false_loss: 16.5885 - val_true_loss: 3.7444\n",
      "Epoch 157/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 3146.9305 - reconstruction_loss: 2753.7422 - kl_loss: 69.5306 - false_loss: 18.8853 - true_loss: 3.7682 - val_loss: 3148.2476 - val_reconstruction_loss: 2753.7878 - val_kl_loss: 68.3163 - val_false_loss: 16.5852 - val_true_loss: 3.7443\n",
      "Epoch 158/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3153.6984 - reconstruction_loss: 2754.5586 - kl_loss: 70.8311 - false_loss: 18.8783 - true_loss: 3.7678 - val_loss: 3148.6411 - val_reconstruction_loss: 2753.9680 - val_kl_loss: 68.3583 - val_false_loss: 16.5812 - val_true_loss: 3.7466\n",
      "Epoch 159/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3175.9971 - reconstruction_loss: 2759.9197 - kl_loss: 70.6856 - false_loss: 18.8706 - true_loss: 3.7678 - val_loss: 3148.7056 - val_reconstruction_loss: 2753.9922 - val_kl_loss: 68.4176 - val_false_loss: 16.5772 - val_true_loss: 3.7454\n",
      "Epoch 160/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3155.8185 - reconstruction_loss: 2755.3418 - kl_loss: 71.1295 - false_loss: 18.8628 - true_loss: 3.7672 - val_loss: 3148.7427 - val_reconstruction_loss: 2753.9824 - val_kl_loss: 68.4085 - val_false_loss: 16.5624 - val_true_loss: 3.7470\n",
      "Epoch 161/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3153.6812 - reconstruction_loss: 2752.6099 - kl_loss: 69.2188 - false_loss: 18.8564 - true_loss: 3.7672 - val_loss: 3148.7798 - val_reconstruction_loss: 2753.9824 - val_kl_loss: 68.4416 - val_false_loss: 16.5535 - val_true_loss: 3.7468\n",
      "Epoch 162/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3151.5273 - reconstruction_loss: 2756.7058 - kl_loss: 70.2496 - false_loss: 18.8489 - true_loss: 3.7669 - val_loss: 3148.8237 - val_reconstruction_loss: 2753.9980 - val_kl_loss: 68.5022 - val_false_loss: 16.5507 - val_true_loss: 3.7453\n",
      "Epoch 163/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3150.6590 - reconstruction_loss: 2755.8191 - kl_loss: 71.2903 - false_loss: 18.8408 - true_loss: 3.7661 - val_loss: 3148.8804 - val_reconstruction_loss: 2754.0122 - val_kl_loss: 68.5665 - val_false_loss: 16.5486 - val_true_loss: 3.7440\n",
      "Epoch 164/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3153.0596 - reconstruction_loss: 2753.6401 - kl_loss: 70.6815 - false_loss: 18.8339 - true_loss: 3.7655 - val_loss: 3148.8655 - val_reconstruction_loss: 2753.9424 - val_kl_loss: 68.5806 - val_false_loss: 16.5385 - val_true_loss: 3.7447\n",
      "Epoch 165/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3167.9577 - reconstruction_loss: 2755.5820 - kl_loss: 73.8015 - false_loss: 18.8269 - true_loss: 3.7657 - val_loss: 3148.9688 - val_reconstruction_loss: 2753.9617 - val_kl_loss: 68.6173 - val_false_loss: 16.5290 - val_true_loss: 3.7452\n",
      "Epoch 166/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3155.0930 - reconstruction_loss: 2756.1558 - kl_loss: 70.7745 - false_loss: 18.8195 - true_loss: 3.7657 - val_loss: 3149.0203 - val_reconstruction_loss: 2753.9778 - val_kl_loss: 68.6795 - val_false_loss: 16.5267 - val_true_loss: 3.7438\n",
      "Epoch 167/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3152.3773 - reconstruction_loss: 2756.1050 - kl_loss: 69.6918 - false_loss: 18.8113 - true_loss: 3.7651 - val_loss: 3149.1052 - val_reconstruction_loss: 2754.0007 - val_kl_loss: 68.6933 - val_false_loss: 16.5177 - val_true_loss: 3.7447\n",
      "Epoch 168/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3155.4317 - reconstruction_loss: 2756.3423 - kl_loss: 71.9500 - false_loss: 18.8051 - true_loss: 3.7650 - val_loss: 3149.1399 - val_reconstruction_loss: 2754.0190 - val_kl_loss: 68.7245 - val_false_loss: 16.5104 - val_true_loss: 3.7442\n",
      "Epoch 169/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3152.1302 - reconstruction_loss: 2751.2417 - kl_loss: 70.3595 - false_loss: 18.7971 - true_loss: 3.7643 - val_loss: 3149.0496 - val_reconstruction_loss: 2753.8982 - val_kl_loss: 68.7452 - val_false_loss: 16.5034 - val_true_loss: 3.7442\n",
      "Epoch 170/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3118.5055 - reconstruction_loss: 2700.2495 - kl_loss: 67.9831 - false_loss: 18.7918 - true_loss: 3.7642 - val_loss: 3148.6272 - val_reconstruction_loss: 2753.4092 - val_kl_loss: 68.7531 - val_false_loss: 16.4968 - val_true_loss: 3.7453\n",
      "Epoch 171/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3123.2940 - reconstruction_loss: 2745.2795 - kl_loss: 68.7681 - false_loss: 18.7883 - true_loss: 3.7657 - val_loss: 3148.7141 - val_reconstruction_loss: 2753.4395 - val_kl_loss: 68.7796 - val_false_loss: 16.4890 - val_true_loss: 3.7456\n",
      "Epoch 172/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3153.7141 - reconstruction_loss: 2752.4712 - kl_loss: 69.6401 - false_loss: 18.7834 - true_loss: 3.7664 - val_loss: 3148.6646 - val_reconstruction_loss: 2753.3271 - val_kl_loss: 68.8077 - val_false_loss: 16.4853 - val_true_loss: 3.7459\n",
      "Epoch 173/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3106.4368 - reconstruction_loss: 2688.4167 - kl_loss: 68.8642 - false_loss: 18.7791 - true_loss: 3.7666 - val_loss: 3148.6289 - val_reconstruction_loss: 2753.2268 - val_kl_loss: 68.8401 - val_false_loss: 16.4831 - val_true_loss: 3.7459\n",
      "Epoch 174/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3182.4955 - reconstruction_loss: 2760.6899 - kl_loss: 69.2903 - false_loss: 18.7745 - true_loss: 3.7679 - val_loss: 3148.6824 - val_reconstruction_loss: 2753.2441 - val_kl_loss: 68.8644 - val_false_loss: 16.4765 - val_true_loss: 3.7459\n",
      "Epoch 175/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3154.5562 - reconstruction_loss: 2755.4458 - kl_loss: 70.9934 - false_loss: 18.7674 - true_loss: 3.7675 - val_loss: 3148.6943 - val_reconstruction_loss: 2753.2244 - val_kl_loss: 68.8634 - val_false_loss: 16.4649 - val_true_loss: 3.7469\n",
      "Epoch 176/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3159.1605 - reconstruction_loss: 2755.4880 - kl_loss: 70.4816 - false_loss: 18.7611 - true_loss: 3.7671 - val_loss: 3148.7358 - val_reconstruction_loss: 2753.2397 - val_kl_loss: 68.8722 - val_false_loss: 16.4547 - val_true_loss: 3.7474\n",
      "Epoch 177/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3151.0423 - reconstruction_loss: 2746.8372 - kl_loss: 70.4448 - false_loss: 18.7533 - true_loss: 3.7663 - val_loss: 3148.6123 - val_reconstruction_loss: 2753.0686 - val_kl_loss: 68.8670 - val_false_loss: 16.4450 - val_true_loss: 3.7487\n",
      "Epoch 178/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3157.6413 - reconstruction_loss: 2751.7029 - kl_loss: 69.5238 - false_loss: 18.7498 - true_loss: 3.7666 - val_loss: 3148.7683 - val_reconstruction_loss: 2753.1162 - val_kl_loss: 68.8512 - val_false_loss: 16.4421 - val_true_loss: 3.7511\n",
      "Epoch 179/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3160.0675 - reconstruction_loss: 2757.8938 - kl_loss: 69.7490 - false_loss: 18.7450 - true_loss: 3.7670 - val_loss: 3148.8164 - val_reconstruction_loss: 2753.1396 - val_kl_loss: 68.8959 - val_false_loss: 16.4390 - val_true_loss: 3.7501\n",
      "Epoch 180/800\n",
      "40/40 [==============================] - 40s 1000ms/step - loss: 3155.9718 - reconstruction_loss: 2758.9973 - kl_loss: 70.7110 - false_loss: 18.7388 - true_loss: 3.7666 - val_loss: 3148.8948 - val_reconstruction_loss: 2753.1733 - val_kl_loss: 68.8971 - val_false_loss: 16.4312 - val_true_loss: 3.7511\n",
      "Epoch 181/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3157.8905 - reconstruction_loss: 2757.1245 - kl_loss: 71.7716 - false_loss: 18.7328 - true_loss: 3.7659 - val_loss: 3148.9351 - val_reconstruction_loss: 2753.1978 - val_kl_loss: 68.9126 - val_false_loss: 16.4228 - val_true_loss: 3.7511\n",
      "Epoch 182/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3151.9143 - reconstruction_loss: 2756.4871 - kl_loss: 71.5570 - false_loss: 18.7262 - true_loss: 3.7651 - val_loss: 3148.9697 - val_reconstruction_loss: 2753.2209 - val_kl_loss: 68.9395 - val_false_loss: 16.4168 - val_true_loss: 3.7506\n",
      "Epoch 183/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 3151.5081 - reconstruction_loss: 2756.3442 - kl_loss: 70.3950 - false_loss: 18.7201 - true_loss: 3.7643 - val_loss: 3149.0088 - val_reconstruction_loss: 2753.2432 - val_kl_loss: 68.9886 - val_false_loss: 16.4145 - val_true_loss: 3.7493\n",
      "Epoch 184/800\n",
      "40/40 [==============================] - 40s 997ms/step - loss: 3151.2408 - reconstruction_loss: 2756.0679 - kl_loss: 71.2362 - false_loss: 18.7133 - true_loss: 3.7637 - val_loss: 3149.0408 - val_reconstruction_loss: 2753.2622 - val_kl_loss: 69.0016 - val_false_loss: 16.4062 - val_true_loss: 3.7494\n",
      "Epoch 185/800\n",
      "40/40 [==============================] - 40s 999ms/step - loss: 3149.7050 - reconstruction_loss: 2752.0103 - kl_loss: 70.3344 - false_loss: 18.7077 - true_loss: 3.7630 - val_loss: 3148.9812 - val_reconstruction_loss: 2753.1689 - val_kl_loss: 69.0353 - val_false_loss: 16.4027 - val_true_loss: 3.7489\n",
      "Epoch 186/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3117.6828 - reconstruction_loss: 2707.9758 - kl_loss: 69.3527 - false_loss: 18.7012 - true_loss: 3.7628 - val_loss: 3148.8596 - val_reconstruction_loss: 2752.9775 - val_kl_loss: 69.0561 - val_false_loss: 16.3998 - val_true_loss: 3.7495\n",
      "Epoch 187/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3091.5891 - reconstruction_loss: 2683.7961 - kl_loss: 69.4202 - false_loss: 18.6955 - true_loss: 3.7631 - val_loss: 3148.7507 - val_reconstruction_loss: 2752.8225 - val_kl_loss: 69.0592 - val_false_loss: 16.3919 - val_true_loss: 3.7504\n",
      "Epoch 188/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3093.0253 - reconstruction_loss: 2679.8110 - kl_loss: 67.5304 - false_loss: 18.6913 - true_loss: 3.7635 - val_loss: 3148.3789 - val_reconstruction_loss: 2752.3970 - val_kl_loss: 69.0763 - val_false_loss: 16.3882 - val_true_loss: 3.7509\n",
      "Epoch 189/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3075.9838 - reconstruction_loss: 2672.4487 - kl_loss: 69.0034 - false_loss: 18.6860 - true_loss: 3.7641 - val_loss: 3148.0115 - val_reconstruction_loss: 2751.9397 - val_kl_loss: 69.1092 - val_false_loss: 16.3888 - val_true_loss: 3.7513\n",
      "Epoch 190/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3076.9874 - reconstruction_loss: 2663.7278 - kl_loss: 68.4610 - false_loss: 18.6819 - true_loss: 3.7647 - val_loss: 3147.5566 - val_reconstruction_loss: 2751.4331 - val_kl_loss: 69.1032 - val_false_loss: 16.3799 - val_true_loss: 3.7526\n",
      "Epoch 191/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3073.3942 - reconstruction_loss: 2672.9702 - kl_loss: 68.2413 - false_loss: 18.6772 - true_loss: 3.7652 - val_loss: 3147.1499 - val_reconstruction_loss: 2750.9561 - val_kl_loss: 69.1131 - val_false_loss: 16.3772 - val_true_loss: 3.7535\n",
      "Epoch 192/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3060.6517 - reconstruction_loss: 2654.6030 - kl_loss: 69.0310 - false_loss: 18.6727 - true_loss: 3.7659 - val_loss: 3146.6633 - val_reconstruction_loss: 2750.4255 - val_kl_loss: 69.1316 - val_false_loss: 16.3719 - val_true_loss: 3.7538\n",
      "Epoch 193/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3070.5590 - reconstruction_loss: 2666.4570 - kl_loss: 69.1261 - false_loss: 18.6685 - true_loss: 3.7662 - val_loss: 3146.2349 - val_reconstruction_loss: 2749.9233 - val_kl_loss: 69.1344 - val_false_loss: 16.3681 - val_true_loss: 3.7551\n",
      "Epoch 194/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3053.2285 - reconstruction_loss: 2662.8152 - kl_loss: 68.6624 - false_loss: 18.6640 - true_loss: 3.7668 - val_loss: 3145.8491 - val_reconstruction_loss: 2749.4529 - val_kl_loss: 69.1687 - val_false_loss: 16.3681 - val_true_loss: 3.7554\n",
      "Epoch 195/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3071.9364 - reconstruction_loss: 2657.0798 - kl_loss: 67.3701 - false_loss: 18.6589 - true_loss: 3.7675 - val_loss: 3145.3862 - val_reconstruction_loss: 2748.9294 - val_kl_loss: 69.2001 - val_false_loss: 16.3667 - val_true_loss: 3.7554\n",
      "Epoch 196/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3051.6621 - reconstruction_loss: 2648.1311 - kl_loss: 70.1176 - false_loss: 18.6544 - true_loss: 3.7680 - val_loss: 3144.9146 - val_reconstruction_loss: 2748.4158 - val_kl_loss: 69.2392 - val_false_loss: 16.3639 - val_true_loss: 3.7549\n",
      "Epoch 197/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3070.8382 - reconstruction_loss: 2677.7590 - kl_loss: 69.3755 - false_loss: 18.6490 - true_loss: 3.7680 - val_loss: 3144.5298 - val_reconstruction_loss: 2747.9314 - val_kl_loss: 69.2297 - val_false_loss: 16.3593 - val_true_loss: 3.7570\n",
      "Epoch 198/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3065.3453 - reconstruction_loss: 2649.1321 - kl_loss: 68.1458 - false_loss: 18.6450 - true_loss: 3.7690 - val_loss: 3144.0557 - val_reconstruction_loss: 2747.4104 - val_kl_loss: 69.2535 - val_false_loss: 16.3556 - val_true_loss: 3.7571\n",
      "Epoch 199/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3047.8693 - reconstruction_loss: 2646.8569 - kl_loss: 70.3769 - false_loss: 18.6403 - true_loss: 3.7691 - val_loss: 3143.5732 - val_reconstruction_loss: 2746.8850 - val_kl_loss: 69.2999 - val_false_loss: 16.3543 - val_true_loss: 3.7563\n",
      "Epoch 200/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3046.2460 - reconstruction_loss: 2646.4219 - kl_loss: 71.0739 - false_loss: 18.6345 - true_loss: 3.7689 - val_loss: 3143.1038 - val_reconstruction_loss: 2746.3770 - val_kl_loss: 69.3352 - val_false_loss: 16.3507 - val_true_loss: 3.7559\n",
      "Epoch 201/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3041.9344 - reconstruction_loss: 2645.9448 - kl_loss: 71.4379 - false_loss: 18.6291 - true_loss: 3.7686 - val_loss: 3142.6150 - val_reconstruction_loss: 2745.8533 - val_kl_loss: 69.3706 - val_false_loss: 16.3476 - val_true_loss: 3.7554\n",
      "Epoch 202/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3042.8155 - reconstruction_loss: 2656.7832 - kl_loss: 71.1447 - false_loss: 18.6240 - true_loss: 3.7684 - val_loss: 3142.3262 - val_reconstruction_loss: 2745.4976 - val_kl_loss: 69.4021 - val_false_loss: 16.3468 - val_true_loss: 3.7555\n",
      "Epoch 203/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3064.0305 - reconstruction_loss: 2647.9727 - kl_loss: 68.0326 - false_loss: 18.6197 - true_loss: 3.7689 - val_loss: 3141.8616 - val_reconstruction_loss: 2744.9856 - val_kl_loss: 69.4278 - val_false_loss: 16.3444 - val_true_loss: 3.7555\n",
      "Epoch 204/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3048.7949 - reconstruction_loss: 2642.9004 - kl_loss: 71.4775 - false_loss: 18.6163 - true_loss: 3.7693 - val_loss: 3141.3821 - val_reconstruction_loss: 2744.4690 - val_kl_loss: 69.4358 - val_false_loss: 16.3368 - val_true_loss: 3.7561\n",
      "Epoch 205/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3053.5655 - reconstruction_loss: 2673.3289 - kl_loss: 70.5974 - false_loss: 18.6104 - true_loss: 3.7692 - val_loss: 3141.0764 - val_reconstruction_loss: 2744.0884 - val_kl_loss: 69.4436 - val_false_loss: 16.3327 - val_true_loss: 3.7573\n",
      "Epoch 206/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3061.1028 - reconstruction_loss: 2650.0083 - kl_loss: 67.7010 - false_loss: 18.6059 - true_loss: 3.7697 - val_loss: 3140.6184 - val_reconstruction_loss: 2743.5854 - val_kl_loss: 69.4554 - val_false_loss: 16.3279 - val_true_loss: 3.7578\n",
      "Epoch 207/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3044.3373 - reconstruction_loss: 2643.7329 - kl_loss: 70.8146 - false_loss: 18.6022 - true_loss: 3.7701 - val_loss: 3140.1619 - val_reconstruction_loss: 2743.0881 - val_kl_loss: 69.4958 - val_false_loss: 16.3265 - val_true_loss: 3.7571\n",
      "Epoch 208/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3043.3055 - reconstruction_loss: 2641.8398 - kl_loss: 70.7997 - false_loss: 18.5970 - true_loss: 3.7699 - val_loss: 3139.6941 - val_reconstruction_loss: 2742.5830 - val_kl_loss: 69.5436 - val_false_loss: 16.3254 - val_true_loss: 3.7562\n",
      "Epoch 209/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 3037.1282 - reconstruction_loss: 2641.3726 - kl_loss: 71.9576 - false_loss: 18.5915 - true_loss: 3.7696 - val_loss: 3139.2219 - val_reconstruction_loss: 2742.0808 - val_kl_loss: 69.5640 - val_false_loss: 16.3198 - val_true_loss: 3.7562\n",
      "Epoch 210/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3066.9585 - reconstruction_loss: 2664.1560 - kl_loss: 69.7705 - false_loss: 18.5881 - true_loss: 3.7696 - val_loss: 3138.8142 - val_reconstruction_loss: 2741.5879 - val_kl_loss: 69.5848 - val_false_loss: 16.3200 - val_true_loss: 3.7569\n",
      "Epoch 211/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3047.6831 - reconstruction_loss: 2640.8132 - kl_loss: 68.8681 - false_loss: 18.5839 - true_loss: 3.7702 - val_loss: 3138.3574 - val_reconstruction_loss: 2741.0945 - val_kl_loss: 69.6148 - val_false_loss: 16.3172 - val_true_loss: 3.7566\n",
      "Epoch 212/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3042.9614 - reconstruction_loss: 2645.6973 - kl_loss: 71.2498 - false_loss: 18.5801 - true_loss: 3.7701 - val_loss: 3137.9153 - val_reconstruction_loss: 2740.6050 - val_kl_loss: 69.6375 - val_false_loss: 16.3143 - val_true_loss: 3.7568\n",
      "Epoch 213/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3044.1895 - reconstruction_loss: 2639.7866 - kl_loss: 70.0665 - false_loss: 18.5754 - true_loss: 3.7702 - val_loss: 3137.4624 - val_reconstruction_loss: 2740.1160 - val_kl_loss: 69.6763 - val_false_loss: 16.3133 - val_true_loss: 3.7561\n",
      "Epoch 214/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3037.1336 - reconstruction_loss: 2638.6929 - kl_loss: 71.7850 - false_loss: 18.5706 - true_loss: 3.7700 - val_loss: 3137.0020 - val_reconstruction_loss: 2739.6279 - val_kl_loss: 69.7076 - val_false_loss: 16.3094 - val_true_loss: 3.7557\n",
      "Epoch 215/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3038.8956 - reconstruction_loss: 2640.2800 - kl_loss: 71.3895 - false_loss: 18.5662 - true_loss: 3.7696 - val_loss: 3136.5479 - val_reconstruction_loss: 2739.1418 - val_kl_loss: 69.7359 - val_false_loss: 16.3059 - val_true_loss: 3.7554\n",
      "Epoch 216/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3038.5351 - reconstruction_loss: 2637.9475 - kl_loss: 71.9006 - false_loss: 18.5611 - true_loss: 3.7693 - val_loss: 3136.1013 - val_reconstruction_loss: 2738.6687 - val_kl_loss: 69.7628 - val_false_loss: 16.3018 - val_true_loss: 3.7551\n",
      "Epoch 217/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3038.4078 - reconstruction_loss: 2638.6694 - kl_loss: 72.2613 - false_loss: 18.5560 - true_loss: 3.7689 - val_loss: 3135.6477 - val_reconstruction_loss: 2738.1890 - val_kl_loss: 69.7865 - val_false_loss: 16.2973 - val_true_loss: 3.7549\n",
      "Epoch 218/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3052.2057 - reconstruction_loss: 2664.6936 - kl_loss: 70.5566 - false_loss: 18.5519 - true_loss: 3.7687 - val_loss: 3135.2781 - val_reconstruction_loss: 2737.7310 - val_kl_loss: 69.8007 - val_false_loss: 16.2976 - val_true_loss: 3.7558\n",
      "Epoch 219/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3051.8616 - reconstruction_loss: 2639.1831 - kl_loss: 67.9535 - false_loss: 18.5487 - true_loss: 3.7695 - val_loss: 3134.8494 - val_reconstruction_loss: 2737.2612 - val_kl_loss: 69.8152 - val_false_loss: 16.2943 - val_true_loss: 3.7561\n",
      "Epoch 220/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3036.8548 - reconstruction_loss: 2637.1382 - kl_loss: 70.7251 - false_loss: 18.5447 - true_loss: 3.7697 - val_loss: 3134.4087 - val_reconstruction_loss: 2736.7947 - val_kl_loss: 69.8310 - val_false_loss: 16.2892 - val_true_loss: 3.7562\n",
      "Epoch 221/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3039.6971 - reconstruction_loss: 2636.8999 - kl_loss: 71.5719 - false_loss: 18.5410 - true_loss: 3.7695 - val_loss: 3133.9783 - val_reconstruction_loss: 2736.3381 - val_kl_loss: 69.8463 - val_false_loss: 16.2829 - val_true_loss: 3.7564\n",
      "Epoch 222/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3039.6303 - reconstruction_loss: 2637.5271 - kl_loss: 72.1225 - false_loss: 18.5360 - true_loss: 3.7691 - val_loss: 3133.5410 - val_reconstruction_loss: 2735.8767 - val_kl_loss: 69.8769 - val_false_loss: 16.2796 - val_true_loss: 3.7559\n",
      "Epoch 223/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3032.3732 - reconstruction_loss: 2637.4570 - kl_loss: 72.2928 - false_loss: 18.5312 - true_loss: 3.7685 - val_loss: 3133.1152 - val_reconstruction_loss: 2735.4260 - val_kl_loss: 69.9065 - val_false_loss: 16.2767 - val_true_loss: 3.7554\n",
      "Epoch 224/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3036.0237 - reconstruction_loss: 2637.6145 - kl_loss: 72.3274 - false_loss: 18.5266 - true_loss: 3.7682 - val_loss: 3132.6873 - val_reconstruction_loss: 2734.9688 - val_kl_loss: 69.9068 - val_false_loss: 16.2688 - val_true_loss: 3.7561\n",
      "Epoch 225/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3036.9944 - reconstruction_loss: 2636.0444 - kl_loss: 72.2800 - false_loss: 18.5218 - true_loss: 3.7679 - val_loss: 3132.2598 - val_reconstruction_loss: 2734.5159 - val_kl_loss: 69.9394 - val_false_loss: 16.2656 - val_true_loss: 3.7556\n",
      "Epoch 226/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3040.6958 - reconstruction_loss: 2639.0120 - kl_loss: 71.7110 - false_loss: 18.5173 - true_loss: 3.7675 - val_loss: 3131.8350 - val_reconstruction_loss: 2734.0662 - val_kl_loss: 69.9549 - val_false_loss: 16.2612 - val_true_loss: 3.7556\n",
      "Epoch 227/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3043.0337 - reconstruction_loss: 2635.5081 - kl_loss: 71.4174 - false_loss: 18.5129 - true_loss: 3.7674 - val_loss: 3131.4197 - val_reconstruction_loss: 2733.6216 - val_kl_loss: 70.0016 - val_false_loss: 16.2608 - val_true_loss: 3.7546\n",
      "Epoch 228/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3040.0798 - reconstruction_loss: 2636.7754 - kl_loss: 72.6391 - false_loss: 18.5083 - true_loss: 3.7669 - val_loss: 3131.0010 - val_reconstruction_loss: 2733.1799 - val_kl_loss: 70.0332 - val_false_loss: 16.2581 - val_true_loss: 3.7540\n",
      "Epoch 229/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3043.1931 - reconstruction_loss: 2638.8796 - kl_loss: 72.2839 - false_loss: 18.5041 - true_loss: 3.7665 - val_loss: 3130.5911 - val_reconstruction_loss: 2732.7427 - val_kl_loss: 70.0504 - val_false_loss: 16.2539 - val_true_loss: 3.7540\n",
      "Epoch 230/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3032.8951 - reconstruction_loss: 2635.0203 - kl_loss: 71.2255 - false_loss: 18.5006 - true_loss: 3.7661 - val_loss: 3130.1777 - val_reconstruction_loss: 2732.3066 - val_kl_loss: 70.0726 - val_false_loss: 16.2500 - val_true_loss: 3.7538\n",
      "Epoch 231/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3033.5776 - reconstruction_loss: 2635.5542 - kl_loss: 72.4561 - false_loss: 18.4963 - true_loss: 3.7658 - val_loss: 3129.7798 - val_reconstruction_loss: 2731.8792 - val_kl_loss: 70.1056 - val_false_loss: 16.2489 - val_true_loss: 3.7532\n",
      "Epoch 232/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3032.7981 - reconstruction_loss: 2636.6499 - kl_loss: 71.9930 - false_loss: 18.4914 - true_loss: 3.7653 - val_loss: 3129.3733 - val_reconstruction_loss: 2731.4495 - val_kl_loss: 70.1317 - val_false_loss: 16.2459 - val_true_loss: 3.7528\n",
      "Epoch 233/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3038.3601 - reconstruction_loss: 2635.8203 - kl_loss: 72.1439 - false_loss: 18.4870 - true_loss: 3.7650 - val_loss: 3128.9739 - val_reconstruction_loss: 2731.0247 - val_kl_loss: 70.1421 - val_false_loss: 16.2397 - val_true_loss: 3.7531\n",
      "Epoch 234/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3030.4357 - reconstruction_loss: 2634.8625 - kl_loss: 72.3845 - false_loss: 18.4832 - true_loss: 3.7645 - val_loss: 3128.5723 - val_reconstruction_loss: 2730.6025 - val_kl_loss: 70.1654 - val_false_loss: 16.2359 - val_true_loss: 3.7528\n",
      "Epoch 235/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 3036.1243 - reconstruction_loss: 2635.5730 - kl_loss: 72.1801 - false_loss: 18.4787 - true_loss: 3.7642 - val_loss: 3128.1707 - val_reconstruction_loss: 2730.1807 - val_kl_loss: 70.1868 - val_false_loss: 16.2319 - val_true_loss: 3.7525\n",
      "Epoch 236/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3031.2776 - reconstruction_loss: 2638.5325 - kl_loss: 72.1573 - false_loss: 18.4744 - true_loss: 3.7637 - val_loss: 3127.7815 - val_reconstruction_loss: 2729.7668 - val_kl_loss: 70.1921 - val_false_loss: 16.2264 - val_true_loss: 3.7530\n",
      "Epoch 237/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3035.7547 - reconstruction_loss: 2634.2695 - kl_loss: 71.2871 - false_loss: 18.4710 - true_loss: 3.7635 - val_loss: 3127.3904 - val_reconstruction_loss: 2729.3533 - val_kl_loss: 70.2217 - val_false_loss: 16.2240 - val_true_loss: 3.7524\n",
      "Epoch 238/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3031.5444 - reconstruction_loss: 2634.8894 - kl_loss: 71.8425 - false_loss: 18.4668 - true_loss: 3.7632 - val_loss: 3127.0159 - val_reconstruction_loss: 2728.9551 - val_kl_loss: 70.2558 - val_false_loss: 16.2219 - val_true_loss: 3.7518\n",
      "Epoch 239/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3036.6686 - reconstruction_loss: 2634.9016 - kl_loss: 72.8255 - false_loss: 18.4623 - true_loss: 3.7628 - val_loss: 3126.6357 - val_reconstruction_loss: 2728.5559 - val_kl_loss: 70.2745 - val_false_loss: 16.2176 - val_true_loss: 3.7516\n",
      "Epoch 240/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3030.7090 - reconstruction_loss: 2634.7268 - kl_loss: 72.0249 - false_loss: 18.4595 - true_loss: 3.7623 - val_loss: 3126.2561 - val_reconstruction_loss: 2728.1567 - val_kl_loss: 70.3053 - val_false_loss: 16.2155 - val_true_loss: 3.7510\n",
      "Epoch 241/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3039.1906 - reconstruction_loss: 2635.4636 - kl_loss: 71.9868 - false_loss: 18.4552 - true_loss: 3.7620 - val_loss: 3125.8730 - val_reconstruction_loss: 2727.7539 - val_kl_loss: 70.3305 - val_false_loss: 16.2130 - val_true_loss: 3.7505\n",
      "Epoch 242/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3034.3732 - reconstruction_loss: 2637.9971 - kl_loss: 72.1598 - false_loss: 18.4514 - true_loss: 3.7616 - val_loss: 3125.5000 - val_reconstruction_loss: 2727.3567 - val_kl_loss: 70.3350 - val_false_loss: 16.2075 - val_true_loss: 3.7510\n",
      "Epoch 243/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3032.3618 - reconstruction_loss: 2633.6921 - kl_loss: 71.5542 - false_loss: 18.4471 - true_loss: 3.7613 - val_loss: 3125.1208 - val_reconstruction_loss: 2726.9600 - val_kl_loss: 70.3493 - val_false_loss: 16.2030 - val_true_loss: 3.7509\n",
      "Epoch 244/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3029.2888 - reconstruction_loss: 2633.9390 - kl_loss: 71.6072 - false_loss: 18.4436 - true_loss: 3.7610 - val_loss: 3124.7620 - val_reconstruction_loss: 2726.5840 - val_kl_loss: 70.3697 - val_false_loss: 16.1992 - val_true_loss: 3.7507\n",
      "Epoch 245/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3038.4602 - reconstruction_loss: 2634.3660 - kl_loss: 72.6698 - false_loss: 18.4399 - true_loss: 3.7606 - val_loss: 3124.3904 - val_reconstruction_loss: 2726.1956 - val_kl_loss: 70.3959 - val_false_loss: 16.1968 - val_true_loss: 3.7502\n",
      "Epoch 246/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3035.2940 - reconstruction_loss: 2637.9473 - kl_loss: 71.5270 - false_loss: 18.4366 - true_loss: 3.7603 - val_loss: 3124.0322 - val_reconstruction_loss: 2725.8145 - val_kl_loss: 70.4212 - val_false_loss: 16.1952 - val_true_loss: 3.7497\n",
      "Epoch 247/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3038.9588 - reconstruction_loss: 2633.3071 - kl_loss: 71.5377 - false_loss: 18.4331 - true_loss: 3.7601 - val_loss: 3123.6646 - val_reconstruction_loss: 2725.4287 - val_kl_loss: 70.4460 - val_false_loss: 16.1928 - val_true_loss: 3.7493\n",
      "Epoch 248/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3033.0101 - reconstruction_loss: 2633.9990 - kl_loss: 71.8948 - false_loss: 18.4292 - true_loss: 3.7597 - val_loss: 3123.3201 - val_reconstruction_loss: 2725.0635 - val_kl_loss: 70.4532 - val_false_loss: 16.1879 - val_true_loss: 3.7496\n",
      "Epoch 249/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3031.7252 - reconstruction_loss: 2633.6938 - kl_loss: 71.4437 - false_loss: 18.4264 - true_loss: 3.7594 - val_loss: 3122.9551 - val_reconstruction_loss: 2724.6843 - val_kl_loss: 70.4673 - val_false_loss: 16.1835 - val_true_loss: 3.7495\n",
      "Epoch 250/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3035.9868 - reconstruction_loss: 2634.8506 - kl_loss: 71.7466 - false_loss: 18.4227 - true_loss: 3.7591 - val_loss: 3122.6121 - val_reconstruction_loss: 2724.3198 - val_kl_loss: 70.4929 - val_false_loss: 16.1819 - val_true_loss: 3.7490\n",
      "Epoch 251/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3033.8177 - reconstruction_loss: 2633.2637 - kl_loss: 71.0891 - false_loss: 18.4194 - true_loss: 3.7586 - val_loss: 3122.2258 - val_reconstruction_loss: 2723.9446 - val_kl_loss: 70.4967 - val_false_loss: 16.1804 - val_true_loss: 3.7488\n",
      "Epoch 252/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 3037.7529 - reconstruction_loss: 2637.7952 - kl_loss: 70.4736 - false_loss: 18.4165 - true_loss: 3.7585 - val_loss: 3121.8564 - val_reconstruction_loss: 2723.5735 - val_kl_loss: 70.4839 - val_false_loss: 16.1765 - val_true_loss: 3.7494\n",
      "Epoch 253/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3035.0135 - reconstruction_loss: 2632.8367 - kl_loss: 68.9924 - false_loss: 18.4138 - true_loss: 3.7584 - val_loss: 3121.4634 - val_reconstruction_loss: 2723.2053 - val_kl_loss: 70.4881 - val_false_loss: 16.1761 - val_true_loss: 3.7488\n",
      "Epoch 254/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3025.8370 - reconstruction_loss: 2633.9229 - kl_loss: 69.0821 - false_loss: 18.4121 - true_loss: 3.7580 - val_loss: 3121.0793 - val_reconstruction_loss: 2722.8433 - val_kl_loss: 70.4992 - val_false_loss: 16.1796 - val_true_loss: 3.7480\n",
      "Epoch 255/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3024.8190 - reconstruction_loss: 2639.9126 - kl_loss: 68.0572 - false_loss: 18.4106 - true_loss: 3.7577 - val_loss: 3120.6809 - val_reconstruction_loss: 2722.4880 - val_kl_loss: 70.4960 - val_false_loss: 16.1820 - val_true_loss: 3.7473\n",
      "Epoch 256/800\n",
      "40/40 [==============================] - 40s 997ms/step - loss: 3022.3610 - reconstruction_loss: 2633.2334 - kl_loss: 67.1191 - false_loss: 18.4097 - true_loss: 3.7573 - val_loss: 3120.2671 - val_reconstruction_loss: 2722.1299 - val_kl_loss: 70.5021 - val_false_loss: 16.1864 - val_true_loss: 3.7460\n",
      "Epoch 257/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3015.7185 - reconstruction_loss: 2634.4204 - kl_loss: 67.3452 - false_loss: 18.4096 - true_loss: 3.7565 - val_loss: 3119.8438 - val_reconstruction_loss: 2721.7842 - val_kl_loss: 70.4893 - val_false_loss: 16.1905 - val_true_loss: 3.7450\n",
      "Epoch 258/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3008.3476 - reconstruction_loss: 2637.3354 - kl_loss: 62.1107 - false_loss: 18.4109 - true_loss: 3.7555 - val_loss: 3119.3643 - val_reconstruction_loss: 2721.4421 - val_kl_loss: 70.4596 - val_false_loss: 16.1994 - val_true_loss: 3.7434\n",
      "Epoch 259/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2998.9312 - reconstruction_loss: 2634.9624 - kl_loss: 60.0720 - false_loss: 18.4194 - true_loss: 3.7541 - val_loss: 3118.8635 - val_reconstruction_loss: 2721.1021 - val_kl_loss: 70.4287 - val_false_loss: 16.2102 - val_true_loss: 3.7414\n",
      "Epoch 260/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2990.3524 - reconstruction_loss: 2633.4683 - kl_loss: 60.1534 - false_loss: 18.4294 - true_loss: 3.7521 - val_loss: 3118.3428 - val_reconstruction_loss: 2720.7581 - val_kl_loss: 70.3920 - val_false_loss: 16.2195 - val_true_loss: 3.7394\n",
      "Epoch 261/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 2991.4777 - reconstruction_loss: 2636.2532 - kl_loss: 59.2815 - false_loss: 18.4395 - true_loss: 3.7499 - val_loss: 3117.8162 - val_reconstruction_loss: 2720.4097 - val_kl_loss: 70.3617 - val_false_loss: 16.2311 - val_true_loss: 3.7370\n",
      "Epoch 262/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2983.1937 - reconstruction_loss: 2638.3606 - kl_loss: 59.8011 - false_loss: 18.4493 - true_loss: 3.7476 - val_loss: 3117.3054 - val_reconstruction_loss: 2720.0728 - val_kl_loss: 70.3346 - val_false_loss: 16.2459 - val_true_loss: 3.7345\n",
      "Epoch 263/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2990.6356 - reconstruction_loss: 2633.1128 - kl_loss: 59.0970 - false_loss: 18.4606 - true_loss: 3.7455 - val_loss: 3116.7722 - val_reconstruction_loss: 2719.7249 - val_kl_loss: 70.3064 - val_false_loss: 16.2601 - val_true_loss: 3.7319\n",
      "Epoch 264/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2982.0046 - reconstruction_loss: 2630.9250 - kl_loss: 59.9337 - false_loss: 18.4719 - true_loss: 3.7432 - val_loss: 3116.2349 - val_reconstruction_loss: 2719.3826 - val_kl_loss: 70.2723 - val_false_loss: 16.2717 - val_true_loss: 3.7294\n",
      "Epoch 265/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2985.0089 - reconstruction_loss: 2634.0090 - kl_loss: 59.4768 - false_loss: 18.4823 - true_loss: 3.7407 - val_loss: 3115.7017 - val_reconstruction_loss: 2719.0403 - val_kl_loss: 70.2402 - val_false_loss: 16.2842 - val_true_loss: 3.7269\n",
      "Epoch 266/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2978.1984 - reconstruction_loss: 2630.3469 - kl_loss: 59.9446 - false_loss: 18.4943 - true_loss: 3.7383 - val_loss: 3115.1887 - val_reconstruction_loss: 2718.7168 - val_kl_loss: 70.2090 - val_false_loss: 16.2964 - val_true_loss: 3.7244\n",
      "Epoch 267/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2986.1898 - reconstruction_loss: 2634.3093 - kl_loss: 59.5335 - false_loss: 18.5049 - true_loss: 3.7359 - val_loss: 3114.6536 - val_reconstruction_loss: 2718.3755 - val_kl_loss: 70.1698 - val_false_loss: 16.3068 - val_true_loss: 3.7221\n",
      "Epoch 268/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2978.0087 - reconstruction_loss: 2630.2473 - kl_loss: 60.0827 - false_loss: 18.5159 - true_loss: 3.7335 - val_loss: 3114.1426 - val_reconstruction_loss: 2718.0625 - val_kl_loss: 70.1400 - val_false_loss: 16.3195 - val_true_loss: 3.7194\n",
      "Epoch 269/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2979.5855 - reconstruction_loss: 2631.5532 - kl_loss: 59.7493 - false_loss: 18.5269 - true_loss: 3.7310 - val_loss: 3113.6079 - val_reconstruction_loss: 2717.7227 - val_kl_loss: 70.1187 - val_false_loss: 16.3346 - val_true_loss: 3.7163\n",
      "Epoch 270/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2978.3536 - reconstruction_loss: 2633.5315 - kl_loss: 59.9047 - false_loss: 18.5373 - true_loss: 3.7285 - val_loss: 3113.0903 - val_reconstruction_loss: 2717.3955 - val_kl_loss: 70.0835 - val_false_loss: 16.3460 - val_true_loss: 3.7139\n",
      "Epoch 271/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2973.8681 - reconstruction_loss: 2629.8547 - kl_loss: 59.5837 - false_loss: 18.5490 - true_loss: 3.7261 - val_loss: 3112.5688 - val_reconstruction_loss: 2717.0613 - val_kl_loss: 70.0460 - val_false_loss: 16.3554 - val_true_loss: 3.7117\n",
      "Epoch 272/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2980.0719 - reconstruction_loss: 2633.6633 - kl_loss: 59.6367 - false_loss: 18.5594 - true_loss: 3.7237 - val_loss: 3112.0464 - val_reconstruction_loss: 2716.7285 - val_kl_loss: 70.0132 - val_false_loss: 16.3671 - val_true_loss: 3.7093\n",
      "Epoch 273/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2976.7768 - reconstruction_loss: 2629.6257 - kl_loss: 59.9479 - false_loss: 18.5696 - true_loss: 3.7214 - val_loss: 3111.5203 - val_reconstruction_loss: 2716.3975 - val_kl_loss: 69.9732 - val_false_loss: 16.3762 - val_true_loss: 3.7071\n",
      "Epoch 274/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2979.7379 - reconstruction_loss: 2634.1121 - kl_loss: 59.7668 - false_loss: 18.5803 - true_loss: 3.7189 - val_loss: 3111.0071 - val_reconstruction_loss: 2716.0747 - val_kl_loss: 69.9383 - val_false_loss: 16.3878 - val_true_loss: 3.7047\n",
      "Epoch 275/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2982.5802 - reconstruction_loss: 2629.8127 - kl_loss: 59.6309 - false_loss: 18.5914 - true_loss: 3.7166 - val_loss: 3110.4856 - val_reconstruction_loss: 2715.7485 - val_kl_loss: 69.9047 - val_false_loss: 16.3993 - val_true_loss: 3.7022\n",
      "Epoch 276/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2971.9265 - reconstruction_loss: 2630.2585 - kl_loss: 60.0836 - false_loss: 18.6017 - true_loss: 3.7141 - val_loss: 3109.9788 - val_reconstruction_loss: 2715.4370 - val_kl_loss: 69.8799 - val_false_loss: 16.4130 - val_true_loss: 3.6993\n",
      "Epoch 277/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2977.8502 - reconstruction_loss: 2629.7065 - kl_loss: 60.2346 - false_loss: 18.6120 - true_loss: 3.7117 - val_loss: 3109.4941 - val_reconstruction_loss: 2715.1445 - val_kl_loss: 69.8507 - val_false_loss: 16.4247 - val_true_loss: 3.6967\n",
      "Epoch 278/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2991.8656 - reconstruction_loss: 2631.5278 - kl_loss: 58.7501 - false_loss: 18.6219 - true_loss: 3.7096 - val_loss: 3108.9934 - val_reconstruction_loss: 2714.8274 - val_kl_loss: 69.8292 - val_false_loss: 16.4387 - val_true_loss: 3.6938\n",
      "Epoch 279/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2976.8009 - reconstruction_loss: 2632.2793 - kl_loss: 60.3672 - false_loss: 18.6313 - true_loss: 3.7074 - val_loss: 3108.4866 - val_reconstruction_loss: 2714.5093 - val_kl_loss: 69.7960 - val_false_loss: 16.4494 - val_true_loss: 3.6915\n",
      "Epoch 280/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2976.9387 - reconstruction_loss: 2629.8716 - kl_loss: 59.7757 - false_loss: 18.6420 - true_loss: 3.7050 - val_loss: 3107.9836 - val_reconstruction_loss: 2714.1921 - val_kl_loss: 69.7764 - val_false_loss: 16.4640 - val_true_loss: 3.6885\n",
      "Epoch 281/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2975.5577 - reconstruction_loss: 2629.6384 - kl_loss: 60.1289 - false_loss: 18.6522 - true_loss: 3.7027 - val_loss: 3107.4795 - val_reconstruction_loss: 2713.8767 - val_kl_loss: 69.7499 - val_false_loss: 16.4763 - val_true_loss: 3.6858\n",
      "Epoch 282/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2974.9694 - reconstruction_loss: 2630.2288 - kl_loss: 60.2189 - false_loss: 18.6624 - true_loss: 3.7003 - val_loss: 3106.9961 - val_reconstruction_loss: 2713.5679 - val_kl_loss: 69.7151 - val_false_loss: 16.4858 - val_true_loss: 3.6838\n",
      "Epoch 283/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2976.1123 - reconstruction_loss: 2633.6887 - kl_loss: 59.6146 - false_loss: 18.6713 - true_loss: 3.6980 - val_loss: 3106.5120 - val_reconstruction_loss: 2713.2622 - val_kl_loss: 69.6848 - val_false_loss: 16.4967 - val_true_loss: 3.6814\n",
      "Epoch 284/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2976.1017 - reconstruction_loss: 2629.0879 - kl_loss: 59.7973 - false_loss: 18.6816 - true_loss: 3.6958 - val_loss: 3106.0229 - val_reconstruction_loss: 2712.9539 - val_kl_loss: 69.6557 - val_false_loss: 16.5077 - val_true_loss: 3.6790\n",
      "Epoch 285/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2978.6491 - reconstruction_loss: 2629.3989 - kl_loss: 59.6657 - false_loss: 18.6917 - true_loss: 3.6935 - val_loss: 3105.5615 - val_reconstruction_loss: 2712.6680 - val_kl_loss: 69.6303 - val_false_loss: 16.5195 - val_true_loss: 3.6766\n",
      "Epoch 286/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.2998 - reconstruction_loss: 2630.1733 - kl_loss: 59.9939 - false_loss: 18.7008 - true_loss: 3.6913 - val_loss: 3105.0781 - val_reconstruction_loss: 2712.3633 - val_kl_loss: 69.6046 - val_false_loss: 16.5318 - val_true_loss: 3.6740\n",
      "Epoch 287/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 2976.3494 - reconstruction_loss: 2630.9175 - kl_loss: 60.2036 - false_loss: 18.7110 - true_loss: 3.6890 - val_loss: 3104.5979 - val_reconstruction_loss: 2712.0608 - val_kl_loss: 69.5778 - val_false_loss: 16.5430 - val_true_loss: 3.6716\n",
      "Epoch 288/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2974.2015 - reconstruction_loss: 2628.7241 - kl_loss: 59.9281 - false_loss: 18.7204 - true_loss: 3.6867 - val_loss: 3104.1223 - val_reconstruction_loss: 2711.7656 - val_kl_loss: 69.5506 - val_false_loss: 16.5542 - val_true_loss: 3.6691\n",
      "Epoch 289/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2975.0571 - reconstruction_loss: 2631.7612 - kl_loss: 60.3931 - false_loss: 18.7299 - true_loss: 3.6844 - val_loss: 3103.6511 - val_reconstruction_loss: 2711.4724 - val_kl_loss: 69.5206 - val_false_loss: 16.5644 - val_true_loss: 3.6668\n",
      "Epoch 290/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2976.1063 - reconstruction_loss: 2630.0847 - kl_loss: 59.4178 - false_loss: 18.7396 - true_loss: 3.6821 - val_loss: 3103.1812 - val_reconstruction_loss: 2711.1780 - val_kl_loss: 69.5020 - val_false_loss: 16.5780 - val_true_loss: 3.6641\n",
      "Epoch 291/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2972.2680 - reconstruction_loss: 2628.3247 - kl_loss: 60.0630 - false_loss: 18.7487 - true_loss: 3.6799 - val_loss: 3102.7131 - val_reconstruction_loss: 2710.8826 - val_kl_loss: 69.4804 - val_false_loss: 16.5897 - val_true_loss: 3.6615\n",
      "Epoch 292/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2976.5647 - reconstruction_loss: 2630.4917 - kl_loss: 60.2860 - false_loss: 18.7586 - true_loss: 3.6776 - val_loss: 3102.2461 - val_reconstruction_loss: 2710.5894 - val_kl_loss: 69.4545 - val_false_loss: 16.6006 - val_true_loss: 3.6591\n",
      "Epoch 293/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2974.3705 - reconstruction_loss: 2628.4343 - kl_loss: 60.0553 - false_loss: 18.7678 - true_loss: 3.6754 - val_loss: 3101.7793 - val_reconstruction_loss: 2710.2981 - val_kl_loss: 69.4358 - val_false_loss: 16.6134 - val_true_loss: 3.6564\n",
      "Epoch 294/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2980.4212 - reconstruction_loss: 2634.3845 - kl_loss: 59.7815 - false_loss: 18.7768 - true_loss: 3.6731 - val_loss: 3101.3206 - val_reconstruction_loss: 2710.0110 - val_kl_loss: 69.4088 - val_false_loss: 16.6245 - val_true_loss: 3.6540\n",
      "Epoch 295/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.7727 - reconstruction_loss: 2628.1252 - kl_loss: 60.2031 - false_loss: 18.7864 - true_loss: 3.6709 - val_loss: 3100.8601 - val_reconstruction_loss: 2709.7227 - val_kl_loss: 69.3834 - val_false_loss: 16.6357 - val_true_loss: 3.6517\n",
      "Epoch 296/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.1508 - reconstruction_loss: 2628.2651 - kl_loss: 60.4355 - false_loss: 18.7951 - true_loss: 3.6687 - val_loss: 3100.4116 - val_reconstruction_loss: 2709.4463 - val_kl_loss: 69.3627 - val_false_loss: 16.6480 - val_true_loss: 3.6491\n",
      "Epoch 297/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2973.6528 - reconstruction_loss: 2629.5632 - kl_loss: 60.2274 - false_loss: 18.8051 - true_loss: 3.6665 - val_loss: 3099.9573 - val_reconstruction_loss: 2709.1633 - val_kl_loss: 69.3377 - val_false_loss: 16.6588 - val_true_loss: 3.6467\n",
      "Epoch 298/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2968.0836 - reconstruction_loss: 2628.3171 - kl_loss: 60.3781 - false_loss: 18.8139 - true_loss: 3.6642 - val_loss: 3099.5613 - val_reconstruction_loss: 2708.9355 - val_kl_loss: 69.3095 - val_false_loss: 16.6678 - val_true_loss: 3.6445\n",
      "Epoch 299/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2983.3719 - reconstruction_loss: 2632.2104 - kl_loss: 59.7514 - false_loss: 18.8230 - true_loss: 3.6621 - val_loss: 3099.1147 - val_reconstruction_loss: 2708.6548 - val_kl_loss: 69.2869 - val_false_loss: 16.6794 - val_true_loss: 3.6421\n",
      "Epoch 300/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2972.9507 - reconstruction_loss: 2627.9609 - kl_loss: 60.1757 - false_loss: 18.8321 - true_loss: 3.6599 - val_loss: 3098.6692 - val_reconstruction_loss: 2708.3774 - val_kl_loss: 69.2644 - val_false_loss: 16.6904 - val_true_loss: 3.6397\n",
      "Epoch 301/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2973.1015 - reconstruction_loss: 2629.1736 - kl_loss: 60.1280 - false_loss: 18.8410 - true_loss: 3.6578 - val_loss: 3098.2271 - val_reconstruction_loss: 2708.1003 - val_kl_loss: 69.2430 - val_false_loss: 16.7018 - val_true_loss: 3.6373\n",
      "Epoch 302/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2973.1775 - reconstruction_loss: 2630.9780 - kl_loss: 60.3877 - false_loss: 18.8497 - true_loss: 3.6557 - val_loss: 3097.8323 - val_reconstruction_loss: 2707.8660 - val_kl_loss: 69.2208 - val_false_loss: 16.7130 - val_true_loss: 3.6350\n",
      "Epoch 303/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2978.7613 - reconstruction_loss: 2629.1489 - kl_loss: 59.2641 - false_loss: 18.8581 - true_loss: 3.6538 - val_loss: 3097.4036 - val_reconstruction_loss: 2707.5945 - val_kl_loss: 69.2021 - val_false_loss: 16.7250 - val_true_loss: 3.6326\n",
      "Epoch 304/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2972.5258 - reconstruction_loss: 2628.3157 - kl_loss: 60.2158 - false_loss: 18.8666 - true_loss: 3.6519 - val_loss: 3096.9773 - val_reconstruction_loss: 2707.3250 - val_kl_loss: 69.1739 - val_false_loss: 16.7337 - val_true_loss: 3.6306\n",
      "Epoch 305/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2978.0183 - reconstruction_loss: 2629.6450 - kl_loss: 60.1245 - false_loss: 18.8753 - true_loss: 3.6499 - val_loss: 3096.5520 - val_reconstruction_loss: 2707.0576 - val_kl_loss: 69.1470 - val_false_loss: 16.7423 - val_true_loss: 3.6286\n",
      "Epoch 306/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.9107 - reconstruction_loss: 2628.1091 - kl_loss: 59.9320 - false_loss: 18.8839 - true_loss: 3.6479 - val_loss: 3096.1304 - val_reconstruction_loss: 2706.7905 - val_kl_loss: 69.1244 - val_false_loss: 16.7521 - val_true_loss: 3.6265\n",
      "Epoch 307/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2976.1835 - reconstruction_loss: 2629.8301 - kl_loss: 60.3497 - false_loss: 18.8925 - true_loss: 3.6459 - val_loss: 3095.7083 - val_reconstruction_loss: 2706.5256 - val_kl_loss: 69.1033 - val_false_loss: 16.7628 - val_true_loss: 3.6242\n",
      "Epoch 308/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.1571 - reconstruction_loss: 2627.8921 - kl_loss: 60.1663 - false_loss: 18.9003 - true_loss: 3.6438 - val_loss: 3095.2849 - val_reconstruction_loss: 2706.2605 - val_kl_loss: 69.0867 - val_false_loss: 16.7747 - val_true_loss: 3.6217\n",
      "Epoch 309/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2973.8191 - reconstruction_loss: 2629.6001 - kl_loss: 60.1548 - false_loss: 18.9092 - true_loss: 3.6417 - val_loss: 3094.8611 - val_reconstruction_loss: 2705.9958 - val_kl_loss: 69.0675 - val_false_loss: 16.7859 - val_true_loss: 3.6193\n",
      "Epoch 310/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2973.3037 - reconstruction_loss: 2627.8398 - kl_loss: 60.2133 - false_loss: 18.9176 - true_loss: 3.6397 - val_loss: 3094.4387 - val_reconstruction_loss: 2705.7332 - val_kl_loss: 69.0427 - val_false_loss: 16.7952 - val_true_loss: 3.6172\n",
      "Epoch 311/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2974.3761 - reconstruction_loss: 2631.1653 - kl_loss: 59.8673 - false_loss: 18.9254 - true_loss: 3.6376 - val_loss: 3094.0222 - val_reconstruction_loss: 2705.4727 - val_kl_loss: 69.0171 - val_false_loss: 16.8043 - val_true_loss: 3.6151\n",
      "Epoch 312/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.1329 - reconstruction_loss: 2627.5464 - kl_loss: 60.0796 - false_loss: 18.9334 - true_loss: 3.6356 - val_loss: 3093.6055 - val_reconstruction_loss: 2705.2126 - val_kl_loss: 68.9966 - val_false_loss: 16.8149 - val_true_loss: 3.6128\n",
      "Epoch 313/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 2972.3418 - reconstruction_loss: 2631.0225 - kl_loss: 60.3904 - false_loss: 18.9415 - true_loss: 3.6336 - val_loss: 3093.2156 - val_reconstruction_loss: 2704.9741 - val_kl_loss: 68.9665 - val_false_loss: 16.8230 - val_true_loss: 3.6110\n",
      "Epoch 314/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2977.1326 - reconstruction_loss: 2628.2717 - kl_loss: 59.3653 - false_loss: 18.9497 - true_loss: 3.6318 - val_loss: 3092.8032 - val_reconstruction_loss: 2704.7180 - val_kl_loss: 68.9446 - val_false_loss: 16.8333 - val_true_loss: 3.6088\n",
      "Epoch 315/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2970.9830 - reconstruction_loss: 2627.7981 - kl_loss: 60.0368 - false_loss: 18.9580 - true_loss: 3.6298 - val_loss: 3092.3965 - val_reconstruction_loss: 2704.4680 - val_kl_loss: 68.9210 - val_false_loss: 16.8428 - val_true_loss: 3.6067\n",
      "Epoch 316/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.6643 - reconstruction_loss: 2628.9297 - kl_loss: 60.0781 - false_loss: 18.9655 - true_loss: 3.6277 - val_loss: 3091.9868 - val_reconstruction_loss: 2704.2148 - val_kl_loss: 68.8994 - val_false_loss: 16.8531 - val_true_loss: 3.6045\n",
      "Epoch 317/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.0955 - reconstruction_loss: 2629.1050 - kl_loss: 60.1792 - false_loss: 18.9731 - true_loss: 3.6257 - val_loss: 3091.5811 - val_reconstruction_loss: 2703.9648 - val_kl_loss: 68.8739 - val_false_loss: 16.8619 - val_true_loss: 3.6024\n",
      "Epoch 318/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2973.8993 - reconstruction_loss: 2628.1311 - kl_loss: 59.8379 - false_loss: 18.9816 - true_loss: 3.6237 - val_loss: 3091.1790 - val_reconstruction_loss: 2703.7173 - val_kl_loss: 68.8500 - val_false_loss: 16.8712 - val_true_loss: 3.6003\n",
      "Epoch 319/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2974.2125 - reconstruction_loss: 2631.7585 - kl_loss: 59.4871 - false_loss: 18.9886 - true_loss: 3.6219 - val_loss: 3090.7888 - val_reconstruction_loss: 2703.4756 - val_kl_loss: 68.8283 - val_false_loss: 16.8820 - val_true_loss: 3.5982\n",
      "Epoch 320/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2977.3285 - reconstruction_loss: 2628.2603 - kl_loss: 59.5707 - false_loss: 18.9967 - true_loss: 3.6201 - val_loss: 3090.4080 - val_reconstruction_loss: 2703.2339 - val_kl_loss: 68.8019 - val_false_loss: 16.8897 - val_true_loss: 3.5965\n",
      "Epoch 321/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2973.4259 - reconstruction_loss: 2628.5747 - kl_loss: 59.6883 - false_loss: 19.0040 - true_loss: 3.6185 - val_loss: 3090.0171 - val_reconstruction_loss: 2702.9893 - val_kl_loss: 68.7834 - val_false_loss: 16.8998 - val_true_loss: 3.5944\n",
      "Epoch 322/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.0220 - reconstruction_loss: 2630.9644 - kl_loss: 60.3628 - false_loss: 19.0112 - true_loss: 3.6166 - val_loss: 3089.7629 - val_reconstruction_loss: 2702.7712 - val_kl_loss: 68.7628 - val_false_loss: 16.9132 - val_true_loss: 3.5940\n",
      "Epoch 323/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 3000.4911 - reconstruction_loss: 2632.2646 - kl_loss: 58.2385 - false_loss: 19.0185 - true_loss: 3.6154 - val_loss: 3089.3838 - val_reconstruction_loss: 2702.5315 - val_kl_loss: 68.7373 - val_false_loss: 16.9209 - val_true_loss: 3.5923\n",
      "Epoch 324/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2972.2458 - reconstruction_loss: 2627.7297 - kl_loss: 59.9331 - false_loss: 19.0256 - true_loss: 3.6137 - val_loss: 3089.0027 - val_reconstruction_loss: 2702.2908 - val_kl_loss: 68.7120 - val_false_loss: 16.9285 - val_true_loss: 3.5905\n",
      "Epoch 325/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2968.1175 - reconstruction_loss: 2627.8188 - kl_loss: 60.1744 - false_loss: 19.0330 - true_loss: 3.6119 - val_loss: 3088.6218 - val_reconstruction_loss: 2702.0530 - val_kl_loss: 68.6908 - val_false_loss: 16.9371 - val_true_loss: 3.5885\n",
      "Epoch 326/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2974.7894 - reconstruction_loss: 2630.7937 - kl_loss: 59.6330 - false_loss: 19.0401 - true_loss: 3.6101 - val_loss: 3088.2478 - val_reconstruction_loss: 2701.8171 - val_kl_loss: 68.6746 - val_false_loss: 16.9488 - val_true_loss: 3.5864\n",
      "Epoch 327/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.8866 - reconstruction_loss: 2627.3950 - kl_loss: 59.9289 - false_loss: 19.0471 - true_loss: 3.6083 - val_loss: 3087.8762 - val_reconstruction_loss: 2701.5801 - val_kl_loss: 68.6549 - val_false_loss: 16.9570 - val_true_loss: 3.5845\n",
      "Epoch 328/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2973.2898 - reconstruction_loss: 2627.9072 - kl_loss: 60.3877 - false_loss: 19.0548 - true_loss: 3.6066 - val_loss: 3087.5286 - val_reconstruction_loss: 2701.3625 - val_kl_loss: 68.6307 - val_false_loss: 16.9650 - val_true_loss: 3.5829\n",
      "Epoch 329/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2978.8409 - reconstruction_loss: 2629.9771 - kl_loss: 59.5544 - false_loss: 19.0614 - true_loss: 3.6049 - val_loss: 3087.1648 - val_reconstruction_loss: 2701.1289 - val_kl_loss: 68.6032 - val_false_loss: 16.9713 - val_true_loss: 3.5814\n",
      "Epoch 330/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2974.4466 - reconstruction_loss: 2628.0476 - kl_loss: 59.9826 - false_loss: 19.0681 - true_loss: 3.6034 - val_loss: 3086.7952 - val_reconstruction_loss: 2700.8984 - val_kl_loss: 68.5765 - val_false_loss: 16.9775 - val_true_loss: 3.5798\n",
      "Epoch 331/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2975.0909 - reconstruction_loss: 2629.7009 - kl_loss: 59.7556 - false_loss: 19.0755 - true_loss: 3.6016 - val_loss: 3086.4312 - val_reconstruction_loss: 2700.6680 - val_kl_loss: 68.5557 - val_false_loss: 16.9855 - val_true_loss: 3.5780\n",
      "Epoch 332/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.0742 - reconstruction_loss: 2627.8472 - kl_loss: 60.1522 - false_loss: 19.0818 - true_loss: 3.5999 - val_loss: 3086.0647 - val_reconstruction_loss: 2700.4412 - val_kl_loss: 68.5343 - val_false_loss: 16.9936 - val_true_loss: 3.5761\n",
      "Epoch 333/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2970.0591 - reconstruction_loss: 2627.8491 - kl_loss: 60.0731 - false_loss: 19.0891 - true_loss: 3.5981 - val_loss: 3085.7009 - val_reconstruction_loss: 2700.2131 - val_kl_loss: 68.5185 - val_false_loss: 17.0035 - val_true_loss: 3.5741\n",
      "Epoch 334/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2976.3087 - reconstruction_loss: 2628.8916 - kl_loss: 60.3943 - false_loss: 19.0968 - true_loss: 3.5964 - val_loss: 3085.3376 - val_reconstruction_loss: 2699.9856 - val_kl_loss: 68.5005 - val_false_loss: 17.0126 - val_true_loss: 3.5721\n",
      "Epoch 335/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.0066 - reconstruction_loss: 2627.4346 - kl_loss: 60.2392 - false_loss: 19.1038 - true_loss: 3.5946 - val_loss: 3084.9763 - val_reconstruction_loss: 2699.7600 - val_kl_loss: 68.4791 - val_false_loss: 17.0204 - val_true_loss: 3.5703\n",
      "Epoch 336/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2972.5973 - reconstruction_loss: 2628.7358 - kl_loss: 60.0326 - false_loss: 19.1102 - true_loss: 3.5928 - val_loss: 3084.6179 - val_reconstruction_loss: 2699.5339 - val_kl_loss: 68.4633 - val_false_loss: 17.0296 - val_true_loss: 3.5683\n",
      "Epoch 337/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2968.5352 - reconstruction_loss: 2628.6360 - kl_loss: 60.3803 - false_loss: 19.1172 - true_loss: 3.5911 - val_loss: 3084.2803 - val_reconstruction_loss: 2699.3303 - val_kl_loss: 68.4395 - val_false_loss: 17.0367 - val_true_loss: 3.5666\n",
      "Epoch 338/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.1897 - reconstruction_loss: 2627.4758 - kl_loss: 59.7727 - false_loss: 19.1240 - true_loss: 3.5893 - val_loss: 3083.9253 - val_reconstruction_loss: 2699.1074 - val_kl_loss: 68.4256 - val_false_loss: 17.0465 - val_true_loss: 3.5646\n",
      "Epoch 339/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 2973.4509 - reconstruction_loss: 2628.1355 - kl_loss: 60.2417 - false_loss: 19.1312 - true_loss: 3.5876 - val_loss: 3083.5713 - val_reconstruction_loss: 2698.8857 - val_kl_loss: 68.4096 - val_false_loss: 17.0558 - val_true_loss: 3.5626\n",
      "Epoch 340/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2973.4459 - reconstruction_loss: 2627.8494 - kl_loss: 60.0408 - false_loss: 19.1378 - true_loss: 3.5859 - val_loss: 3083.2385 - val_reconstruction_loss: 2698.6677 - val_kl_loss: 68.3884 - val_false_loss: 17.0627 - val_true_loss: 3.5611\n",
      "Epoch 341/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2972.3572 - reconstruction_loss: 2628.9993 - kl_loss: 59.8305 - false_loss: 19.1441 - true_loss: 3.5843 - val_loss: 3082.8918 - val_reconstruction_loss: 2698.4524 - val_kl_loss: 68.3709 - val_false_loss: 17.0718 - val_true_loss: 3.5592\n",
      "Epoch 342/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2969.5016 - reconstruction_loss: 2627.1892 - kl_loss: 59.9811 - false_loss: 19.1503 - true_loss: 3.5826 - val_loss: 3082.5396 - val_reconstruction_loss: 2698.2334 - val_kl_loss: 68.3481 - val_false_loss: 17.0788 - val_true_loss: 3.5575\n",
      "Epoch 343/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.5932 - reconstruction_loss: 2628.0415 - kl_loss: 60.1363 - false_loss: 19.1572 - true_loss: 3.5809 - val_loss: 3082.1917 - val_reconstruction_loss: 2698.0178 - val_kl_loss: 68.3288 - val_false_loss: 17.0873 - val_true_loss: 3.5557\n",
      "Epoch 344/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2973.4488 - reconstruction_loss: 2629.2808 - kl_loss: 60.2594 - false_loss: 19.1638 - true_loss: 3.5792 - val_loss: 3081.8682 - val_reconstruction_loss: 2697.8113 - val_kl_loss: 68.3005 - val_false_loss: 17.0935 - val_true_loss: 3.5545\n",
      "Epoch 345/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2976.7798 - reconstruction_loss: 2629.5498 - kl_loss: 59.1337 - false_loss: 19.1702 - true_loss: 3.5776 - val_loss: 3081.5322 - val_reconstruction_loss: 2697.5974 - val_kl_loss: 68.2776 - val_false_loss: 17.1005 - val_true_loss: 3.5530\n",
      "Epoch 346/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2971.6484 - reconstruction_loss: 2627.2400 - kl_loss: 59.9750 - false_loss: 19.1768 - true_loss: 3.5761 - val_loss: 3081.1914 - val_reconstruction_loss: 2697.3855 - val_kl_loss: 68.2639 - val_false_loss: 17.1107 - val_true_loss: 3.5510\n",
      "Epoch 347/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.0416 - reconstruction_loss: 2628.1523 - kl_loss: 60.2095 - false_loss: 19.1831 - true_loss: 3.5744 - val_loss: 3080.8494 - val_reconstruction_loss: 2697.1731 - val_kl_loss: 68.2450 - val_false_loss: 17.1190 - val_true_loss: 3.5491\n",
      "Epoch 348/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2974.2871 - reconstruction_loss: 2628.9080 - kl_loss: 59.5705 - false_loss: 19.1903 - true_loss: 3.5728 - val_loss: 3080.5234 - val_reconstruction_loss: 2696.9666 - val_kl_loss: 68.2249 - val_false_loss: 17.1268 - val_true_loss: 3.5476\n",
      "Epoch 349/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.1849 - reconstruction_loss: 2627.5249 - kl_loss: 60.3731 - false_loss: 19.1961 - true_loss: 3.5713 - val_loss: 3080.1917 - val_reconstruction_loss: 2696.7617 - val_kl_loss: 68.2006 - val_false_loss: 17.1330 - val_true_loss: 3.5460\n",
      "Epoch 350/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.8877 - reconstruction_loss: 2628.5835 - kl_loss: 59.7092 - false_loss: 19.2026 - true_loss: 3.5697 - val_loss: 3079.8555 - val_reconstruction_loss: 2696.5537 - val_kl_loss: 68.1798 - val_false_loss: 17.1406 - val_true_loss: 3.5443\n",
      "Epoch 351/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2969.5521 - reconstruction_loss: 2627.4961 - kl_loss: 59.8787 - false_loss: 19.2095 - true_loss: 3.5681 - val_loss: 3079.5481 - val_reconstruction_loss: 2696.3726 - val_kl_loss: 68.1639 - val_false_loss: 17.1493 - val_true_loss: 3.5425\n",
      "Epoch 352/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.5663 - reconstruction_loss: 2628.1726 - kl_loss: 60.1593 - false_loss: 19.2152 - true_loss: 3.5664 - val_loss: 3079.2124 - val_reconstruction_loss: 2696.1655 - val_kl_loss: 68.1448 - val_false_loss: 17.1574 - val_true_loss: 3.5407\n",
      "Epoch 353/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2972.6927 - reconstruction_loss: 2631.5645 - kl_loss: 59.6046 - false_loss: 19.2215 - true_loss: 3.5648 - val_loss: 3078.8882 - val_reconstruction_loss: 2695.9648 - val_kl_loss: 68.1175 - val_false_loss: 17.1631 - val_true_loss: 3.5394\n",
      "Epoch 354/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.4775 - reconstruction_loss: 2627.1257 - kl_loss: 59.6797 - false_loss: 19.2282 - true_loss: 3.5633 - val_loss: 3078.5586 - val_reconstruction_loss: 2695.7593 - val_kl_loss: 68.1000 - val_false_loss: 17.1717 - val_true_loss: 3.5376\n",
      "Epoch 355/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.2925 - reconstruction_loss: 2626.4382 - kl_loss: 60.2216 - false_loss: 19.2346 - true_loss: 3.5617 - val_loss: 3078.2288 - val_reconstruction_loss: 2695.5562 - val_kl_loss: 68.0809 - val_false_loss: 17.1792 - val_true_loss: 3.5359\n",
      "Epoch 356/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2976.3317 - reconstruction_loss: 2628.6606 - kl_loss: 60.0110 - false_loss: 19.2410 - true_loss: 3.5601 - val_loss: 3077.9006 - val_reconstruction_loss: 2695.3540 - val_kl_loss: 68.0609 - val_false_loss: 17.1864 - val_true_loss: 3.5342\n",
      "Epoch 357/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2968.9683 - reconstruction_loss: 2626.6013 - kl_loss: 60.4635 - false_loss: 19.2473 - true_loss: 3.5584 - val_loss: 3077.5740 - val_reconstruction_loss: 2695.1516 - val_kl_loss: 68.0363 - val_false_loss: 17.1917 - val_true_loss: 3.5328\n",
      "Epoch 358/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.4496 - reconstruction_loss: 2627.2419 - kl_loss: 59.9121 - false_loss: 19.2536 - true_loss: 3.5567 - val_loss: 3077.2622 - val_reconstruction_loss: 2694.9656 - val_kl_loss: 68.0177 - val_false_loss: 17.1992 - val_true_loss: 3.5310\n",
      "Epoch 359/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2971.0107 - reconstruction_loss: 2627.6660 - kl_loss: 60.2979 - false_loss: 19.2592 - true_loss: 3.5551 - val_loss: 3076.9426 - val_reconstruction_loss: 2694.7708 - val_kl_loss: 67.9968 - val_false_loss: 17.2059 - val_true_loss: 3.5294\n",
      "Epoch 360/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.0754 - reconstruction_loss: 2627.5486 - kl_loss: 60.2383 - false_loss: 19.2655 - true_loss: 3.5535 - val_loss: 3076.6206 - val_reconstruction_loss: 2694.5725 - val_kl_loss: 67.9784 - val_false_loss: 17.2136 - val_true_loss: 3.5277\n",
      "Epoch 361/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2969.1134 - reconstruction_loss: 2627.3835 - kl_loss: 60.2063 - false_loss: 19.2718 - true_loss: 3.5518 - val_loss: 3076.3015 - val_reconstruction_loss: 2694.3762 - val_kl_loss: 67.9618 - val_false_loss: 17.2216 - val_true_loss: 3.5260\n",
      "Epoch 362/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2964.7825 - reconstruction_loss: 2627.4248 - kl_loss: 60.2205 - false_loss: 19.2777 - true_loss: 3.5502 - val_loss: 3075.9883 - val_reconstruction_loss: 2694.1824 - val_kl_loss: 67.9472 - val_false_loss: 17.2300 - val_true_loss: 3.5242\n",
      "Epoch 363/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.2349 - reconstruction_loss: 2627.5125 - kl_loss: 60.0913 - false_loss: 19.2843 - true_loss: 3.5486 - val_loss: 3075.6694 - val_reconstruction_loss: 2693.9854 - val_kl_loss: 67.9290 - val_false_loss: 17.2372 - val_true_loss: 3.5225\n",
      "Epoch 364/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2969.4046 - reconstruction_loss: 2627.6663 - kl_loss: 60.2110 - false_loss: 19.2901 - true_loss: 3.5471 - val_loss: 3075.3547 - val_reconstruction_loss: 2693.7917 - val_kl_loss: 67.9117 - val_false_loss: 17.2450 - val_true_loss: 3.5208\n",
      "Epoch 365/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 2968.2227 - reconstruction_loss: 2626.6367 - kl_loss: 60.0369 - false_loss: 19.2960 - true_loss: 3.5455 - val_loss: 3075.0461 - val_reconstruction_loss: 2693.6035 - val_kl_loss: 67.8936 - val_false_loss: 17.2520 - val_true_loss: 3.5192\n",
      "Epoch 366/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2964.5172 - reconstruction_loss: 2627.2944 - kl_loss: 60.1420 - false_loss: 19.3021 - true_loss: 3.5438 - val_loss: 3074.7366 - val_reconstruction_loss: 2693.4133 - val_kl_loss: 67.8759 - val_false_loss: 17.2592 - val_true_loss: 3.5176\n",
      "Epoch 367/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2964.1035 - reconstruction_loss: 2626.8540 - kl_loss: 60.1357 - false_loss: 19.3078 - true_loss: 3.5423 - val_loss: 3074.4302 - val_reconstruction_loss: 2693.2258 - val_kl_loss: 67.8609 - val_false_loss: 17.2672 - val_true_loss: 3.5158\n",
      "Epoch 368/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2972.0844 - reconstruction_loss: 2626.6274 - kl_loss: 60.3447 - false_loss: 19.3143 - true_loss: 3.5407 - val_loss: 3074.1230 - val_reconstruction_loss: 2693.0366 - val_kl_loss: 67.8469 - val_false_loss: 17.2754 - val_true_loss: 3.5140\n",
      "Epoch 369/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2965.3679 - reconstruction_loss: 2627.5640 - kl_loss: 60.1430 - false_loss: 19.3203 - true_loss: 3.5391 - val_loss: 3073.8157 - val_reconstruction_loss: 2692.8472 - val_kl_loss: 67.8279 - val_false_loss: 17.2820 - val_true_loss: 3.5125\n",
      "Epoch 370/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2968.5592 - reconstruction_loss: 2627.0127 - kl_loss: 60.4419 - false_loss: 19.3256 - true_loss: 3.5376 - val_loss: 3073.5474 - val_reconstruction_loss: 2692.6956 - val_kl_loss: 67.8136 - val_false_loss: 17.2900 - val_true_loss: 3.5107\n",
      "Epoch 371/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2971.1814 - reconstruction_loss: 2627.0125 - kl_loss: 60.2421 - false_loss: 19.3316 - true_loss: 3.5361 - val_loss: 3073.2476 - val_reconstruction_loss: 2692.5134 - val_kl_loss: 67.7965 - val_false_loss: 17.2970 - val_true_loss: 3.5091\n",
      "Epoch 372/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2968.7133 - reconstruction_loss: 2627.0930 - kl_loss: 60.4439 - false_loss: 19.3376 - true_loss: 3.5345 - val_loss: 3072.9507 - val_reconstruction_loss: 2692.3315 - val_kl_loss: 67.7797 - val_false_loss: 17.3042 - val_true_loss: 3.5075\n",
      "Epoch 373/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.3319 - reconstruction_loss: 2626.4995 - kl_loss: 60.2734 - false_loss: 19.3434 - true_loss: 3.5330 - val_loss: 3072.6492 - val_reconstruction_loss: 2692.1455 - val_kl_loss: 67.7640 - val_false_loss: 17.3116 - val_true_loss: 3.5059\n",
      "Epoch 374/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2971.8316 - reconstruction_loss: 2627.1609 - kl_loss: 60.0654 - false_loss: 19.3493 - true_loss: 3.5315 - val_loss: 3072.3508 - val_reconstruction_loss: 2691.9629 - val_kl_loss: 67.7445 - val_false_loss: 17.3176 - val_true_loss: 3.5044\n",
      "Epoch 375/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2967.4198 - reconstruction_loss: 2627.3003 - kl_loss: 60.1764 - false_loss: 19.3548 - true_loss: 3.5299 - val_loss: 3072.0557 - val_reconstruction_loss: 2691.7808 - val_kl_loss: 67.7282 - val_false_loss: 17.3247 - val_true_loss: 3.5028\n",
      "Epoch 376/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.1661 - reconstruction_loss: 2626.2534 - kl_loss: 60.2604 - false_loss: 19.3606 - true_loss: 3.5284 - val_loss: 3071.7639 - val_reconstruction_loss: 2691.6033 - val_kl_loss: 67.7141 - val_false_loss: 17.3325 - val_true_loss: 3.5011\n",
      "Epoch 377/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.7858 - reconstruction_loss: 2626.9038 - kl_loss: 59.9224 - false_loss: 19.3663 - true_loss: 3.5269 - val_loss: 3071.4702 - val_reconstruction_loss: 2691.4207 - val_kl_loss: 67.7033 - val_false_loss: 17.3414 - val_true_loss: 3.4993\n",
      "Epoch 378/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.5452 - reconstruction_loss: 2626.5083 - kl_loss: 60.3776 - false_loss: 19.3713 - true_loss: 3.5254 - val_loss: 3071.1750 - val_reconstruction_loss: 2691.2390 - val_kl_loss: 67.6868 - val_false_loss: 17.3483 - val_true_loss: 3.4978\n",
      "Epoch 379/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.8808 - reconstruction_loss: 2627.4651 - kl_loss: 60.5213 - false_loss: 19.3770 - true_loss: 3.5239 - val_loss: 3070.8843 - val_reconstruction_loss: 2691.0591 - val_kl_loss: 67.6701 - val_false_loss: 17.3551 - val_true_loss: 3.4962\n",
      "Epoch 380/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.7527 - reconstruction_loss: 2626.3091 - kl_loss: 59.9167 - false_loss: 19.3829 - true_loss: 3.5224 - val_loss: 3070.6057 - val_reconstruction_loss: 2690.8894 - val_kl_loss: 67.6636 - val_false_loss: 17.3650 - val_true_loss: 3.4943\n",
      "Epoch 381/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.4226 - reconstruction_loss: 2626.4934 - kl_loss: 60.7233 - false_loss: 19.3884 - true_loss: 3.5210 - val_loss: 3070.3176 - val_reconstruction_loss: 2690.7122 - val_kl_loss: 67.6446 - val_false_loss: 17.3706 - val_true_loss: 3.4929\n",
      "Epoch 382/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2968.1714 - reconstruction_loss: 2626.4688 - kl_loss: 60.2159 - false_loss: 19.3942 - true_loss: 3.5195 - val_loss: 3070.0281 - val_reconstruction_loss: 2690.5330 - val_kl_loss: 67.6264 - val_false_loss: 17.3767 - val_true_loss: 3.4915\n",
      "Epoch 383/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.2631 - reconstruction_loss: 2627.6660 - kl_loss: 60.1529 - false_loss: 19.3991 - true_loss: 3.5180 - val_loss: 3069.7415 - val_reconstruction_loss: 2690.3550 - val_kl_loss: 67.6115 - val_false_loss: 17.3839 - val_true_loss: 3.4899\n",
      "Epoch 384/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2970.5502 - reconstruction_loss: 2626.4048 - kl_loss: 60.1172 - false_loss: 19.4048 - true_loss: 3.5166 - val_loss: 3069.4563 - val_reconstruction_loss: 2690.1785 - val_kl_loss: 67.5972 - val_false_loss: 17.3910 - val_true_loss: 3.4884\n",
      "Epoch 385/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2968.0320 - reconstruction_loss: 2626.2258 - kl_loss: 60.2996 - false_loss: 19.4102 - true_loss: 3.5152 - val_loss: 3069.1726 - val_reconstruction_loss: 2690.0044 - val_kl_loss: 67.5818 - val_false_loss: 17.3976 - val_true_loss: 3.4868\n",
      "Epoch 386/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2971.4582 - reconstruction_loss: 2627.9233 - kl_loss: 60.4616 - false_loss: 19.4164 - true_loss: 3.5138 - val_loss: 3068.8911 - val_reconstruction_loss: 2689.8306 - val_kl_loss: 67.5619 - val_false_loss: 17.4029 - val_true_loss: 3.4855\n",
      "Epoch 387/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2964.5492 - reconstruction_loss: 2625.6470 - kl_loss: 60.0060 - false_loss: 19.4215 - true_loss: 3.5123 - val_loss: 3068.6108 - val_reconstruction_loss: 2689.6567 - val_kl_loss: 67.5441 - val_false_loss: 17.4086 - val_true_loss: 3.4841\n",
      "Epoch 388/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2965.5722 - reconstruction_loss: 2627.3503 - kl_loss: 60.0759 - false_loss: 19.4267 - true_loss: 3.5109 - val_loss: 3068.3306 - val_reconstruction_loss: 2689.4834 - val_kl_loss: 67.5293 - val_false_loss: 17.4156 - val_true_loss: 3.4826\n",
      "Epoch 389/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2965.6636 - reconstruction_loss: 2625.7554 - kl_loss: 60.6305 - false_loss: 19.4319 - true_loss: 3.5095 - val_loss: 3068.0500 - val_reconstruction_loss: 2689.3108 - val_kl_loss: 67.5124 - val_false_loss: 17.4216 - val_true_loss: 3.4812\n",
      "Epoch 390/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2967.5307 - reconstruction_loss: 2626.3013 - kl_loss: 59.9103 - false_loss: 19.4374 - true_loss: 3.5081 - val_loss: 3067.7788 - val_reconstruction_loss: 2689.1462 - val_kl_loss: 67.4972 - val_false_loss: 17.4283 - val_true_loss: 3.4797\n",
      "Epoch 391/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 2967.3708 - reconstruction_loss: 2625.8760 - kl_loss: 60.5848 - false_loss: 19.4424 - true_loss: 3.5067 - val_loss: 3067.5022 - val_reconstruction_loss: 2688.9756 - val_kl_loss: 67.4788 - val_false_loss: 17.4335 - val_true_loss: 3.4784\n",
      "Epoch 392/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2968.0133 - reconstruction_loss: 2627.4712 - kl_loss: 59.9338 - false_loss: 19.4478 - true_loss: 3.5052 - val_loss: 3067.2290 - val_reconstruction_loss: 2688.8052 - val_kl_loss: 67.4637 - val_false_loss: 17.4402 - val_true_loss: 3.4769\n",
      "Epoch 393/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2966.7732 - reconstruction_loss: 2625.4731 - kl_loss: 60.3222 - false_loss: 19.4533 - true_loss: 3.5039 - val_loss: 3066.9561 - val_reconstruction_loss: 2688.6367 - val_kl_loss: 67.4492 - val_false_loss: 17.4468 - val_true_loss: 3.4755\n",
      "Epoch 394/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2967.6361 - reconstruction_loss: 2627.1338 - kl_loss: 60.3484 - false_loss: 19.4584 - true_loss: 3.5025 - val_loss: 3066.6833 - val_reconstruction_loss: 2688.4683 - val_kl_loss: 67.4330 - val_false_loss: 17.4527 - val_true_loss: 3.4741\n",
      "Epoch 395/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2964.5009 - reconstruction_loss: 2626.1814 - kl_loss: 60.1666 - false_loss: 19.4636 - true_loss: 3.5011 - val_loss: 3066.4136 - val_reconstruction_loss: 2688.3025 - val_kl_loss: 67.4199 - val_false_loss: 17.4597 - val_true_loss: 3.4725\n",
      "Epoch 396/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2965.2324 - reconstruction_loss: 2625.9519 - kl_loss: 60.5896 - false_loss: 19.4686 - true_loss: 3.4997 - val_loss: 3066.1440 - val_reconstruction_loss: 2688.1357 - val_kl_loss: 67.4012 - val_false_loss: 17.4647 - val_true_loss: 3.4713\n",
      "Epoch 397/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2969.2019 - reconstruction_loss: 2625.8975 - kl_loss: 60.0049 - false_loss: 19.4742 - true_loss: 3.4984 - val_loss: 3065.8748 - val_reconstruction_loss: 2687.9692 - val_kl_loss: 67.3879 - val_false_loss: 17.4713 - val_true_loss: 3.4698\n",
      "Epoch 398/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2965.2783 - reconstruction_loss: 2625.8254 - kl_loss: 60.4263 - false_loss: 19.4788 - true_loss: 3.4970 - val_loss: 3065.6074 - val_reconstruction_loss: 2687.8047 - val_kl_loss: 67.3767 - val_false_loss: 17.4786 - val_true_loss: 3.4682\n",
      "Epoch 399/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2966.7295 - reconstruction_loss: 2626.2837 - kl_loss: 60.4190 - false_loss: 19.4841 - true_loss: 3.4956 - val_loss: 3065.3430 - val_reconstruction_loss: 2687.6414 - val_kl_loss: 67.3562 - val_false_loss: 17.4830 - val_true_loss: 3.4670\n",
      "Epoch 400/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.5295 - reconstruction_loss: 2626.2339 - kl_loss: 60.3424 - false_loss: 19.4890 - true_loss: 3.4943 - val_loss: 3065.0793 - val_reconstruction_loss: 2687.4785 - val_kl_loss: 67.3404 - val_false_loss: 17.4892 - val_true_loss: 3.4657\n",
      "Epoch 401/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2970.4650 - reconstruction_loss: 2627.9246 - kl_loss: 60.2945 - false_loss: 19.4942 - true_loss: 3.4930 - val_loss: 3064.8276 - val_reconstruction_loss: 2687.3254 - val_kl_loss: 67.3212 - val_false_loss: 17.4940 - val_true_loss: 3.4645\n",
      "Epoch 402/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2965.1365 - reconstruction_loss: 2625.7034 - kl_loss: 60.0544 - false_loss: 19.4991 - true_loss: 3.4917 - val_loss: 3064.5659 - val_reconstruction_loss: 2687.1628 - val_kl_loss: 67.3077 - val_false_loss: 17.5004 - val_true_loss: 3.4631\n",
      "Epoch 403/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.6945 - reconstruction_loss: 2625.3301 - kl_loss: 60.0267 - false_loss: 19.5038 - true_loss: 3.4904 - val_loss: 3064.3059 - val_reconstruction_loss: 2687.0027 - val_kl_loss: 67.2948 - val_false_loss: 17.5071 - val_true_loss: 3.4617\n",
      "Epoch 404/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.1208 - reconstruction_loss: 2626.3516 - kl_loss: 60.3037 - false_loss: 19.5090 - true_loss: 3.4891 - val_loss: 3064.0466 - val_reconstruction_loss: 2686.8416 - val_kl_loss: 67.2806 - val_false_loss: 17.5134 - val_true_loss: 3.4603\n",
      "Epoch 405/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.5698 - reconstruction_loss: 2625.5806 - kl_loss: 60.3843 - false_loss: 19.5144 - true_loss: 3.4878 - val_loss: 3063.7888 - val_reconstruction_loss: 2686.6826 - val_kl_loss: 67.2637 - val_false_loss: 17.5186 - val_true_loss: 3.4590\n",
      "Epoch 406/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2964.8615 - reconstruction_loss: 2626.8845 - kl_loss: 60.3551 - false_loss: 19.5189 - true_loss: 3.4864 - val_loss: 3063.5449 - val_reconstruction_loss: 2686.5361 - val_kl_loss: 67.2479 - val_false_loss: 17.5243 - val_true_loss: 3.4577\n",
      "Epoch 407/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2968.6827 - reconstruction_loss: 2625.8804 - kl_loss: 60.0660 - false_loss: 19.5237 - true_loss: 3.4852 - val_loss: 3063.2888 - val_reconstruction_loss: 2686.3772 - val_kl_loss: 67.2362 - val_false_loss: 17.5311 - val_true_loss: 3.4563\n",
      "Epoch 408/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2964.5596 - reconstruction_loss: 2626.0437 - kl_loss: 60.1387 - false_loss: 19.5284 - true_loss: 3.4838 - val_loss: 3063.0398 - val_reconstruction_loss: 2686.2249 - val_kl_loss: 67.2273 - val_false_loss: 17.5386 - val_true_loss: 3.4547\n",
      "Epoch 409/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.6517 - reconstruction_loss: 2625.2915 - kl_loss: 60.5044 - false_loss: 19.5332 - true_loss: 3.4825 - val_loss: 3062.7869 - val_reconstruction_loss: 2686.0684 - val_kl_loss: 67.2118 - val_false_loss: 17.5439 - val_true_loss: 3.4534\n",
      "Epoch 410/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2962.6996 - reconstruction_loss: 2625.8000 - kl_loss: 60.2543 - false_loss: 19.5378 - true_loss: 3.4812 - val_loss: 3062.5352 - val_reconstruction_loss: 2685.9138 - val_kl_loss: 67.1958 - val_false_loss: 17.5490 - val_true_loss: 3.4522\n",
      "Epoch 411/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2967.6233 - reconstruction_loss: 2627.5112 - kl_loss: 60.2647 - false_loss: 19.5431 - true_loss: 3.4799 - val_loss: 3062.2834 - val_reconstruction_loss: 2685.7578 - val_kl_loss: 67.1826 - val_false_loss: 17.5553 - val_true_loss: 3.4508\n",
      "Epoch 412/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2968.3102 - reconstruction_loss: 2624.9875 - kl_loss: 60.3113 - false_loss: 19.5474 - true_loss: 3.4787 - val_loss: 3062.0337 - val_reconstruction_loss: 2685.6035 - val_kl_loss: 67.1678 - val_false_loss: 17.5606 - val_true_loss: 3.4496\n",
      "Epoch 413/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.7325 - reconstruction_loss: 2625.8933 - kl_loss: 60.2923 - false_loss: 19.5519 - true_loss: 3.4774 - val_loss: 3061.7839 - val_reconstruction_loss: 2685.4485 - val_kl_loss: 67.1557 - val_false_loss: 17.5668 - val_true_loss: 3.4482\n",
      "Epoch 414/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2966.4060 - reconstruction_loss: 2625.5842 - kl_loss: 60.5228 - false_loss: 19.5570 - true_loss: 3.4762 - val_loss: 3061.5422 - val_reconstruction_loss: 2685.3013 - val_kl_loss: 67.1421 - val_false_loss: 17.5727 - val_true_loss: 3.4468\n",
      "Epoch 415/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2969.3137 - reconstruction_loss: 2626.1309 - kl_loss: 60.3032 - false_loss: 19.5622 - true_loss: 3.4749 - val_loss: 3061.2981 - val_reconstruction_loss: 2685.1516 - val_kl_loss: 67.1244 - val_false_loss: 17.5769 - val_true_loss: 3.4457\n",
      "Epoch 416/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2965.0231 - reconstruction_loss: 2625.0059 - kl_loss: 60.3436 - false_loss: 19.5664 - true_loss: 3.4736 - val_loss: 3061.0588 - val_reconstruction_loss: 2685.0051 - val_kl_loss: 67.1109 - val_false_loss: 17.5827 - val_true_loss: 3.4444\n",
      "Epoch 417/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 2967.5726 - reconstruction_loss: 2625.7649 - kl_loss: 60.3856 - false_loss: 19.5712 - true_loss: 3.4724 - val_loss: 3060.8184 - val_reconstruction_loss: 2684.8582 - val_kl_loss: 67.0987 - val_false_loss: 17.5888 - val_true_loss: 3.4431\n",
      "Epoch 418/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.5170 - reconstruction_loss: 2625.3394 - kl_loss: 60.4656 - false_loss: 19.5761 - true_loss: 3.4711 - val_loss: 3060.5728 - val_reconstruction_loss: 2684.7061 - val_kl_loss: 67.0851 - val_false_loss: 17.5944 - val_true_loss: 3.4418\n",
      "Epoch 419/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.7669 - reconstruction_loss: 2626.5815 - kl_loss: 60.1425 - false_loss: 19.5802 - true_loss: 3.4699 - val_loss: 3060.3442 - val_reconstruction_loss: 2684.5698 - val_kl_loss: 67.0695 - val_false_loss: 17.5994 - val_true_loss: 3.4406\n",
      "Epoch 420/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2968.7239 - reconstruction_loss: 2624.9531 - kl_loss: 60.5379 - false_loss: 19.5853 - true_loss: 3.4687 - val_loss: 3060.1060 - val_reconstruction_loss: 2684.4231 - val_kl_loss: 67.0550 - val_false_loss: 17.6045 - val_true_loss: 3.4394\n",
      "Epoch 421/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.9971 - reconstruction_loss: 2625.4910 - kl_loss: 60.3559 - false_loss: 19.5897 - true_loss: 3.4674 - val_loss: 3059.8657 - val_reconstruction_loss: 2684.2742 - val_kl_loss: 67.0394 - val_false_loss: 17.6094 - val_true_loss: 3.4382\n",
      "Epoch 422/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.1544 - reconstruction_loss: 2626.1692 - kl_loss: 60.2702 - false_loss: 19.5944 - true_loss: 3.4662 - val_loss: 3059.6304 - val_reconstruction_loss: 2684.1292 - val_kl_loss: 67.0267 - val_false_loss: 17.6152 - val_true_loss: 3.4370\n",
      "Epoch 423/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2967.6625 - reconstruction_loss: 2624.9883 - kl_loss: 60.7945 - false_loss: 19.5989 - true_loss: 3.4650 - val_loss: 3059.3899 - val_reconstruction_loss: 2683.9802 - val_kl_loss: 67.0110 - val_false_loss: 17.6198 - val_true_loss: 3.4358\n",
      "Epoch 424/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.7162 - reconstruction_loss: 2625.5522 - kl_loss: 60.3606 - false_loss: 19.6039 - true_loss: 3.4638 - val_loss: 3059.1538 - val_reconstruction_loss: 2683.8333 - val_kl_loss: 66.9991 - val_false_loss: 17.6259 - val_true_loss: 3.4345\n",
      "Epoch 425/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2964.7095 - reconstruction_loss: 2625.2935 - kl_loss: 60.1520 - false_loss: 19.6079 - true_loss: 3.4627 - val_loss: 3058.9253 - val_reconstruction_loss: 2683.6902 - val_kl_loss: 66.9880 - val_false_loss: 17.6315 - val_true_loss: 3.4333\n",
      "Epoch 426/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.5983 - reconstruction_loss: 2625.5093 - kl_loss: 60.2271 - false_loss: 19.6119 - true_loss: 3.4615 - val_loss: 3058.6904 - val_reconstruction_loss: 2683.5449 - val_kl_loss: 66.9751 - val_false_loss: 17.6368 - val_true_loss: 3.4320\n",
      "Epoch 427/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2967.8669 - reconstruction_loss: 2625.6284 - kl_loss: 60.2868 - false_loss: 19.6166 - true_loss: 3.4603 - val_loss: 3058.4575 - val_reconstruction_loss: 2683.4011 - val_kl_loss: 66.9628 - val_false_loss: 17.6428 - val_true_loss: 3.4308\n",
      "Epoch 428/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.5489 - reconstruction_loss: 2625.9551 - kl_loss: 60.2964 - false_loss: 19.6215 - true_loss: 3.4591 - val_loss: 3058.2241 - val_reconstruction_loss: 2683.2561 - val_kl_loss: 66.9479 - val_false_loss: 17.6478 - val_true_loss: 3.4296\n",
      "Epoch 429/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2972.2649 - reconstruction_loss: 2625.2544 - kl_loss: 60.5324 - false_loss: 19.6256 - true_loss: 3.4580 - val_loss: 3057.9927 - val_reconstruction_loss: 2683.1118 - val_kl_loss: 66.9352 - val_false_loss: 17.6531 - val_true_loss: 3.4284\n",
      "Epoch 430/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2970.2981 - reconstruction_loss: 2627.0852 - kl_loss: 60.1271 - false_loss: 19.6299 - true_loss: 3.4569 - val_loss: 3057.7668 - val_reconstruction_loss: 2682.9729 - val_kl_loss: 66.9232 - val_false_loss: 17.6589 - val_true_loss: 3.4272\n",
      "Epoch 431/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.3944 - reconstruction_loss: 2624.7605 - kl_loss: 60.3586 - false_loss: 19.6343 - true_loss: 3.4557 - val_loss: 3057.5356 - val_reconstruction_loss: 2682.8286 - val_kl_loss: 66.9091 - val_false_loss: 17.6637 - val_true_loss: 3.4260\n",
      "Epoch 432/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2962.2828 - reconstruction_loss: 2624.6206 - kl_loss: 60.1847 - false_loss: 19.6387 - true_loss: 3.4545 - val_loss: 3057.3240 - val_reconstruction_loss: 2682.7046 - val_kl_loss: 66.8990 - val_false_loss: 17.6699 - val_true_loss: 3.4247\n",
      "Epoch 433/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2964.6579 - reconstruction_loss: 2624.9458 - kl_loss: 60.5762 - false_loss: 19.6427 - true_loss: 3.4534 - val_loss: 3057.0967 - val_reconstruction_loss: 2682.5630 - val_kl_loss: 66.8854 - val_false_loss: 17.6748 - val_true_loss: 3.4235\n",
      "Epoch 434/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2966.8686 - reconstruction_loss: 2624.7231 - kl_loss: 60.4942 - false_loss: 19.6473 - true_loss: 3.4523 - val_loss: 3056.8799 - val_reconstruction_loss: 2682.4326 - val_kl_loss: 66.8731 - val_false_loss: 17.6800 - val_true_loss: 3.4223\n",
      "Epoch 435/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2963.5722 - reconstruction_loss: 2624.7205 - kl_loss: 60.6467 - false_loss: 19.6515 - true_loss: 3.4511 - val_loss: 3056.6541 - val_reconstruction_loss: 2682.2905 - val_kl_loss: 66.8548 - val_false_loss: 17.6829 - val_true_loss: 3.4215\n",
      "Epoch 436/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2962.6949 - reconstruction_loss: 2623.1897 - kl_loss: 60.6563 - false_loss: 19.6557 - true_loss: 3.4500 - val_loss: 3056.4263 - val_reconstruction_loss: 2682.1475 - val_kl_loss: 66.8411 - val_false_loss: 17.6873 - val_true_loss: 3.4204\n",
      "Epoch 437/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2970.8651 - reconstruction_loss: 2627.0518 - kl_loss: 59.9467 - false_loss: 19.6601 - true_loss: 3.4489 - val_loss: 3056.1997 - val_reconstruction_loss: 2682.0032 - val_kl_loss: 66.8290 - val_false_loss: 17.6926 - val_true_loss: 3.4192\n",
      "Epoch 438/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2965.8655 - reconstruction_loss: 2621.6140 - kl_loss: 60.9941 - false_loss: 19.6642 - true_loss: 3.4478 - val_loss: 3055.9724 - val_reconstruction_loss: 2681.8591 - val_kl_loss: 66.8154 - val_false_loss: 17.6968 - val_true_loss: 3.4181\n",
      "Epoch 439/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2965.1518 - reconstruction_loss: 2621.1001 - kl_loss: 60.9176 - false_loss: 19.6685 - true_loss: 3.4466 - val_loss: 3055.7524 - val_reconstruction_loss: 2681.7214 - val_kl_loss: 66.8028 - val_false_loss: 17.7013 - val_true_loss: 3.4170\n",
      "Epoch 440/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2963.3673 - reconstruction_loss: 2620.6775 - kl_loss: 61.0061 - false_loss: 19.6725 - true_loss: 3.4455 - val_loss: 3055.5232 - val_reconstruction_loss: 2681.5745 - val_kl_loss: 66.7890 - val_false_loss: 17.7053 - val_true_loss: 3.4160\n",
      "Epoch 441/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2962.1129 - reconstruction_loss: 2621.0620 - kl_loss: 60.7573 - false_loss: 19.6770 - true_loss: 3.4443 - val_loss: 3055.2954 - val_reconstruction_loss: 2681.4292 - val_kl_loss: 66.7790 - val_false_loss: 17.7107 - val_true_loss: 3.4148\n",
      "Epoch 442/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2962.4800 - reconstruction_loss: 2620.7224 - kl_loss: 60.7761 - false_loss: 19.6805 - true_loss: 3.4432 - val_loss: 3055.0681 - val_reconstruction_loss: 2681.2837 - val_kl_loss: 66.7687 - val_false_loss: 17.7158 - val_true_loss: 3.4136\n",
      "Epoch 443/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 2963.3858 - reconstruction_loss: 2620.3608 - kl_loss: 61.3029 - false_loss: 19.6848 - true_loss: 3.4420 - val_loss: 3054.8430 - val_reconstruction_loss: 2681.1392 - val_kl_loss: 66.7543 - val_false_loss: 17.7197 - val_true_loss: 3.4126\n",
      "Epoch 444/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.0021 - reconstruction_loss: 2620.6404 - kl_loss: 60.7497 - false_loss: 19.6887 - true_loss: 3.4409 - val_loss: 3054.6196 - val_reconstruction_loss: 2680.9949 - val_kl_loss: 66.7456 - val_false_loss: 17.7252 - val_true_loss: 3.4114\n",
      "Epoch 445/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2966.6399 - reconstruction_loss: 2620.7515 - kl_loss: 61.3309 - false_loss: 19.6932 - true_loss: 3.4399 - val_loss: 3054.4097 - val_reconstruction_loss: 2680.8652 - val_kl_loss: 66.7331 - val_false_loss: 17.7299 - val_true_loss: 3.4103\n",
      "Epoch 446/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2958.6601 - reconstruction_loss: 2620.0012 - kl_loss: 60.6416 - false_loss: 19.6970 - true_loss: 3.4387 - val_loss: 3054.1851 - val_reconstruction_loss: 2680.7202 - val_kl_loss: 66.7238 - val_false_loss: 17.7353 - val_true_loss: 3.4091\n",
      "Epoch 447/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2958.5972 - reconstruction_loss: 2619.4382 - kl_loss: 61.0158 - false_loss: 19.7008 - true_loss: 3.4376 - val_loss: 3053.9604 - val_reconstruction_loss: 2680.5754 - val_kl_loss: 66.7150 - val_false_loss: 17.7409 - val_true_loss: 3.4079\n",
      "Epoch 448/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.4057 - reconstruction_loss: 2621.3960 - kl_loss: 60.8929 - false_loss: 19.7053 - true_loss: 3.4365 - val_loss: 3053.7405 - val_reconstruction_loss: 2680.4336 - val_kl_loss: 66.7039 - val_false_loss: 17.7458 - val_true_loss: 3.4068\n",
      "Epoch 449/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.2500 - reconstruction_loss: 2619.1094 - kl_loss: 60.8752 - false_loss: 19.7092 - true_loss: 3.4354 - val_loss: 3053.5183 - val_reconstruction_loss: 2680.2905 - val_kl_loss: 66.6956 - val_false_loss: 17.7515 - val_true_loss: 3.4056\n",
      "Epoch 450/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2958.4918 - reconstruction_loss: 2618.9727 - kl_loss: 60.9342 - false_loss: 19.7133 - true_loss: 3.4343 - val_loss: 3053.3013 - val_reconstruction_loss: 2680.1526 - val_kl_loss: 66.6851 - val_false_loss: 17.7560 - val_true_loss: 3.4044\n",
      "Epoch 451/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.4312 - reconstruction_loss: 2621.5090 - kl_loss: 60.9019 - false_loss: 19.7165 - true_loss: 3.4332 - val_loss: 3053.0815 - val_reconstruction_loss: 2680.0095 - val_kl_loss: 66.6757 - val_false_loss: 17.7613 - val_true_loss: 3.4033\n",
      "Epoch 452/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2964.6983 - reconstruction_loss: 2618.8484 - kl_loss: 60.9845 - false_loss: 19.7211 - true_loss: 3.4322 - val_loss: 3052.8628 - val_reconstruction_loss: 2679.8682 - val_kl_loss: 66.6699 - val_false_loss: 17.7675 - val_true_loss: 3.4020\n",
      "Epoch 453/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.1933 - reconstruction_loss: 2619.5825 - kl_loss: 61.1083 - false_loss: 19.7245 - true_loss: 3.4311 - val_loss: 3052.6528 - val_reconstruction_loss: 2679.7322 - val_kl_loss: 66.6577 - val_false_loss: 17.7720 - val_true_loss: 3.4010\n",
      "Epoch 454/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2966.0835 - reconstruction_loss: 2618.9446 - kl_loss: 60.9858 - false_loss: 19.7288 - true_loss: 3.4301 - val_loss: 3052.4370 - val_reconstruction_loss: 2679.5913 - val_kl_loss: 66.6479 - val_false_loss: 17.7765 - val_true_loss: 3.3999\n",
      "Epoch 455/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2964.1259 - reconstruction_loss: 2620.1038 - kl_loss: 61.1613 - false_loss: 19.7326 - true_loss: 3.4291 - val_loss: 3052.2256 - val_reconstruction_loss: 2679.4565 - val_kl_loss: 66.6374 - val_false_loss: 17.7812 - val_true_loss: 3.3989\n",
      "Epoch 456/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2959.6916 - reconstruction_loss: 2618.6548 - kl_loss: 60.9031 - false_loss: 19.7363 - true_loss: 3.4280 - val_loss: 3052.0083 - val_reconstruction_loss: 2679.3157 - val_kl_loss: 66.6294 - val_false_loss: 17.7865 - val_true_loss: 3.3977\n",
      "Epoch 457/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.5824 - reconstruction_loss: 2619.2764 - kl_loss: 61.3294 - false_loss: 19.7406 - true_loss: 3.4270 - val_loss: 3051.7925 - val_reconstruction_loss: 2679.1763 - val_kl_loss: 66.6194 - val_false_loss: 17.7911 - val_true_loss: 3.3966\n",
      "Epoch 458/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2960.2640 - reconstruction_loss: 2619.2134 - kl_loss: 61.2893 - false_loss: 19.7442 - true_loss: 3.4259 - val_loss: 3051.5786 - val_reconstruction_loss: 2679.0383 - val_kl_loss: 66.6085 - val_false_loss: 17.7953 - val_true_loss: 3.3955\n",
      "Epoch 459/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2955.3794 - reconstruction_loss: 2618.8403 - kl_loss: 60.7175 - false_loss: 19.7478 - true_loss: 3.4248 - val_loss: 3051.3638 - val_reconstruction_loss: 2678.8989 - val_kl_loss: 66.5987 - val_false_loss: 17.7999 - val_true_loss: 3.3945\n",
      "Epoch 460/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2959.5215 - reconstruction_loss: 2619.5552 - kl_loss: 61.3676 - false_loss: 19.7515 - true_loss: 3.4238 - val_loss: 3051.1499 - val_reconstruction_loss: 2678.7605 - val_kl_loss: 66.5869 - val_false_loss: 17.8039 - val_true_loss: 3.3935\n",
      "Epoch 461/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2960.7038 - reconstruction_loss: 2618.9624 - kl_loss: 60.9499 - false_loss: 19.7554 - true_loss: 3.4227 - val_loss: 3050.9468 - val_reconstruction_loss: 2678.6296 - val_kl_loss: 66.5739 - val_false_loss: 17.8073 - val_true_loss: 3.3926\n",
      "Epoch 462/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.8063 - reconstruction_loss: 2619.0803 - kl_loss: 61.1020 - false_loss: 19.7591 - true_loss: 3.4217 - val_loss: 3050.7427 - val_reconstruction_loss: 2678.4990 - val_kl_loss: 66.5663 - val_false_loss: 17.8126 - val_true_loss: 3.3914\n",
      "Epoch 463/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2959.1227 - reconstruction_loss: 2618.2546 - kl_loss: 60.6325 - false_loss: 19.7628 - true_loss: 3.4207 - val_loss: 3050.5325 - val_reconstruction_loss: 2678.3618 - val_kl_loss: 66.5604 - val_false_loss: 17.8182 - val_true_loss: 3.3902\n",
      "Epoch 464/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2960.3165 - reconstruction_loss: 2619.7124 - kl_loss: 61.2690 - false_loss: 19.7664 - true_loss: 3.4197 - val_loss: 3050.3232 - val_reconstruction_loss: 2678.2256 - val_kl_loss: 66.5487 - val_false_loss: 17.8221 - val_true_loss: 3.3893\n",
      "Epoch 465/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2962.0306 - reconstruction_loss: 2617.5366 - kl_loss: 61.1700 - false_loss: 19.7706 - true_loss: 3.4187 - val_loss: 3050.1128 - val_reconstruction_loss: 2678.0884 - val_kl_loss: 66.5361 - val_false_loss: 17.8256 - val_true_loss: 3.3883\n",
      "Epoch 466/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.1023 - reconstruction_loss: 2619.8391 - kl_loss: 60.7407 - false_loss: 19.7743 - true_loss: 3.4177 - val_loss: 3049.9033 - val_reconstruction_loss: 2677.9521 - val_kl_loss: 66.5280 - val_false_loss: 17.8308 - val_true_loss: 3.3872\n",
      "Epoch 467/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.9060 - reconstruction_loss: 2617.7493 - kl_loss: 61.0581 - false_loss: 19.7776 - true_loss: 3.4167 - val_loss: 3049.6995 - val_reconstruction_loss: 2677.8203 - val_kl_loss: 66.5183 - val_false_loss: 17.8353 - val_true_loss: 3.3862\n",
      "Epoch 468/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.7335 - reconstruction_loss: 2618.5034 - kl_loss: 61.0747 - false_loss: 19.7815 - true_loss: 3.4157 - val_loss: 3049.4927 - val_reconstruction_loss: 2677.6853 - val_kl_loss: 66.5117 - val_false_loss: 17.8407 - val_true_loss: 3.3850\n",
      "Epoch 469/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 2958.3801 - reconstruction_loss: 2617.7607 - kl_loss: 60.9287 - false_loss: 19.7851 - true_loss: 3.4147 - val_loss: 3049.2859 - val_reconstruction_loss: 2677.5500 - val_kl_loss: 66.5048 - val_false_loss: 17.8460 - val_true_loss: 3.3839\n",
      "Epoch 470/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2959.8482 - reconstruction_loss: 2618.3406 - kl_loss: 61.1391 - false_loss: 19.7884 - true_loss: 3.4137 - val_loss: 3049.0808 - val_reconstruction_loss: 2677.4165 - val_kl_loss: 66.4970 - val_false_loss: 17.8509 - val_true_loss: 3.3828\n",
      "Epoch 471/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.2200 - reconstruction_loss: 2617.9729 - kl_loss: 61.1755 - false_loss: 19.7923 - true_loss: 3.4127 - val_loss: 3048.8748 - val_reconstruction_loss: 2677.2825 - val_kl_loss: 66.4854 - val_false_loss: 17.8546 - val_true_loss: 3.3819\n",
      "Epoch 472/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2962.3557 - reconstruction_loss: 2618.2629 - kl_loss: 61.3097 - false_loss: 19.7960 - true_loss: 3.4117 - val_loss: 3048.7188 - val_reconstruction_loss: 2677.1982 - val_kl_loss: 66.4772 - val_false_loss: 17.8591 - val_true_loss: 3.3808\n",
      "Epoch 473/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2967.5708 - reconstruction_loss: 2620.6401 - kl_loss: 60.5702 - false_loss: 19.7995 - true_loss: 3.4108 - val_loss: 3048.5149 - val_reconstruction_loss: 2677.0654 - val_kl_loss: 66.4656 - val_false_loss: 17.8631 - val_true_loss: 3.3799\n",
      "Epoch 474/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2954.9653 - reconstruction_loss: 2617.2249 - kl_loss: 60.7123 - false_loss: 19.8030 - true_loss: 3.4098 - val_loss: 3048.3159 - val_reconstruction_loss: 2676.9370 - val_kl_loss: 66.4569 - val_false_loss: 17.8677 - val_true_loss: 3.3788\n",
      "Epoch 475/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.2602 - reconstruction_loss: 2617.4082 - kl_loss: 61.3957 - false_loss: 19.8072 - true_loss: 3.4088 - val_loss: 3048.1138 - val_reconstruction_loss: 2676.8049 - val_kl_loss: 66.4491 - val_false_loss: 17.8724 - val_true_loss: 3.3778\n",
      "Epoch 476/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.2317 - reconstruction_loss: 2617.8457 - kl_loss: 61.0256 - false_loss: 19.8104 - true_loss: 3.4079 - val_loss: 3047.9116 - val_reconstruction_loss: 2676.6733 - val_kl_loss: 66.4411 - val_false_loss: 17.8770 - val_true_loss: 3.3767\n",
      "Epoch 477/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.5444 - reconstruction_loss: 2617.1196 - kl_loss: 61.2428 - false_loss: 19.8139 - true_loss: 3.4069 - val_loss: 3047.7180 - val_reconstruction_loss: 2676.5500 - val_kl_loss: 66.4307 - val_false_loss: 17.8808 - val_true_loss: 3.3757\n",
      "Epoch 478/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2962.0309 - reconstruction_loss: 2617.9038 - kl_loss: 61.1342 - false_loss: 19.8177 - true_loss: 3.4059 - val_loss: 3047.5178 - val_reconstruction_loss: 2676.4199 - val_kl_loss: 66.4245 - val_false_loss: 17.8860 - val_true_loss: 3.3746\n",
      "Epoch 479/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2957.8160 - reconstruction_loss: 2617.8391 - kl_loss: 61.2730 - false_loss: 19.8207 - true_loss: 3.4049 - val_loss: 3047.3242 - val_reconstruction_loss: 2676.2959 - val_kl_loss: 66.4160 - val_false_loss: 17.8905 - val_true_loss: 3.3736\n",
      "Epoch 480/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2959.2221 - reconstruction_loss: 2617.9399 - kl_loss: 61.1777 - false_loss: 19.8242 - true_loss: 3.4039 - val_loss: 3047.1255 - val_reconstruction_loss: 2676.1665 - val_kl_loss: 66.4074 - val_false_loss: 17.8948 - val_true_loss: 3.3726\n",
      "Epoch 481/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2957.7639 - reconstruction_loss: 2616.9402 - kl_loss: 61.3278 - false_loss: 19.8279 - true_loss: 3.4030 - val_loss: 3046.9265 - val_reconstruction_loss: 2676.0364 - val_kl_loss: 66.3991 - val_false_loss: 17.8993 - val_true_loss: 3.3716\n",
      "Epoch 482/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2955.2868 - reconstruction_loss: 2617.8496 - kl_loss: 60.7877 - false_loss: 19.8312 - true_loss: 3.4020 - val_loss: 3046.7505 - val_reconstruction_loss: 2675.9290 - val_kl_loss: 66.3940 - val_false_loss: 17.9046 - val_true_loss: 3.3704\n",
      "Epoch 483/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.3298 - reconstruction_loss: 2618.1094 - kl_loss: 61.1525 - false_loss: 19.8346 - true_loss: 3.4011 - val_loss: 3046.5530 - val_reconstruction_loss: 2675.7998 - val_kl_loss: 66.3884 - val_false_loss: 17.9099 - val_true_loss: 3.3693\n",
      "Epoch 484/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2957.2968 - reconstruction_loss: 2617.7566 - kl_loss: 61.4585 - false_loss: 19.8383 - true_loss: 3.4001 - val_loss: 3046.3569 - val_reconstruction_loss: 2675.6714 - val_kl_loss: 66.3766 - val_false_loss: 17.9130 - val_true_loss: 3.3684\n",
      "Epoch 485/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2953.5793 - reconstruction_loss: 2617.3027 - kl_loss: 60.7840 - false_loss: 19.8411 - true_loss: 3.3991 - val_loss: 3046.1636 - val_reconstruction_loss: 2675.5454 - val_kl_loss: 66.3710 - val_false_loss: 17.9183 - val_true_loss: 3.3673\n",
      "Epoch 486/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.2245 - reconstruction_loss: 2617.3679 - kl_loss: 61.3495 - false_loss: 19.8448 - true_loss: 3.3982 - val_loss: 3045.9697 - val_reconstruction_loss: 2675.4177 - val_kl_loss: 66.3608 - val_false_loss: 17.9220 - val_true_loss: 3.3664\n",
      "Epoch 487/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2958.4770 - reconstruction_loss: 2618.8738 - kl_loss: 61.0624 - false_loss: 19.8482 - true_loss: 3.3972 - val_loss: 3045.7773 - val_reconstruction_loss: 2675.2922 - val_kl_loss: 66.3521 - val_false_loss: 17.9264 - val_true_loss: 3.3655\n",
      "Epoch 488/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2960.1362 - reconstruction_loss: 2616.7844 - kl_loss: 60.9624 - false_loss: 19.8517 - true_loss: 3.3964 - val_loss: 3045.5862 - val_reconstruction_loss: 2675.1680 - val_kl_loss: 66.3413 - val_false_loss: 17.9299 - val_true_loss: 3.3646\n",
      "Epoch 489/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2961.9724 - reconstruction_loss: 2616.7239 - kl_loss: 61.1450 - false_loss: 19.8552 - true_loss: 3.3954 - val_loss: 3045.3931 - val_reconstruction_loss: 2675.0430 - val_kl_loss: 66.3326 - val_false_loss: 17.9339 - val_true_loss: 3.3636\n",
      "Epoch 490/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2959.8940 - reconstruction_loss: 2617.1426 - kl_loss: 61.2277 - false_loss: 19.8584 - true_loss: 3.3945 - val_loss: 3045.2026 - val_reconstruction_loss: 2674.9172 - val_kl_loss: 66.3284 - val_false_loss: 17.9397 - val_true_loss: 3.3625\n",
      "Epoch 491/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2953.9691 - reconstruction_loss: 2617.1694 - kl_loss: 61.1037 - false_loss: 19.8618 - true_loss: 3.3935 - val_loss: 3045.0127 - val_reconstruction_loss: 2674.7937 - val_kl_loss: 66.3227 - val_false_loss: 17.9447 - val_true_loss: 3.3614\n",
      "Epoch 492/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2959.8235 - reconstruction_loss: 2617.9707 - kl_loss: 61.5049 - false_loss: 19.8650 - true_loss: 3.3926 - val_loss: 3044.8242 - val_reconstruction_loss: 2674.6704 - val_kl_loss: 66.3138 - val_false_loss: 17.9486 - val_true_loss: 3.3605\n",
      "Epoch 493/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2955.2807 - reconstruction_loss: 2616.7874 - kl_loss: 61.1896 - false_loss: 19.8684 - true_loss: 3.3917 - val_loss: 3044.6350 - val_reconstruction_loss: 2674.5459 - val_kl_loss: 66.3043 - val_false_loss: 17.9523 - val_true_loss: 3.3596\n",
      "Epoch 494/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2957.6344 - reconstruction_loss: 2616.7798 - kl_loss: 61.1248 - false_loss: 19.8718 - true_loss: 3.3908 - val_loss: 3044.4453 - val_reconstruction_loss: 2674.4219 - val_kl_loss: 66.2984 - val_false_loss: 17.9569 - val_true_loss: 3.3586\n",
      "Epoch 495/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 1s/step - loss: 2963.8191 - reconstruction_loss: 2619.3774 - kl_loss: 60.9302 - false_loss: 19.8750 - true_loss: 3.3899 - val_loss: 3044.2605 - val_reconstruction_loss: 2674.3003 - val_kl_loss: 66.2885 - val_false_loss: 17.9609 - val_true_loss: 3.3577\n",
      "Epoch 496/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2958.8687 - reconstruction_loss: 2616.5325 - kl_loss: 61.3267 - false_loss: 19.8785 - true_loss: 3.3890 - val_loss: 3044.0725 - val_reconstruction_loss: 2674.1770 - val_kl_loss: 66.2764 - val_false_loss: 17.9636 - val_true_loss: 3.3569\n",
      "Epoch 497/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2960.0058 - reconstruction_loss: 2616.5164 - kl_loss: 61.2015 - false_loss: 19.8818 - true_loss: 3.3881 - val_loss: 3043.8857 - val_reconstruction_loss: 2674.0554 - val_kl_loss: 66.2681 - val_false_loss: 17.9674 - val_true_loss: 3.3560\n",
      "Epoch 498/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.7468 - reconstruction_loss: 2618.0820 - kl_loss: 61.1490 - false_loss: 19.8850 - true_loss: 3.3872 - val_loss: 3043.7004 - val_reconstruction_loss: 2673.9336 - val_kl_loss: 66.2576 - val_false_loss: 17.9707 - val_true_loss: 3.3552\n",
      "Epoch 499/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.1752 - reconstruction_loss: 2616.6077 - kl_loss: 61.1553 - false_loss: 19.8881 - true_loss: 3.3863 - val_loss: 3043.5208 - val_reconstruction_loss: 2673.8181 - val_kl_loss: 66.2494 - val_false_loss: 17.9746 - val_true_loss: 3.3542\n",
      "Epoch 500/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2962.3997 - reconstruction_loss: 2617.5066 - kl_loss: 61.0759 - false_loss: 19.8912 - true_loss: 3.3854 - val_loss: 3043.3367 - val_reconstruction_loss: 2673.6985 - val_kl_loss: 66.2410 - val_false_loss: 17.9785 - val_true_loss: 3.3533\n",
      "Epoch 501/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2954.5985 - reconstruction_loss: 2617.0564 - kl_loss: 61.5021 - false_loss: 19.8945 - true_loss: 3.3845 - val_loss: 3043.1572 - val_reconstruction_loss: 2673.5818 - val_kl_loss: 66.2313 - val_false_loss: 17.9817 - val_true_loss: 3.3525\n",
      "Epoch 502/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2960.3254 - reconstruction_loss: 2617.8088 - kl_loss: 61.1901 - false_loss: 19.8980 - true_loss: 3.3836 - val_loss: 3042.9744 - val_reconstruction_loss: 2673.4626 - val_kl_loss: 66.2226 - val_false_loss: 17.9857 - val_true_loss: 3.3516\n",
      "Epoch 503/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2960.8919 - reconstruction_loss: 2616.6494 - kl_loss: 60.9530 - false_loss: 19.9007 - true_loss: 3.3827 - val_loss: 3042.7925 - val_reconstruction_loss: 2673.3440 - val_kl_loss: 66.2155 - val_false_loss: 17.9898 - val_true_loss: 3.3506\n",
      "Epoch 504/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2961.3779 - reconstruction_loss: 2616.7056 - kl_loss: 61.2613 - false_loss: 19.9038 - true_loss: 3.3818 - val_loss: 3042.6099 - val_reconstruction_loss: 2673.2246 - val_kl_loss: 66.2071 - val_false_loss: 17.9936 - val_true_loss: 3.3497\n",
      "Epoch 505/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2956.6030 - reconstruction_loss: 2616.8342 - kl_loss: 61.3384 - false_loss: 19.9070 - true_loss: 3.3809 - val_loss: 3042.4312 - val_reconstruction_loss: 2673.1086 - val_kl_loss: 66.1963 - val_false_loss: 17.9964 - val_true_loss: 3.3490\n",
      "Epoch 506/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2956.2147 - reconstruction_loss: 2618.3755 - kl_loss: 61.0048 - false_loss: 19.9100 - true_loss: 3.3800 - val_loss: 3042.2593 - val_reconstruction_loss: 2672.9932 - val_kl_loss: 66.1860 - val_false_loss: 18.0003 - val_true_loss: 3.3482\n",
      "Epoch 507/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2960.3085 - reconstruction_loss: 2617.2905 - kl_loss: 60.9514 - false_loss: 19.9133 - true_loss: 3.3793 - val_loss: 3042.0803 - val_reconstruction_loss: 2672.8755 - val_kl_loss: 66.1774 - val_false_loss: 18.0040 - val_true_loss: 3.3474\n",
      "Epoch 508/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2957.3988 - reconstruction_loss: 2616.4927 - kl_loss: 61.0486 - false_loss: 19.9162 - true_loss: 3.3784 - val_loss: 3041.9036 - val_reconstruction_loss: 2672.7595 - val_kl_loss: 66.1724 - val_false_loss: 18.0088 - val_true_loss: 3.3464\n",
      "Epoch 509/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2963.8827 - reconstruction_loss: 2616.4141 - kl_loss: 61.4401 - false_loss: 19.9196 - true_loss: 3.3776 - val_loss: 3041.7302 - val_reconstruction_loss: 2672.6482 - val_kl_loss: 66.1664 - val_false_loss: 18.0131 - val_true_loss: 3.3454\n",
      "Epoch 510/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2961.2792 - reconstruction_loss: 2619.2856 - kl_loss: 61.0856 - false_loss: 19.9225 - true_loss: 3.3768 - val_loss: 3041.5530 - val_reconstruction_loss: 2672.5325 - val_kl_loss: 66.1581 - val_false_loss: 18.0167 - val_true_loss: 3.3445\n",
      "Epoch 511/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2955.6176 - reconstruction_loss: 2616.5867 - kl_loss: 61.0142 - false_loss: 19.9257 - true_loss: 3.3759 - val_loss: 3041.3784 - val_reconstruction_loss: 2672.4197 - val_kl_loss: 66.1518 - val_false_loss: 18.0210 - val_true_loss: 3.3436\n",
      "Epoch 512/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.4935 - reconstruction_loss: 2616.3074 - kl_loss: 61.5629 - false_loss: 19.9287 - true_loss: 3.3751 - val_loss: 3041.2136 - val_reconstruction_loss: 2672.3164 - val_kl_loss: 66.1430 - val_false_loss: 18.0243 - val_true_loss: 3.3427\n",
      "Epoch 513/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2965.5693 - reconstruction_loss: 2620.3765 - kl_loss: 60.4929 - false_loss: 19.9317 - true_loss: 3.3742 - val_loss: 3041.0391 - val_reconstruction_loss: 2672.2014 - val_kl_loss: 66.1386 - val_false_loss: 18.0294 - val_true_loss: 3.3417\n",
      "Epoch 514/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2954.4061 - reconstruction_loss: 2616.2957 - kl_loss: 60.9167 - false_loss: 19.9348 - true_loss: 3.3734 - val_loss: 3040.8643 - val_reconstruction_loss: 2672.0869 - val_kl_loss: 66.1349 - val_false_loss: 18.0345 - val_true_loss: 3.3407\n",
      "Epoch 515/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.8498 - reconstruction_loss: 2616.4634 - kl_loss: 61.2492 - false_loss: 19.9380 - true_loss: 3.3725 - val_loss: 3040.6914 - val_reconstruction_loss: 2671.9751 - val_kl_loss: 66.1276 - val_false_loss: 18.0382 - val_true_loss: 3.3398\n",
      "Epoch 516/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2958.4822 - reconstruction_loss: 2617.1194 - kl_loss: 61.0385 - false_loss: 19.9410 - true_loss: 3.3717 - val_loss: 3040.5178 - val_reconstruction_loss: 2671.8611 - val_kl_loss: 66.1187 - val_false_loss: 18.0415 - val_true_loss: 3.3389\n",
      "Epoch 517/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2960.8882 - reconstruction_loss: 2618.2466 - kl_loss: 61.0979 - false_loss: 19.9440 - true_loss: 3.3708 - val_loss: 3040.3474 - val_reconstruction_loss: 2671.7502 - val_kl_loss: 66.1104 - val_false_loss: 18.0452 - val_true_loss: 3.3381\n",
      "Epoch 518/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2958.1644 - reconstruction_loss: 2616.6731 - kl_loss: 60.8227 - false_loss: 19.9467 - true_loss: 3.3700 - val_loss: 3040.1816 - val_reconstruction_loss: 2671.6379 - val_kl_loss: 66.1007 - val_false_loss: 18.0482 - val_true_loss: 3.3374\n",
      "Epoch 519/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2963.9661 - reconstruction_loss: 2617.4626 - kl_loss: 60.9914 - false_loss: 19.9494 - true_loss: 3.3693 - val_loss: 3040.0112 - val_reconstruction_loss: 2671.5269 - val_kl_loss: 66.0934 - val_false_loss: 18.0519 - val_true_loss: 3.3366\n",
      "Epoch 520/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2960.4248 - reconstruction_loss: 2616.4001 - kl_loss: 61.5341 - false_loss: 19.9526 - true_loss: 3.3684 - val_loss: 3039.8413 - val_reconstruction_loss: 2671.4148 - val_kl_loss: 66.0851 - val_false_loss: 18.0552 - val_true_loss: 3.3358\n",
      "Epoch 521/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 40s 1s/step - loss: 2963.3369 - reconstruction_loss: 2619.4536 - kl_loss: 60.7350 - false_loss: 19.9555 - true_loss: 3.3676 - val_loss: 3039.6741 - val_reconstruction_loss: 2671.3059 - val_kl_loss: 66.0769 - val_false_loss: 18.0591 - val_true_loss: 3.3349\n",
      "Epoch 522/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2956.3918 - reconstruction_loss: 2616.3186 - kl_loss: 60.9487 - false_loss: 19.9584 - true_loss: 3.3668 - val_loss: 3039.5066 - val_reconstruction_loss: 2671.1968 - val_kl_loss: 66.0715 - val_false_loss: 18.0634 - val_true_loss: 3.3340\n",
      "Epoch 523/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2961.6367 - reconstruction_loss: 2616.9956 - kl_loss: 61.2498 - false_loss: 19.9613 - true_loss: 3.3660 - val_loss: 3039.3372 - val_reconstruction_loss: 2671.0854 - val_kl_loss: 66.0640 - val_false_loss: 18.0669 - val_true_loss: 3.3332\n",
      "Epoch 524/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2960.6533 - reconstruction_loss: 2616.5264 - kl_loss: 61.1780 - false_loss: 19.9644 - true_loss: 3.3652 - val_loss: 3039.1736 - val_reconstruction_loss: 2670.9807 - val_kl_loss: 66.0568 - val_false_loss: 18.0705 - val_true_loss: 3.3323\n",
      "Epoch 525/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2959.3548 - reconstruction_loss: 2616.8679 - kl_loss: 60.9614 - false_loss: 19.9671 - true_loss: 3.3644 - val_loss: 3039.0049 - val_reconstruction_loss: 2670.8701 - val_kl_loss: 66.0512 - val_false_loss: 18.0746 - val_true_loss: 3.3314\n",
      "Epoch 526/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2953.9238 - reconstruction_loss: 2616.2339 - kl_loss: 61.3504 - false_loss: 19.9698 - true_loss: 3.3635 - val_loss: 3038.8372 - val_reconstruction_loss: 2670.7600 - val_kl_loss: 66.0443 - val_false_loss: 18.0784 - val_true_loss: 3.3305\n",
      "Epoch 527/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2956.0043 - reconstruction_loss: 2617.4812 - kl_loss: 61.4805 - false_loss: 19.9728 - true_loss: 3.3627 - val_loss: 3038.6736 - val_reconstruction_loss: 2670.6541 - val_kl_loss: 66.0367 - val_false_loss: 18.0818 - val_true_loss: 3.3297\n",
      "Epoch 528/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2961.8739 - reconstruction_loss: 2617.3972 - kl_loss: 60.9134 - false_loss: 19.9757 - true_loss: 3.3619 - val_loss: 3038.5081 - val_reconstruction_loss: 2670.5449 - val_kl_loss: 66.0321 - val_false_loss: 18.0863 - val_true_loss: 3.3288\n",
      "Epoch 529/800\n",
      "40/40 [==============================] - 40s 1s/step - loss: 2955.7007 - reconstruction_loss: 2615.8755 - kl_loss: 61.2143 - false_loss: 19.9785 - true_loss: 3.3611 - val_loss: 3038.3418 - val_reconstruction_loss: 2670.4358 - val_kl_loss: 66.0279 - val_false_loss: 18.0907 - val_true_loss: 3.3278\n",
      "Epoch 530/800\n",
      "40/40 [==============================] - 41s 1s/step - loss: 2953.9610 - reconstruction_loss: 2620.2905 - kl_loss: 61.0205 - false_loss: 19.9814 - true_loss: 3.3603 - val_loss: 3038.1797 - val_reconstruction_loss: 2670.3298 - val_kl_loss: 66.0167 - val_false_loss: 18.0937 - val_true_loss: 3.3272\n",
      "Epoch 531/800\n",
      " 8/40 [=====>........................] - ETA: 31s - loss: 2962.2405 - reconstruction_loss: 2620.3701 - kl_loss: 60.2760 - false_loss: 19.9830 - true_loss: 3.3599"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"vae_best_model.hdf5\",\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=False,\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit(x = [data,true_data,false_data ],y= data[:,:,:,:], epochs=800, batch_size=3000, \n",
    "          validation_data=([data_test,true_data_test,false_data_test ], data_test),validation_batch_size=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.save(\"VAE-ENCODERvmini_59_double.h5\")\n",
    "# model.decoder.save(\"VAE-DECODERv14.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random \n",
    "for i in range(10):\n",
    "    index = int(random.random()*1000)\n",
    "    plot_data = data[index:index+1,:,:]\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.xlabel(\"Fchans\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.imshow(plot_data[0,:,:,0], interpolation='nearest', cmap=plt.get_cmap('hot'))\n",
    "    plt.show()\n",
    "  \n",
    "    stuff = model.encoder.predict(plot_data)\n",
    "    sample = sample_creation(stuff)\n",
    "    reconstruction = model.decoder.predict(sample)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(\"reconstruction\")\n",
    "    plt.xlabel(\"Fchans\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.imshow(reconstruction[0,:,:,0], interpolation='nearest', cmap=plt.get_cmap('hot'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
