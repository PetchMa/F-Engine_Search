{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pma/.local/lib/python3.6/site-packages/numba/core/decorators.py:255: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n",
      "/home/pma/.local/lib/python3.6/site-packages/numba/core/decorators.py:255: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, prange, njit\n",
    "from blimpy import Waterfall\n",
    "import time\n",
    "import random\n",
    "from synthetic_real_dynamic import create_true, create_full_cadence, create_false, create_true_single_shot, create_true_faster\n",
    "import math\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.insert(1, '../ML_Training')\n",
    "sys.path.insert(2, '../GBT_pipeline')\n",
    "from preprocess_dynamic import get_data\n",
    "from single_search import search_model_eval, combine\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import gc\n",
    "from data_generation import create_data_set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[1],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[2],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[3],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 2000\n",
    "plate_train = np.load('../../../../../../../datax/scratch/pma/real_filtered_LARGE_HIP110750.npy')[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6567, 6, 16, 4096)\n",
      "Creating True\n",
      "(2000, 6, 16, 4096)\n",
      "(2000, 6, 16, 4096) (2000, 6, 16, 512)\n",
      "(2000, 6, 16, 512)\n",
      "(12000, 16, 512, 1)\n",
      "Creating False\n",
      "(12000, 6, 16, 4096) (12000, 6, 16, 512)\n",
      "(12000, 6, 16, 512)\n",
      "Creating True\n",
      "(6000, 6, 16, 4096) (6000, 6, 16, 512)\n",
      "(6000, 6, 16, 512)\n",
      "(6000, 6, 16, 4096) (6000, 6, 16, 512)\n",
      "(6000, 6, 16, 512)\n",
      "(12000, 6, 16, 512, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(plate_train.shape)\n",
    "data, false_data_train, true_data_train = create_data_set(plate_train, NUM_SAMPLES=NUM_SAMPLES, snr_base=20, snr_range = 50, factor=1)\n",
    "del plate_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 500\n",
    "plate_test = np.load('../../../../../../../datax/scratch/pma/real_filtered_LARGE_test_HIP15638.npy')[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6567, 6, 16, 4096)\n",
      "Creating True\n",
      "(500, 6, 16, 4096)\n",
      "(500, 6, 16, 4096) (500, 6, 16, 512)\n",
      "(500, 6, 16, 512)\n",
      "(3000, 16, 512, 1)\n",
      "Creating False\n",
      "(3000, 6, 16, 4096) (3000, 6, 16, 512)\n",
      "(3000, 6, 16, 512)\n",
      "Creating True\n",
      "(1500, 6, 16, 4096) (1500, 6, 16, 512)\n",
      "(1500, 6, 16, 512)\n",
      "(1500, 6, 16, 4096) (1500, 6, 16, 512)\n",
      "(1500, 6, 16, 512)\n",
      "(3000, 6, 16, 512, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(plate_test.shape)\n",
    "NUM_SAMPLES = 500\n",
    "data, false_data_test, true_data_test = create_data_set(plate_test, NUM_SAMPLES=NUM_SAMPLES, snr_base=20, snr_range = 10, factor=1)\n",
    "del plate_test, data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(data):\n",
    "    new_data = np.zeros((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],data.shape[4]))\n",
    "    for i in prange(data.shape[0]):\n",
    "        new_data[i*data.shape[1] : (i+1)*data.shape[1],:,:,:] = data[i,:,:,:,:]\n",
    "    return new_data\n",
    "\n",
    "def model_compute(data, model):\n",
    "    print(\"combine\")\n",
    "    data = combine(data)\n",
    "    result= model.predict(data, batch_size=500)[2]\n",
    "    print(\"recombine\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "tensorflow      INFO     Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "tensorflow      WARNING  No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "combine\n",
      "recombine\n",
      "combine\n",
      "recombine\n"
     ]
    }
   ],
   "source": [
    "from execute_model import model_load\n",
    "model = model_load(\"../test_bench/VAE-BLPC1-ENCODER_compressed_512v3-10.h5\")\n",
    "\n",
    "true_train = model_compute(true_data_train, model)\n",
    "false_train =model_compute(false_data_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(true_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 48)\n"
     ]
    }
   ],
   "source": [
    "def recombine(data):\n",
    "    result = []\n",
    "    for k in range(data.shape[0]//6):\n",
    "        result.append(data[k*6:(k+1)*6,:].ravel())\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "true_train = recombine(true_train)\n",
    "false_train = recombine(false_train)\n",
    "print(true_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine\n",
      "recombine\n",
      "combine\n",
      "recombine\n",
      "(3000, 48)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "true_test = model_compute(true_data_test, model)\n",
    "false_test =model_compute(false_data_test, model)\n",
    "true_test = recombine(true_test)\n",
    "false_test = recombine(false_test)\n",
    "print(true_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 48)\n",
      "(24000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = np.concatenate((true_train,false_train))\n",
    "print(train.shape)\n",
    "true_labels = np.zeros((true_train.shape[0]))\n",
    "true_labels[:]=1\n",
    "\n",
    "false_labels = np.zeros((false_train.shape[0]))\n",
    "false_labels[:]=0\n",
    "labels = np.concatenate((true_labels,false_labels))\n",
    "print(labels.shape)\n",
    "train, labels = shuffle(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 48)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "test = np.concatenate((true_test,false_test))\n",
    "print(test.shape)\n",
    "true_test_labels = np.ones((true_test.shape[0]))\n",
    "\n",
    "false_test_labels = np.zeros((false_test.shape[0]))\n",
    "test_labels = np.concatenate((true_test_labels,false_test_labels))\n",
    "print(test_labels.shape)\n",
    "test, test_labels = shuffle(test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', n_estimators=10000, n_jobs=-1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model with 100 trees\n",
    "tree = RandomForestClassifier(n_estimators=10000, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt',n_jobs=-1)\n",
    "# Fit on training data\n",
    "tree.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual class predictions\n",
    "rf_predictions = tree.predict(test)\n",
    "# Probabilities for each class\n",
    "rf_probs = tree.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956885555555557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(test_labels, rf_probs)\n",
    "print(roc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49333333333333335\n"
     ]
    }
   ],
   "source": [
    "# Actual class predictions\n",
    "rf_predictions_true = tree.predict(true_test)\n",
    "# Probabilities for each class\n",
    "count = 0\n",
    "for i in range(rf_predictions_true.shape[0]):\n",
    "#     if rf_predictions_true[i]==test_labels[i]:\n",
    "    count+=1\n",
    "print(count/true_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766666666666667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score( test_labels,tree.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9643333333333333\n"
     ]
    }
   ],
   "source": [
    "rf_probs = clf.predict(test)\n",
    "\n",
    "roc_value = roc_auc_score(test_labels, rf_probs)\n",
    "print(roc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train, labels)\n",
    "\n",
    "clf.score(test, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
